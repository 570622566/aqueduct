{
    "docs": [
        {
            "location": "/", 
            "text": "Aqueduct\n\n\nAqueduct is an HTTP web server framework for building REST applications written in Dart.\n\n\nHow to Use this Documentation\n\n\nThe menu on the left contains a hierarchy documents. Those documents - and how you should use them - are described in the following table:\n\n\n\n\n\n\n\n\nLocation\n\n\nDescription\n\n\nRecommended Usage\n\n\n\n\n\n\n\n\n\n\nTop-Level (e.g. Tour, Core Concepts)\n\n\nIntroductory and quick reference documents\n\n\nRead these documents when you are new to Aqueduct\n\n\n\n\n\n\nSnippets\n\n\nExample code snippets of common behaviors\n\n\nRead these documents for examples and inspiration\n\n\n\n\n\n\nTutorial\n\n\nA linear, guided tutorial to building your first application\n\n\nA 1-3 hour long tutorial to learn Aqueduct\n\n\n\n\n\n\nGuides\n\n\nA hierarchy of in-depth guides for the many facets of Aqueduct\n\n\nRefer to these documents often to understand concepts and usage of Aqueduct\n\n\n\n\n\n\n\n\nIn addition to these guides, be sure to use the \nAPI Reference\n to look up classes, methods, functions and other elements of the framework.\n\n\nGetting Started Tips\n\n\nThe best way to get started is to read the \nCore Concepts guide\n while working through the \ntutorial\n. Then, add new features to the application created during the tutorial by looking up the classes you are using in the \nAPI Reference\n, and implementing behavior not found in the tutorial. It's a good idea to install a tool like \nDash\n for viewing the API Reference.\n\n\nOnce you have the basic concepts down, start reading the guides in the left hand menu to take advantage of the many features of the framework. Check out the repository of examples \nhere\n.\n\n\nImport \nthis file\n into IntelliJ IDEA for Aqueduct file and code templates.\n\n\nAqueduct is catered towards test-driven development - the best way to write an application is to write tests using a \ntest harness\n and run those tests after implementing an endpoint. You may also run the command \naqueduct document client\n in your project directory to generate a web client for your application. This client can be opened in any browser and will execute requests against your locally running application.", 
            "title": "Home"
        }, 
        {
            "location": "/#aqueduct", 
            "text": "Aqueduct is an HTTP web server framework for building REST applications written in Dart.", 
            "title": "Aqueduct"
        }, 
        {
            "location": "/#how-to-use-this-documentation", 
            "text": "The menu on the left contains a hierarchy documents. Those documents - and how you should use them - are described in the following table:     Location  Description  Recommended Usage      Top-Level (e.g. Tour, Core Concepts)  Introductory and quick reference documents  Read these documents when you are new to Aqueduct    Snippets  Example code snippets of common behaviors  Read these documents for examples and inspiration    Tutorial  A linear, guided tutorial to building your first application  A 1-3 hour long tutorial to learn Aqueduct    Guides  A hierarchy of in-depth guides for the many facets of Aqueduct  Refer to these documents often to understand concepts and usage of Aqueduct     In addition to these guides, be sure to use the  API Reference  to look up classes, methods, functions and other elements of the framework.", 
            "title": "How to Use this Documentation"
        }, 
        {
            "location": "/#getting-started-tips", 
            "text": "The best way to get started is to read the  Core Concepts guide  while working through the  tutorial . Then, add new features to the application created during the tutorial by looking up the classes you are using in the  API Reference , and implementing behavior not found in the tutorial. It's a good idea to install a tool like  Dash  for viewing the API Reference.  Once you have the basic concepts down, start reading the guides in the left hand menu to take advantage of the many features of the framework. Check out the repository of examples  here .  Import  this file  into IntelliJ IDEA for Aqueduct file and code templates.  Aqueduct is catered towards test-driven development - the best way to write an application is to write tests using a  test harness  and run those tests after implementing an endpoint. You may also run the command  aqueduct document client  in your project directory to generate a web client for your application. This client can be opened in any browser and will execute requests against your locally running application.", 
            "title": "Getting Started Tips"
        }, 
        {
            "location": "/core_concepts/", 
            "text": "Resources\n\n\nResources are the things your application exposes through its HTTP API. A resource can be anything - a user profile in an application, a temperature sensor in Antarctica, or a high score for a game. For example, the GitHub API exposes organization, repository, issue and pull request resources; a social network API has profiles, posts, and user relationships.\n\n\nResources are organized into collections (e.g., all of the posts), for which individual resources within that collection can be uniquely identified (e.g., a single post). Requests are made to an application to retrieve the state of a resource or to provide the desired state of a resource. Most often, resources are represented as JSON arrays and objects. When retrieving a resource, its JSON representation is encoded into the response body. When providing the desired state of a resource, a client sends the JSON representation of the desired resource state in the request body.\n\n\nFor more details on the concept of a resource, see the \nRFC Specification for HTTP/1.1\n.\n\n\nRouting\n\n\nResources are identified by the path of an HTTP request. For example, the URL \nhttp://example.com/organizations\n identifies the collection of organization resources on the server \nhttp://example.com\n. The URL \nhttp://example.com/organizations/1\n identifies a single organization.\n\n\nAn application exposes \nroutes\n for each resource it manages. A route is a string that matches the path of a request. When a request's path matches a route, the associated handler is invoked to handle the request. Routes look like paths, but have some additional syntax. For example, the route \n/organizations\n will match requests with the path \n/organizations\n. The route \n/organizations/:id\n will match the paths \n/organizations/1\n, \n/organizations/2\n, and so on.\n\n\nComplex routes can be formed with additional syntax. See the guide on \nrouting\n for usage details.\n\n\nControllers\n\n\nControllers are objects that handle requests. For example, a controller might fetch rows from a database and send them to the client in the response body. Another controller might verify the username and password of a request's Authorization header are valid.\n\n\nControllers are linked together to form a series of actions to take for a request. These linked together controllers are called a \nchannel\n. If the above examples were linked together, the channel would check if a request were authorized before it sent a response containing database rows.\n\n\nThere are two flavors of controllers. An \nendpoint controller\n performs operations on a resource or resource collection, and always sends a response. Endpoint controllers \nfulfill\n requests by returning the state of a resource or by changing the state of a resource. You write most of your application-specific logic endpoint controllers.\n\n\nA \nmiddleware controller\n takes an action for a request, but isn't responsible for fulfilling the request. Middleware controllers can do many different things and are often reusable in many channels. Most often, a middleware controller validates something about a request before it reaches an endpoint controller. Middleware controllers can send a response for a request, and doing so prevents any other controller in that channel from handling the request.\n\n\nA channel must have exactly one endpoint controller. It can be preceded by zero or more middleware controllers. See the guides on \nControllers\n and \nResourceControllers\n for usage details.\n\n\nThe Application Channel\n\n\nThe application channel is an object that contains all of the controllers in an application. It designates one controller as the first controller to receive every request called its \nentry point\n. Controllers are linked to the entry point (directly or transitively) to form the entire application channel. In nearly every application, the entry point is a router; this controller splits the channel into sub-channels for a given route.\n\n\nThe application channel is also responsible for initializing the application's services, reading configuration files and other startup related tasks. See the guide on the \nApplication Channel\n for more details.\n\n\nServices\n\n\nA service is an object that encapsulates complex tasks or algorithms, external communication or tasks that will be reused across an application. The purpose of a service object is to provide a simple interface to more detailed behavior. For example, a database connection is a service object; a user of a database connection doesn't know the details of how the connection is made or how to encode the query onto the wire, but it can still execute queries.\n\n\nThe primary user of service objects are controllers. Services are injected into controllers by passing them as arguments to the controller's constructor. The controller keeps a reference to the service, so that it can use it when handling a request.\n\n\nFor more details on injecting services, see the guide on the \nApplication Channel\n.\n\n\nIsolates\n\n\nIsolates are memory-isolated threads; an object created on one isolate can't be referenced by another isolate. When an application starts, one or more isolates containing replicas of your application code are spawned. This behavior effectively 'load balances' your application across multiple threads.\n\n\nA benefit to this structure is that each isolate has its own set of services, like database connections. This eliminates the need for techniques like 'database connection pooling', because the entire application is effectively 'pooled'.\n\n\nBindings\n\n\nA request might contain headers, query parameters, a body and path parameters that need to be parsed, validated and used in controller code. Bindings are annotations added to variables that perform this parsing and validation automatically. Appropriate error responses are sent when a bound value can't be parsed into expected type or validation fails.\n\n\nBindings cut down on boiler plate code and reduce testing surface, making development faster and code easier to reason about. For more information on bindings, see the guide on \nResource Controllers\n.\n\n\nQueries and Data Models\n\n\nApplication store information in databases for persistence. Writing database queries by hand is error-prone and doesn't leverage static analysis tools that are so valuable in a Dart application. Aqueduct's ORM (Object-Relational Mapping) provides statically-typed queries that are easy to write and test.\n\n\nYour application's data model is defined by creating Dart classes. Each class is mapped to a database table, and each property of that class is mapped to a column in that table. Aqueduct's command-line tool generates database migration files that detect changes in your data model that can be applied to a live, versioned database. A data model can also be represented as a JSON object to build tools on top of your application.\n\n\nFor more details, see the guide on \nAuthorization\n.\n\n\nAuthorization\n\n\nOAuth 2.0 is a standardized authorization framework. Aqueduct contains a specification-compliant implementation of an OAuth 2.0 server that can be integrated directly into your application, or stood up alone to provide an authorization server for federated services. This implementation is easily customizable - it can store authorization artifacts - like tokens and client identifiers - in different types of databases or use stateless authorization mechanisms like JWT. The default implementation leverages the Aqueduct ORM to store artifacts in PostgreSQL.\n\n\nFor more details, see the guide on \nDatabases\n.\n\n\nDocumentation\n\n\nOpenAPI 3.0 is a standardized documentation format for HTTP APIs. Many built-in Aqueduct objects support 'automatic' documentation. Objects that are specific to your application can build on top of this to immediately document your application for every change you make.\n\n\nFor more details, see the guide on \nOpenAPI Documentation\n.", 
            "title": "Core Concepts"
        }, 
        {
            "location": "/core_concepts/#resources", 
            "text": "Resources are the things your application exposes through its HTTP API. A resource can be anything - a user profile in an application, a temperature sensor in Antarctica, or a high score for a game. For example, the GitHub API exposes organization, repository, issue and pull request resources; a social network API has profiles, posts, and user relationships.  Resources are organized into collections (e.g., all of the posts), for which individual resources within that collection can be uniquely identified (e.g., a single post). Requests are made to an application to retrieve the state of a resource or to provide the desired state of a resource. Most often, resources are represented as JSON arrays and objects. When retrieving a resource, its JSON representation is encoded into the response body. When providing the desired state of a resource, a client sends the JSON representation of the desired resource state in the request body.  For more details on the concept of a resource, see the  RFC Specification for HTTP/1.1 .", 
            "title": "Resources"
        }, 
        {
            "location": "/core_concepts/#routing", 
            "text": "Resources are identified by the path of an HTTP request. For example, the URL  http://example.com/organizations  identifies the collection of organization resources on the server  http://example.com . The URL  http://example.com/organizations/1  identifies a single organization.  An application exposes  routes  for each resource it manages. A route is a string that matches the path of a request. When a request's path matches a route, the associated handler is invoked to handle the request. Routes look like paths, but have some additional syntax. For example, the route  /organizations  will match requests with the path  /organizations . The route  /organizations/:id  will match the paths  /organizations/1 ,  /organizations/2 , and so on.  Complex routes can be formed with additional syntax. See the guide on  routing  for usage details.", 
            "title": "Routing"
        }, 
        {
            "location": "/core_concepts/#controllers", 
            "text": "Controllers are objects that handle requests. For example, a controller might fetch rows from a database and send them to the client in the response body. Another controller might verify the username and password of a request's Authorization header are valid.  Controllers are linked together to form a series of actions to take for a request. These linked together controllers are called a  channel . If the above examples were linked together, the channel would check if a request were authorized before it sent a response containing database rows.  There are two flavors of controllers. An  endpoint controller  performs operations on a resource or resource collection, and always sends a response. Endpoint controllers  fulfill  requests by returning the state of a resource or by changing the state of a resource. You write most of your application-specific logic endpoint controllers.  A  middleware controller  takes an action for a request, but isn't responsible for fulfilling the request. Middleware controllers can do many different things and are often reusable in many channels. Most often, a middleware controller validates something about a request before it reaches an endpoint controller. Middleware controllers can send a response for a request, and doing so prevents any other controller in that channel from handling the request.  A channel must have exactly one endpoint controller. It can be preceded by zero or more middleware controllers. See the guides on  Controllers  and  ResourceControllers  for usage details.", 
            "title": "Controllers"
        }, 
        {
            "location": "/core_concepts/#the-application-channel", 
            "text": "The application channel is an object that contains all of the controllers in an application. It designates one controller as the first controller to receive every request called its  entry point . Controllers are linked to the entry point (directly or transitively) to form the entire application channel. In nearly every application, the entry point is a router; this controller splits the channel into sub-channels for a given route.  The application channel is also responsible for initializing the application's services, reading configuration files and other startup related tasks. See the guide on the  Application Channel  for more details.", 
            "title": "The Application Channel"
        }, 
        {
            "location": "/core_concepts/#services", 
            "text": "A service is an object that encapsulates complex tasks or algorithms, external communication or tasks that will be reused across an application. The purpose of a service object is to provide a simple interface to more detailed behavior. For example, a database connection is a service object; a user of a database connection doesn't know the details of how the connection is made or how to encode the query onto the wire, but it can still execute queries.  The primary user of service objects are controllers. Services are injected into controllers by passing them as arguments to the controller's constructor. The controller keeps a reference to the service, so that it can use it when handling a request.  For more details on injecting services, see the guide on the  Application Channel .", 
            "title": "Services"
        }, 
        {
            "location": "/core_concepts/#isolates", 
            "text": "Isolates are memory-isolated threads; an object created on one isolate can't be referenced by another isolate. When an application starts, one or more isolates containing replicas of your application code are spawned. This behavior effectively 'load balances' your application across multiple threads.  A benefit to this structure is that each isolate has its own set of services, like database connections. This eliminates the need for techniques like 'database connection pooling', because the entire application is effectively 'pooled'.", 
            "title": "Isolates"
        }, 
        {
            "location": "/core_concepts/#bindings", 
            "text": "A request might contain headers, query parameters, a body and path parameters that need to be parsed, validated and used in controller code. Bindings are annotations added to variables that perform this parsing and validation automatically. Appropriate error responses are sent when a bound value can't be parsed into expected type or validation fails.  Bindings cut down on boiler plate code and reduce testing surface, making development faster and code easier to reason about. For more information on bindings, see the guide on  Resource Controllers .", 
            "title": "Bindings"
        }, 
        {
            "location": "/core_concepts/#queries-and-data-models", 
            "text": "Application store information in databases for persistence. Writing database queries by hand is error-prone and doesn't leverage static analysis tools that are so valuable in a Dart application. Aqueduct's ORM (Object-Relational Mapping) provides statically-typed queries that are easy to write and test.  Your application's data model is defined by creating Dart classes. Each class is mapped to a database table, and each property of that class is mapped to a column in that table. Aqueduct's command-line tool generates database migration files that detect changes in your data model that can be applied to a live, versioned database. A data model can also be represented as a JSON object to build tools on top of your application.  For more details, see the guide on  Authorization .", 
            "title": "Queries and Data Models"
        }, 
        {
            "location": "/core_concepts/#authorization", 
            "text": "OAuth 2.0 is a standardized authorization framework. Aqueduct contains a specification-compliant implementation of an OAuth 2.0 server that can be integrated directly into your application, or stood up alone to provide an authorization server for federated services. This implementation is easily customizable - it can store authorization artifacts - like tokens and client identifiers - in different types of databases or use stateless authorization mechanisms like JWT. The default implementation leverages the Aqueduct ORM to store artifacts in PostgreSQL.  For more details, see the guide on  Databases .", 
            "title": "Authorization"
        }, 
        {
            "location": "/core_concepts/#documentation", 
            "text": "OpenAPI 3.0 is a standardized documentation format for HTTP APIs. Many built-in Aqueduct objects support 'automatic' documentation. Objects that are specific to your application can build on top of this to immediately document your application for every change you make.  For more details, see the guide on  OpenAPI Documentation .", 
            "title": "Documentation"
        }, 
        {
            "location": "/getting_started/", 
            "text": "Getting Started with Aqueduct\n\n\nInstallation\n\n\n\n\nInstall Dart\n.\n\n\n\n\nActivate the Aqueduct CLI\n\n\npub global activate aqueduct\n\n\n\n\n\n\n\n\n\nCreate a new project.\n\n\naqueduct create my_project\n\n\n\n\n\n\n\n\n\nOpen the project directory in an \nIntelliJ IDE\n, \nAtom\n or \nVisual Studio Code\n. All three IDEs have a Dart plugin.\n\n\nHow to Learn Aqueduct\n\n\nThere are different approaches depending on how you prefer to learn.\n\n\n\n\nThe \nguided tutorial\n is a hands-on walkthrough where you build an application while learning basic Aqueduct concepts.\n\n\nThe \nexample repository\n contains a few deployable applications that you may review or tinker with.\n\n\nThe guides (located in the menu on this website) dive deeply into the concepts of Aqueduct and show example code.\n\n\nCreating a new project\n and using the \nAPI reference\n to jump right in.\n\n\n\n\nIt is best to first understand how HTTP requests are responded to - the foundation of Aqueduct - before moving on to topics such as the ORM and OAuth 2.0. Both the tutorial and the \nHTTP guides\n are the primary source of this information. A project created by the \naqueduct\n tool has example routes connected for modification, too.\n\n\nCreating a Project\n\n\nThe \naqueduct create\n command-line tool creates new Aqueduct project directories. The default template contains the minimal project structure for running an Aqueduct application. A project name must be snake_case.\n\n\naqueduct create my_project_name\n\n\n\n\n\nOther templates exist that contain foundational code for using Aqueduct's ORM and OAuth 2.0 implementation. These templates can be listed:\n\n\naqueduct create list-templates\n\n\n\n\n\nYou may provide the name of a template when creating a project to use that template:\n\n\naqueduct create -t db my_project_name\n\n\n\n\n\nUsing the Aqueduct ORM\n\n\nAqueduct's ORM uses PostgreSQL. During development, you will need a locally running instance of PostgreSQL. On macOS, installing  \nPostgres.app\n is a very convenient way to run PostgreSQL locally. For other platforms, see \nPostgreSQL's downloads page\n.\n\n\nWhen creating a project, use the \ndb\n template. If adding to an existing project, see \nthis guide\n.\n\n\nTo create a database, make sure PostgreSQL is running and open the command-line utility to connect to it.\n\n\npsql\n\n\n\n\n\n\n\nLocation of psql with Postgres.app\n\n\nIf you installed Postgres.app, \npsql\n is inside the application bundle. You can run this tool by selecting \nOpen psql\n from the status bar item in the Finder.\n\n\n\n\nThen, create a database that your application will connect to and a user that it will connect with:\n\n\nCREATE\n \nDATABASE\n \nmy_database_name\n;\n\n\nCREATE\n \nUSER\n \ndart_app\n \nWITH\n \nPASSWORD\n \ndart\n;\n\n\nGRANT\n \nALL\n \nON\n \nDATABASE\n \nmy_database_name\n \nTO\n \ndart_app\n;\n\n\n\n\n\n\nAn application must create a \nManagedContext\n that handles the connection to this database:\n\n\nclass\n \nMyChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \nManagedContext\n \ncontext\n;\n\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \nvar\n \ndataModel\n \n=\n \nnew\n \nManagedDataModel\n.\nfromCurrentMirrorSystem\n();\n\n    \nvar\n \nstore\n \n=\n \nnew\n \nPostgreSQLPersistentStore\n.\nfromConnectionInfo\n(\n\n      \ndart_app\n,\n \ndart\n,\n \nlocalhost\n,\n \n5432\n,\n \nmy_database_name\n);\n\n    \ncontext\n \n=\n \nnew\n \nManagedContext\n(\ndataModel\n,\n \nstore\n);\n\n  \n}\n\n\n  \n...\n\n\n}\n\n\n\n\n\n\nOnce you have declared \nManagedObject\ns in your application, generate the database schema by generating and executing migrations from your project's directory:\n\n\naqueduct db generate\naqueduct db upgrade --connect postgres://dart_app:dart@localhost:5432/my_database_name\n\n\n\n\n\nSee the guides on \nconnecting to a database\n and \ntesting with a database\n for more details on configuring a database connection.", 
            "title": "Getting Started"
        }, 
        {
            "location": "/getting_started/#getting-started-with-aqueduct", 
            "text": "", 
            "title": "Getting Started with Aqueduct"
        }, 
        {
            "location": "/getting_started/#installation", 
            "text": "Install Dart .   Activate the Aqueduct CLI  pub global activate aqueduct    Create a new project.  aqueduct create my_project    Open the project directory in an  IntelliJ IDE ,  Atom  or  Visual Studio Code . All three IDEs have a Dart plugin.", 
            "title": "Installation"
        }, 
        {
            "location": "/getting_started/#how-to-learn-aqueduct", 
            "text": "There are different approaches depending on how you prefer to learn.   The  guided tutorial  is a hands-on walkthrough where you build an application while learning basic Aqueduct concepts.  The  example repository  contains a few deployable applications that you may review or tinker with.  The guides (located in the menu on this website) dive deeply into the concepts of Aqueduct and show example code.  Creating a new project  and using the  API reference  to jump right in.   It is best to first understand how HTTP requests are responded to - the foundation of Aqueduct - before moving on to topics such as the ORM and OAuth 2.0. Both the tutorial and the  HTTP guides  are the primary source of this information. A project created by the  aqueduct  tool has example routes connected for modification, too.", 
            "title": "How to Learn Aqueduct"
        }, 
        {
            "location": "/getting_started/#creating-a-project", 
            "text": "The  aqueduct create  command-line tool creates new Aqueduct project directories. The default template contains the minimal project structure for running an Aqueduct application. A project name must be snake_case.  aqueduct create my_project_name  Other templates exist that contain foundational code for using Aqueduct's ORM and OAuth 2.0 implementation. These templates can be listed:  aqueduct create list-templates  You may provide the name of a template when creating a project to use that template:  aqueduct create -t db my_project_name", 
            "title": "Creating a Project"
        }, 
        {
            "location": "/getting_started/#using-the-aqueduct-orm", 
            "text": "Aqueduct's ORM uses PostgreSQL. During development, you will need a locally running instance of PostgreSQL. On macOS, installing   Postgres.app  is a very convenient way to run PostgreSQL locally. For other platforms, see  PostgreSQL's downloads page .  When creating a project, use the  db  template. If adding to an existing project, see  this guide .  To create a database, make sure PostgreSQL is running and open the command-line utility to connect to it.  psql   Location of psql with Postgres.app  If you installed Postgres.app,  psql  is inside the application bundle. You can run this tool by selecting  Open psql  from the status bar item in the Finder.   Then, create a database that your application will connect to and a user that it will connect with:  CREATE   DATABASE   my_database_name ;  CREATE   USER   dart_app   WITH   PASSWORD   dart ;  GRANT   ALL   ON   DATABASE   my_database_name   TO   dart_app ;   An application must create a  ManagedContext  that handles the connection to this database:  class   MyChannel   extends   ApplicationChannel   { \n   ManagedContext   context ; \n\n   @ override \n   Future   prepare ()   async   { \n     var   dataModel   =   new   ManagedDataModel . fromCurrentMirrorSystem (); \n     var   store   =   new   PostgreSQLPersistentStore . fromConnectionInfo ( \n       dart_app ,   dart ,   localhost ,   5432 ,   my_database_name ); \n     context   =   new   ManagedContext ( dataModel ,   store ); \n   } \n\n   ...  }   Once you have declared  ManagedObject s in your application, generate the database schema by generating and executing migrations from your project's directory:  aqueduct db generate\naqueduct db upgrade --connect postgres://dart_app:dart@localhost:5432/my_database_name  See the guides on  connecting to a database  and  testing with a database  for more details on configuring a database connection.", 
            "title": "Using the Aqueduct ORM"
        }, 
        {
            "location": "/tour/", 
            "text": "Aqueduct: A Tour\n\n\nCreate applications with the \naqueduct\n tool:\n\n\naqueduct create my_app\n\n\n\n\n\nRun applications by using the \naqueduct\n tool in a project directory:\n\n\naqueduct serve\n\n\n\n\n\nStructure\n\n\nAn Aqueduct application is a series of controllers that form a \nchannel\n for a request to flow through. Any of those controllers may respond to a request and take it out of the channel. Controllers in the middle of the channel often verify something, while the controller at the end fulfills the request. Fulfillment might mean returning the contents of a file or storing data from the request body in a database.\n\n\nInitialization\n\n\nAn application's channel is created by subclassing \nApplicationChannel\n. This type also performs any other application initialization, like creating database connections and defining how authorization occurs.\n\n\nimport\n \npackage:aqueduct/aqueduct.dart\n;\n\n\n\nclass\n \nAppApplicationChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \ndatabaseContext\n \n=\n \ncontextFrom\n(\noptions\n);\n\n  \n}\n\n\n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nnew\n \nRouter\n();\n\n    \nrouter\n\n      \n.\nroute\n(\n/resource/[:id]\n)\n\n      \n.\nlink\n(()\n \n=\n \nnew\n \nResourceController\n(\ndatabaseContext\n));\n\n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nRouting\n\n\nA \nrouter\n splits a channel into sub-channels based on the path of a request. A request with the path \n/users\n will be handled by a different controller than a request with the path \n/posts\n, for example. Routes are defined by \nroute specification syntax\n. Routes can contain variables and optional segments, enabling routes to be grouped together.\n\n\n@\noverride\n\n\nController\n \nget\n \nentryPoint\n \n{\n\n  \nfinal\n \nrouter\n \n=\n \nnew\n \nRouter\n();\n\n\n  \nrouter\n\n    \n.\nroute\n(\n/users/[:id]\n)\n\n    \n.\nlink\n(()\n \n=\n \nnew\n \nUserController\n());\n\n\n  \nrouter\n\n    \n.\nroute\n(\n/file/*\n)\n\n    \n.\nlink\n(()\n \n=\n \nnew\n \nFileController\n());\n\n\n  \nrouter\n\n    \n.\nroute\n(\n/health\n)\n\n    \n.\nlinkFunction\n((\nreq\n)\n \nasync\n \n=\n \nnew\n \nResponse\n.\nok\n(\nnull\n));\n\n\n  \nreturn\n \nrouter\n;\n\n\n}\n    \n\n\n\n\n\nControllers\n\n\nResourceControllers\n are the controller that most often fulfill a request. An \nResourceController\n subclass handles all operations for resource, e.g. \nPOST /users\n, \nGET /users\n and \nGET /users/1\n.\n\n\nSubclasses implement a \noperation method\n for each operation:\n\n\nimport\n \npackage:aqueduct/aqueduct.dart\n\n\n\nclass\n \nResourceController\n \nextends\n \nResourceController\n \n{\n\n  \n@\nOperation\n.\nget\n()\n\n  \nFuture\nResponse\n \ngetAllResources\n()\n \nasync\n \n{\n\n    \nreturn\n \nnew\n \nResponse\n.\nok\n(\nawait\n \nfetchResources\n())\n;\n\n  \n}\n\n\n  \n@\nOperation\n.\nget\n(\nid\n)\n\n  \nFuture\nResponse\n \ngetResourceByID\n(\n@\nBind\n.\npath\n(\nid\n)\n \nint\n \nid\n)\n \nasync\n \n{\n\n    \nreturn\n \nnew\n \nResponse\n.\nok\n(\nawait\n \nfetchResource\n(\nid\n));\n\n  \n}\n\n\n  \n@\nOperation\n.\npost\n()\n\n  \nFuture\nResponse\n \ncreateResource\n(\n@\nBind\n.\nbody\n()\n \nResource\n \nresource\n)\n \nasync\n \n{\n\n    \nvar\n \ninserted\n \n=\n \nawait\n \ninsertResource\n(\nresource\n);\n\n    \nreturn\n \nnew\n \nResponse\n.\nok\n(\ninserted\n);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nProperties of the request are bound to operation method arguments and controller properties:\n\n\nclass\n \nResourceController\n \nextends\n \nResourceController\n \n{\n\n  \n@\nOperation\n.\nget\n()\n\n  \nFuture\nResponse\n \ngetAllResources\n(\n\n      \n@\nBind\n.\nheader\n(\nx-request-id\n)\n \nString\n \nrequestID\n,\n\n      \n{\n@\nBind\n.\nquery\n(\nlimit\n)\n \nint\n \nlimit\n})\n \nasync\n \n{\n\n    \nreturn\n \nnew\n \nResponse\n.\nok\n(\nawait\n \nfetchResources\n(\nlimit\n \n??\n \n0\n));\n\n  \n}\n\n\n  \n@\nOperation\n.\npost\n()\n\n  \nFuture\nResponse\n \ncreateResource\n(\n@\nBind\n.\nbody\n()\n \nResource\n \nresource\n)\n \nasync\n \n{\n\n    \nvar\n \ninserted\n \n=\n \nawait\n \ninsertResourceIntoDatabase\n(\nresource\n);\n\n    \nreturn\n \nnew\n \nResponse\n.\nok\n(\ninserted\n);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nManagedObjectController\nT\ns are \nResourceController\ns that automatically map a REST interface to database queries:\n\n\nrouter\n\n  \n.\nroute\n(\n/users/[:id]\n)\n\n  \n.\nlink\n(()\n \n=\n \nnew\n \nManagedObjectController\nUser\n(\ncontext\n));\n\n\n\n\n\n\nController\n is the base class for all controllers that form a channel. They only have a single method to handle the request, and must either return the request or a response. When a controller returns a response, the request is taken out of the channel.\n\n\nclass\n \nVerifyingController\n \nextends\n \nController\n \n{\n\n  \n@\noverride\n\n  \nFuture\nRequestOrResponse\n \nhandle\n(\nRequest\n \nrequest\n)\n \nasync\n \n{\n\n    \nif\n \n(\nrequest\n.\nraw\n.\nheaders\n.\nvalue\n(\nx-secret-key\n)\n \n==\n \nsecret!\n)\n \n{\n\n      \nreturn\n \nrequest\n;\n\n    \n}\n\n\n    \nreturn\n \nnew\n \nResponse\n.\nbadRequest\n();\n\n  \n}\n\n\n}\n\n\n\n\n\n\nThis behavior lets a channel prevent invalid requests from being fulfilled, or let's a controller be reused in multiple places to provide some preprocessing step.\n\n\nUncaught exceptions are caught by the controller and translated into an appropriate response, removing the request from the channel. Exceptions should only be caught when another response is desired or when the request should continue to the next controller in the channel.\n\n\nConfiguration\n\n\nRead YAML configuration data into type-safe and name-safe structures at startup:\n\n\n// config.yaml\ndatabase:\n  host: ...\n  port: 5432\n  databaseName: foo\notherOption: hello\nnumberOfDoodads: 3  \n\n\n\n\n\nSubclass \nConfigurationItem\n and declare a property for each key in the configuration file:\n\n\nclass\n \nAppConfig\n \nextends\n \nConfigurationItem\n \n{\n\n  \nAppConfig\n(\nString\n \npath\n)\n \n:\n \nsuper\n.\nfromFile\n(\npath\n);\n\n\n  \nDatabaseConnectionInfo\n \ndatabase\n;\n\n  \nString\n \notherOption\n;\n\n  \nint\n \nnumberOfDoodads\n;\n\n\n}\n\n\n\n\n\n\nRead the configuration file identified by an \nApplicationOptions\n:\n\n\nimport\n \npackage:aqueduct/aqueduct.dart\n;\n\n\n\nclass\n \nAppApplicationChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \nvar\n \noptions\n \n=\n \nnew\n \nAppConfig\n(\noptions\n.\nconfigurationFilePath\n);\n\n    \n...\n\n  \n}\n\n\n}\n\n\n\n\n\n\nRunning and Concurrency\n\n\nAqueduct applications are run with the \naqueduct serve\n command line tool, which can also open debugging and instrumentation tools and specify how many threads the application should run on:\n\n\naqueduct serve --observe --isolates 5\n\n\n\n\n\nRun applications detached or still connected to the shell:\n\n\naqueduct serve --detached --port $PORT\n\n\n\n\n\nAqueduct applications are multi-isolate (multi-threaded). Each isolate runs a replica of the same web server with its own set of services like database connections. This makes behavior like database connection pooling implicit.\n\n\nQuerying a Database\n\n\nDatabase operations are built and executed with instances of \nQuery\nT\n.\n\n\nimport\n \npackage:aqueduct/aqueduct.dart\n\n\n\nclass\n \nResourceController\n \nextends\n \nResourceController\n \n{\n\n  \n@\nOperation\n.\nget\n()\n\n  \nFuture\nResponse\n \ngetAllResources\n()\n \nasync\n \n{\n\n    \nvar\n \nquery\n \n=\n \nnew\n \nQuery\nResource\n(\ncontext\n)\n;\n\n\n    \nvar\n \nresults\n \n=\n \nawait\n \nquery\n.\nfetch\n();\n\n\n    \nreturn\n \nnew\n \nResponse\n.\nok\n(\nresults\n);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nThe results can be filtered by the \nQuery.where\n property, which has the same properties as the object being queried.\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nEmployee\n(\ncontext\n)\n\n  \n..\nwhere\n((\ne\n)\n \n=\n \ne\n.\nname\n).\nstartsWith\n(\nSa\n)\n\n  \n..\nwhere\n((\ne\n)\n \n=\n \ne\n.\nsalary\n).\ngreaterThan\n(\n50000\n);\n\n\nvar\n \nresults\n \n=\n \nawait\n \nquery\n.\nfetch\n();\n\n\n\n\n\n\nValues set on the properties of \nQuery.values\n are sent to the database on insert and update operations. Like \nQuery.where\n, \nQuery.values\n has the same properties as the object being inserted or updated.\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nEmployee\n(\ncontext\n)\n\n  \n..\nvalues\n.\nname\n \n=\n \nBob\n\n  \n..\nvalues\n.\nsalary\n \n=\n \n50000\n;\n\n\n\nvar\n \nbob\n \n=\n \nawait\n \nquery\n.\ninsert\n();\n  \n\n\nvar\n \nupdateQuery\n \n=\n \nnew\n \nQuery\nEmployee\n(\ncontext\n)\n\n  \n..\nwhere\n((\ne\n)\n \n=\n \ne\n.\nid\n).\nequalTo\n(\nbob\n.\nid\n)\n\n  \n..\nvalues\n.\nname\n \n=\n \nBobby\n;\n\n\nbob\n \n=\n \nawait\n \nupdateQuery\n.\nupdateOne\n();\n  \n\n\n\n\n\nQuery\nT\ns can sort and page on a result set. It can also join tables and return objects and their relationships:\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nEmployee\n(\ncontext\n)\n\n  \n..\nwhere\n((\ne\n)\n \n=\n \ne\n.\nname\n).\nequalTo\n(\nSue Gallagher\n)\n\n  \n..\njoin\n(\nobject:\n \n(\ne\n)\n \n=\n \ne\n.\nmanager\n)\n\n  \n..\njoin\n(\nset\n:\n \n(\ne\n)\n \n=\n \ne\n.\ndirectReports\n);\n\n\n\nvar\n \nherAndHerManagerAndHerDirectReports\n \n=\n \nawait\n \nquery\n.\nfetchOne\n();\n\n\n\n\n\n\nExceptions thrown for queries are caught by a controller and translated into the appropriate status code. Unique constraint conflicts return 409,\nmissing required properties return 400 and database connection failure returns 503.\n\n\nDefining a Data Model\n\n\nManagedObject\nT\n instances represent a row in a database; each property is a column in the corresponding table. This class is always subclassed and is in fact made up of two classes:\n\n\nclass\n \nEmployee\n \nextends\n \nManagedObject\n_Employee\n \nimplements\n \n_Employee\n \n{\n\n  \nbool\n \nget\n \nwasRecentlyHired\n \n=\n \nhireDate\n.\ndifference\n(\nnew\n \nDateTime\n.\nnow\n()).\ninDays\n \n \n30\n;\n\n\n}\n\n\nclass\n \n_Employee\n  \n{\n\n  \n@\nprimaryKey\n\n  \nint\n \nindex\n;\n\n\n  \n@\nColumn\n(\nindexed:\n \ntrue\n)\n\n  \nString\n \nname\n;\n\n\n  \nDateTime\n \nhireDate\n;\n\n  \nint\n \nsalary\n;\n\n\n}\n\n\n\n\n\n\nManagedObject\nT\ns have relationship properties for has-one, has-many and many-to-many references to other \nManagedObject\nT\ns. The property with \nRelate\n metadata is a foreign key column.\n\n\nclass\n \nEmployee\n \nextends\n \nManagedObject\n_Employee\n \nimplements\n \n_Employee\n \n{}\n\n\nclass\n \n_Employee\n \n{\n\n  \n...\n\n\n  \nManagedSet\nInitiative\n \ninitiatives\n;\n\n\n}\n\n\n\nclass\n \nInitiative\n \nextends\n \nManagedObject\n_Initiative\n \nimplements\n \n_Initiative\n \n{}\n\n\nclass\n \n_Initiative\n \n{\n\n  \n...\n\n\n  \n@\nRelate\n(\n#\ninitiatives\n)\n\n  \nEmployee\n \nleader\n;\n\n\n}\n\n\n\n\n\n\nManagedObject\nT\ns are easily read from and written to JSON (or any other format):\n\n\nclass\n \nUserController\n \nextends\n \nResourceController\n \n{\n\n  \n@\nOperation\n.\nput\n(\nid\n)\n\n  \nFuture\nResponse\n \nupdateUser\n(\n@\nBind\n.\npath\n(\nid\n)\n \nint\n \nid\n,\n \n@\nBind\n.\nbody\n()\n \nUser\n \nuser\n)\n \nasync\n \n{\n\n    \nvar\n \nquery\n \n=\n \nnew\n \nQuery\nUser\n(\ncontext\n)\n\n      \n..\nwhere\n((\nu\n)\n \n=\n \ne\n.\nid\n).\nequalTo\n(\nid\n)\n\n      \n..\nvalues\n \n=\n \nuser\n;\n\n\n    \nvar\n \nupdatedUser\n \n=\n \nawait\n \nquery\n.\nupdateOne\n();\n\n\n    \nreturn\n \nnew\n \nResponse\n.\nok\n(\nupdatedUser\n);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nAutomatic Database Migration\n\n\nGenerate and run database migrations with the \naqueduct db\n tool:\n\n\naqueduct db generate\naqueduct db validate\naqueduct db upgrade --connect postgres@://...\n\n\n\n\n\nOAuth 2.0\n\n\nAuthentication and authorization are enabled at application startup by creating an \nAuthServer\n with \nManagedAuthDelegate\n:\n\n\nimport\n \npackage:aqueduct/aqueduct.dart\n;\n\n\nimport\n \npackage:aqueduct/managed_auth.dart\n;\n\n\n\nclass\n \nAppApplicationChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \nAuthServer\n \nauthServer\n;\n\n  \nManagedContext\n \ncontext\n;\n\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \ncontext\n \n=\n \nnew\n \nManagedContext\n(...);\n\n\n    \nfinal\n \ndelegate\n \n=\n \nnew\n \nManagedAuthDelegate\nUser\n(\ncontext\n);\n\n    \nauthServer\n \n=\n \nnew\n \nAuthServer\n(\ndelegate\n);\n\n  \n}\n  \n\n}\n\n\n\n\n\n\nSet up routes to exchange credentials for tokens using \nAuthController\n and \nAuthCodeController\n. Add \nAuthorizer\ns between routes and their controller to restrict access to authorized resource owners only:\n\n\nController\n \nget\n \nentryPoint\n \n{\n\n  \nfinal\n \nrouter\n \n=\n \nnew\n \nRouter\n();\n\n  \nrouter\n\n    \n.\nroute\n(\n/auth/token\n)\n\n    \n.\nlink\n(()\n \n=\n \nnew\n \nAuthController\n(\nauthServer\n));\n\n\n  \nrouter\n\n    \n.\nroute\n(\n/auth/code\n)\n\n    \n.\nlink\n(()\n \n=\n \nnew\n \nAuthCodeController\n(\nauthServer\n));\n\n\n  \nrouter\n\n    \n.\nroute\n(\n/protected\n)\n\n    \n.\nlink\n(()\n \n=\n \nnew\n \nAuthorizer\n.\nbearer\n(\nauthServer\n))\n\n    \n.\nlink\n(()\n \n=\n \nnew\n \nProtectedController\n());\n\n\n  \nreturn\n \nrouter\n;\n\n\n}\n\n\n\n\n\n\nInsert OAuth 2.0 clients into a database:\n\n\naqueduct auth add-client --id com.app.mobile --secret foobar --redirect-uri https://somewhereoutthere.com\n\n\n\n\n\nLogging\n\n\nAll requests are logged to an instance of \nLogger\n. Set up a listener for logger in \nApplicationChannel\n to print log messages to the console. (See also \nscribe\n for logging to rotating files.)\n\n\nclass\n \nWildfireChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \nlogger\n.\nonRecord\n.\nlisten\n((\nrecord\n)\n \n{\n\n      \nprint\n(\n$\nrecord\n);\n\n    \n});\n\n  \n}\n\n\n}\n\n\n\n\n\n\nTesting\n\n\nTests are run by starting the Aqueduct application and verifying responses in a test file. A test harness is included in projects generated from \naqueduct create\n that starts and stops a test instance of your application and uploads your database schema to a temporary, local database.\n\n\nimport\n \nharness/app.dart\n;\n\n\n\nvoid\n \nmain\n()\n \n{\n\n  \nvar\n \napp\n \n=\n \nnew\n \nTestApplication\n();\n\n\n  \nsetUpAll\n(()\n \nasync\n \n{\n\n    \nawait\n \napp\n.\nstart\n();\n\n  \n});\n\n\n  \ntest\n(\n...\n,\n \n()\n \nasync\n \n{\n\n    \nvar\n \nresponse\n \n=\n \nawait\n \napp\n.\nclient\n.\nrequest\n(\n/endpoint\n).\nget\n();\n\n    \n...\n\n  \n});\n\n\n}\n\n\n\n\n\n\nA \nTestClient\n executes requests configured for the locally running test instance of your application. Instances of \nTestResponse\n are returned and can be evaluated with matchers like any other Dart tests. There are special matchers specifically for Aqueduct.\n\n\ntest\n(\nPOST /users creates a user\n,\n \n()\n \nasync\n \n{\n\n  \nvar\n \nrequest\n \n=\n \napp\n.\nclient\n.\nrequest\n(\n/users\n)\n\n    \n..\njson\n \n=\n \n{\nemail\n:\n \nbob@stablekernel.com\n};\n\n  \nvar\n \nresponse\n \n=\n \nawait\n \nrequest\n.\npost\n();\n\n\n  \nexpect\n(\nresponse\n,\n \nhasResponse\n(\n200\n,\n \n{\n\n    \nid\n:\n \nisNumber\n,\n\n    \nemail\n:\n \nbob@stablekernel.com\n\n  \n}));\n\n\n});\n\n\n\ntest\n(\nGET /users/1 returns a user\n,\n \n()\n \nasync\n \n{\n\n  \nvar\n \nresponse\n \n=\n \nawait\n \napp\n.\nclient\n.\nauthenticatedRequest\n(\n/users/1\n).\nget\n();\n\n  \nexpect\n(\nresponse\n,\n \nhasResponse\n(\n200\n,\n \npartial\n({\n\n    \nemail\n:\n \nbob@stablekernel.com\n\n  \n})));\n\n\n});\n\n\n\n\n\n\nDocumentation\n\n\nGenerate OpenAPI specifications automatically:\n\n\naqueduct document", 
            "title": "Tour"
        }, 
        {
            "location": "/tour/#aqueduct-a-tour", 
            "text": "Create applications with the  aqueduct  tool:  aqueduct create my_app  Run applications by using the  aqueduct  tool in a project directory:  aqueduct serve", 
            "title": "Aqueduct: A Tour"
        }, 
        {
            "location": "/tour/#structure", 
            "text": "An Aqueduct application is a series of controllers that form a  channel  for a request to flow through. Any of those controllers may respond to a request and take it out of the channel. Controllers in the middle of the channel often verify something, while the controller at the end fulfills the request. Fulfillment might mean returning the contents of a file or storing data from the request body in a database.", 
            "title": "Structure"
        }, 
        {
            "location": "/tour/#initialization", 
            "text": "An application's channel is created by subclassing  ApplicationChannel . This type also performs any other application initialization, like creating database connections and defining how authorization occurs.  import   package:aqueduct/aqueduct.dart ;  class   AppApplicationChannel   extends   ApplicationChannel   { \n   @ override \n   Future   prepare ()   async   { \n     databaseContext   =   contextFrom ( options ); \n   } \n\n   @ override \n   Controller   get   entryPoint   { \n     final   router   =   new   Router (); \n     router \n       . route ( /resource/[:id] ) \n       . link (()   =   new   ResourceController ( databaseContext )); \n     return   router ; \n   }  }", 
            "title": "Initialization"
        }, 
        {
            "location": "/tour/#routing", 
            "text": "A  router  splits a channel into sub-channels based on the path of a request. A request with the path  /users  will be handled by a different controller than a request with the path  /posts , for example. Routes are defined by  route specification syntax . Routes can contain variables and optional segments, enabling routes to be grouped together.  @ override  Controller   get   entryPoint   { \n   final   router   =   new   Router (); \n\n   router \n     . route ( /users/[:id] ) \n     . link (()   =   new   UserController ()); \n\n   router \n     . route ( /file/* ) \n     . link (()   =   new   FileController ()); \n\n   router \n     . route ( /health ) \n     . linkFunction (( req )   async   =   new   Response . ok ( null )); \n\n   return   router ;  }", 
            "title": "Routing"
        }, 
        {
            "location": "/tour/#controllers", 
            "text": "ResourceControllers  are the controller that most often fulfill a request. An  ResourceController  subclass handles all operations for resource, e.g.  POST /users ,  GET /users  and  GET /users/1 .  Subclasses implement a  operation method  for each operation:  import   package:aqueduct/aqueduct.dart  class   ResourceController   extends   ResourceController   { \n   @ Operation . get () \n   Future Response   getAllResources ()   async   { \n     return   new   Response . ok ( await   fetchResources ()) ; \n   } \n\n   @ Operation . get ( id ) \n   Future Response   getResourceByID ( @ Bind . path ( id )   int   id )   async   { \n     return   new   Response . ok ( await   fetchResource ( id )); \n   } \n\n   @ Operation . post () \n   Future Response   createResource ( @ Bind . body ()   Resource   resource )   async   { \n     var   inserted   =   await   insertResource ( resource ); \n     return   new   Response . ok ( inserted ); \n   }  }   Properties of the request are bound to operation method arguments and controller properties:  class   ResourceController   extends   ResourceController   { \n   @ Operation . get () \n   Future Response   getAllResources ( \n       @ Bind . header ( x-request-id )   String   requestID , \n       { @ Bind . query ( limit )   int   limit })   async   { \n     return   new   Response . ok ( await   fetchResources ( limit   ??   0 )); \n   } \n\n   @ Operation . post () \n   Future Response   createResource ( @ Bind . body ()   Resource   resource )   async   { \n     var   inserted   =   await   insertResourceIntoDatabase ( resource ); \n     return   new   Response . ok ( inserted ); \n   }  }   ManagedObjectController T s are  ResourceController s that automatically map a REST interface to database queries:  router \n   . route ( /users/[:id] ) \n   . link (()   =   new   ManagedObjectController User ( context ));   Controller  is the base class for all controllers that form a channel. They only have a single method to handle the request, and must either return the request or a response. When a controller returns a response, the request is taken out of the channel.  class   VerifyingController   extends   Controller   { \n   @ override \n   Future RequestOrResponse   handle ( Request   request )   async   { \n     if   ( request . raw . headers . value ( x-secret-key )   ==   secret! )   { \n       return   request ; \n     } \n\n     return   new   Response . badRequest (); \n   }  }   This behavior lets a channel prevent invalid requests from being fulfilled, or let's a controller be reused in multiple places to provide some preprocessing step.  Uncaught exceptions are caught by the controller and translated into an appropriate response, removing the request from the channel. Exceptions should only be caught when another response is desired or when the request should continue to the next controller in the channel.", 
            "title": "Controllers"
        }, 
        {
            "location": "/tour/#configuration", 
            "text": "Read YAML configuration data into type-safe and name-safe structures at startup:  // config.yaml\ndatabase:\n  host: ...\n  port: 5432\n  databaseName: foo\notherOption: hello\nnumberOfDoodads: 3    Subclass  ConfigurationItem  and declare a property for each key in the configuration file:  class   AppConfig   extends   ConfigurationItem   { \n   AppConfig ( String   path )   :   super . fromFile ( path ); \n\n   DatabaseConnectionInfo   database ; \n   String   otherOption ; \n   int   numberOfDoodads ;  }   Read the configuration file identified by an  ApplicationOptions :  import   package:aqueduct/aqueduct.dart ;  class   AppApplicationChannel   extends   ApplicationChannel   { \n   @ override \n   Future   prepare ()   async   { \n     var   options   =   new   AppConfig ( options . configurationFilePath ); \n     ... \n   }  }", 
            "title": "Configuration"
        }, 
        {
            "location": "/tour/#running-and-concurrency", 
            "text": "Aqueduct applications are run with the  aqueduct serve  command line tool, which can also open debugging and instrumentation tools and specify how many threads the application should run on:  aqueduct serve --observe --isolates 5  Run applications detached or still connected to the shell:  aqueduct serve --detached --port $PORT  Aqueduct applications are multi-isolate (multi-threaded). Each isolate runs a replica of the same web server with its own set of services like database connections. This makes behavior like database connection pooling implicit.", 
            "title": "Running and Concurrency"
        }, 
        {
            "location": "/tour/#querying-a-database", 
            "text": "Database operations are built and executed with instances of  Query T .  import   package:aqueduct/aqueduct.dart  class   ResourceController   extends   ResourceController   { \n   @ Operation . get () \n   Future Response   getAllResources ()   async   { \n     var   query   =   new   Query Resource ( context ) ; \n\n     var   results   =   await   query . fetch (); \n\n     return   new   Response . ok ( results ); \n   }  }   The results can be filtered by the  Query.where  property, which has the same properties as the object being queried.  var   query   =   new   Query Employee ( context ) \n   .. where (( e )   =   e . name ). startsWith ( Sa ) \n   .. where (( e )   =   e . salary ). greaterThan ( 50000 );  var   results   =   await   query . fetch ();   Values set on the properties of  Query.values  are sent to the database on insert and update operations. Like  Query.where ,  Query.values  has the same properties as the object being inserted or updated.  var   query   =   new   Query Employee ( context ) \n   .. values . name   =   Bob \n   .. values . salary   =   50000 ;  var   bob   =   await   query . insert ();    var   updateQuery   =   new   Query Employee ( context ) \n   .. where (( e )   =   e . id ). equalTo ( bob . id ) \n   .. values . name   =   Bobby ;  bob   =   await   updateQuery . updateOne ();     Query T s can sort and page on a result set. It can also join tables and return objects and their relationships:  var   query   =   new   Query Employee ( context ) \n   .. where (( e )   =   e . name ). equalTo ( Sue Gallagher ) \n   .. join ( object:   ( e )   =   e . manager ) \n   .. join ( set :   ( e )   =   e . directReports );  var   herAndHerManagerAndHerDirectReports   =   await   query . fetchOne ();   Exceptions thrown for queries are caught by a controller and translated into the appropriate status code. Unique constraint conflicts return 409,\nmissing required properties return 400 and database connection failure returns 503.", 
            "title": "Querying a Database"
        }, 
        {
            "location": "/tour/#defining-a-data-model", 
            "text": "ManagedObject T  instances represent a row in a database; each property is a column in the corresponding table. This class is always subclassed and is in fact made up of two classes:  class   Employee   extends   ManagedObject _Employee   implements   _Employee   { \n   bool   get   wasRecentlyHired   =   hireDate . difference ( new   DateTime . now ()). inDays     30 ;  }  class   _Employee    { \n   @ primaryKey \n   int   index ; \n\n   @ Column ( indexed:   true ) \n   String   name ; \n\n   DateTime   hireDate ; \n   int   salary ;  }   ManagedObject T s have relationship properties for has-one, has-many and many-to-many references to other  ManagedObject T s. The property with  Relate  metadata is a foreign key column.  class   Employee   extends   ManagedObject _Employee   implements   _Employee   {}  class   _Employee   { \n   ... \n\n   ManagedSet Initiative   initiatives ;  }  class   Initiative   extends   ManagedObject _Initiative   implements   _Initiative   {}  class   _Initiative   { \n   ... \n\n   @ Relate ( # initiatives ) \n   Employee   leader ;  }   ManagedObject T s are easily read from and written to JSON (or any other format):  class   UserController   extends   ResourceController   { \n   @ Operation . put ( id ) \n   Future Response   updateUser ( @ Bind . path ( id )   int   id ,   @ Bind . body ()   User   user )   async   { \n     var   query   =   new   Query User ( context ) \n       .. where (( u )   =   e . id ). equalTo ( id ) \n       .. values   =   user ; \n\n     var   updatedUser   =   await   query . updateOne (); \n\n     return   new   Response . ok ( updatedUser ); \n   }  }", 
            "title": "Defining a Data Model"
        }, 
        {
            "location": "/tour/#automatic-database-migration", 
            "text": "Generate and run database migrations with the  aqueduct db  tool:  aqueduct db generate\naqueduct db validate\naqueduct db upgrade --connect postgres@://...", 
            "title": "Automatic Database Migration"
        }, 
        {
            "location": "/tour/#oauth-20", 
            "text": "Authentication and authorization are enabled at application startup by creating an  AuthServer  with  ManagedAuthDelegate :  import   package:aqueduct/aqueduct.dart ;  import   package:aqueduct/managed_auth.dart ;  class   AppApplicationChannel   extends   ApplicationChannel   { \n   AuthServer   authServer ; \n   ManagedContext   context ; \n\n   @ override \n   Future   prepare ()   async   { \n     context   =   new   ManagedContext (...); \n\n     final   delegate   =   new   ManagedAuthDelegate User ( context ); \n     authServer   =   new   AuthServer ( delegate ); \n   }    }   Set up routes to exchange credentials for tokens using  AuthController  and  AuthCodeController . Add  Authorizer s between routes and their controller to restrict access to authorized resource owners only:  Controller   get   entryPoint   { \n   final   router   =   new   Router (); \n   router \n     . route ( /auth/token ) \n     . link (()   =   new   AuthController ( authServer )); \n\n   router \n     . route ( /auth/code ) \n     . link (()   =   new   AuthCodeController ( authServer )); \n\n   router \n     . route ( /protected ) \n     . link (()   =   new   Authorizer . bearer ( authServer )) \n     . link (()   =   new   ProtectedController ()); \n\n   return   router ;  }   Insert OAuth 2.0 clients into a database:  aqueduct auth add-client --id com.app.mobile --secret foobar --redirect-uri https://somewhereoutthere.com", 
            "title": "OAuth 2.0"
        }, 
        {
            "location": "/tour/#logging", 
            "text": "All requests are logged to an instance of  Logger . Set up a listener for logger in  ApplicationChannel  to print log messages to the console. (See also  scribe  for logging to rotating files.)  class   WildfireChannel   extends   ApplicationChannel   { \n   @ override \n   Future   prepare ()   async   { \n     logger . onRecord . listen (( record )   { \n       print ( $ record ); \n     }); \n   }  }", 
            "title": "Logging"
        }, 
        {
            "location": "/tour/#testing", 
            "text": "Tests are run by starting the Aqueduct application and verifying responses in a test file. A test harness is included in projects generated from  aqueduct create  that starts and stops a test instance of your application and uploads your database schema to a temporary, local database.  import   harness/app.dart ;  void   main ()   { \n   var   app   =   new   TestApplication (); \n\n   setUpAll (()   async   { \n     await   app . start (); \n   }); \n\n   test ( ... ,   ()   async   { \n     var   response   =   await   app . client . request ( /endpoint ). get (); \n     ... \n   });  }   A  TestClient  executes requests configured for the locally running test instance of your application. Instances of  TestResponse  are returned and can be evaluated with matchers like any other Dart tests. There are special matchers specifically for Aqueduct.  test ( POST /users creates a user ,   ()   async   { \n   var   request   =   app . client . request ( /users ) \n     .. json   =   { email :   bob@stablekernel.com }; \n   var   response   =   await   request . post (); \n\n   expect ( response ,   hasResponse ( 200 ,   { \n     id :   isNumber , \n     email :   bob@stablekernel.com \n   }));  });  test ( GET /users/1 returns a user ,   ()   async   { \n   var   response   =   await   app . client . authenticatedRequest ( /users/1 ). get (); \n   expect ( response ,   hasResponse ( 200 ,   partial ({ \n     email :   bob@stablekernel.com \n   })));  });", 
            "title": "Testing"
        }, 
        {
            "location": "/tour/#documentation", 
            "text": "Generate OpenAPI specifications automatically:  aqueduct document", 
            "title": "Documentation"
        }, 
        {
            "location": "/migration/", 
            "text": "Migration from Aqueduct 2 to Aqueduct 3.0\n\n\nAqueduct 3 makes a number of breaking changes from Aqueduct 2. Some of these changes are changes to behavior, and others are simple API renaming. This guide demonstrates the changes required for commonly used code.\n\n\nRequestSink is now ApplicationChannel\n\n\nThis type has been renamed to \nApplicationChannel\n and its methods for initializing an application have changed. The method \nsetupRouter\n has been replaced by the getter \nentryPoint\n. All controller creating code should be located in this getter, and you must now create the \nRouter\n yourself if you choose to. Additionally, the methods to link together controllers (e.g., \ngenerate\n, \npipe\n) have been replaced with the \nlink\n method, which always takes a closure.\n\n\nclass\n \nChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \nService\n \nservice\n;\n\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \nservice\n \n=\n \nService\n(\noptions\n.\ncontext\n[\nservice\n]);\n\n  \n}\n\n\n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nRouter\n();\n\n    \nrouter\n.\nlink\n(()\n \n=\n \nMyController\n(\nservice\n));\n\n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nThe object returned by this getter is the first controller to receive a request, and does not have to be a router (e.g., it could be global middleware). By default, the closure provided to \nlink\n is invoked once at startup and the same controller instance is reused for all requests. If a \nController\n implements \nRecyclable\nT\n, the closure is invoke for each new request and a new controller is created to handle the request.\n\n\nYou are no longer required to implement a constructor for \nApplicationChannel\n. All of your initialization should be provided by overriding \nprepare\n in your channel. You will have access to configuration data through an \noptions\n property in both \nprepare\n and \nentryPoint\n.\n\n\nHTTPController is now ResourceController\n\n\nThe name of this type has changed, and the syntax for identifying operation methods and binding values has improved.\n\n\nclass\n \nMyController\n \nextends\n \nResourceController\n \n{\n\n  \n@\nOperation\n.\nget\n()\n\n  \nFuture\nResponse\n \ngetAll\n({\n@\nBind\n.\nquery\n(\nfilter\n)\n \nString\n \nfilter\n})\n \nasync\n \n{\n\n    \n...\n\n  \n}\n\n\n  \n@\nOperation\n.\nput\n(\nid\n)\n\n  \nFuture\nResponse\n \nupdateThing\n(\n@\nBind\n.\npath\n(\nid\n)\n \nint\n \nid\n,\n \n@\nBind\n.\nbody\n()\n \nThing\n \nthing\n)\n \nasync\n \n{\n\n    \n...\n    \n  \n}\n\n\n}\n\n\n\n\n\n\nOperation methods must now be decorated an \nOperation\n annotation; this replaces metadata like \n@httpGet\n. For an operation method to match a request with path variables, the names of those path variables must be arguments to the \nOperation\n constructor. In previous versions, path variable methods were selected if the method's arguments bound a path variable. This is no longer the case - binding a path variable has no impact on the selection of a method, the path variable \nmust\n be identified in the \nOperation\n. You no longer have to bind a path variable and can retrieve it through the \nrequest.path\n.\n\n\nBound parameters are identified by the \nBind\n annotation, and the type of binding is identified by the constructor used. This syntax replaces \nHTTPQuery.bind()\n, etc.\n\n\nQuery.where syntax has changed\n\n\nPreviously, query filters were applied by assigning expressions like \nwhereEqualTo\n to properties of \nQuery.where\n. This has been replaced with the property selector syntax that is used when joining, sorting or paging by a property.\n\n\nfinal\n \nquery\n \n=\n \nQuery\nUser\n()\n\n  \n..\nwhere\n((\nu\n)\n \n=\n \nu\n.\nid\n).\nequalTo\n(\n1\n);\n\n\n\n\n\n\nMethods like \nwhereEqualTo\n no longer exist - all expressions to apply to a selected property are instance methods of the object returned by \nwhere\n.\n\n\nTest library is now aqueduct_test\n\n\nThe test library is now a separate library named \naqueduct_test\n and must be added to your \npubspec.yaml\n. Much of its behavior has changed to make writing tests more effective. See the \ndocumentation\n for more details.\n\n\nSwagger -\n OpenAPI\n\n\nAqueduct had experimental support for Swagger documentation generation. It now has full, tested support for OpenAPI 3 documentation generation. See the \ndocumentation\n for more details.\n\n\nRenames\n\n\nThe following common signatures are a non-exhaustive list of simple API renaming:\n\n\nAuthorization.resourceOwnerIdentifier -\n Authorization.ownerID\nRequest.innerRequest -\n Request.raw\nAuthStorage -\n AuthServerDelegate\nAuthServer.storage -\n AuthServer.delegate\nApplicationConfiguration -\n ApplicationOptions\nApplication.configuration -\n Application.options\nServiceRegistry -\n ServiceRegistry\nManagedTableAttributes -\n Table\nManagedRelationshipDeleteRule -\n DeleteRule\nManagedRelationship -\n Relate\nManagedColumnAttributes -\n Column\nmanagedPrimaryKey -\n primaryKey\nManagedTransientAttribute -\n Serialize\nSerialize now replaces managedTransientAttribute, managedTransientInputAttribute, and managedTransientOutputAttribute.\nRequestController -\n Controller\nRequestController.processRequest -\n Controller.handle\nHTTPController -\n ResourceController\nRouter.unhandledRequestController -\n Router.unmatchedController", 
            "title": "3.0 Migration Guide"
        }, 
        {
            "location": "/migration/#migration-from-aqueduct-2-to-aqueduct-30", 
            "text": "Aqueduct 3 makes a number of breaking changes from Aqueduct 2. Some of these changes are changes to behavior, and others are simple API renaming. This guide demonstrates the changes required for commonly used code.", 
            "title": "Migration from Aqueduct 2 to Aqueduct 3.0"
        }, 
        {
            "location": "/migration/#requestsink-is-now-applicationchannel", 
            "text": "This type has been renamed to  ApplicationChannel  and its methods for initializing an application have changed. The method  setupRouter  has been replaced by the getter  entryPoint . All controller creating code should be located in this getter, and you must now create the  Router  yourself if you choose to. Additionally, the methods to link together controllers (e.g.,  generate ,  pipe ) have been replaced with the  link  method, which always takes a closure.  class   Channel   extends   ApplicationChannel   { \n   Service   service ; \n\n   @ override \n   Future   prepare ()   async   { \n     service   =   Service ( options . context [ service ]); \n   } \n\n   @ override \n   Controller   get   entryPoint   { \n     final   router   =   Router (); \n     router . link (()   =   MyController ( service )); \n     return   router ; \n   }  }   The object returned by this getter is the first controller to receive a request, and does not have to be a router (e.g., it could be global middleware). By default, the closure provided to  link  is invoked once at startup and the same controller instance is reused for all requests. If a  Controller  implements  Recyclable T , the closure is invoke for each new request and a new controller is created to handle the request.  You are no longer required to implement a constructor for  ApplicationChannel . All of your initialization should be provided by overriding  prepare  in your channel. You will have access to configuration data through an  options  property in both  prepare  and  entryPoint .", 
            "title": "RequestSink is now ApplicationChannel"
        }, 
        {
            "location": "/migration/#httpcontroller-is-now-resourcecontroller", 
            "text": "The name of this type has changed, and the syntax for identifying operation methods and binding values has improved.  class   MyController   extends   ResourceController   { \n   @ Operation . get () \n   Future Response   getAll ({ @ Bind . query ( filter )   String   filter })   async   { \n     ... \n   } \n\n   @ Operation . put ( id ) \n   Future Response   updateThing ( @ Bind . path ( id )   int   id ,   @ Bind . body ()   Thing   thing )   async   { \n     ...     \n   }  }   Operation methods must now be decorated an  Operation  annotation; this replaces metadata like  @httpGet . For an operation method to match a request with path variables, the names of those path variables must be arguments to the  Operation  constructor. In previous versions, path variable methods were selected if the method's arguments bound a path variable. This is no longer the case - binding a path variable has no impact on the selection of a method, the path variable  must  be identified in the  Operation . You no longer have to bind a path variable and can retrieve it through the  request.path .  Bound parameters are identified by the  Bind  annotation, and the type of binding is identified by the constructor used. This syntax replaces  HTTPQuery.bind() , etc.", 
            "title": "HTTPController is now ResourceController"
        }, 
        {
            "location": "/migration/#querywhere-syntax-has-changed", 
            "text": "Previously, query filters were applied by assigning expressions like  whereEqualTo  to properties of  Query.where . This has been replaced with the property selector syntax that is used when joining, sorting or paging by a property.  final   query   =   Query User () \n   .. where (( u )   =   u . id ). equalTo ( 1 );   Methods like  whereEqualTo  no longer exist - all expressions to apply to a selected property are instance methods of the object returned by  where .", 
            "title": "Query.where syntax has changed"
        }, 
        {
            "location": "/migration/#test-library-is-now-aqueduct_test", 
            "text": "The test library is now a separate library named  aqueduct_test  and must be added to your  pubspec.yaml . Much of its behavior has changed to make writing tests more effective. See the  documentation  for more details.", 
            "title": "Test library is now aqueduct_test"
        }, 
        {
            "location": "/migration/#swagger-openapi", 
            "text": "Aqueduct had experimental support for Swagger documentation generation. It now has full, tested support for OpenAPI 3 documentation generation. See the  documentation  for more details.", 
            "title": "Swagger -&gt; OpenAPI"
        }, 
        {
            "location": "/migration/#renames", 
            "text": "The following common signatures are a non-exhaustive list of simple API renaming:  Authorization.resourceOwnerIdentifier -  Authorization.ownerID\nRequest.innerRequest -  Request.raw\nAuthStorage -  AuthServerDelegate\nAuthServer.storage -  AuthServer.delegate\nApplicationConfiguration -  ApplicationOptions\nApplication.configuration -  Application.options\nServiceRegistry -  ServiceRegistry\nManagedTableAttributes -  Table\nManagedRelationshipDeleteRule -  DeleteRule\nManagedRelationship -  Relate\nManagedColumnAttributes -  Column\nmanagedPrimaryKey -  primaryKey\nManagedTransientAttribute -  Serialize\nSerialize now replaces managedTransientAttribute, managedTransientInputAttribute, and managedTransientOutputAttribute.\nRequestController -  Controller\nRequestController.processRequest -  Controller.handle\nHTTPController -  ResourceController\nRouter.unhandledRequestController -  Router.unmatchedController", 
            "title": "Renames"
        }, 
        {
            "location": "/best_practices/", 
            "text": "Best Practices for Developing Aqueduct Applications\n\n\nKeep Dart Projects Separate\n\n\nBecause Dart is cross-platform, developers should avoid combining client application projects with Aqueduct projects. Instead, use a single repository with an independent project for each facet of the system. When there are opportunities for code sharing between platforms (typically between Flutter and AngularDart), shared code can live in a dependency project in the same repository.\n\n\nA typical directory structure for an multi-faceted application looks like this:\n\n\napplication_name/\n  aqueduct/\n  flutter/\n  angular/\n  shared/\n\n\n\n\n\n\n\nProject Definition\n\n\nA \nproject\n is a directory that contain a \npubspec.yaml\n file and \nlib\n directory.\n\n\n\n\nIt is tempting to share your data model types between your server and client applications, but this falls apart for anything but the most simple of applications. There are enough behavioral differences between the four representations of your data model - in the database, on the server, on the wire (JSON), and on the client - that a single type will have a hard time encompassing. Instead, generate an OpenAPI specification with \naqueduct document\n and use one of the many open-source tools for generating client data model types.\n\n\nUse Test Driven Development (or something close to it)\n\n\nIn Aqueduct, testing is a first-class citizen. The \naqueduct_test\n package has classes and methods for initializing and running an application for testing, making requests to that application, and verifying the responses. There is value to using tools like Postman or CURL to test proof of concept code, but the \naqueduct_test\n package is geared specifically for replacing these tools while retaining automated tests as the project grows.\n\n\nAn example test suite looks like this:\n\n\nvoid\n \nmain\n()\n \n{\n\n  \nfinal\n \nharness\n \n=\n \nnew\n \nHarness\n()..\ninstall\n();\n\n\n  \ntest\n(\nGET /endpoint returns 200 and a simple object\n,\n \n()\n \nasync\n \n{\n\n    \nfinal\n \nresponse\n \n=\n \nawait\n \nharness\n.\nagent\n.\nget\n(\n/endpoint\n);\n\n    \nexpectResponse\n(\nresponse\n,\n \n200\n,\n \nbody:\n \n{\nkey\n:\n \nvalue\n});\n\n  \n});\n\n\n}\n\n\n\n\n\n\nUse a bin Script to Verify Assumptions\n\n\nKeep a simple Dart script file in the \nbin/\n directory that imports your project. Use this file as a scratchpad to test exploratory code before committing to a test suite. Don't check this file into source control.\n\n\nimport\n \npackage:myapp/myapp.dart\n;\n\n\n\nFuture\n \nmain\n()\n \nasync\n \n{\n\n  \nvar\n \nwhatIsThis\n \n=\n \nawait\n \nsomeYetToBeNamedUsefullyMethod\n();\n\n  \nprint\n(\n$\nwhatIsThis\n);\n\n\n}\n\n\n\n\n\n\nCreate New Projects from a Template\n\n\nUse \naqueduct create\n to create applications with the appropriate structure and boilerplate. There are templates for different kinds of applications; view these templates with \naqueduct create list-templates\n.\n\n\nUse a Debugger\n\n\nA debugger allows you to stop execution of a running application at a particular line of code to verify variable values, and then continue to step through that code line by line. It can be used when running test suites or when running the application through the \nbin/main.dart\n script.\n\n\nIn IntelliJ IDEA, right-click on any file with a \nmain\n function (which includes test suites) and select \nDebug\n option. Use breakpoints (by clicking on the gutter area to the left of the text editing area) to stop execution at a particular line before it is executed.\n\n\nUse the Suggested Project Directory Structure\n\n\nSee \nAqueduct Project Structure\n.\n\n\nPass Services to Controllers in entryPoint\n\n\nPass service objects to controllers in \nentryPoint\n and only pass the services the controller will use.\n\n\nclass\n \nAppChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \nGitHub\n \ngithubService\n;\n\n  \nPostgreSQLConnection\n \ndatabaseConnection\n;\n\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \ndatabaseConnection\n \n=\n \nnew\n \nPostgreSQLConnection\n();\n\n    \ngithubService\n \n=\n \nnew\n \nGitHub\n();\n\n  \n}\n\n\n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nnew\n \nRouter\n();\n\n\n    \nrouter\n\n      \n.\nroute\n(\n/data\n)\n\n      \n.\nlink\n(()\n \n=\n \nnew\n \nDBController\n(\ndatabaseConnection\n));\n\n\n    \nrouter\n\n      \n.\nroute\n(\n/github\n)\n\n      \n.\nlink\n(()\n \n=\n \nnew\n \nGitHubController\n(\ngithubService\n));\n\n\n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nPassing references like this allows for injecting dependencies that depend on the environment; e.g. in production, development or during tests. It also avoids tight coupling between the objects in your application.\n\n\nMinimize the access a controller has to its dependencies; e.g. don't pass it a \nStreamController\n when it only needs \nSink\n or a \nStream\n.\n\n\nUse a Test Harness\n\n\nA test harness initializes your application in a test suite. It has built in behavior that you can add to for things that are specific to your application. Documentation for using a test harness in your application is located \nhere\n.\n\n\nUse config.src.yaml\n\n\nUse the convention of \nconfig.src.yaml file\n to prevent configuration errors and inject test dependencies.\n\n\nUnderstand how Aqueduct Uses Isolates\n\n\nSee more in \nApplication Structure\n.\n\n\nUse ResourceController Subclasses\n\n\nSubclassing \nResourceController\n provides significant conveniences, safeties and behaviors used by the majority of an application's request handling logic. Prefer to use this class for non-middleware controllers.\n\n\nKeep ApplicationChannel Tidy\n\n\nA \nApplicationChannel\n should handle initialization, routing and nothing more. Consider moving non-initialization behavior into a service object in a separate file.\n\n\nAvoid Raw SQL Queries\n\n\nPrefer to use the Aqueduct ORM. It sends appropriate HTTP responses for different kinds of errors, validates input data and is ensures the queries match up with your data model.\n\n\nUse API Reference\n\n\nAqueduct is an object oriented framework - behaviors are implemented by instances of some type. The types of objects, their properties and their behaviors all follow similar naming conventions to make the API more discoverable.\n\n\nMany types in Aqueduct have a prefix in common with related types. For example, types like \nAuthServer\n, \nAuthServerDelegate\n and \nAuthCode\n are all related because they deal with authentication and authorization. Methods are named consistently across classes (e.g, \nasMap\n is a common method name).\n\n\nWhen looking for a solution, look at the \nAPI reference\n for the objects you have access to. These objects may already have the behavior you wish to implement or have a reference to an object with that behavior.\n\n\nUse try-catch Sparingly\n\n\nAll request handling code is wrapped in a try-catch block that will interpret exceptions and errors and return meaningful HTTP responses. Unknown exceptions will yield a 500 Server Error response. In general, you do not need to use try-catch unless you want a different HTTP response than the one being returned for the exception.\n\n\nCode that throws an exception during initialization should not be caught if the error is fatal to the application launching successfully.", 
            "title": "Best Practices"
        }, 
        {
            "location": "/best_practices/#best-practices-for-developing-aqueduct-applications", 
            "text": "", 
            "title": "Best Practices for Developing Aqueduct Applications"
        }, 
        {
            "location": "/best_practices/#keep-dart-projects-separate", 
            "text": "Because Dart is cross-platform, developers should avoid combining client application projects with Aqueduct projects. Instead, use a single repository with an independent project for each facet of the system. When there are opportunities for code sharing between platforms (typically between Flutter and AngularDart), shared code can live in a dependency project in the same repository.  A typical directory structure for an multi-faceted application looks like this:  application_name/\n  aqueduct/\n  flutter/\n  angular/\n  shared/   Project Definition  A  project  is a directory that contain a  pubspec.yaml  file and  lib  directory.   It is tempting to share your data model types between your server and client applications, but this falls apart for anything but the most simple of applications. There are enough behavioral differences between the four representations of your data model - in the database, on the server, on the wire (JSON), and on the client - that a single type will have a hard time encompassing. Instead, generate an OpenAPI specification with  aqueduct document  and use one of the many open-source tools for generating client data model types.", 
            "title": "Keep Dart Projects Separate"
        }, 
        {
            "location": "/best_practices/#use-test-driven-development-or-something-close-to-it", 
            "text": "In Aqueduct, testing is a first-class citizen. The  aqueduct_test  package has classes and methods for initializing and running an application for testing, making requests to that application, and verifying the responses. There is value to using tools like Postman or CURL to test proof of concept code, but the  aqueduct_test  package is geared specifically for replacing these tools while retaining automated tests as the project grows.  An example test suite looks like this:  void   main ()   { \n   final   harness   =   new   Harness ().. install (); \n\n   test ( GET /endpoint returns 200 and a simple object ,   ()   async   { \n     final   response   =   await   harness . agent . get ( /endpoint ); \n     expectResponse ( response ,   200 ,   body:   { key :   value }); \n   });  }", 
            "title": "Use Test Driven Development (or something close to it)"
        }, 
        {
            "location": "/best_practices/#use-a-bin-script-to-verify-assumptions", 
            "text": "Keep a simple Dart script file in the  bin/  directory that imports your project. Use this file as a scratchpad to test exploratory code before committing to a test suite. Don't check this file into source control.  import   package:myapp/myapp.dart ;  Future   main ()   async   { \n   var   whatIsThis   =   await   someYetToBeNamedUsefullyMethod (); \n   print ( $ whatIsThis );  }", 
            "title": "Use a bin Script to Verify Assumptions"
        }, 
        {
            "location": "/best_practices/#create-new-projects-from-a-template", 
            "text": "Use  aqueduct create  to create applications with the appropriate structure and boilerplate. There are templates for different kinds of applications; view these templates with  aqueduct create list-templates .", 
            "title": "Create New Projects from a Template"
        }, 
        {
            "location": "/best_practices/#use-a-debugger", 
            "text": "A debugger allows you to stop execution of a running application at a particular line of code to verify variable values, and then continue to step through that code line by line. It can be used when running test suites or when running the application through the  bin/main.dart  script.  In IntelliJ IDEA, right-click on any file with a  main  function (which includes test suites) and select  Debug  option. Use breakpoints (by clicking on the gutter area to the left of the text editing area) to stop execution at a particular line before it is executed.", 
            "title": "Use a Debugger"
        }, 
        {
            "location": "/best_practices/#use-the-suggested-project-directory-structure", 
            "text": "See  Aqueduct Project Structure .", 
            "title": "Use the Suggested Project Directory Structure"
        }, 
        {
            "location": "/best_practices/#pass-services-to-controllers-in-entrypoint", 
            "text": "Pass service objects to controllers in  entryPoint  and only pass the services the controller will use.  class   AppChannel   extends   ApplicationChannel   { \n   GitHub   githubService ; \n   PostgreSQLConnection   databaseConnection ; \n\n   @ override \n   Future   prepare ()   async   { \n     databaseConnection   =   new   PostgreSQLConnection (); \n     githubService   =   new   GitHub (); \n   } \n\n   @ override \n   Controller   get   entryPoint   { \n     final   router   =   new   Router (); \n\n     router \n       . route ( /data ) \n       . link (()   =   new   DBController ( databaseConnection )); \n\n     router \n       . route ( /github ) \n       . link (()   =   new   GitHubController ( githubService )); \n\n     return   router ; \n   }  }   Passing references like this allows for injecting dependencies that depend on the environment; e.g. in production, development or during tests. It also avoids tight coupling between the objects in your application.  Minimize the access a controller has to its dependencies; e.g. don't pass it a  StreamController  when it only needs  Sink  or a  Stream .", 
            "title": "Pass Services to Controllers in entryPoint"
        }, 
        {
            "location": "/best_practices/#use-a-test-harness", 
            "text": "A test harness initializes your application in a test suite. It has built in behavior that you can add to for things that are specific to your application. Documentation for using a test harness in your application is located  here .", 
            "title": "Use a Test Harness"
        }, 
        {
            "location": "/best_practices/#use-configsrcyaml", 
            "text": "Use the convention of  config.src.yaml file  to prevent configuration errors and inject test dependencies.", 
            "title": "Use config.src.yaml"
        }, 
        {
            "location": "/best_practices/#understand-how-aqueduct-uses-isolates", 
            "text": "See more in  Application Structure .", 
            "title": "Understand how Aqueduct Uses Isolates"
        }, 
        {
            "location": "/best_practices/#use-resourcecontroller-subclasses", 
            "text": "Subclassing  ResourceController  provides significant conveniences, safeties and behaviors used by the majority of an application's request handling logic. Prefer to use this class for non-middleware controllers.", 
            "title": "Use ResourceController Subclasses"
        }, 
        {
            "location": "/best_practices/#keep-applicationchannel-tidy", 
            "text": "A  ApplicationChannel  should handle initialization, routing and nothing more. Consider moving non-initialization behavior into a service object in a separate file.", 
            "title": "Keep ApplicationChannel Tidy"
        }, 
        {
            "location": "/best_practices/#avoid-raw-sql-queries", 
            "text": "Prefer to use the Aqueduct ORM. It sends appropriate HTTP responses for different kinds of errors, validates input data and is ensures the queries match up with your data model.", 
            "title": "Avoid Raw SQL Queries"
        }, 
        {
            "location": "/best_practices/#use-api-reference", 
            "text": "Aqueduct is an object oriented framework - behaviors are implemented by instances of some type. The types of objects, their properties and their behaviors all follow similar naming conventions to make the API more discoverable.  Many types in Aqueduct have a prefix in common with related types. For example, types like  AuthServer ,  AuthServerDelegate  and  AuthCode  are all related because they deal with authentication and authorization. Methods are named consistently across classes (e.g,  asMap  is a common method name).  When looking for a solution, look at the  API reference  for the objects you have access to. These objects may already have the behavior you wish to implement or have a reference to an object with that behavior.", 
            "title": "Use API Reference"
        }, 
        {
            "location": "/best_practices/#use-try-catch-sparingly", 
            "text": "All request handling code is wrapped in a try-catch block that will interpret exceptions and errors and return meaningful HTTP responses. Unknown exceptions will yield a 500 Server Error response. In general, you do not need to use try-catch unless you want a different HTTP response than the one being returned for the exception.  Code that throws an exception during initialization should not be caught if the error is fatal to the application launching successfully.", 
            "title": "Use try-catch Sparingly"
        }, 
        {
            "location": "/intellij/", 
            "text": "Aqueduct IntellIJ IDEA Templates\n\n\nThis document describes how to install file and code templates for Aqueduct when using an IntelliJ IDE (e.g., IDEA, IDEA CE, Webstorm).\n\n\nInstallation\n\n\nDownload the \nthis file\n and import it into IntelliJ by selecting \nImport Settings...\n from the \nFile\n menu.\n\n\nFile Templates\n\n\nFile templates are created by selecting \nNew\n from the \nFile\n menu or by right-clicking a directory in the project navigator. The following templates exists:\n\n\n\n\n\n\n\n\nTemplate Name\n\n\nBehavior\n\n\n\n\n\n\n\n\n\n\nAqueduct ResourceController\n\n\nCreates a new file with the skeleton of an \nResourceController\n.\n\n\n\n\n\n\nAqueduct ManagedObject\n\n\nCreates a new file with the skeleton of a \nManagedObject\n subclass\n\n\n\n\n\n\nAqueduct Test\n\n\nCreates a new file that creates and installs a \nTestHarness\n subclass from your project.\n\n\n\n\n\n\n\n\nLive Templates\n\n\nLive templates are keywords that expand into a larger code block. Typing the keyword in a Dart file and hitting return will enter common Aqueduct code. Live templates often have placeholders that can by jumped between by using the return key.\n\n\nLive Templates: HTTP\n\n\n\n\n\n\n\n\nShortcut\n\n\nBehavior\n\n\n\n\n\n\n\n\n\n\noperation\n\n\nCreates a new operation method in a \nResourceController\n.\n\n\n\n\n\n\nbindbody\n\n\nAdds a body binding to an operation method.\n\n\n\n\n\n\nbindheader\n\n\nAdds a header binding to an operation method.\n\n\n\n\n\n\nbindquery\n\n\nAdds a query binding to an operation method.\n\n\n\n\n\n\nbindpath\n\n\nAdds a path binding to an operation method.\n\n\n\n\n\n\n\n\nLive Templates: ORM\n\n\n\n\n\n\n\n\nShortcut\n\n\nBehavior\n\n\n\n\n\n\n\n\n\n\nps\n\n\nEnters the property selector syntax for \nQuery.where\n, \nQuery.join\n and other query configuration methods.\n\n\n\n\n\n\ncolumn\n\n\nAdds a column annotated field to a \nManagedObject\n.\n\n\n\n\n\n\nrelate\n\n\nAdds a relationship annotated field to a \nManagedObject\n.\n\n\n\n\n\n\n\n\nLive Templates: Testing\n\n\n\n\n\n\n\n\nShortcut\n\n\nBehavior\n\n\n\n\n\n\n\n\n\n\ntest\n\n\nCreates a test closure in a test file.", 
            "title": "IntelliJ IDEA Templates"
        }, 
        {
            "location": "/intellij/#aqueduct-intellij-idea-templates", 
            "text": "This document describes how to install file and code templates for Aqueduct when using an IntelliJ IDE (e.g., IDEA, IDEA CE, Webstorm).", 
            "title": "Aqueduct IntellIJ IDEA Templates"
        }, 
        {
            "location": "/intellij/#installation", 
            "text": "Download the  this file  and import it into IntelliJ by selecting  Import Settings...  from the  File  menu.", 
            "title": "Installation"
        }, 
        {
            "location": "/intellij/#file-templates", 
            "text": "File templates are created by selecting  New  from the  File  menu or by right-clicking a directory in the project navigator. The following templates exists:     Template Name  Behavior      Aqueduct ResourceController  Creates a new file with the skeleton of an  ResourceController .    Aqueduct ManagedObject  Creates a new file with the skeleton of a  ManagedObject  subclass    Aqueduct Test  Creates a new file that creates and installs a  TestHarness  subclass from your project.", 
            "title": "File Templates"
        }, 
        {
            "location": "/intellij/#live-templates", 
            "text": "Live templates are keywords that expand into a larger code block. Typing the keyword in a Dart file and hitting return will enter common Aqueduct code. Live templates often have placeholders that can by jumped between by using the return key.", 
            "title": "Live Templates"
        }, 
        {
            "location": "/intellij/#live-templates-http", 
            "text": "Shortcut  Behavior      operation  Creates a new operation method in a  ResourceController .    bindbody  Adds a body binding to an operation method.    bindheader  Adds a header binding to an operation method.    bindquery  Adds a query binding to an operation method.    bindpath  Adds a path binding to an operation method.", 
            "title": "Live Templates: HTTP"
        }, 
        {
            "location": "/intellij/#live-templates-orm", 
            "text": "Shortcut  Behavior      ps  Enters the property selector syntax for  Query.where ,  Query.join  and other query configuration methods.    column  Adds a column annotated field to a  ManagedObject .    relate  Adds a relationship annotated field to a  ManagedObject .", 
            "title": "Live Templates: ORM"
        }, 
        {
            "location": "/intellij/#live-templates-testing", 
            "text": "Shortcut  Behavior      test  Creates a test closure in a test file.", 
            "title": "Live Templates: Testing"
        }, 
        {
            "location": "/snippets/", 
            "text": "Aqueduct Snippets\n\n\nThese snippets are quick examples of common code that you can use and modify in your application.\n\n\n\n\nHTTP Routing, Request and Response Snippets\n\n\nORM and Database Snippets\n\n\nAuthorization and Authentication Snippets\n\n\nIntegration Test Snippets", 
            "title": "Overview"
        }, 
        {
            "location": "/snippets/#aqueduct-snippets", 
            "text": "These snippets are quick examples of common code that you can use and modify in your application.   HTTP Routing, Request and Response Snippets  ORM and Database Snippets  Authorization and Authentication Snippets  Integration Test Snippets", 
            "title": "Aqueduct Snippets"
        }, 
        {
            "location": "/snippets/http/", 
            "text": "Aqueduct HTTP Snippets\n\n\nHello, World\n\n\nclass\n \nAppChannel\n \nextends\n \nApplicationChannel\n \n{\n  \n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nRouter\n();\n\n\n    \nrouter\n.\nroute\n(\n/hello_world\n).\nlinkFunction\n((\nrequest\n)\n \nasync\n \n{\n\n      \nreturn\n \nResponse\n.\nok\n(\nHello, world!\n)\n\n        \n..\ncontentType\n \n=\n \nContentType\n.\nTEXT\n;\n\n    \n});\n\n\n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nRoute Variables\n\n\nclass\n \nAppChannel\n \nextends\n \nApplicationChannel\n \n{\n  \n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nRouter\n();\n\n\n    \nrouter\n.\nroute\n(\n/variable/[:variable]\n).\nlinkFunction\n((\nrequest\n)\n \nasync\n \n{\n\n      \nreturn\n \nResponse\n.\nok\n({\n\n        \nmethod\n:\n \nrequest\n.\nraw\n.\nmethod\n,\n\n        \npath\n:\n \nrequest\n.\npath\n.\nvariables\n[\nvariable\n]\n \n??\n \nnot specified\n\n      \n});\n      \n    \n});\n\n\n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nGrouping Routes and Binding Path Variables\n\n\nclass\n \nAppChannel\n \nextends\n \nApplicationChannel\n \n{\n  \n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nRouter\n();\n\n\n    \nrouter\n\n      \n.\nroute\n(\n/users/[:id]\n)\n\n      \n.\nlink\n(()\n \n=\n \nMyController\n());\n\n\n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n}\n\n\n\nclass\n \nMyController\n \nextends\n \nResourceController\n \n{\n\n  \nfinal\n \nList\nString\n \nthings\n \n=\n \n[\nthing1\n,\n \nthing2\n];\n\n\n  \n@\nOperation\n.\nget\n()\n\n  \nFuture\nResponse\n \ngetThings\n()\n \nasync\n \n{\n\n    \nreturn\n \nResponse\n.\nok\n(\nthings\n);\n\n  \n}\n\n\n  \n@\nOperation\n.\nget\n(\nid\n)\n\n  \nFuture\nResponse\n \ngetThing\n(\n@\nBind\n.\npath\n(\nid\n)\n \nint\n \nid\n)\n \nasync\n \n{\n\n    \nif\n \n(\nid\n \n \n0\n \n||\n \nid\n \n=\n \nthings\n.\nlength\n)\n \n{\n\n      \nreturn\n \nResponse\n.\nnotFound\n();\n\n    \n}\n\n    \nreturn\n \nResponse\n.\nok\n(\nthings\n[\nid\n]);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nCustom Middleware\n\n\nclass\n \nAppChannel\n \nextends\n \nApplicationChannel\n \n{\n  \n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nRouter\n();\n\n\n    \nrouter\n\n      \n.\nroute\n(\n/rate_limit\n)\n\n      \n.\nlink\n(()\n \n=\n \nRateLimiter\n())\n\n      \n.\nlinkFunction\n((\nreq\n)\n \nasync\n \n=\n \nResponse\n.\nok\n({\n\n        \nrequests_remaining\n:\n \nreq\n.\nattachments\n[\nremaining\n]\n\n      \n}));\n\n\n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n}\n\n\n\nclass\n \nRateLimiter\n \nextends\n \nRequestController\n \n{\n\n  \n@\noverride\n\n  \nFuture\nRequestOrResponse\n \nhandle\n(\nRequest\n \nrequest\n)\n \nasync\n \n{\n\n    \nfinal\n \napiKey\n \n=\n \nrequest\n.\nraw\n.\nheaders\n.\nvalue\n(\nx-apikey\n);\n\n    \nfinal\n \nrequestsRemaining\n \n=\n \nawait\n \nremainingRequestsForAPIKey\n(\napiKey\n);\n\n    \nif\n \n(\nrequestsRemaining\n \n=\n \n0\n)\n \n{\n\n      \nreturn\n \nResponse\n(\n429\n,\n \nnull\n,\n \nnull\n);\n\n    \n}\n\n\n    \nrequest\n.\naddResponseModifier\n((\nr\n)\n \n{\n\n      \nr\n.\nheaders\n[\nx-remaining-requests\n]\n \n=\n \nrequestsRemaining\n;\n\n    \n});\n\n\n    \nreturn\n \nrequest\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nApplication-Wide CORS Allowed Origins\n\n\nclass\n \nAppChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \n// All controllers will use this policy by default\n\n    \nCORSPolicy\n.\ndefaultPolicy\n.\nallowedOrigins\n \n=\n \n[\nhttps://mywebsite.com\n];\n\n  \n}\n\n\n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nRouter\n();\n\n\n    \nrouter\n.\nroute\n(\n/things\n).\nlinkFunction\n((\nrequest\n)\n \nasync\n \n{\n\n      \nreturn\n \nResponse\n.\nok\n([\nWidget\n,\n \nDoodad\n,\n \nTransformer\n]);\n\n    \n});\n\n\n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nServe Files and Set Cache-Control Headers\n\n\nclass\n \nAppChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nRouter\n();\n\n\n    \nrouter\n.\nroute\n(\n/files/*\n).\nlink\n(()\n \n=\n\n      \nFileController\n(\nweb\n)\n\n        \n..\naddCachePolicy\n(\nnew\n \nCachePolicy\n(\nexpirationFromNow:\n \nnew\n \nDuration\n(\ndays:\n \n365\n)),\n\n          \n(\npath\n)\n \n=\n \npath\n.\nendsWith\n(\n.js\n)\n \n||\n \npath\n.\nendsWith\n(\n.css\n))\n      \n    \n);\n\n\n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nStreaming Responses (Server Side Events with text/event-stream)\n\n\nclass\n \nAppChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \nfinal\n \nStreamController\nString\n \ncontroller\n \n=\n \nnew\n \nStreamController\nString\n();\n  \n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \nvar\n \ncount\n \n=\n \n0\n;\n\n     \nTimer\n.\nperiodic\n(\nnew\n \nDuration\n(\nseconds:\n \n1\n),\n \n(\n_\n)\n \n{\n\n      \ncount\n \n++\n;\n\n      \ncontroller\n.\nadd\n(\nThis server has been up for \n$\ncount\n seconds\n\\n\n);\n\n    \n});\n\n  \n}\n\n\n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nnew\n \nRouter\n();\n\n\n    \nrouter\n.\nroute\n(\n/stream\n).\nlinkFunction\n((\nreq\n)\n \nasync\n \n{\n\n      \nreturn\n \nResponse\n.\nok\n(\ncontroller\n.\nstream\n)\n\n          \n..\nbufferOutput\n \n=\n \nfalse\n\n          \n..\ncontentType\n \n=\n \nnew\n \nContentType\n(\n\n            \ntext\n,\n \nevent-stream\n,\n \ncharset:\n \nutf-8\n);\n\n    \n});\n\n\n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nA websocket server\n\n\nclass\n \nAppChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \nList\nWebSocket\n \nwebsockets\n \n=\n \n[];\n\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \n// When another isolate gets a websocket message, echo it to\n\n    \n// websockets connected on this isolate.\n\n    \nmessageHub\n.\nlisten\n(\nsendBytesToConnectedClients\n);\n\n  \n}\n\n\n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nRouter\n();\n\n\n    \n// Allow websocket clients to connect to ws://host/connect\n\n    \nrouter\n.\nroute\n(\n/connect\n).\nlinkFunction\n((\nrequest\n)\n \nasync\n \n{\n\n      \nvar\n \nwebsocket\n \n=\n \nawait\n \nWebSocketTransformer\n.\nupgrade\n(\nrequest\n.\nraw\n);\n\n      \nwebsocket\n.\nlisten\n(\necho\n,\n \nonDone:\n \n()\n \n{\n\n        \nwebsockets\n.\nremove\n(\nwebsocket\n);\n\n      \n},\n \ncancelOnError:\n \ntrue\n);\n\n      \nwebsockets\n.\nadd\n(\nwebsocket\n);\n\n\n      \n// Take request out of channel\n\n      \nreturn\n \nnull\n;\n\n    \n});\n\n\n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n  \nvoid\n \nsendBytesToConnectedClients\n(\nList\nint\n \nbytes\n)\n \n{\n\n    \nwebsockets\n.\nforEach\n((\nws\n)\n \n{\n\n      \nws\n.\nadd\n(\nbytes\n);\n\n    \n});\n\n  \n}\n\n\n  \nvoid\n \necho\n(\nList\nint\n \nbytes\n)\n \n{\n\n    \nsendBytesToConnectedClients\n(\nbytes\n);\n\n\n    \n// Send to other isolates\n\n    \nmessageHub\n.\nadd\n(\nbytes\n);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nSetting Content-Type and Encoding a Response Body\n\n\nclass\n \nAppChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \nfinal\n \nContentType\n \nCSV\n \n=\n \nContentType\n(\ntext\n,\n \ncsv\n,\n \ncharset:\n \nutf-8\n);\n\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \n// CsvCodec extends dart:convert.Codec\n\n    \nCodecRegistry\n.\ndefaultInstance\n.\nadd\n(\nCSV\n,\n \nnew\n \nCsvCodec\n());\n\n  \n}\n\n\n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nRouter\n();\n\n\n    \nrouter\n.\nroute\n(\n/csv\n).\nlinkFunction\n((\nreq\n)\n \nasync\n \n{\n\n      \n// These values will get converted by CsvCodec into a comma-separated string\n\n      \nreturn\n \nResponse\n.\nok\n([[\n1\n,\n \n2\n,\n \n3\n],\n \n[\na\n,\n \nb\n,\n \nc\n]])\n\n        \n..\ncontentType\n \n=\n \nCSV\n;\n\n    \n});\n\n\n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nProxy a File From Another Server\n\n\nclass\n \nAppChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nRouter\n();\n\n\n    \nrouter\n.\nroute\n(\n/proxy/*\n).\nlinkFunction\n((\nreq\n)\n \nasync\n \n{\n\n      \nvar\n \nfileURL\n \n=\n \nhttps://otherserver/\n${\nreq\n.\npath\n.\nremainingPath\n}\n;\n\n      \nvar\n \nfileRequest\n \n=\n \nawait\n \nclient\n.\ngetUrl\n(\nurl\n);\n\n      \nvar\n \nfileResponse\n \n=\n \nawait\n \nreq\n.\nclose\n();\n\n      \nif\n \n(\nfileResponse\n.\nstatusCode\n \n!=\n \n200\n)\n \n{\n\n        \nreturn\n \nnew\n \nResponse\n.\nnotFound\n();\n\n      \n}\n\n\n      \n// A dart:io.HttpResponse is a Stream\nList\nint\n of its body bytes.\n\n      \nreturn\n \nnew\n \nResponse\n.\nok\n(\nfileResponse\n)\n\n        \n..\ncontentType\n \n=\n \nfileResponse\n.\nheaders\n.\ncontentType\n\n        \n// let the data just pass through because it has already been encoded\n\n        \n// according to content-type; applying encoding again would cause\n\n        \n// an issue\n\n        \n..\nencodeBody\n \n=\n \nfalse\n;\n\n    \n});\n\n\n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n}", 
            "title": "HTTP"
        }, 
        {
            "location": "/snippets/http/#aqueduct-http-snippets", 
            "text": "", 
            "title": "Aqueduct HTTP Snippets"
        }, 
        {
            "location": "/snippets/http/#hello-world", 
            "text": "class   AppChannel   extends   ApplicationChannel   {   \n   @ override \n   Controller   get   entryPoint   { \n     final   router   =   Router (); \n\n     router . route ( /hello_world ). linkFunction (( request )   async   { \n       return   Response . ok ( Hello, world! ) \n         .. contentType   =   ContentType . TEXT ; \n     }); \n\n     return   router ; \n   }  }", 
            "title": "Hello, World"
        }, 
        {
            "location": "/snippets/http/#route-variables", 
            "text": "class   AppChannel   extends   ApplicationChannel   {   \n   @ override \n   Controller   get   entryPoint   { \n     final   router   =   Router (); \n\n     router . route ( /variable/[:variable] ). linkFunction (( request )   async   { \n       return   Response . ok ({ \n         method :   request . raw . method , \n         path :   request . path . variables [ variable ]   ??   not specified \n       });       \n     }); \n\n     return   router ; \n   }  }", 
            "title": "Route Variables"
        }, 
        {
            "location": "/snippets/http/#grouping-routes-and-binding-path-variables", 
            "text": "class   AppChannel   extends   ApplicationChannel   {   \n   @ override \n   Controller   get   entryPoint   { \n     final   router   =   Router (); \n\n     router \n       . route ( /users/[:id] ) \n       . link (()   =   MyController ()); \n\n     return   router ; \n   }  }  class   MyController   extends   ResourceController   { \n   final   List String   things   =   [ thing1 ,   thing2 ]; \n\n   @ Operation . get () \n   Future Response   getThings ()   async   { \n     return   Response . ok ( things ); \n   } \n\n   @ Operation . get ( id ) \n   Future Response   getThing ( @ Bind . path ( id )   int   id )   async   { \n     if   ( id     0   ||   id   =   things . length )   { \n       return   Response . notFound (); \n     } \n     return   Response . ok ( things [ id ]); \n   }  }", 
            "title": "Grouping Routes and Binding Path Variables"
        }, 
        {
            "location": "/snippets/http/#custom-middleware", 
            "text": "class   AppChannel   extends   ApplicationChannel   {   \n   @ override \n   Controller   get   entryPoint   { \n     final   router   =   Router (); \n\n     router \n       . route ( /rate_limit ) \n       . link (()   =   RateLimiter ()) \n       . linkFunction (( req )   async   =   Response . ok ({ \n         requests_remaining :   req . attachments [ remaining ] \n       })); \n\n     return   router ; \n   }  }  class   RateLimiter   extends   RequestController   { \n   @ override \n   Future RequestOrResponse   handle ( Request   request )   async   { \n     final   apiKey   =   request . raw . headers . value ( x-apikey ); \n     final   requestsRemaining   =   await   remainingRequestsForAPIKey ( apiKey ); \n     if   ( requestsRemaining   =   0 )   { \n       return   Response ( 429 ,   null ,   null ); \n     } \n\n     request . addResponseModifier (( r )   { \n       r . headers [ x-remaining-requests ]   =   requestsRemaining ; \n     }); \n\n     return   request ; \n   }  }", 
            "title": "Custom Middleware"
        }, 
        {
            "location": "/snippets/http/#application-wide-cors-allowed-origins", 
            "text": "class   AppChannel   extends   ApplicationChannel   { \n   @ override \n   Future   prepare ()   async   { \n     // All controllers will use this policy by default \n     CORSPolicy . defaultPolicy . allowedOrigins   =   [ https://mywebsite.com ]; \n   } \n\n   @ override \n   Controller   get   entryPoint   { \n     final   router   =   Router (); \n\n     router . route ( /things ). linkFunction (( request )   async   { \n       return   Response . ok ([ Widget ,   Doodad ,   Transformer ]); \n     }); \n\n     return   router ; \n   }  }", 
            "title": "Application-Wide CORS Allowed Origins"
        }, 
        {
            "location": "/snippets/http/#serve-files-and-set-cache-control-headers", 
            "text": "class   AppChannel   extends   ApplicationChannel   { \n   @ override \n   Controller   get   entryPoint   { \n     final   router   =   Router (); \n\n     router . route ( /files/* ). link (()   = \n       FileController ( web ) \n         .. addCachePolicy ( new   CachePolicy ( expirationFromNow:   new   Duration ( days:   365 )), \n           ( path )   =   path . endsWith ( .js )   ||   path . endsWith ( .css ))       \n     ); \n\n     return   router ; \n   }  }", 
            "title": "Serve Files and Set Cache-Control Headers"
        }, 
        {
            "location": "/snippets/http/#streaming-responses-server-side-events-with-textevent-stream", 
            "text": "class   AppChannel   extends   ApplicationChannel   { \n   final   StreamController String   controller   =   new   StreamController String ();   \n\n   @ override \n   Future   prepare ()   async   { \n     var   count   =   0 ; \n      Timer . periodic ( new   Duration ( seconds:   1 ),   ( _ )   { \n       count   ++ ; \n       controller . add ( This server has been up for  $ count  seconds \\n ); \n     }); \n   } \n\n   @ override \n   Controller   get   entryPoint   { \n     final   router   =   new   Router (); \n\n     router . route ( /stream ). linkFunction (( req )   async   { \n       return   Response . ok ( controller . stream ) \n           .. bufferOutput   =   false \n           .. contentType   =   new   ContentType ( \n             text ,   event-stream ,   charset:   utf-8 ); \n     }); \n\n     return   router ; \n   }  }", 
            "title": "Streaming Responses (Server Side Events with text/event-stream)"
        }, 
        {
            "location": "/snippets/http/#a-websocket-server", 
            "text": "class   AppChannel   extends   ApplicationChannel   { \n   List WebSocket   websockets   =   []; \n\n   @ override \n   Future   prepare ()   async   { \n     // When another isolate gets a websocket message, echo it to \n     // websockets connected on this isolate. \n     messageHub . listen ( sendBytesToConnectedClients ); \n   } \n\n   @ override \n   Controller   get   entryPoint   { \n     final   router   =   Router (); \n\n     // Allow websocket clients to connect to ws://host/connect \n     router . route ( /connect ). linkFunction (( request )   async   { \n       var   websocket   =   await   WebSocketTransformer . upgrade ( request . raw ); \n       websocket . listen ( echo ,   onDone:   ()   { \n         websockets . remove ( websocket ); \n       },   cancelOnError:   true ); \n       websockets . add ( websocket ); \n\n       // Take request out of channel \n       return   null ; \n     }); \n\n     return   router ; \n   } \n\n   void   sendBytesToConnectedClients ( List int   bytes )   { \n     websockets . forEach (( ws )   { \n       ws . add ( bytes ); \n     }); \n   } \n\n   void   echo ( List int   bytes )   { \n     sendBytesToConnectedClients ( bytes ); \n\n     // Send to other isolates \n     messageHub . add ( bytes ); \n   }  }", 
            "title": "A websocket server"
        }, 
        {
            "location": "/snippets/http/#setting-content-type-and-encoding-a-response-body", 
            "text": "class   AppChannel   extends   ApplicationChannel   { \n   final   ContentType   CSV   =   ContentType ( text ,   csv ,   charset:   utf-8 ); \n\n   @ override \n   Future   prepare ()   async   { \n     // CsvCodec extends dart:convert.Codec \n     CodecRegistry . defaultInstance . add ( CSV ,   new   CsvCodec ()); \n   } \n\n   @ override \n   Controller   get   entryPoint   { \n     final   router   =   Router (); \n\n     router . route ( /csv ). linkFunction (( req )   async   { \n       // These values will get converted by CsvCodec into a comma-separated string \n       return   Response . ok ([[ 1 ,   2 ,   3 ],   [ a ,   b ,   c ]]) \n         .. contentType   =   CSV ; \n     }); \n\n     return   router ; \n   }  }", 
            "title": "Setting Content-Type and Encoding a Response Body"
        }, 
        {
            "location": "/snippets/http/#proxy-a-file-from-another-server", 
            "text": "class   AppChannel   extends   ApplicationChannel   { \n   @ override \n   Controller   get   entryPoint   { \n     final   router   =   Router (); \n\n     router . route ( /proxy/* ). linkFunction (( req )   async   { \n       var   fileURL   =   https://otherserver/ ${ req . path . remainingPath } ; \n       var   fileRequest   =   await   client . getUrl ( url ); \n       var   fileResponse   =   await   req . close (); \n       if   ( fileResponse . statusCode   !=   200 )   { \n         return   new   Response . notFound (); \n       } \n\n       // A dart:io.HttpResponse is a Stream List int  of its body bytes. \n       return   new   Response . ok ( fileResponse ) \n         .. contentType   =   fileResponse . headers . contentType \n         // let the data just pass through because it has already been encoded \n         // according to content-type; applying encoding again would cause \n         // an issue \n         .. encodeBody   =   false ; \n     }); \n\n     return   router ; \n   }  }", 
            "title": "Proxy a File From Another Server"
        }, 
        {
            "location": "/snippets/orm/", 
            "text": "Aqueduct ORM Snippets\n\n\nFilter Query by Column/Property (WHERE clause)\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nEmployee\n(\ncontext\n)\n\n  \n..\nwhere\n((\ne\n)\n \n=\n \ne\n.\ntitle\n).\nequalTo\n(\nProgrammer\n);\n\n\nvar\n \nemployees\n \n=\n \nawait\n \nquery\n.\nfetch\n();\n\n\n\n\n\n\nFetching Only Some Columns/Properties\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nEmployee\n(\ncontext\n)\n\n  \n..\nresultingProperties\n((\ne\n)\n \n=\n \n[\ne\n.\nid\n,\n \ne\n.\nname\n]);\n\n\nvar\n \nemployees\n \n=\n \nawait\n \nquery\n.\nfetch\n();\n\n\n\n\n\n\nSorting Rows/Objects\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nEmployee\n(\ncontext\n)\n\n  \n..\nsortBy\n((\ne\n)\n \n=\n \ne\n.\nsalary\n,\n \nQuerySortOrder\n.\nascending\n);\n\n\nvar\n \nemployees\n \n=\n \nawait\n \nquery\n.\nfetch\n();\n\n\n\n\n\n\nFetching Only One Row/Object\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nEmployee\n(\ncontext\n)\n\n  \n..\nwhere\n((\ne\n)\n \n=\n \ne\n.\nid\n).\nequalTo\n(\n1\n);\n\n\nvar\n \nemployee\n \n=\n \nawait\n \nquery\n.\nfetchOne\n();\n\n\n\n\n\n\nExecuting a Join (Has-One)\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nTeam\n(\ncontext\n)\n\n  \n..\njoin\n(\nobject:\n \n(\ne\n)\n \n=\n \ne\n.\nleague\n);\n\n\nvar\n \nteamsAndTheirLeague\n \n=\n \nawait\n \nquery\n.\nfetch\n();\n\n\n\n\n\n\nExecuting a Join (Has-Many)\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nTeam\n(\ncontext\n)\n\n  \n..\njoin\n(\nset\n:\n \n(\ne\n)\n \n=\n \ne\n.\nplayers\n);\n\n\nvar\n \nteamsAndTheirPlayers\n \n=\n \nawait\n \nquery\n.\nfetch\n();\n\n\n\n\n\n\nFiltering Joined Rows/Objects\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nTeam\n(\ncontext\n);\n\n\n\nvar\n \nsubquery\n \n=\n \nquery\n.\njoin\n(\nset\n:\n \n(\ne\n)\n \n=\n \ne\n.\nplayers\n)\n\n  \n..\nwhere\n((\np\n)\n \n=\n \np\n.\nyearsPlayed\n).\nlessThanOrEqualTo\n(\n1\n);\n\n\n\nvar\n \nteamsAndTheirRookiePlayers\n \n=\n \nawait\n \nquery\n.\nfetch\n();\n\n\n\n\n\n\nFilter Rows/Objects by Relationship Property\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nTeam\n(\ncontext\n)\n\n  \n..\nwhere\n((\nt\n)\n \n=\n \nt\n.\nplayers\n.\nhaveAtLeastOneWhere\n.\nyearsPlayed\n).\nlessThanOrEqualTo\n(\n1\n);\n\n\n\nvar\n \nteamsWithRookies\n \n=\n \nawait\n \nquery\n.\nfetch\n();\n\n\n\n\n\n\nComplex/Unsupported WHERE Clause (using 'OR')\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nTeam\n(\ncontext\n)\n\n  \n..\npredicate\n \n=\n \nnew\n \nQueryPredicate\n(\nname = \n@name1\n OR name = \n@name2\n,\n \n{\n\n      \nname1\n:\n \nBadgers\n,\n\n      \nname2\n:\n \nGophers\n\n    \n});\n\n\n\nvar\n \nbadgerAndGopherTeams\n \n=\n \nawait\n \nquery\n.\nfetch\n();\n\n\n\n\n\n\nUpdating a Row/Object\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nTeam\n(\ncontext\n)\n\n  \n..\nwhere\n((\nt\n)\n \n=\n \nt\n.\nid\n).\nequalTo\n(\n10\n)\n\n  \n..\nvalues\n.\nname\n \n=\n \nBadgers\n;\n\n\n\nvar\n \nteam\n \n=\n \nawait\n \nquery\n.\nupdateOne\n();\n\n\n\n\n\n\nConfigure a Database Connection from Configuration File\n\n\nclass\n \nAppChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \ncontext\n \n=\n \ncontextWithConnectionInfo\n(\noptions\n.\nconfigurationFilePath\n.\ndatabase\n);\n\n  \n}\n\n\n  \nManagedContext\n \ncontext\n;\n\n\n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nnew\n \nRouter\n();\n\n    \n...\n\n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n  \nManagedContext\n \ncontextWithConnectionInfo\n(\n\n      \nDatabaseConnectionConfiguration\n \nconnectionInfo\n)\n \n{\n\n    \nvar\n \ndataModel\n \n=\n \nnew\n \nManagedDataModel\n.\nfromCurrentMirrorSystem\n();\n\n    \nvar\n \npsc\n \n=\n \nnew\n \nPostgreSQLPersistentStore\n(\n\n        \nconnectionInfo\n.\nusername\n,\n\n        \nconnectionInfo\n.\npassword\n,\n\n        \nconnectionInfo\n.\nhost\n,\n\n        \nconnectionInfo\n.\nport\n,\n\n        \nconnectionInfo\n.\ndatabaseName\n);\n\n\n    \nreturn\n \nnew\n \nManagedContext\n(\ndataModel\n,\n \npsc\n);\n\n  \n}\n\n\n}\n\n\n\nclass\n \nMyAppConfiguration\n \nextends\n \nConfigurationItem\n \n{\n\n  \nMyAppConfiguration\n(\nString\n \nfileName\n)\n \n:\n \nsuper\n.\nfromFile\n(\nfileName\n);\n\n\n  \nDatabaseConnectionConfiguration\n \ndatabase\n;\n\n\n}", 
            "title": "ORM"
        }, 
        {
            "location": "/snippets/orm/#aqueduct-orm-snippets", 
            "text": "", 
            "title": "Aqueduct ORM Snippets"
        }, 
        {
            "location": "/snippets/orm/#filter-query-by-columnproperty-where-clause", 
            "text": "var   query   =   new   Query Employee ( context ) \n   .. where (( e )   =   e . title ). equalTo ( Programmer );  var   employees   =   await   query . fetch ();", 
            "title": "Filter Query by Column/Property (WHERE clause)"
        }, 
        {
            "location": "/snippets/orm/#fetching-only-some-columnsproperties", 
            "text": "var   query   =   new   Query Employee ( context ) \n   .. resultingProperties (( e )   =   [ e . id ,   e . name ]);  var   employees   =   await   query . fetch ();", 
            "title": "Fetching Only Some Columns/Properties"
        }, 
        {
            "location": "/snippets/orm/#sorting-rowsobjects", 
            "text": "var   query   =   new   Query Employee ( context ) \n   .. sortBy (( e )   =   e . salary ,   QuerySortOrder . ascending );  var   employees   =   await   query . fetch ();", 
            "title": "Sorting Rows/Objects"
        }, 
        {
            "location": "/snippets/orm/#fetching-only-one-rowobject", 
            "text": "var   query   =   new   Query Employee ( context ) \n   .. where (( e )   =   e . id ). equalTo ( 1 );  var   employee   =   await   query . fetchOne ();", 
            "title": "Fetching Only One Row/Object"
        }, 
        {
            "location": "/snippets/orm/#executing-a-join-has-one", 
            "text": "var   query   =   new   Query Team ( context ) \n   .. join ( object:   ( e )   =   e . league );  var   teamsAndTheirLeague   =   await   query . fetch ();", 
            "title": "Executing a Join (Has-One)"
        }, 
        {
            "location": "/snippets/orm/#executing-a-join-has-many", 
            "text": "var   query   =   new   Query Team ( context ) \n   .. join ( set :   ( e )   =   e . players );  var   teamsAndTheirPlayers   =   await   query . fetch ();", 
            "title": "Executing a Join (Has-Many)"
        }, 
        {
            "location": "/snippets/orm/#filtering-joined-rowsobjects", 
            "text": "var   query   =   new   Query Team ( context );  var   subquery   =   query . join ( set :   ( e )   =   e . players ) \n   .. where (( p )   =   p . yearsPlayed ). lessThanOrEqualTo ( 1 );  var   teamsAndTheirRookiePlayers   =   await   query . fetch ();", 
            "title": "Filtering Joined Rows/Objects"
        }, 
        {
            "location": "/snippets/orm/#filter-rowsobjects-by-relationship-property", 
            "text": "var   query   =   new   Query Team ( context ) \n   .. where (( t )   =   t . players . haveAtLeastOneWhere . yearsPlayed ). lessThanOrEqualTo ( 1 );  var   teamsWithRookies   =   await   query . fetch ();", 
            "title": "Filter Rows/Objects by Relationship Property"
        }, 
        {
            "location": "/snippets/orm/#complexunsupported-where-clause-using-or", 
            "text": "var   query   =   new   Query Team ( context ) \n   .. predicate   =   new   QueryPredicate ( name =  @name1  OR name =  @name2 ,   { \n       name1 :   Badgers , \n       name2 :   Gophers \n     });  var   badgerAndGopherTeams   =   await   query . fetch ();", 
            "title": "Complex/Unsupported WHERE Clause (using 'OR')"
        }, 
        {
            "location": "/snippets/orm/#updating-a-rowobject", 
            "text": "var   query   =   new   Query Team ( context ) \n   .. where (( t )   =   t . id ). equalTo ( 10 ) \n   .. values . name   =   Badgers ;  var   team   =   await   query . updateOne ();", 
            "title": "Updating a Row/Object"
        }, 
        {
            "location": "/snippets/orm/#configure-a-database-connection-from-configuration-file", 
            "text": "class   AppChannel   extends   ApplicationChannel   { \n   @ override \n   Future   prepare ()   async   { \n     context   =   contextWithConnectionInfo ( options . configurationFilePath . database ); \n   } \n\n   ManagedContext   context ; \n\n   @ override \n   Controller   get   entryPoint   { \n     final   router   =   new   Router (); \n     ... \n     return   router ; \n   } \n\n   ManagedContext   contextWithConnectionInfo ( \n       DatabaseConnectionConfiguration   connectionInfo )   { \n     var   dataModel   =   new   ManagedDataModel . fromCurrentMirrorSystem (); \n     var   psc   =   new   PostgreSQLPersistentStore ( \n         connectionInfo . username , \n         connectionInfo . password , \n         connectionInfo . host , \n         connectionInfo . port , \n         connectionInfo . databaseName ); \n\n     return   new   ManagedContext ( dataModel ,   psc ); \n   }  }  class   MyAppConfiguration   extends   ConfigurationItem   { \n   MyAppConfiguration ( String   fileName )   :   super . fromFile ( fileName ); \n\n   DatabaseConnectionConfiguration   database ;  }", 
            "title": "Configure a Database Connection from Configuration File"
        }, 
        {
            "location": "/snippets/auth/", 
            "text": "Aqueduct Authorization and Authentication Snippets\n\n\nEnable OAuth 2.0\n\n\nimport\n \npackage:aqueduct/aqueduct.dart\n;\n\n\nimport\n \npackage:aqueduct/managed_auth.dart\n;\n\n\n\nclass\n \nAppChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \nAuthServer\n \nauthServer\n;\n\n  \nManagedContext\n \ncontext\n;\n\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \nfinal\n \ndataModel\n \n=\n \nnew\n \nManagedDataModel\n.\nfromCurrentMirrorSystem\n();\n\n    \nfinal\n \npsc\n \n=\n \nnew\n \nPostgreSQLPersistentStore\n(\n\n        \nusername\n,\n\n        \npassword\n,\n\n        \nlocalhost\n,\n\n        \n5432\n\n        \nmy_app\n);\n\n\n    \ncontext\n \n=\n \nnew\n \nManagedContext\n(\ndataModel\n,\n \npsc\n);\n\n\n    \nfinal\n \ndelegate\n \n=\n \nnew\n \nManagedAuthDelegate\nUser\n(\ncontext\n);\n\n    \nauthServer\n \n=\n \nnew\n \nAuthServer\n(\ndelegate\n);\n\n  \n}\n\n\n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nRouter\n();\n\n    \nrouter\n.\nroute\n(\n/auth/token\n).\nlink\n(()\n \n=\n \nAuthController\n(\nauthServer\n));\n  \n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nAdd OAuth 2.0 Clients to Database\n\n\naqueduct auth add-client \\\n  --id com.app.test \\\n  --secret supersecret \\\n  --allowed-scopes \nprofile kiosk:location raw_db_access.readonly\n \\\n  --connect postgres://username:password@localhost:5432/my_app\n\n\n\n\n\nRequire OAuth 2.0 Scope to Access Routes\n\n\nimport\n \npackage:aqueduct/aqueduct.dart\n;\n\n\nimport\n \npackage:aqueduct/managed_auth.dart\n;\n\n\n\nclass\n \nAppChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \nAuthServer\n \nauthServer\n;\n\n  \nManagedContext\n \ncontext\n;\n\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \nfinal\n \ndataModel\n \n=\n \nManagedDataModel\n.\nfromCurrentMirrorSystem\n();\n\n    \nfinal\n \npsc\n \n=\n \nPostgreSQLPersistentStore\n(\n\n        \nusername\n,\n\n        \npassword\n,\n\n        \nlocalhost\n,\n\n        \n5432\n\n        \nmy_app\n);\n\n\n    \ncontext\n \n=\n \nnew\n \nManagedContext\n(\ndataModel\n,\n \npsc\n);\n\n\n    \nfinal\n \ndelegate\n \n=\n \nManagedAuthDelegate\nUser\n(\ncontext\n);\n\n    \nauthServer\n \n=\n \nAuthServer\n(\ndelegate\n);\n\n  \n}\n\n\n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nrouter\n.\nroute\n(\n/auth/token\n).\nlink\n(()\n \n=\n \nAuthController\n(\nauthServer\n));\n\n\n    \nrouter\n\n      \n.\nroute\n(\n/profile\n)\n\n      \n.\nlink\n(()\n \n=\n \nAuthorizer\n.\nbearer\n(\nauthServer\n,\n \nscopes:\n \n[\nprofile.readonly\n]))\n\n      \n.\nlink\n(()\n \n=\n \nProfileController\n(\ncontext\n));\n\n  \n}\n\n\n}\n\n\n\nclass\n \nProfileController\n \nextends\n \nResourceController\n \n{\n\n  \nProfileController\n(\nthis\n.\ncontext\n);\n\n\n  \nfinal\n \nManagedContext\n \ncontext\n;\n\n\n  \n@\nOperation\n.\nget\n()\n\n  \nFuture\nResponse\n \ngetProfile\n()\n \nasync\n \n{\n\n    \nfinal\n \nid\n \n=\n \nrequest\n.\nauthorization\n.\nownerID\n;\n\n    \nfinal\n \nquery\n \n=\n \nnew\n \nQuery\nUser\n(\ncontext\n)\n\n      \n..\nwhere\n((\nu\n)\n \n=\n \nu\n.\nid\n).\nequalTo\n(\nid\n);\n\n\n    \nreturn\n \nnew\n \nResponse\n.\nok\n(\nawait\n \nquery\n.\nfetchOne\n());\n\n  \n}\n\n\n}\n\n\n\n\n\n\nBasic Authentication\n\n\nimport\n \npackage:aqueduct/aqueduct.dart\n;\n\n\n\nclass\n \nAppChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nnew\n \nRouter\n();\n\n    \nrouter\n\n      \n.\nroute\n(\n/profile\n)\n\n      \n.\nlink\n(()\n \n=\n \nAuthorizer\n.\nbasic\n(\nPasswordVerifier\n()))\n\n      \n.\nlinkFunction\n((\nreq\n)\n \nasync\n \n=\n \nnew\n \nResponse\n.\nok\n(\nnull\n));\n\n\n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n}\n\n\n\nclass\n \nPasswordVerifier\n \nextends\n \nAuthValidator\n \n{\n\n  \n@\noverride\n\n  \nFutureOr\nAuthorization\n \nvalidate\nT\n(\nAuthorizationParser\nT\n \nparser\n,\n \nT\n \nauthorizationData\n,\n \n{\nList\nAuthScope\n \nrequiredScope\n})\n \n{}\n\n    \nif\n \n(\n!\nisPasswordCorrect\n(\nauthorizationData\n))\n \n{\n\n      \nreturn\n \nnull\n;\n\n    \n}\n\n\n    \nreturn\n \nAuthorization\n(\nnull\n,\n \nauthorizationData\n.\nusername\n,\n \nthis\n);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nAdd OAuth 2.0 Authorization Code Flow\n\n\nimport\n \npackage:aqueduct/aqueduct.dart\n;\n\n\nimport\n \npackage:aqueduct/managed_auth.dart\n;\n\n\n\nclass\n \nAppChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \nAuthServer\n \nauthServer\n;\n\n  \nManagedContext\n \ncontext\n;\n\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \nfinal\n \ndataModel\n \n=\n \nManagedDataModel\n.\nfromCurrentMirrorSystem\n();\n\n    \nfinal\n \npsc\n \n=\n \nPostgreSQLPersistentStore\n(\n\n        \nusername\n,\n\n        \npassword\n,\n\n        \nlocalhost\n,\n\n        \n5432\n\n        \nmy_app\n);\n\n\n    \ncontext\n \n=\n \nnew\n \nManagedContext\n(\ndataModel\n,\n \npsc\n);\n\n\n    \nfinal\n \ndelegate\n \n=\n \nnew\n \nManagedAuthDelegate\nUser\n(\ncontext\n);\n\n    \nauthServer\n \n=\n \nnew\n \nAuthServer\n(\ndelegate\n);\n\n  \n}\n  \n\n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nnew\n \nRouter\n();\n\n\n    \nrouter\n.\nroute\n(\n/auth/token\n).\nlink\n(()\n \n=\n \nAuthController\n(\nauthServer\n));\n  \n\n    \nrouter\n.\nroute\n(\n/auth/code\n).\nlink\n(()\n \n=\n \nAuthCodeController\n(\nauthServer\n,\n \ndelegate:\n \nthis\n));\n\n\n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n  \nFuture\nString\n \nrender\n(\nAuthCodeController\n \nforController\n,\n \nUri\n \nrequestUri\n,\n \nString\n \nresponseType\n,\n \nString\n \nclientID\n,\n\n      \nString\n \nstate\n,\n \nString\n \nscope\n)\n \nasync\n \n{\n\n    \nreturn\n \n\n\n!DOCTYPE html\n\n\nhtml lang=\nen\n\n\n\nhead\n\n\n    \nmeta charset=\nUTF-8\n\n\n    \ntitle\nLogin\n/title\n\n\n/head\n\n\n\nbody\n\n\ndiv class=\ncontainer\n\n\n    \nh1\nLogin\n/h1\n\n\n    \nform action=\n${requestUri.path}\n method=\nPOST\n\n\n        \ninput type=\nhidden\n name=\nstate\n value=\n$state\n\n\n        \ninput type=\nhidden\n name=\nclient_id\n value=\n$clientID\n\n\n        \ninput type=\nhidden\n name=\nresponse_type\n value=\n$responseType\n\n\n        \ndiv class=\nform-group\n\n\n            \nlabel for=\nusername\nUser Name\n/label\n\n\n            \ninput type=\ntext\n class=\nform-control\n name=\nusername\n placeholder=\nPlease enter your user name\n\n\n        \n/div\n\n\n        \ndiv class=\nform-group\n\n\n            \nlabel for=\npassword\nPassword\n/label\n\n\n            \ninput type=\npassword\n class=\nform-control\n name=\npassword\n placeholder=\nPlease enter your password\n\n\n        \n/div\n\n\n        \nbutton type=\nsubmit\n class=\nbtn btn-success\nLogin\n/button\n\n\n    \n/form\n\n\n/div\n\n\n/body\n\n\n\n/html\n\n\n    \n;\n    \n  \n}\n\n\n}", 
            "title": "Authentication and Authorization"
        }, 
        {
            "location": "/snippets/auth/#aqueduct-authorization-and-authentication-snippets", 
            "text": "", 
            "title": "Aqueduct Authorization and Authentication Snippets"
        }, 
        {
            "location": "/snippets/auth/#enable-oauth-20", 
            "text": "import   package:aqueduct/aqueduct.dart ;  import   package:aqueduct/managed_auth.dart ;  class   AppChannel   extends   ApplicationChannel   { \n   AuthServer   authServer ; \n   ManagedContext   context ; \n\n   @ override \n   Future   prepare ()   async   { \n     final   dataModel   =   new   ManagedDataModel . fromCurrentMirrorSystem (); \n     final   psc   =   new   PostgreSQLPersistentStore ( \n         username , \n         password , \n         localhost , \n         5432 \n         my_app ); \n\n     context   =   new   ManagedContext ( dataModel ,   psc ); \n\n     final   delegate   =   new   ManagedAuthDelegate User ( context ); \n     authServer   =   new   AuthServer ( delegate ); \n   } \n\n   @ override \n   Controller   get   entryPoint   { \n     final   router   =   Router (); \n     router . route ( /auth/token ). link (()   =   AuthController ( authServer ));   \n     return   router ; \n   }  }", 
            "title": "Enable OAuth 2.0"
        }, 
        {
            "location": "/snippets/auth/#add-oauth-20-clients-to-database", 
            "text": "aqueduct auth add-client \\\n  --id com.app.test \\\n  --secret supersecret \\\n  --allowed-scopes  profile kiosk:location raw_db_access.readonly  \\\n  --connect postgres://username:password@localhost:5432/my_app", 
            "title": "Add OAuth 2.0 Clients to Database"
        }, 
        {
            "location": "/snippets/auth/#require-oauth-20-scope-to-access-routes", 
            "text": "import   package:aqueduct/aqueduct.dart ;  import   package:aqueduct/managed_auth.dart ;  class   AppChannel   extends   ApplicationChannel   { \n   AuthServer   authServer ; \n   ManagedContext   context ; \n\n   @ override \n   Future   prepare ()   async   { \n     final   dataModel   =   ManagedDataModel . fromCurrentMirrorSystem (); \n     final   psc   =   PostgreSQLPersistentStore ( \n         username , \n         password , \n         localhost , \n         5432 \n         my_app ); \n\n     context   =   new   ManagedContext ( dataModel ,   psc ); \n\n     final   delegate   =   ManagedAuthDelegate User ( context ); \n     authServer   =   AuthServer ( delegate ); \n   } \n\n   @ override \n   Controller   get   entryPoint   { \n     router . route ( /auth/token ). link (()   =   AuthController ( authServer )); \n\n     router \n       . route ( /profile ) \n       . link (()   =   Authorizer . bearer ( authServer ,   scopes:   [ profile.readonly ])) \n       . link (()   =   ProfileController ( context )); \n   }  }  class   ProfileController   extends   ResourceController   { \n   ProfileController ( this . context ); \n\n   final   ManagedContext   context ; \n\n   @ Operation . get () \n   Future Response   getProfile ()   async   { \n     final   id   =   request . authorization . ownerID ; \n     final   query   =   new   Query User ( context ) \n       .. where (( u )   =   u . id ). equalTo ( id ); \n\n     return   new   Response . ok ( await   query . fetchOne ()); \n   }  }", 
            "title": "Require OAuth 2.0 Scope to Access Routes"
        }, 
        {
            "location": "/snippets/auth/#basic-authentication", 
            "text": "import   package:aqueduct/aqueduct.dart ;  class   AppChannel   extends   ApplicationChannel   { \n   @ override \n   Controller   get   entryPoint   { \n     final   router   =   new   Router (); \n     router \n       . route ( /profile ) \n       . link (()   =   Authorizer . basic ( PasswordVerifier ())) \n       . linkFunction (( req )   async   =   new   Response . ok ( null )); \n\n     return   router ; \n   }  }  class   PasswordVerifier   extends   AuthValidator   { \n   @ override \n   FutureOr Authorization   validate T ( AuthorizationParser T   parser ,   T   authorizationData ,   { List AuthScope   requiredScope })   {} \n     if   ( ! isPasswordCorrect ( authorizationData ))   { \n       return   null ; \n     } \n\n     return   Authorization ( null ,   authorizationData . username ,   this ); \n   }  }", 
            "title": "Basic Authentication"
        }, 
        {
            "location": "/snippets/auth/#add-oauth-20-authorization-code-flow", 
            "text": "import   package:aqueduct/aqueduct.dart ;  import   package:aqueduct/managed_auth.dart ;  class   AppChannel   extends   ApplicationChannel   { \n   AuthServer   authServer ; \n   ManagedContext   context ; \n\n   @ override \n   Future   prepare ()   async   { \n     final   dataModel   =   ManagedDataModel . fromCurrentMirrorSystem (); \n     final   psc   =   PostgreSQLPersistentStore ( \n         username , \n         password , \n         localhost , \n         5432 \n         my_app ); \n\n     context   =   new   ManagedContext ( dataModel ,   psc ); \n\n     final   delegate   =   new   ManagedAuthDelegate User ( context ); \n     authServer   =   new   AuthServer ( delegate ); \n   }   \n\n   @ override \n   Controller   get   entryPoint   { \n     final   router   =   new   Router (); \n\n     router . route ( /auth/token ). link (()   =   AuthController ( authServer ));   \n\n     router . route ( /auth/code ). link (()   =   AuthCodeController ( authServer ,   delegate:   this )); \n\n     return   router ; \n   } \n\n   Future String   render ( AuthCodeController   forController ,   Uri   requestUri ,   String   responseType ,   String   clientID , \n       String   state ,   String   scope )   async   { \n     return    !DOCTYPE html  html lang= en  head       meta charset= UTF-8       title Login /title  /head  body  div class= container       h1 Login /h1       form action= ${requestUri.path}  method= POST           input type= hidden  name= state  value= $state           input type= hidden  name= client_id  value= $clientID           input type= hidden  name= response_type  value= $responseType           div class= form-group               label for= username User Name /label               input type= text  class= form-control  name= username  placeholder= Please enter your user name           /div           div class= form-group               label for= password Password /label               input type= password  class= form-control  name= password  placeholder= Please enter your password           /div           button type= submit  class= btn btn-success Login /button       /form  /div  /body  /html       ;     \n   }  }", 
            "title": "Add OAuth 2.0 Authorization Code Flow"
        }, 
        {
            "location": "/snippets/test/", 
            "text": "Aqueduct Test Snippets\n\n\nExpect that Response Returns a JSON Object with an ID\n\n\ntest\n(\nthat Response Returns a JSON Object\n,\n \n()\n \nasync\n \n{\n\n  \nexpectResponse\n(\n\n    \nawait\n \napp\n.\nclient\n.\nrequest\n(\n/endpoint\n).\nget\n(),\n\n    \n200\n,\n \nbody:\n \n{\n\n      \nid\n:\n \nisNumber\n\n    \n}\n\n  \n);\n\n\n});\n\n\n\n\n\n\nExpect that Response Returns a List of JSON Objects with IDs\n\n\ntest\n(\nthat Response returns a list of JSON Objects with IDs\n,\n \n()\n \nasync\n \n{\n\n  \nexpectResponse\n(\n\n    \nawait\n \napp\n.\nclient\n.\nrequest\n(\n/endpoint\n).\nget\n(),\n\n    \n200\n,\n \nbody:\n \neveryElement\n({\n\n      \nid\n:\n \nisNumber\n\n    \n})\n\n  \n);\n\n\n});\n\n\n\n\n\n\nExpect that Last-Modified Header Is After Date\n\n\ntest\n(\nthat Last-Modified Header Is After Date \n,\n \n()\n \nasync\n \n{\n\n  \nexpect\n(\n\n    \nawait\n \napp\n.\nclient\n.\nrequest\n(\n/endpoint\n).\nget\n(),\n\n    \nhasHeaders\n({\n\n      \nlast-modified\n:\n \nisAfter\n(\nnew\n \nDateTime\n(\n2017\n))\n\n    \n});\n\n\n});\n\n\n\n\n\n\nHTTP POST with JSON in Test\n\n\ntest\n(\nthat can send JSON body\n,\n \n()\n \nasync\n \n{\n\n  \nvar\n \nrequest\n \n=\n \napp\n.\nclient\n.\nrequest\n(\n/endpoint\n)\n\n    \n..\njson\n \n=\n \n{\n\n      \nid\n:\n \n1\n\n    \n};\n\n  \nexpect\n(\nawait\n \nrequest\n.\npost\n(),\n \nhasStatus\n(\n202\n));\n\n\n});", 
            "title": "Testing"
        }, 
        {
            "location": "/snippets/test/#aqueduct-test-snippets", 
            "text": "", 
            "title": "Aqueduct Test Snippets"
        }, 
        {
            "location": "/snippets/test/#expect-that-response-returns-a-json-object-with-an-id", 
            "text": "test ( that Response Returns a JSON Object ,   ()   async   { \n   expectResponse ( \n     await   app . client . request ( /endpoint ). get (), \n     200 ,   body:   { \n       id :   isNumber \n     } \n   );  });", 
            "title": "Expect that Response Returns a JSON Object with an ID"
        }, 
        {
            "location": "/snippets/test/#expect-that-response-returns-a-list-of-json-objects-with-ids", 
            "text": "test ( that Response returns a list of JSON Objects with IDs ,   ()   async   { \n   expectResponse ( \n     await   app . client . request ( /endpoint ). get (), \n     200 ,   body:   everyElement ({ \n       id :   isNumber \n     }) \n   );  });", 
            "title": "Expect that Response Returns a List of JSON Objects with IDs"
        }, 
        {
            "location": "/snippets/test/#expect-that-last-modified-header-is-after-date", 
            "text": "test ( that Last-Modified Header Is After Date  ,   ()   async   { \n   expect ( \n     await   app . client . request ( /endpoint ). get (), \n     hasHeaders ({ \n       last-modified :   isAfter ( new   DateTime ( 2017 )) \n     });  });", 
            "title": "Expect that Last-Modified Header Is After Date"
        }, 
        {
            "location": "/snippets/test/#http-post-with-json-in-test", 
            "text": "test ( that can send JSON body ,   ()   async   { \n   var   request   =   app . client . request ( /endpoint ) \n     .. json   =   { \n       id :   1 \n     }; \n   expect ( await   request . post (),   hasStatus ( 202 ));  });", 
            "title": "HTTP POST with JSON in Test"
        }, 
        {
            "location": "/tut/getting-started/", 
            "text": "1. Getting Started\n\n\nBy the end of this tutorial, you will have created an Aqueduct application that serves fictional heroes from a PostgreSQL database. You will learn the following:\n\n\n\n\nRun an Aqueduct application\n\n\nRoute HTTP requests to the appropriate handler in your code\n\n\nStore and retrieve database data\n\n\nWrite automated tests for each endpoint\n\n\n\n\n\n\nGetting Help\n\n\nIf at anytime you get stuck, hop on over to the \nAqueduct Slack channel\n.\n\n\n\n\nInstallation\n\n\nTo get started, make sure you have the following software installed:\n\n\n\n\nDart (\nInstall Instructions\n)\n\n\nIntelliJ IDEA or any other Jetbrains IDE, including the free Community Edition (\nInstall Instructions\n)\n\n\nThe IntelliJ IDEA Dart Plugin (\nInstall Instructions\n)\n\n\n\n\nInstall the \naqueduct\n command line tool by running the following command in your shell:\n\n\npub global activate aqueduct\n\n\n\n\n\n\n\nIf you get warning text about your \nPATH\n, make sure to read it before moving on.\n\n\n\n\nCreating a Project\n\n\nCreate a new project named \nheroes\n by entering the following in your shell:\n\n\naqueduct create heroes\n\n\n\n\n\nThis creates a \nheroes\n project directory. Open this directory with IntelliJ IDEA by dragging the project folder onto IntellIJ IDEA's icon.\n\n\nIn IntelliJ's project view, locate the \nlib\n directory; this is where your project's code will go. This project has two source files - \nheroes.dart\n and \nchannel.dart\n. Open the file \nheroes.dart\n. Click \nEnable Dart Support\n in the top right corner of the editor.\n\n\nHandling HTTP Requests\n\n\nIn your browser, navigate to \nhttp://aqueduct-tutorial.stablekernel.io\n. This browser application is a 'Hero Manager' - it allows a user to view, create, delete and update heroes. (It is a slightly modified version of the \nAngularDart Tour of Heroes Tutorial\n.) It will make HTTP requests to \nhttp://localhost:8888\n to fetch and manipulate hero data. The application you will build in this tutorial respond to those requests.\n\n\n\n\nRunning the Browser Application Locally\n\n\nThe browser application is served over HTTP so that it can access your Aqueduct application when it runs locally on your machine. Your browser may warn you about navigating to an insecure webpage, because it is in fact insecure. You can run this application locally by grabbing the source code from \nhere\n.\n\n\n\n\nIn this first chapter, you will write code to handle two requests: one to get a list of heroes, and the other to get a single hero by its identifier. These two requests take the following form:\n\n\n\n\nGET /heroes\n to the list of heroes\n\n\nGET /heroes/:id\n to get an individual hero\n\n\n\n\n\n\nHTTP Operation Shorthand\n\n\nAn HTTP request always contains an HTTP method (e.g., \nGET\n, \nPOST\n) and a URL (e.g., \nhttp://localhost:8888/heroes\n). Since you can host an application on another server and \nhttp\n is implied, we can reference requests by their method and path alone. The above two requests are an example of this shorthand reference. The ':id' segment is a variable: it can be 1, 2, 3, and so on.\n\n\n\n\nController Objects Handle Requests\n\n\nRequests are handled by \ncontroller objects\n. A controller object evaluates a request and takes some action on it. This might be responding to the request, validating it in some way, or any number of other tasks. Controllers are linked together, such that each of their actions are applied to a single request. This allows applications to construct powerful request handling logic from a few building blocks. A series of linked together controllers is called a \nchannel\n.\n\n\nOur application will link two controllers:\n\n\n\n\na \nRouter\n that makes sure the request path is \n/heroes\n or \n/heroes/:id\n\n\na \nHeroesControllers\n that construct a response with hero information in the body\n\n\n\n\nControllers are linked together in an \napplication channel\n. An application channel is an object that is created when your application first starts up. It handles the initialization of your application, including linking controllers.\n\n\n\n\nYou create an application channel by subclassing \nApplicationChannel\n. This subclass is declared in \nlib/channel.dart\n by the template. Navigate to that file and note the current implementation of \nApplicationChannel.entryPoint\n:\n\n\n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nRouter\n();\n\n\n    \nrouter\n\n      \n.\nroute\n(\n/example\n)\n\n      \n.\nlinkFunction\n((\nrequest\n)\n \nasync\n \n{\n\n        \nreturn\n \nResponse\n.\nok\n({\nkey\n:\n \nvalue\n});\n\n      \n});\n\n\n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n\n\n\n\nThe controller returned from \nentryPoint\n is the first controller to receive every request in an application - in our case, this is a \nRouter\n. Controllers are linked to the router; the template has one linked function controller that is called when a request's path is \n/example\n. We need to link a yet-to-be-created \nHeroesController\n to the router when the path is \n/heroes\n.\n\n\nFirst, we need to define \nHeroesController\n and how it handles requests. Create a new file in \nlib/controller/heroes_controller.dart\n and add the following code (you may need to create the subdirectory \nlib/controller/\n):\n\n\nimport\n \npackage:aqueduct/aqueduct.dart\n;\n\n\nimport\n \npackage:heroes/heroes.dart\n;\n\n\n\nclass\n \nHeroesController\n \nextends\n \nController\n \n{\n\n  \nfinal\n \n_heroes\n \n=\n \n[\n\n    \n{\nid\n:\n \n11\n,\n \nname\n:\n \nMr. Nice\n},\n\n    \n{\nid\n:\n \n12\n,\n \nname\n:\n \nNarco\n},\n\n    \n{\nid\n:\n \n13\n,\n \nname\n:\n \nBombasto\n},\n\n    \n{\nid\n:\n \n14\n,\n \nname\n:\n \nCeleritas\n},\n\n    \n{\nid\n:\n \n15\n,\n \nname\n:\n \nMagneta\n},\n    \n  \n];\n\n\n  \n@\noverride\n\n  \nFuture\nRequestOrResponse\n \nhandle\n(\nRequest\n \nrequest\n)\n \nasync\n \n{\n\n    \nreturn\n \nResponse\n.\nok\n(\n_heroes\n);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nNotice that \nHeroesController\n is a subclass of \nController\n; this allows it to be linked to other controllers and handle requests. It overrides its \nhandle\n method by returning a \nResponse\n object. This particular response object has a 200 OK status code, and it body contains a JSON-encoded list of hero objects. When a controller returns a \nResponse\n object from its \nhandle\n method, that response is sent to the client.\n\n\nAs it stands right now, our \nHeroesController\n will never be used. We need to link it to the entry point of our application for it to receive requests. First, import the file with our controller at the top of \nchannel.dart\n.\n\n\nimport\n \ncontroller/heroes_controller.dart\n;\n\n\n\n\n\n\nThen link this \nHeroesController\n to the \nRouter\n for the request's with the path \n/heroes\n by modifying \nentryPoint\n.\n\n\n@\noverride\n\n\nController\n \nget\n \nentryPoint\n \n{\n\n  \nfinal\n \nrouter\n \n=\n \nRouter\n();\n\n\n  \nrouter\n\n    \n.\nroute\n(\n/heroes\n)\n\n    \n.\nlink\n(()\n \n=\n \nHeroesController\n());\n\n\n  \nrouter\n\n    \n.\nroute\n(\n/example\n)\n\n    \n.\nlinkFunction\n((\nrequest\n)\n \nasync\n \n{\n\n      \nreturn\n \nnew\n \nResponse\n.\nok\n({\nkey\n:\n \nvalue\n});\n\n    \n});\n\n\n  \nreturn\n \nrouter\n;\n\n\n}\n\n\n\n\n\n\nWe now have a simple, functioning application that will return a list of heroes. In the project directory, run the following command from the command-line:\n\n\naqueduct serve\n\n\n\n\n\nThis will start your application running locally. Reload the browser page \nhttp://aqueduct-tutorial.stablekernel.io\n. It will make a request to \nhttp://localhost:8888/heroes\n and your application will serve it. You'll see your heroes in your web browser:\n\n\nScreenshot of Heroes Application\n\n\n\n\nYou can also see the actual response of your request by entering the following into your shell:\n\n\ncurl -X GET http://localhost:8888/heroes\n\n\n\n\n\nYou'll get JSON output like this:\n\n\n[\n\n  \n{\nid\n:\n11\n,\nname\n:\nMr. Nice\n},\n\n  \n{\nid\n:\n12\n,\nname\n:\nNarco\n},\n\n  \n{\nid\n:\n13\n,\nname\n:\nBombasto\n},\n\n  \n{\nid\n:\n14\n,\nname\n:\nCeleritas\n},\n\n  \n{\nid\n:\n15\n,\nname\n:\nMagneta\n}\n\n\n]\n\n\n\n\n\n\nYou'll also see this request logged in the shell that you started \naqueduct serve\n in.\n\n\n\n\nBrowser Clients\n\n\nIn addition to \ncurl\n, you can create a SwaggerUI browser application that executes requests against your locally running application. In your project directory, run \naqueduct document client\n and it will generate a file named \nclient.html\n. Open this file in your browser for a UI that constructs and executes requests that your application supports.\n\n\n\n\nLinking Controllers\n\n\nWhen a controller handles a request, it can either send a response or let one of its linked controllers handle the request. By default, a \nRouter\n will send a 404 Not Found response for any request. Adding a route to a \nRouter\n creates an entry point to a new channel that controllers can be linked to. In our application, \nHeroesController\n is linked to the route \n/heroes\n.\n\n\nControllers come in two different flavors: endpoint and middleware. Endpoint controllers, like \nHeroesController\n, always send a response. They implement the behavior that a request is seeking. Middleware controllers, like \nRouter\n, handles requests before they reach an endpoint controller. A router, for example, handles a request by directing it to the right controller. Controllers like \nAuthorizer\n verify the authorization of the request. You can create all kinds of controllers to provide any behavior you like.\n\n\nA channel can have zero or many middleware controllers, but must end in an endpoint controller. Most controllers can only have one linked controller, but a \nRouter\n allows for many. For example, a larger application might look like this:\n\n\n@\noverride\n\n\nController\n \nget\n \nentryPoint\n \n{\n\n  \nfinal\n \nrouter\n \n=\n \nRouter\n();\n\n\n  \nrouter\n\n    \n.\nroute\n(\n/users\n)\n\n    \n.\nlink\n(()\n \n=\n \nAPIKeyValidator\n())\n\n    \n.\nlink\n(()\n \n=\n \nAuthorizer\n.\nbearer\n())\n\n    \n.\nlink\n(()\n \n=\n \nUsersController\n());\n\n\n  \nrouter\n\n    \n.\nroute\n(\n/posts\n)\n\n    \n.\nlink\n(()\n \n=\n \nAPIKeyValidator\n())\n\n    \n.\nlink\n(()\n \n=\n \nPostsController\n());\n\n\n  \nreturn\n \nrouter\n;\n\n\n}\n\n\n\n\n\n\nEach of these objects is a subclass of \nController\n, giving them the ability to be linked together to handle requests. A request goes through controllers in the order they are linked. A request for the path \n/users\n will go through an \nAPIKeyValidator\n, an \nAuthorizer\n and finally a \nUsersController\n. Each of these controllers has an opportunity to respond, preventing the next controller from receiving the request.\n\n\nAdvanced Routing\n\n\nRight now, our application handles \nGET /heroes\n requests. The browser application uses the this list to populate its hero dashboard. If we click on an individual hero, the browser application will display an individual hero. When navigating to this page, the browser application makes a request to our server for an individual hero. This request contains the unique id of the selected hero in the path, e.g. \n/heroes/11\n or \n/heroes/13\n.\n\n\nOur server doesn't handle this request yet - it only handles requests that have exactly the path \n/heroes\n. Since a request for individual heroes will have a path that changes depending on the hero, we need our route to include a \npath variable\n.\n\n\nA path variable is a segment of route that matches a value for the same segment in the incoming request path. A path variable is a segment prefixed with a colon (\n:\n). For example, the route \n/heroes/:id\n contains a path variable named \nid\n. If the request path is \n/heroes/1\n, \n/heroes/2\n, and so on, the request will be sent to our \nHeroesController\n. The \nHeroesController\n will have access to the value of the path variable to determine which hero to return.\n\n\nThere's one hiccup. The route \n/heroes/:id\n no longer matches the path \n/heroes\n. It'd be a lot easier to organize our code if both \n/heroes\n and \n/heroes/:id\n went to our \nHeroesController\n; it does heroic stuff. For this reason, we can declare the \n:id\n portion of our route to be optional by wrapping it in square brackets. In \nchannel.dart\n, modify the \n/heroes\n route:\n\n\nrouter\n\n  \n.\nroute\n(\n/heroes/[:id]\n)\n\n  \n.\nlink\n(()\n \n=\n \nHeroesController\n());\n\n\n\n\n\n\nSince the second segment of the path is optional, the path \n/heroes\n still matches the route. If the path contains a second segment, the value of that segment is bound to the path variable named \nid\n. We can access path variables through the \nRequest\n object. In \nheroes_controller.dart\n, modify \nhandle\n:\n\n\n// In just a moment, we\nll replace this code with something even better,\n\n\n// but it\ns important to understand where this information comes from first!\n\n\n@\noverride\n\n\nFuture\nRequestOrResponse\n \nhandle\n(\nRequest\n \nrequest\n)\n \nasync\n \n{\n\n  \nif\n \n(\nrequest\n.\npath\n.\nvariables\n.\ncontainsKey\n(\nid\n))\n \n{\n\n    \nfinal\n \nid\n \n=\n \nint\n.\nparse\n(\nrequest\n.\npath\n.\nvariables\n[\nid\n]);\n\n    \nfinal\n \nhero\n \n=\n \n_heroes\n.\nfirstWhere\n((\nhero\n)\n \n=\n \nhero\n[\nid\n]\n \n==\n \nid\n,\n \norElse:\n \n()\n \n=\n \nnull\n);\n\n    \nif\n \n(\nhero\n \n==\n \nnull\n)\n \n{\n\n      \nreturn\n \nResponse\n.\nnotFound\n();\n\n    \n}\n\n\n    \nreturn\n \nResponse\n.\nok\n(\nhero\n);\n\n  \n}\n\n\n  \nreturn\n \nResponse\n.\nok\n(\n_heroes\n);\n\n\n}\n\n\n\n\n\n\nIn your shell currently running the application, hit Ctrl-C to stop the application. Then, run \naqueduct serve\n again. In the browser application, click on a hero and you will be taken to a detail page for that hero.\n\n\n\n\nYou can verify that your server is responding correctly by executing \ncurl -X GET http://localhost:8888/heroes/11\n to view the single hero object. You can also trigger a 404 Not Found response by getting a hero that doesn't exist.\n\n\nResourceControllers and Operation Methods\n\n\nOur \nHeroesController\n is OK right now, but it'll soon run into a problem: what happens when we want to create a new hero? Or update an existing hero's name? Our \nhandle\n method will start to get unmanageable, quickly.\n\n\nThat's where \nResourceController\n comes in. A \nResourceController\n allows you to create a distinct method for each operation that we can perform on our heroes. One method will handle getting a list of heroes, another will handle getting a single hero, and so on. Each method has an annotation that identifies the HTTP method and path variables the request must have to trigger it.\n\n\nIn \nheroes_controller.dart\n, replace \nHeroesController\n with the following:\n\n\nclass\n \nHeroesController\n \nextends\n \nResourceController\n \n{\n\n  \nfinal\n \n_heroes\n \n=\n \n[\n\n    \n{\nid\n:\n \n11\n,\n \nname\n:\n \nMr. Nice\n},\n\n    \n{\nid\n:\n \n12\n,\n \nname\n:\n \nNarco\n},\n\n    \n{\nid\n:\n \n13\n,\n \nname\n:\n \nBombasto\n},\n\n    \n{\nid\n:\n \n14\n,\n \nname\n:\n \nCeleritas\n},\n\n    \n{\nid\n:\n \n15\n,\n \nname\n:\n \nMagneta\n},\n\n  \n];\n\n\n  \n@\nOperation\n.\nget\n()\n\n  \nFuture\nResponse\n \ngetAllHeroes\n()\n \nasync\n \n{\n\n    \nreturn\n \nResponse\n.\nok\n(\n_heroes\n);\n\n  \n}\n\n\n  \n@\nOperation\n.\nget\n(\nid\n)\n\n  \nFuture\nResponse\n \ngetHeroByID\n()\n \nasync\n \n{\n\n    \nfinal\n \nid\n \n=\n \nint\n.\nparse\n(\nrequest\n.\npath\n.\nvariables\n[\nid\n]);\n\n    \nfinal\n \nhero\n \n=\n \n_heroes\n.\nfirstWhere\n((\nhero\n)\n \n=\n \nhero\n[\nid\n]\n \n==\n \nid\n,\n \norElse:\n \n()\n \n=\n \nnull\n);\n\n    \nif\n \n(\nhero\n \n==\n \nnull\n)\n \n{\n\n      \nreturn\n \nResponse\n.\nnotFound\n();\n\n    \n}\n\n\n    \nreturn\n \nResponse\n.\nok\n(\nhero\n);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nNotice that we didn't have to override \nhandle\n in \nResourceController\n. A \nResourceController\n implements this method to call one of our \noperation methods\n. An operation method - like \ngetAllHeroes\n and \ngetHeroByID\n - must have an \nOperation\n annotation. The named constructor \nOperation.get\n means these methods get called when the request's method is GET. An operation method must also return a \nFuture\nResponse\n.\n\n\ngetHeroByID\n's annotation also has an argument - the name of our path variable \nid\n. If that path variable exists in the request's path, \ngetHeroByID\n will be called. If it doesn't exist, \ngetAllHeroes\n will be called.\n\n\n\n\nNaming Operation Methods\n\n\nThe plain English phrase for an operation - like 'get hero by id' - is a really good name for an operation method and a good name will be useful when you generate OpenAPI documentation from your code.\n\n\n\n\nReload the application by hitting Ctrl-C in the terminal that ran \naqueduct serve\n and then run \naqueduct serve\n again. The browser application should still behave the same.\n\n\nRequest Binding\n\n\nIn our \ngetHeroByID\n method, we make a dangerous assumption that the path variable 'id' can be parsed into an integer. If 'id' were something else, like a string, \nint.parse\n would throw an exception. When exceptions are thrown in operation methods, the controller catches it and sends a 500 Server Error response. 500s are bad, they don't tell the client what's wrong. A 404 Not Found is a better response here, but writing the code to catch that exception and create this response is cumbersome.\n\n\nInstead, we can rely on a feature of operation methods called \nrequest binding\n. An operation method can declare parameters and \nbind\n them to properties of the request. When our operation method gets called, it will be passed values from the request as arguments. Request bindings automatically parse values into the type of the parameter (and return a better error response if parsing fails). Change the method \ngetHeroByID()\n:\n\n\n@\nOperation\n.\nget\n(\nid\n)\n\n\nFuture\nResponse\n \ngetHeroByID\n(\n@\nBind\n.\npath\n(\nid\n)\n \nint\n \nid\n)\n \nasync\n \n{\n\n  \nfinal\n \nhero\n \n=\n \n_heroes\n.\nfirstWhere\n((\nhero\n)\n \n=\n \nhero\n[\nid\n]\n \n==\n \nid\n,\n \norElse:\n \n()\n \n=\n \nnull\n);\n\n\n  \nif\n \n(\nhero\n \n==\n \nnull\n)\n \n{\n\n    \nreturn\n \nResponse\n.\nnotFound\n();\n\n  \n}\n\n\n  \nreturn\n \nResponse\n.\nok\n(\nhero\n);\n\n\n}\n\n\n\n\n\n\nThe value of the path variable \nid\n will be parsed as an integer and be available to this method in the \nid\n parameter. The \n@Bind\n annotation on an operation method parameter tells Aqueduct the value from the request we want bound. Using the named constructor \nBind.path\n binds a path variable, and the name of that variable is indicated in the argument to this constructor.\n\n\nYou can bind path variables, headers, query parameters and bodies. When binding path variables, we have to specify which path variable with the argument to \n@Bind.path(pathVariableName)\n.\n\n\n\n\nBound Parameter Names\n\n\nThe name of a bound parameter doesn't have to match the name of the path variable. We could have declared it as \n@Bind.path('id') int heroID\n. Only the argument to \nBind\n's constructor must match the actual name of the path variable. This is valuable for other types of bindings, like headers, that may contain characters that aren't valid Dart variable names, e.g. \nX-API-Key\n.\n\n\n\n\nThe More You Know: Multi-threading and Application State\n\n\nIn this simple exercise, we used a constant list of heroes as our source of data. For a simple getting-your-feet-wet demo, this is fine. However, in a real application, you'd store this data in a database. That way you could add data to it and not risk losing it when the application was restarted.\n\n\nMore generally, a web server should never hang on to data that can change. While previously just a best practice, stateless web servers are becoming a requirement with the prevalence of containerization and tools like Kubernetes. Aqueduct makes it a bit easier to detect violations of this rule with its multi-threading strategy.\n\n\nWhen you run an Aqueduct application, it creates multiple threads. Each of these threads has its own isolated heap in memory; meaning data that exists on one thread can't be accessed from other threads. In Dart, these isolated threads are called \nisolates\n.\n\n\nAn instance of your application channel is created for each isolate. Each HTTP request is given to just one of the isolates to be handled. In a sense, your one application behaves the same as running your application on multiple servers behind a load balancer. (It also makes your application substantially faster.)\n\n\nIf you are storing any data in your application, you'll find out really quick. Why? A request that changes data will only change that data in one of your application's isolates. When you make a request to get that data again, its unlikely that you'll see the changes - another isolate with different data will probably handle that request.\n\n\nNext Chapter: Reading from a Database", 
            "title": "1. Getting Started"
        }, 
        {
            "location": "/tut/getting-started/#1-getting-started", 
            "text": "By the end of this tutorial, you will have created an Aqueduct application that serves fictional heroes from a PostgreSQL database. You will learn the following:   Run an Aqueduct application  Route HTTP requests to the appropriate handler in your code  Store and retrieve database data  Write automated tests for each endpoint    Getting Help  If at anytime you get stuck, hop on over to the  Aqueduct Slack channel .", 
            "title": "1. Getting Started"
        }, 
        {
            "location": "/tut/getting-started/#installation", 
            "text": "To get started, make sure you have the following software installed:   Dart ( Install Instructions )  IntelliJ IDEA or any other Jetbrains IDE, including the free Community Edition ( Install Instructions )  The IntelliJ IDEA Dart Plugin ( Install Instructions )   Install the  aqueduct  command line tool by running the following command in your shell:  pub global activate aqueduct   If you get warning text about your  PATH , make sure to read it before moving on.", 
            "title": "Installation"
        }, 
        {
            "location": "/tut/getting-started/#creating-a-project", 
            "text": "Create a new project named  heroes  by entering the following in your shell:  aqueduct create heroes  This creates a  heroes  project directory. Open this directory with IntelliJ IDEA by dragging the project folder onto IntellIJ IDEA's icon.  In IntelliJ's project view, locate the  lib  directory; this is where your project's code will go. This project has two source files -  heroes.dart  and  channel.dart . Open the file  heroes.dart . Click  Enable Dart Support  in the top right corner of the editor.", 
            "title": "Creating a Project"
        }, 
        {
            "location": "/tut/getting-started/#handling-http-requests", 
            "text": "In your browser, navigate to  http://aqueduct-tutorial.stablekernel.io . This browser application is a 'Hero Manager' - it allows a user to view, create, delete and update heroes. (It is a slightly modified version of the  AngularDart Tour of Heroes Tutorial .) It will make HTTP requests to  http://localhost:8888  to fetch and manipulate hero data. The application you will build in this tutorial respond to those requests.   Running the Browser Application Locally  The browser application is served over HTTP so that it can access your Aqueduct application when it runs locally on your machine. Your browser may warn you about navigating to an insecure webpage, because it is in fact insecure. You can run this application locally by grabbing the source code from  here .   In this first chapter, you will write code to handle two requests: one to get a list of heroes, and the other to get a single hero by its identifier. These two requests take the following form:   GET /heroes  to the list of heroes  GET /heroes/:id  to get an individual hero    HTTP Operation Shorthand  An HTTP request always contains an HTTP method (e.g.,  GET ,  POST ) and a URL (e.g.,  http://localhost:8888/heroes ). Since you can host an application on another server and  http  is implied, we can reference requests by their method and path alone. The above two requests are an example of this shorthand reference. The ':id' segment is a variable: it can be 1, 2, 3, and so on.", 
            "title": "Handling HTTP Requests"
        }, 
        {
            "location": "/tut/getting-started/#controller-objects-handle-requests", 
            "text": "Requests are handled by  controller objects . A controller object evaluates a request and takes some action on it. This might be responding to the request, validating it in some way, or any number of other tasks. Controllers are linked together, such that each of their actions are applied to a single request. This allows applications to construct powerful request handling logic from a few building blocks. A series of linked together controllers is called a  channel .  Our application will link two controllers:   a  Router  that makes sure the request path is  /heroes  or  /heroes/:id  a  HeroesControllers  that construct a response with hero information in the body   Controllers are linked together in an  application channel . An application channel is an object that is created when your application first starts up. It handles the initialization of your application, including linking controllers.   You create an application channel by subclassing  ApplicationChannel . This subclass is declared in  lib/channel.dart  by the template. Navigate to that file and note the current implementation of  ApplicationChannel.entryPoint :     @ override \n   Controller   get   entryPoint   { \n     final   router   =   Router (); \n\n     router \n       . route ( /example ) \n       . linkFunction (( request )   async   { \n         return   Response . ok ({ key :   value }); \n       }); \n\n     return   router ; \n   }   The controller returned from  entryPoint  is the first controller to receive every request in an application - in our case, this is a  Router . Controllers are linked to the router; the template has one linked function controller that is called when a request's path is  /example . We need to link a yet-to-be-created  HeroesController  to the router when the path is  /heroes .  First, we need to define  HeroesController  and how it handles requests. Create a new file in  lib/controller/heroes_controller.dart  and add the following code (you may need to create the subdirectory  lib/controller/ ):  import   package:aqueduct/aqueduct.dart ;  import   package:heroes/heroes.dart ;  class   HeroesController   extends   Controller   { \n   final   _heroes   =   [ \n     { id :   11 ,   name :   Mr. Nice }, \n     { id :   12 ,   name :   Narco }, \n     { id :   13 ,   name :   Bombasto }, \n     { id :   14 ,   name :   Celeritas }, \n     { id :   15 ,   name :   Magneta },     \n   ]; \n\n   @ override \n   Future RequestOrResponse   handle ( Request   request )   async   { \n     return   Response . ok ( _heroes ); \n   }  }   Notice that  HeroesController  is a subclass of  Controller ; this allows it to be linked to other controllers and handle requests. It overrides its  handle  method by returning a  Response  object. This particular response object has a 200 OK status code, and it body contains a JSON-encoded list of hero objects. When a controller returns a  Response  object from its  handle  method, that response is sent to the client.  As it stands right now, our  HeroesController  will never be used. We need to link it to the entry point of our application for it to receive requests. First, import the file with our controller at the top of  channel.dart .  import   controller/heroes_controller.dart ;   Then link this  HeroesController  to the  Router  for the request's with the path  /heroes  by modifying  entryPoint .  @ override  Controller   get   entryPoint   { \n   final   router   =   Router (); \n\n   router \n     . route ( /heroes ) \n     . link (()   =   HeroesController ()); \n\n   router \n     . route ( /example ) \n     . linkFunction (( request )   async   { \n       return   new   Response . ok ({ key :   value }); \n     }); \n\n   return   router ;  }   We now have a simple, functioning application that will return a list of heroes. In the project directory, run the following command from the command-line:  aqueduct serve  This will start your application running locally. Reload the browser page  http://aqueduct-tutorial.stablekernel.io . It will make a request to  http://localhost:8888/heroes  and your application will serve it. You'll see your heroes in your web browser:", 
            "title": "Controller Objects Handle Requests"
        }, 
        {
            "location": "/tut/getting-started/#screenshot-of-heroes-application", 
            "text": "You can also see the actual response of your request by entering the following into your shell:  curl -X GET http://localhost:8888/heroes  You'll get JSON output like this:  [ \n   { id : 11 , name : Mr. Nice }, \n   { id : 12 , name : Narco }, \n   { id : 13 , name : Bombasto }, \n   { id : 14 , name : Celeritas }, \n   { id : 15 , name : Magneta }  ]   You'll also see this request logged in the shell that you started  aqueduct serve  in.   Browser Clients  In addition to  curl , you can create a SwaggerUI browser application that executes requests against your locally running application. In your project directory, run  aqueduct document client  and it will generate a file named  client.html . Open this file in your browser for a UI that constructs and executes requests that your application supports.", 
            "title": "Screenshot of Heroes Application"
        }, 
        {
            "location": "/tut/getting-started/#linking-controllers", 
            "text": "When a controller handles a request, it can either send a response or let one of its linked controllers handle the request. By default, a  Router  will send a 404 Not Found response for any request. Adding a route to a  Router  creates an entry point to a new channel that controllers can be linked to. In our application,  HeroesController  is linked to the route  /heroes .  Controllers come in two different flavors: endpoint and middleware. Endpoint controllers, like  HeroesController , always send a response. They implement the behavior that a request is seeking. Middleware controllers, like  Router , handles requests before they reach an endpoint controller. A router, for example, handles a request by directing it to the right controller. Controllers like  Authorizer  verify the authorization of the request. You can create all kinds of controllers to provide any behavior you like.  A channel can have zero or many middleware controllers, but must end in an endpoint controller. Most controllers can only have one linked controller, but a  Router  allows for many. For example, a larger application might look like this:  @ override  Controller   get   entryPoint   { \n   final   router   =   Router (); \n\n   router \n     . route ( /users ) \n     . link (()   =   APIKeyValidator ()) \n     . link (()   =   Authorizer . bearer ()) \n     . link (()   =   UsersController ()); \n\n   router \n     . route ( /posts ) \n     . link (()   =   APIKeyValidator ()) \n     . link (()   =   PostsController ()); \n\n   return   router ;  }   Each of these objects is a subclass of  Controller , giving them the ability to be linked together to handle requests. A request goes through controllers in the order they are linked. A request for the path  /users  will go through an  APIKeyValidator , an  Authorizer  and finally a  UsersController . Each of these controllers has an opportunity to respond, preventing the next controller from receiving the request.", 
            "title": "Linking Controllers"
        }, 
        {
            "location": "/tut/getting-started/#advanced-routing", 
            "text": "Right now, our application handles  GET /heroes  requests. The browser application uses the this list to populate its hero dashboard. If we click on an individual hero, the browser application will display an individual hero. When navigating to this page, the browser application makes a request to our server for an individual hero. This request contains the unique id of the selected hero in the path, e.g.  /heroes/11  or  /heroes/13 .  Our server doesn't handle this request yet - it only handles requests that have exactly the path  /heroes . Since a request for individual heroes will have a path that changes depending on the hero, we need our route to include a  path variable .  A path variable is a segment of route that matches a value for the same segment in the incoming request path. A path variable is a segment prefixed with a colon ( : ). For example, the route  /heroes/:id  contains a path variable named  id . If the request path is  /heroes/1 ,  /heroes/2 , and so on, the request will be sent to our  HeroesController . The  HeroesController  will have access to the value of the path variable to determine which hero to return.  There's one hiccup. The route  /heroes/:id  no longer matches the path  /heroes . It'd be a lot easier to organize our code if both  /heroes  and  /heroes/:id  went to our  HeroesController ; it does heroic stuff. For this reason, we can declare the  :id  portion of our route to be optional by wrapping it in square brackets. In  channel.dart , modify the  /heroes  route:  router \n   . route ( /heroes/[:id] ) \n   . link (()   =   HeroesController ());   Since the second segment of the path is optional, the path  /heroes  still matches the route. If the path contains a second segment, the value of that segment is bound to the path variable named  id . We can access path variables through the  Request  object. In  heroes_controller.dart , modify  handle :  // In just a moment, we ll replace this code with something even better,  // but it s important to understand where this information comes from first!  @ override  Future RequestOrResponse   handle ( Request   request )   async   { \n   if   ( request . path . variables . containsKey ( id ))   { \n     final   id   =   int . parse ( request . path . variables [ id ]); \n     final   hero   =   _heroes . firstWhere (( hero )   =   hero [ id ]   ==   id ,   orElse:   ()   =   null ); \n     if   ( hero   ==   null )   { \n       return   Response . notFound (); \n     } \n\n     return   Response . ok ( hero ); \n   } \n\n   return   Response . ok ( _heroes );  }   In your shell currently running the application, hit Ctrl-C to stop the application. Then, run  aqueduct serve  again. In the browser application, click on a hero and you will be taken to a detail page for that hero.   You can verify that your server is responding correctly by executing  curl -X GET http://localhost:8888/heroes/11  to view the single hero object. You can also trigger a 404 Not Found response by getting a hero that doesn't exist.", 
            "title": "Advanced Routing"
        }, 
        {
            "location": "/tut/getting-started/#resourcecontrollers-and-operation-methods", 
            "text": "Our  HeroesController  is OK right now, but it'll soon run into a problem: what happens when we want to create a new hero? Or update an existing hero's name? Our  handle  method will start to get unmanageable, quickly.  That's where  ResourceController  comes in. A  ResourceController  allows you to create a distinct method for each operation that we can perform on our heroes. One method will handle getting a list of heroes, another will handle getting a single hero, and so on. Each method has an annotation that identifies the HTTP method and path variables the request must have to trigger it.  In  heroes_controller.dart , replace  HeroesController  with the following:  class   HeroesController   extends   ResourceController   { \n   final   _heroes   =   [ \n     { id :   11 ,   name :   Mr. Nice }, \n     { id :   12 ,   name :   Narco }, \n     { id :   13 ,   name :   Bombasto }, \n     { id :   14 ,   name :   Celeritas }, \n     { id :   15 ,   name :   Magneta }, \n   ]; \n\n   @ Operation . get () \n   Future Response   getAllHeroes ()   async   { \n     return   Response . ok ( _heroes ); \n   } \n\n   @ Operation . get ( id ) \n   Future Response   getHeroByID ()   async   { \n     final   id   =   int . parse ( request . path . variables [ id ]); \n     final   hero   =   _heroes . firstWhere (( hero )   =   hero [ id ]   ==   id ,   orElse:   ()   =   null ); \n     if   ( hero   ==   null )   { \n       return   Response . notFound (); \n     } \n\n     return   Response . ok ( hero ); \n   }  }   Notice that we didn't have to override  handle  in  ResourceController . A  ResourceController  implements this method to call one of our  operation methods . An operation method - like  getAllHeroes  and  getHeroByID  - must have an  Operation  annotation. The named constructor  Operation.get  means these methods get called when the request's method is GET. An operation method must also return a  Future Response .  getHeroByID 's annotation also has an argument - the name of our path variable  id . If that path variable exists in the request's path,  getHeroByID  will be called. If it doesn't exist,  getAllHeroes  will be called.   Naming Operation Methods  The plain English phrase for an operation - like 'get hero by id' - is a really good name for an operation method and a good name will be useful when you generate OpenAPI documentation from your code.   Reload the application by hitting Ctrl-C in the terminal that ran  aqueduct serve  and then run  aqueduct serve  again. The browser application should still behave the same.", 
            "title": "ResourceControllers and Operation Methods"
        }, 
        {
            "location": "/tut/getting-started/#request-binding", 
            "text": "In our  getHeroByID  method, we make a dangerous assumption that the path variable 'id' can be parsed into an integer. If 'id' were something else, like a string,  int.parse  would throw an exception. When exceptions are thrown in operation methods, the controller catches it and sends a 500 Server Error response. 500s are bad, they don't tell the client what's wrong. A 404 Not Found is a better response here, but writing the code to catch that exception and create this response is cumbersome.  Instead, we can rely on a feature of operation methods called  request binding . An operation method can declare parameters and  bind  them to properties of the request. When our operation method gets called, it will be passed values from the request as arguments. Request bindings automatically parse values into the type of the parameter (and return a better error response if parsing fails). Change the method  getHeroByID() :  @ Operation . get ( id )  Future Response   getHeroByID ( @ Bind . path ( id )   int   id )   async   { \n   final   hero   =   _heroes . firstWhere (( hero )   =   hero [ id ]   ==   id ,   orElse:   ()   =   null ); \n\n   if   ( hero   ==   null )   { \n     return   Response . notFound (); \n   } \n\n   return   Response . ok ( hero );  }   The value of the path variable  id  will be parsed as an integer and be available to this method in the  id  parameter. The  @Bind  annotation on an operation method parameter tells Aqueduct the value from the request we want bound. Using the named constructor  Bind.path  binds a path variable, and the name of that variable is indicated in the argument to this constructor.  You can bind path variables, headers, query parameters and bodies. When binding path variables, we have to specify which path variable with the argument to  @Bind.path(pathVariableName) .   Bound Parameter Names  The name of a bound parameter doesn't have to match the name of the path variable. We could have declared it as  @Bind.path('id') int heroID . Only the argument to  Bind 's constructor must match the actual name of the path variable. This is valuable for other types of bindings, like headers, that may contain characters that aren't valid Dart variable names, e.g.  X-API-Key .", 
            "title": "Request Binding"
        }, 
        {
            "location": "/tut/getting-started/#the-more-you-know-multi-threading-and-application-state", 
            "text": "In this simple exercise, we used a constant list of heroes as our source of data. For a simple getting-your-feet-wet demo, this is fine. However, in a real application, you'd store this data in a database. That way you could add data to it and not risk losing it when the application was restarted.  More generally, a web server should never hang on to data that can change. While previously just a best practice, stateless web servers are becoming a requirement with the prevalence of containerization and tools like Kubernetes. Aqueduct makes it a bit easier to detect violations of this rule with its multi-threading strategy.  When you run an Aqueduct application, it creates multiple threads. Each of these threads has its own isolated heap in memory; meaning data that exists on one thread can't be accessed from other threads. In Dart, these isolated threads are called  isolates .  An instance of your application channel is created for each isolate. Each HTTP request is given to just one of the isolates to be handled. In a sense, your one application behaves the same as running your application on multiple servers behind a load balancer. (It also makes your application substantially faster.)  If you are storing any data in your application, you'll find out really quick. Why? A request that changes data will only change that data in one of your application's isolates. When you make a request to get that data again, its unlikely that you'll see the changes - another isolate with different data will probably handle that request.", 
            "title": "The More You Know: Multi-threading and Application State"
        }, 
        {
            "location": "/tut/getting-started/#next-chapter-reading-from-a-database", 
            "text": "", 
            "title": "Next Chapter: Reading from a Database"
        }, 
        {
            "location": "/tut/executing-queries/", 
            "text": "2. Reading from a Database\n\n\nWe will continue to build on the last chapter's project, \nheroes\n, by storing our heroes in a database. This will let us to edit our heroes and keep the changes when we restart the application.\n\n\nObject-Relational Mapping\n\n\nA relational database management system (like PostgreSQL or MySQL) stores its data in the form of tables. A table represents some sort of entity - like a person or a bank account. Each table has columns that describe the attributes of that entity - like a name or a balance. Every row in a table is an instance of that entity - like a single person named Bob or a bank account.\n\n\nIn an object-oriented framework like Aqueduct, we have representations for tables, columns and rows. A class represents a table, its instances are rows, and instance properties are column values. An ORM translates rows in a database to and from objects in an application.\n\n\n\n\n\n\n\n\nAqueduct\n\n\nDatabase\n\n\nExample #1\n\n\nExample #2\n\n\n\n\n\n\n\n\n\n\nClass\n\n\nTable\n\n\nPerson\n\n\nBank Account\n\n\n\n\n\n\nInstance\n\n\nRow\n\n\nA person named Bob\n\n\nSally's Bank Account\n\n\n\n\n\n\nProperty\n\n\nColumn\n\n\nPerson's Name\n\n\nBank Account Balance\n\n\n\n\n\n\n\n\nIn Aqueduct, each database table-class pairing is called an \nentity\n. Collectively, an application's entities are called its \ndata model\n.\n\n\nBuilding a Data Model\n\n\nIn our \nheroes\n application, we will have one type of entity - a \"hero\". To create a new entity, we subclass \nManagedObject\nT\n. Create a new directory \nlib/model/\n and then add a new file to this directory named \nhero.dart\n. Add the following code:\n\n\nimport\n \npackage:heroes/heroes.dart\n;\n\n\n\nclass\n \nHero\n \nextends\n \nManagedObject\n_Hero\n \nimplements\n \n_Hero\n \n{}\n\n\n\nclass\n \n_Hero\n \n{\n\n  \n@\nprimaryKey\n\n  \nint\n \nid\n;\n\n\n  \n@\nColumn\n(\nunique:\n \ntrue\n)\n\n  \nString\n \nname\n;\n\n\n}\n\n\n\n\n\n\nThis declares a \nHero\n entity. Entities are always made up of two classes.\n\n\nThe \n_Hero\n class is a direct mapping of a database table. This table's name will have the same name as the class: \n_Hero\n. Every property declared in this class will have a corresponding column in this table. Therefore, the \n_Hero\n table will have two columns - \nid\n and \nname\n. The \nid\n column is this table's primary key (a unique identifier for each hero). The name of each hero must be unique.\n\n\nThe other class, \nHero\n, is what we work with in our code - when we fetch heroes from a database, they will be instances of \nHero\n.\n\n\nThe \nHero\n class is called the \ninstance type\n of the entity, because that's what we have instances of. \n_Hero\n is the \ntable definition\n of the entity. You won't use the table definition for anything other than describing the database table.\n\n\nAn instance type must \nimplement\n its table definition; this gives our \nHero\n all of the properties of \n_Hero\n. An instance type must \nextend\n \nManagedObject\nT\n, where \nT\n is also the table definition. \nManagedObject\nT\n has behavior for automatically transferring objects to the database and back (among other things).\n\n\n\n\nTransient Properties\n\n\nProperties declared in the instance type aren't stored in the database. This is different than properties in the table definition. For example, a database table might have a \nfirstName\n and \nlastName\n, but it's useful in some places to have a \nfullName\n property. Declaring the \nfullName\n property in the instance type means we have easy access to the full name, but we still store the first and last name individually.\n\n\n\n\nDefining a Context\n\n\nOur application needs to know two things to execute database queries:\n\n\n\n\nWhat is the data model (our collection of entities)?\n\n\nWhat database are we connecting to?\n\n\n\n\nBoth of these things are set up when an application is first started. In \nchannel.dart\n, add a new property \ncontext\n and update \nprepare()\n:\n\n\nclass\n \nHeroesChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \nManagedContext\n \ncontext\n;\n\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \nlogger\n.\nonRecord\n.\nlisten\n((\nrec\n)\n \n=\n \nprint\n(\n$\nrec\n \n${\nrec\n.\nerror\n \n??\n \n}\n \n${\nrec\n.\nstackTrace\n \n??\n \n}\n));\n\n\n    \nfinal\n \ndataModel\n \n=\n \nManagedDataModel\n.\nfromCurrentMirrorSystem\n();\n\n    \nfinal\n \npersistentStore\n \n=\n \nPostgreSQLPersistentStore\n.\nfromConnectionInfo\n(\n\n      \nheroes_user\n,\n \npassword\n,\n \nlocalhost\n,\n \n5432\n,\n \nheroes\n);\n\n\n    \ncontext\n \n=\n \nManagedContext\n(\ndataModel\n,\n \npersistentStore\n);\n\n  \n}\n\n\n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \n...\n\n\n\n\n\n\nManagedDataModel.fromCurrentMirrorSystem()\n will find all of our \nManagedObject\nT\n subclasses and 'compile' them into a data model. A \nPostgreSQLPersistentStore\n takes database connection information that it will use to connect and send queries to a database. Together, these objects are packaged in a \nManagedContext\n.\n\n\n\n\nConfiguring a Database Connection\n\n\nThis tutorial hardcodes the information needed to connect to a database. In a future chapter, we will move these values to a configuration file so that we can change them during tests and various deployment environments.\n\n\n\n\nThe context will coordinate with these two objects to execute queries and translate objects to and from the database. Controllers that make database queries need a reference to the context. So, we'll want \nHeroesController\n to have access to the context.\n\n\nIn \nheroes_controller.dart\n, add a property and create a new constructor:\n\n\nclass\n \nHeroesController\n \nextends\n \nResourceController\n \n{\n\n  \nHeroesController\n(\nthis\n.\ncontext\n);\n\n\n  \nfinal\n \nManagedContext\n \ncontext\n;\n  \n  \n...\n\n\n\n\n\n\nNow that \nHeroesController\n requires a context in its constructor, we need to pass it the context we created in \nprepare()\n. Update \nentryPoint\n in \nchannel.dart\n.\n\n\n@\noverride\n\n\nController\n \nget\n \nentryPoint\n \n{\n\n  \nfinal\n \nrouter\n \n=\n \nRouter\n();\n\n\n  \nrouter\n\n    \n.\nroute\n(\n/heroes/[:id]\n)\n\n    \n.\nlink\n(()\n \n=\n \nHeroesController\n(\ncontext\n));\n\n\n  \nrouter\n\n    \n.\nroute\n(\n/example\n)\n\n    \n.\nlinkFunction\n((\nrequest\n)\n \nasync\n \n{\n\n      \nreturn\n \nnew\n \nResponse\n.\nok\n({\nkey\n:\n \nvalue\n});\n\n  \n});\n\n\n  \nreturn\n \nrouter\n;\n\n\n}\n\n\n\n\n\n\nNow that we've 'injected' this context into our \nHeroesController\n constructor, each \nHeroesController\n can execute database queries.\n\n\n\n\nService Objects and Dependency Injection\n\n\nOur context is an example of a \nservice object\n. A service encapsulates logic and state into a single object that can be reused in multiple controllers. A typical service object accesses another server, like a database or another REST API. Some service objects may simply provide a simplified interface to a complex process, like applying transforms to an image. Services are passed in a controller's constructor;\nthis is called \ndependency injection\n. Unlike many frameworks, Aqueduct does not require a complex dependency injection framework; this is because you write the code to create instances of your controllers and can pass whatever you like in their constructor.\n\n\n\n\nExecuting Queries\n\n\nOur operation methods in \nHeroesController\n currently return heroes from an in-memory list. To fetch data from a database instead of this list, we create and execute instances of \nQuery\nT\n in our \nManagedContext\n.\n\n\nLet's start by replacing \ngetAllHeroes\n in \nheroes_controller.dart\n. Make sure to import your \nmodel/hero.dart\n file at the top:\n\n\nimport\n \npackage:heroes/heroes.dart\n;\n\n\nimport\n \npackage:heroes/model/hero.dart\n;\n\n\n\nclass\n \nHeroesController\n \nextends\n \nResourceController\n \n{\n\n  \nHeroesController\n(\nthis\n.\ncontext\n);\n\n\n  \nfinal\n \nManagedContext\n \ncontext\n;\n\n\n  \n@\nOperation\n.\nget\n()\n\n  \nFuture\nResponse\n \ngetAllHeroes\n()\n \nasync\n \n{\n\n    \nfinal\n \nheroQuery\n \n=\n \nQuery\nHero\n(\ncontext\n);\n\n    \nfinal\n \nheroes\n \n=\n \nawait\n \nheroQuery\n.\nfetch\n();\n\n\n    \nreturn\n \nResponse\n.\nok\n(\nheroes\n);\n\n  \n}\n\n\n\n...\n\n\n\n\n\n\nHere, we create an instance of \nQuery\nHero\n and then execute its \nfetch()\n method. The type argument to \nQuery\nT\n is an instance type; it lets the query know which table to fetch rows from and the type of objects that are returned by the query. The context argument tells it which database to fetch it from. The \nfetch()\n execution method returns a \nList\nHero\n. We write that list to the body of the response.\n\n\nNow, let's update \ngetHeroByID\n to fetch a single hero from the database.\n\n\n@\nOperation\n.\nget\n(\nid\n)\n\n\nFuture\nResponse\n \ngetHeroByID\n(\n@\nBind\n.\npath\n(\nid\n)\n \nint\n \nid\n)\n \nasync\n \n{\n\n  \nfinal\n \nheroQuery\n \n=\n \nQuery\nHero\n(\ncontext\n)\n\n    \n..\nwhere\n((\nh\n)\n \n=\n \nh\n.\nid\n).\nequalTo\n(\nid\n);\n    \n\n  \nfinal\n \nhero\n \n=\n \nawait\n \nheroQuery\n.\nfetchOne\n();\n\n\n  \nif\n \n(\nhero\n \n==\n \nnull\n)\n \n{\n\n    \nreturn\n \nResponse\n.\nnotFound\n();\n\n  \n}\n\n  \nreturn\n \nResponse\n.\nok\n(\nhero\n);\n\n\n}\n\n\n\n\n\n\nThis query does two interesting things. First, it uses the \nwhere\n method to filter heroes that have the same \nid\n as the path variable. For example, \n/heroes/1\n will fetch a hero with an \nid\n of \n1\n. This works because \nQuery.where\n adds a SQL WHERE clause to the query. We'd get the following SQL:\n\n\nSELECT\n \nid\n,\n \nname\n \nFROM\n \n_question\n \nWHERE\n \nid\n \n=\n \n1\n;\n\n\n\n\n\n\nThe \nwhere\n method uses the \nproperty selector\n syntax. This syntax is a closure that takes an argument of the type being queried, and must return a property of that object. This creates an expression object that targets the selected property. By invoking methods like \nequalTo\n on this expression object, a boolean expression is added to the query.\n\n\n\n\nProperty Selectors\n\n\nMany query configuration methods use the property selector syntax. Setting up a keyboard shortcut (called a Live Template in IntelliJ) to enter the syntax is beneficial. A downloadable settings configuration for IntelliJ exists \nhere\n that includes this shortcut.\n\n\n\n\nThe \nfetchOne()\n execution method will fetch a single object that fulfills all of the expressions applied to the query. If no database row meets the criteria, \nnull\n is returned. Our controller returns a 404 Not Found response in that scenario.\n\n\nWe have now written code that fetches heroes from a database instead of from in memory, but we don't have a database - yet.\n\n\n\n\nUse fetchOne() on Unique Properties\n\n\nIf more than one database row meets the criteria of a \nfetchOne()\n, an exception is thrown. It's only safe to use \nfetchOne()\n when applying an expression to a unique property, like a primary key.\n\n\n\n\nSetting Up a Database\n\n\nFor development, you'll need to install a PostgreSQL server on your local machine. If you are on macOS, your best bet is to use \nPostgres.app\n. This application starts a PostgreSQL instance when it is open, and closes it when the application is shut down. For other platforms, see \nthis page\n.\n\n\nOnce you have PostgreSQL installed and running, open a command line interface to it. If you are using \nPostgres.app\n, select the elephant icon in your status bar and then select \nOpen psql\n. Otherwise, enter \npsql\n into the command-line.\n\n\n\n\nIf you installed Postgres.app\n\n\nThe \npsql\n command-line utility is inside the \nPostgres.app\n application bundle, so entering \npsql\n from the command-line won't find the executable. Once you open \npsql\n from the status bar item, you'll see the full path to \npsql\n on your machine. This is typically \n/Applications/Postgres.app/Contents/Versions/9.6/psql\n.\n\n\n\n\nIn \npsql\n, create a new database and a user to manage it.\n\n\nCREATE\n \nDATABASE\n \nheroes\n;\n\n\nCREATE\n \nUSER\n \nheroes_user\n \nWITH\n \ncreatedb\n;\n\n\nALTER\n \nUSER\n \nheroes_user\n \nWITH\n \npassword\n \npassword\n;\n\n\nGRANT\n \nall\n \nON\n \ndatabase\n \nheroes\n \nTO\n \nheroes_user\n;\n\n\n\n\n\n\nNext, we need to create the table where heroes are stored in this database. From your project directory, run the following command:\n\n\naqueduct db generate\n\n\n\n\n\nThis command will create a new \nmigration file\n. A migration file is a Dart script that runs a series of SQL commands to alter a database's schema. It is created in a new directory in your project named \nmigrations/\n. Open \nmigrations/00000001_initial.migration.dart\n, it should look like this:\n\n\nimport\n \npackage:aqueduct/aqueduct.dart\n;\n\n\nimport\n \ndart:async\n;\n\n\n\nclass\n \nMigration1\n \nextends\n \nMigration\n \n{\n\n  \n@\noverride\n\n  \nFuture\n \nupgrade\n()\n \nasync\n \n{\n\n    \ndatabase\n.\ncreateTable\n(\nSchemaTable\n(\n\n      \n_Hero\n,\n \n[\n\n        \nSchemaColumn\n(\nid\n,\n \nManagedPropertyType\n.\nbigInteger\n,\n\n            \nisPrimaryKey:\n \ntrue\n,\n \nautoincrement:\n \ntrue\n,\n \nisIndexed:\n \nfalse\n,\n \nisNullable:\n \nfalse\n,\n \nisUnique:\n \nfalse\n),\n\n        \nSchemaColumn\n(\nname\n,\n \nManagedPropertyType\n.\nstring\n,\n\n            \nisPrimaryKey:\n \nfalse\n,\n \nautoincrement:\n \nfalse\n,\n \nisIndexed:\n \nfalse\n,\n \nisNullable:\n \nfalse\n,\n \nisUnique:\n \ntrue\n),\n\n      \n],\n\n    \n));\n\n  \n}\n\n\n  \n@\noverride\n\n  \nFuture\n \ndowngrade\n()\n \nasync\n \n{}\n\n\n  \n@\noverride\n\n  \nFuture\n \nseed\n()\n \nasync\n \n{}\n\n\n}\n\n\n\n\n\n\nIn a moment, we'll execute this migration file. That will create a new table named \n_Hero\n with columns for \nid\n and \nname\n. Before we run it, we should seed the database with some initial heroes. In the \nseed()\n method, add the following:\n\n\n@\noverride\n\n\nFuture\n \nseed\n()\n \nasync\n \n{\n\n  \nfinal\n \nheroNames\n \n=\n \n[\nMr. Nice\n,\n \nNarco\n,\n \nBombasto\n,\n \nCeleritas\n,\n \nMagneta\n];\n\n\n  \nfor\n \n(\nfinal\n \nheroName\n \nin\n \nheroNames\n)\n \n{\n    \n    \nawait\n \ndatabase\n.\nstore\n.\nexecute\n(\nINSERT INTO _Hero (name) VALUES (@name)\n,\n \nsubstitutionValues:\n \n{\n\n      \nname\n:\n \nheroName\n\n    \n});\n\n  \n}\n\n\n}\n\n\n\n\n\n\nApply this migration file to our locally running \nheroes\n database with the following command in the project directory:\n\n\naqueduct\n \ndb\n \nupgrade\n \n--\nconnect\n \npostgres:\n//heroes_user:password@localhost:5432/heroes\n\n\n\n\n\n\nRe-run your application with \naqueduct serve\n. Then, reload \nhttp://aqueduct-tutorial.stablekernel.io\n. Your dashboard of heroes and detail page for each will still show up - but this time, they are sourced from a database.\n\n\n\n\nManagedObjects and Migration Scripts\n\n\nIn our migration's \nseed()\n method, we executed SQL queries instead of using the Aqueduct ORM. \nIt is very important that you do not use\n \nQuery\nT\n, \nManagedObject\nT\n or other elements of the Aqueduct ORM in migration files. Migration files represent an ordered series of historical steps that describe your database schema. If you replay those steps (which is what executing a migration file does), you will end up with the same database schema every time. However, a \nManagedObject\nT\n subclass changes over time - the definition of a managed object is not historical, it only represents the current point in time. Since a \nManagedObject\nT\n subclass can change, using one in our migration file would mean that our migration file could change.\n\n\n\n\nQuery Parameters and HTTP Headers\n\n\nIn the browser application, the dashboard has a text field for searching heroes. When you enter text into it, it will send the search term to the server by appending a query parameter to \nGET /heroes\n. For example, if you entered the text \nabc\n, it'd make this request:\n\n\nGET /heroes?name=abc\n\n\n\n\n\n\n\n\nOur Aqueduct application can use this value to return a list of heroes that contains the search string. In \nheroes_controller.dart\n, modify \ngetAllHeroes()\n to bind the 'name' query parameter:\n\n\n@\nOperation\n.\nget\n()\n\n\nFuture\nResponse\n \ngetAllHeroes\n({\n@\nBind\n.\nquery\n(\nname\n)\n \nString\n \nname\n})\n \nasync\n \n{\n\n  \nfinal\n \nheroQuery\n \n=\n \nQuery\nHero\n(\ncontext\n);\n\n  \nif\n \n(\nname\n \n!=\n \nnull\n)\n \n{\n\n    \nheroQuery\n.\nwhere\n((\nh\n)\n \n=\n \nh\n.\nname\n).\ncontains\n(\nname\n,\n \ncaseSensitive:\n \nfalse\n);\n\n  \n}\n\n  \nfinal\n \nheroes\n \n=\n \nawait\n \nheroQuery\n.\nfetch\n();\n\n\n  \nreturn\n \nResponse\n.\nok\n(\nheroes\n);\n\n\n}\n\n\n\n\n\n\nYou can re-run your Aqueduct application and use the search bar in the client application.\n\n\nThe \n@Bind.query('name')\n annotation will bind the value of the 'name' query parameter if it is included in the request URL. Otherwise, \nname\n will be null.\n\n\nNotice that \nname\n is an \noptional parameter\n (it is surrounded by curly brackets). An optional parameter in an operation method is also optional in the HTTP request. If we removed the curly brackets from this binding, the 'name' query parameter would become required and the request \nGET /heroes\n without \n?name=x\n would fail with a 400 Bad Request.\n\n\n\n\nResourceController Binding\n\n\nThere is even more to bindings than we've shown (like automatically parsing bound values into types like \nint\n and \nDateTime\n). For more information, see \nResourceControllers\n.\n\n\n\n\nBinding query and header parameters in a operation method is a good way to make your code more intentional and avoid boilerplate parsing code. Aqueduct is able to generate better documentation when using bindings.\n\n\nNext: Storing Data", 
            "title": "2. Reading from a Database"
        }, 
        {
            "location": "/tut/executing-queries/#2-reading-from-a-database", 
            "text": "We will continue to build on the last chapter's project,  heroes , by storing our heroes in a database. This will let us to edit our heroes and keep the changes when we restart the application.", 
            "title": "2. Reading from a Database"
        }, 
        {
            "location": "/tut/executing-queries/#object-relational-mapping", 
            "text": "A relational database management system (like PostgreSQL or MySQL) stores its data in the form of tables. A table represents some sort of entity - like a person or a bank account. Each table has columns that describe the attributes of that entity - like a name or a balance. Every row in a table is an instance of that entity - like a single person named Bob or a bank account.  In an object-oriented framework like Aqueduct, we have representations for tables, columns and rows. A class represents a table, its instances are rows, and instance properties are column values. An ORM translates rows in a database to and from objects in an application.     Aqueduct  Database  Example #1  Example #2      Class  Table  Person  Bank Account    Instance  Row  A person named Bob  Sally's Bank Account    Property  Column  Person's Name  Bank Account Balance     In Aqueduct, each database table-class pairing is called an  entity . Collectively, an application's entities are called its  data model .", 
            "title": "Object-Relational Mapping"
        }, 
        {
            "location": "/tut/executing-queries/#building-a-data-model", 
            "text": "In our  heroes  application, we will have one type of entity - a \"hero\". To create a new entity, we subclass  ManagedObject T . Create a new directory  lib/model/  and then add a new file to this directory named  hero.dart . Add the following code:  import   package:heroes/heroes.dart ;  class   Hero   extends   ManagedObject _Hero   implements   _Hero   {}  class   _Hero   { \n   @ primaryKey \n   int   id ; \n\n   @ Column ( unique:   true ) \n   String   name ;  }   This declares a  Hero  entity. Entities are always made up of two classes.  The  _Hero  class is a direct mapping of a database table. This table's name will have the same name as the class:  _Hero . Every property declared in this class will have a corresponding column in this table. Therefore, the  _Hero  table will have two columns -  id  and  name . The  id  column is this table's primary key (a unique identifier for each hero). The name of each hero must be unique.  The other class,  Hero , is what we work with in our code - when we fetch heroes from a database, they will be instances of  Hero .  The  Hero  class is called the  instance type  of the entity, because that's what we have instances of.  _Hero  is the  table definition  of the entity. You won't use the table definition for anything other than describing the database table.  An instance type must  implement  its table definition; this gives our  Hero  all of the properties of  _Hero . An instance type must  extend   ManagedObject T , where  T  is also the table definition.  ManagedObject T  has behavior for automatically transferring objects to the database and back (among other things).   Transient Properties  Properties declared in the instance type aren't stored in the database. This is different than properties in the table definition. For example, a database table might have a  firstName  and  lastName , but it's useful in some places to have a  fullName  property. Declaring the  fullName  property in the instance type means we have easy access to the full name, but we still store the first and last name individually.", 
            "title": "Building a Data Model"
        }, 
        {
            "location": "/tut/executing-queries/#defining-a-context", 
            "text": "Our application needs to know two things to execute database queries:   What is the data model (our collection of entities)?  What database are we connecting to?   Both of these things are set up when an application is first started. In  channel.dart , add a new property  context  and update  prepare() :  class   HeroesChannel   extends   ApplicationChannel   { \n   ManagedContext   context ; \n\n   @ override \n   Future   prepare ()   async   { \n     logger . onRecord . listen (( rec )   =   print ( $ rec   ${ rec . error   ??   }   ${ rec . stackTrace   ??   } )); \n\n     final   dataModel   =   ManagedDataModel . fromCurrentMirrorSystem (); \n     final   persistentStore   =   PostgreSQLPersistentStore . fromConnectionInfo ( \n       heroes_user ,   password ,   localhost ,   5432 ,   heroes ); \n\n     context   =   ManagedContext ( dataModel ,   persistentStore ); \n   } \n\n   @ override \n   Controller   get   entryPoint   { \n     ...   ManagedDataModel.fromCurrentMirrorSystem()  will find all of our  ManagedObject T  subclasses and 'compile' them into a data model. A  PostgreSQLPersistentStore  takes database connection information that it will use to connect and send queries to a database. Together, these objects are packaged in a  ManagedContext .   Configuring a Database Connection  This tutorial hardcodes the information needed to connect to a database. In a future chapter, we will move these values to a configuration file so that we can change them during tests and various deployment environments.   The context will coordinate with these two objects to execute queries and translate objects to and from the database. Controllers that make database queries need a reference to the context. So, we'll want  HeroesController  to have access to the context.  In  heroes_controller.dart , add a property and create a new constructor:  class   HeroesController   extends   ResourceController   { \n   HeroesController ( this . context ); \n\n   final   ManagedContext   context ;   \n   ...   Now that  HeroesController  requires a context in its constructor, we need to pass it the context we created in  prepare() . Update  entryPoint  in  channel.dart .  @ override  Controller   get   entryPoint   { \n   final   router   =   Router (); \n\n   router \n     . route ( /heroes/[:id] ) \n     . link (()   =   HeroesController ( context )); \n\n   router \n     . route ( /example ) \n     . linkFunction (( request )   async   { \n       return   new   Response . ok ({ key :   value }); \n   }); \n\n   return   router ;  }   Now that we've 'injected' this context into our  HeroesController  constructor, each  HeroesController  can execute database queries.   Service Objects and Dependency Injection  Our context is an example of a  service object . A service encapsulates logic and state into a single object that can be reused in multiple controllers. A typical service object accesses another server, like a database or another REST API. Some service objects may simply provide a simplified interface to a complex process, like applying transforms to an image. Services are passed in a controller's constructor;\nthis is called  dependency injection . Unlike many frameworks, Aqueduct does not require a complex dependency injection framework; this is because you write the code to create instances of your controllers and can pass whatever you like in their constructor.", 
            "title": "Defining a Context"
        }, 
        {
            "location": "/tut/executing-queries/#executing-queries", 
            "text": "Our operation methods in  HeroesController  currently return heroes from an in-memory list. To fetch data from a database instead of this list, we create and execute instances of  Query T  in our  ManagedContext .  Let's start by replacing  getAllHeroes  in  heroes_controller.dart . Make sure to import your  model/hero.dart  file at the top:  import   package:heroes/heroes.dart ;  import   package:heroes/model/hero.dart ;  class   HeroesController   extends   ResourceController   { \n   HeroesController ( this . context ); \n\n   final   ManagedContext   context ; \n\n   @ Operation . get () \n   Future Response   getAllHeroes ()   async   { \n     final   heroQuery   =   Query Hero ( context ); \n     final   heroes   =   await   heroQuery . fetch (); \n\n     return   Response . ok ( heroes ); \n   }  ...   Here, we create an instance of  Query Hero  and then execute its  fetch()  method. The type argument to  Query T  is an instance type; it lets the query know which table to fetch rows from and the type of objects that are returned by the query. The context argument tells it which database to fetch it from. The  fetch()  execution method returns a  List Hero . We write that list to the body of the response.  Now, let's update  getHeroByID  to fetch a single hero from the database.  @ Operation . get ( id )  Future Response   getHeroByID ( @ Bind . path ( id )   int   id )   async   { \n   final   heroQuery   =   Query Hero ( context ) \n     .. where (( h )   =   h . id ). equalTo ( id );     \n\n   final   hero   =   await   heroQuery . fetchOne (); \n\n   if   ( hero   ==   null )   { \n     return   Response . notFound (); \n   } \n   return   Response . ok ( hero );  }   This query does two interesting things. First, it uses the  where  method to filter heroes that have the same  id  as the path variable. For example,  /heroes/1  will fetch a hero with an  id  of  1 . This works because  Query.where  adds a SQL WHERE clause to the query. We'd get the following SQL:  SELECT   id ,   name   FROM   _question   WHERE   id   =   1 ;   The  where  method uses the  property selector  syntax. This syntax is a closure that takes an argument of the type being queried, and must return a property of that object. This creates an expression object that targets the selected property. By invoking methods like  equalTo  on this expression object, a boolean expression is added to the query.   Property Selectors  Many query configuration methods use the property selector syntax. Setting up a keyboard shortcut (called a Live Template in IntelliJ) to enter the syntax is beneficial. A downloadable settings configuration for IntelliJ exists  here  that includes this shortcut.   The  fetchOne()  execution method will fetch a single object that fulfills all of the expressions applied to the query. If no database row meets the criteria,  null  is returned. Our controller returns a 404 Not Found response in that scenario.  We have now written code that fetches heroes from a database instead of from in memory, but we don't have a database - yet.   Use fetchOne() on Unique Properties  If more than one database row meets the criteria of a  fetchOne() , an exception is thrown. It's only safe to use  fetchOne()  when applying an expression to a unique property, like a primary key.", 
            "title": "Executing Queries"
        }, 
        {
            "location": "/tut/executing-queries/#setting-up-a-database", 
            "text": "For development, you'll need to install a PostgreSQL server on your local machine. If you are on macOS, your best bet is to use  Postgres.app . This application starts a PostgreSQL instance when it is open, and closes it when the application is shut down. For other platforms, see  this page .  Once you have PostgreSQL installed and running, open a command line interface to it. If you are using  Postgres.app , select the elephant icon in your status bar and then select  Open psql . Otherwise, enter  psql  into the command-line.   If you installed Postgres.app  The  psql  command-line utility is inside the  Postgres.app  application bundle, so entering  psql  from the command-line won't find the executable. Once you open  psql  from the status bar item, you'll see the full path to  psql  on your machine. This is typically  /Applications/Postgres.app/Contents/Versions/9.6/psql .   In  psql , create a new database and a user to manage it.  CREATE   DATABASE   heroes ;  CREATE   USER   heroes_user   WITH   createdb ;  ALTER   USER   heroes_user   WITH   password   password ;  GRANT   all   ON   database   heroes   TO   heroes_user ;   Next, we need to create the table where heroes are stored in this database. From your project directory, run the following command:  aqueduct db generate  This command will create a new  migration file . A migration file is a Dart script that runs a series of SQL commands to alter a database's schema. It is created in a new directory in your project named  migrations/ . Open  migrations/00000001_initial.migration.dart , it should look like this:  import   package:aqueduct/aqueduct.dart ;  import   dart:async ;  class   Migration1   extends   Migration   { \n   @ override \n   Future   upgrade ()   async   { \n     database . createTable ( SchemaTable ( \n       _Hero ,   [ \n         SchemaColumn ( id ,   ManagedPropertyType . bigInteger , \n             isPrimaryKey:   true ,   autoincrement:   true ,   isIndexed:   false ,   isNullable:   false ,   isUnique:   false ), \n         SchemaColumn ( name ,   ManagedPropertyType . string , \n             isPrimaryKey:   false ,   autoincrement:   false ,   isIndexed:   false ,   isNullable:   false ,   isUnique:   true ), \n       ], \n     )); \n   } \n\n   @ override \n   Future   downgrade ()   async   {} \n\n   @ override \n   Future   seed ()   async   {}  }   In a moment, we'll execute this migration file. That will create a new table named  _Hero  with columns for  id  and  name . Before we run it, we should seed the database with some initial heroes. In the  seed()  method, add the following:  @ override  Future   seed ()   async   { \n   final   heroNames   =   [ Mr. Nice ,   Narco ,   Bombasto ,   Celeritas ,   Magneta ]; \n\n   for   ( final   heroName   in   heroNames )   {     \n     await   database . store . execute ( INSERT INTO _Hero (name) VALUES (@name) ,   substitutionValues:   { \n       name :   heroName \n     }); \n   }  }   Apply this migration file to our locally running  heroes  database with the following command in the project directory:  aqueduct   db   upgrade   -- connect   postgres: //heroes_user:password@localhost:5432/heroes   Re-run your application with  aqueduct serve . Then, reload  http://aqueduct-tutorial.stablekernel.io . Your dashboard of heroes and detail page for each will still show up - but this time, they are sourced from a database.   ManagedObjects and Migration Scripts  In our migration's  seed()  method, we executed SQL queries instead of using the Aqueduct ORM.  It is very important that you do not use   Query T ,  ManagedObject T  or other elements of the Aqueduct ORM in migration files. Migration files represent an ordered series of historical steps that describe your database schema. If you replay those steps (which is what executing a migration file does), you will end up with the same database schema every time. However, a  ManagedObject T  subclass changes over time - the definition of a managed object is not historical, it only represents the current point in time. Since a  ManagedObject T  subclass can change, using one in our migration file would mean that our migration file could change.", 
            "title": "Setting Up a Database"
        }, 
        {
            "location": "/tut/executing-queries/#query-parameters-and-http-headers", 
            "text": "In the browser application, the dashboard has a text field for searching heroes. When you enter text into it, it will send the search term to the server by appending a query parameter to  GET /heroes . For example, if you entered the text  abc , it'd make this request:  GET /heroes?name=abc    Our Aqueduct application can use this value to return a list of heroes that contains the search string. In  heroes_controller.dart , modify  getAllHeroes()  to bind the 'name' query parameter:  @ Operation . get ()  Future Response   getAllHeroes ({ @ Bind . query ( name )   String   name })   async   { \n   final   heroQuery   =   Query Hero ( context ); \n   if   ( name   !=   null )   { \n     heroQuery . where (( h )   =   h . name ). contains ( name ,   caseSensitive:   false ); \n   } \n   final   heroes   =   await   heroQuery . fetch (); \n\n   return   Response . ok ( heroes );  }   You can re-run your Aqueduct application and use the search bar in the client application.  The  @Bind.query('name')  annotation will bind the value of the 'name' query parameter if it is included in the request URL. Otherwise,  name  will be null.  Notice that  name  is an  optional parameter  (it is surrounded by curly brackets). An optional parameter in an operation method is also optional in the HTTP request. If we removed the curly brackets from this binding, the 'name' query parameter would become required and the request  GET /heroes  without  ?name=x  would fail with a 400 Bad Request.   ResourceController Binding  There is even more to bindings than we've shown (like automatically parsing bound values into types like  int  and  DateTime ). For more information, see  ResourceControllers .   Binding query and header parameters in a operation method is a good way to make your code more intentional and avoid boilerplate parsing code. Aqueduct is able to generate better documentation when using bindings.", 
            "title": "Query Parameters and HTTP Headers"
        }, 
        {
            "location": "/tut/executing-queries/#next-storing-data", 
            "text": "", 
            "title": "Next: Storing Data"
        }, 
        {
            "location": "/tut/storing-data/", 
            "text": "3. Storing Data in a Database\n\n\nIn the previous exercise, we loaded some heroes into the database our application reads from. Now, we will allow our application to store, delete and modify heroes in the database. Before we embark on this part of the journey, it's important that we understand how an HTTP API is intended to work.\n\n\nHTTP Resources and Methods\n\n\nThe \nHTTP specification\n defines the concept of a \nresource\n. A resource can be anything - a hero, a bank account, a light switch in your home, a temperature sensor in Antarctica, etc. Some of these things are physical objects (the light switch), and some are digital - and they are all resources. An HTTP server application is an interface to these resources; a client requests that something be done with a resource, and the server finds a way to get it done.\n\n\nResources are identified with a URI. A URI \nuniversally identifies\n a resource: it has the address of a server to connect to, and a path that identifies the resource on that server. When writing Aqueduct applications, we don't care much about the server part of a URL - the internet figures out that part. What we do care about is the path of the URL - like \n/heroes\n.\n\n\nAn application uses the URL path to determine which resource the request wants to work with. Right now, our application works with hero resources. A request with the path \n/heroes/1\n wants to do something with an individual hero (that is identified by the number \n1\n). A request with the path \n/heroes\n will act on the entire collection of heroes.\n\n\nThese actions are primarily described by the request method (like GET, POST, OR DELETE). Each of these methods has a general meaning that describes an action that can be applied to a resource. For example, a \nGET /heroes\n means \"get me all of the hero resources\". The meaning for each of these methods are as follows:\n\n\n\n\nGET: returns a collection of some resource or an individual resource\n\n\nPOST: inserts or appends a resource to a collection of some resource; a representation of the resource is in the request body\n\n\nPUT: replaces a resource with the contents of the request body (or in some cases, replaces the entire collection of some resource)\n\n\nDELETE: deletes a resource (or in some cases, deletes the entire collection of some resource)\n\n\n\n\nIt turns out, we can create a lot of incredible behavior by just combining these methods and a request path. More importantly, by following these specifications, client applications can use generic libraries to access any HTTP API with very little effort. This allows us to create complex systems that are easily made available to a browser, mobile phone or any other internet-connected device.\n\n\nInserting Data\n\n\nWe'll start by adding behavior that allows for new heroes to be inserted into the database. Following our previous discussion, the HTTP request must take the form \nPOST /heroes\n - we are appending a new hero to the collection of heroes. This request will contain the JSON representation of a hero in its body, for example:\n\n\n{\n\n  \nname\n:\n \nMaster of Aqueducts\n\n\n}\n\n\n\n\n\n\nOur \nHeroesController\n will handle this operation. In general, a single endpoint controller should handle every operation on a resource collection and its individual resources. In \nheroes_controller.dart\n, add the following operation method:\n\n\n@\nOperation\n.\npost\n()\n\n\nFuture\nResponse\n \ncreateHero\n()\n \nasync\n \n{\n\n  \nfinal\n \nMap\nString\n,\n \ndynamic\n \nbody\n \n=\n \nawait\n \nrequest\n.\nbody\n.\ndecode\n();\n\n  \nfinal\n \nquery\n \n=\n \nQuery\nHero\n(\ncontext\n)\n\n    \n..\nvalues\n.\nname\n \n=\n \nbody\n[\nname\n]\n \nas\n \nString\n;\n\n\n  \nfinal\n \ninsertedHero\n \n=\n \nawait\n \nquery\n.\ninsert\n();\n\n\n  \nreturn\n \nResponse\n.\nok\n(\ninsertedHero\n);\n\n\n}\n\n\n\n\n\n\nThis operation method decodes the hero from the request's body, constructs a query that inserts that hero, and then returns it in the response.\n\n\nUsing a \nQuery\nHero\n to insert a row isn't very different than using one to fetch rows. When inserting a row, we execute \nquery.insert()\n instead of \nquery.fetch()\n. Instead of applying expressions with \nwhere\n, we set the properties of \nvalues\n. The \nvalues\n of a query is an empty instance of the type being inserted.\n\n\nEach property we set on \nvalues\n is sent in an \nINSERT\n command to the database. The generated SQL for the above would be something like:\n\n\nINSERT\n \nINTO\n \n_Hero\n \n(\nname\n)\n \nVALUES\n \n(\nHero Name\n);\n\n\n\n\n\n\nThe database automatically generates a value for the \nid\n property of a \nHero\n (its \n@primaryKey\n annotation enables the \"auto-incrementing\" option). When the row has been successfully inserted, a new \nHero\n object is returned - containing any values that were generated by the database. Most API endpoints return the created object in the response so that the client has the same information that the server has, and our application is no different.\n\n\n\n\nColumn Attributes\n\n\nSee \nthe API reference for Column\n for column options like auto-incrementing.\n\n\n\n\nRe-run your application. In the browser application, click on \nHeroes\n near the top of the page. Then, enter a name into the \nHero name:\n field and click \nAdd\n. The new hero will appear. You can re-run the application and that hero will still be available, because it has been stored in the database on your machine.\n\n\n\n\n\n\nSub-resources\n\n\nWe mentioned that a single controller should handle every operation for a resource collection and its individual resources. Some resources are complex enough that they can have sub-resources. For example, an organization of heroes (like the X-Men or Fantastic Four) contains heroes, but it might also contain buildings and equipment owned by the organization. The heroes, buildings and equipment are sub-resources of an organization.  Each sub-resource should have its own route and controller instead of trying to shove everything into a single route and controller. See the following code snippet for an example.\n\n\n\n\n@\noverride\n\n\nController\n \nget\n \nentryPoint\n \n{\n\n  \nreturn\n \nRouter\n()\n\n    \n..\nroute\n(\n/organizations/[:orgName]\n)\n\n      \n.\nlink\n(()\n \n=\n \nOrganizationController\n());\n\n    \n..\nroute\n(\n/organizations/:orgName/heroes/[:heroID]\n)\n\n      \n.\nlink\n(()\n \n=\n \nOrgHeroesController\n());\n\n    \n..\nroute\n(\n/organizations/:orgName/buildings/[:buildingID]\n)\n\n      \n.\nlink\n(()\n \n=\n \nOrgBuildingController\n());\n\n\n}\n\n\n\n\n\n\nRequest and Response Bodies\n\n\nSo far, we've largely glossed over how request and response bodies are handled, and now is a good time to dig in to this topic.\n\n\nResponse Body Encoding\n\n\nWhen we create a response, we specify its status code and optionally its headers and body. For example, the following creates a response with a status code of 200 OK with an empty list body:\n\n\nResponse\n.\nok\n([])\n\n\n\n\n\n\nThe first argument to \nResponse.ok\n is a \nbody object\n. A body object is automatically encoded according to the \ncontentType\n of its response. By default, the content type of a response is \napplication/json\n - so by default, all of our response body objects are JSON-encoded in the response body.\n\n\n\n\nOther Response Constructors\n\n\nThe default constructor for a \nResponse\n takes a status code, map of headers and a body object: \nResponse(200, {}, \"body\")\n. There are many named constructors for \nResponse\n, like \nResponse.ok\n or \nResponse.notFound\n. These constructors set the status code and expose parameters that are intended for that type of response. For example, a 200 OK response should have a body, so \nResponse.ok\n has a required body object argument. See \nthe API reference for Response\n for possible constructors and properties of a response.\n\n\n\n\nTo change the format a body object is encoded into, you set the \ncontentType\n of the response. For example,\n\n\nResponse\n.\nok\n([])\n\n  \n..\ncontentType\n \n=\n \nnew\n \nContentType\n(\napplication\n,\n \nxml\n);\n\n\n\n\n\n\nThe default supported content types are JSON, \napplication/x-www-form-urlencoded\n and all \ntext/*\n types. To encode other content-types, you must register a \nCodec\n with \nCodecRegistry.\n A body object is only valid if the codec selected by the response's content-type can encode it. If it can't, an error will be thrown and a 500 Server Error response is sent instead.\n\n\nTypes that implement \nSerializable\n may also be body objects. Objects that implement this type provide an \nasMap()\n method that converts their properties into a \nMap\n before being passed to the encoder. This \nMap\n must be encodable for the response's content-type codec. You may also provide a \nList\n of \nSerializable\n, for which the list of each object's \nasMap()\n is passed to the encoder.\n\n\nManagedObject\n implements the \nSerializable\n interface, and therefore all managed objects (and lists of managed objects) can be body objects.\n\n\nRequest Body Decoding\n\n\nEvery \nRequest\n has a \nbody\n property of type \nRequestBody\n. A \nRequestBody\n decodes the contents of the request body into Dart objects that you use in your application. This decoding is performed by the \nCodec\n that is associated with the request's content-type. The decoded object is determined by the format of the data - for example, a JSON array decodes into a \nList\n, a JSON object into a \nMap\n.\n\n\nWhen you write code to decode a request body, you are also validating the request body is in the expected format. For example, your \nHeroesController\n invokes \ndecode\n like this:\n\n\nMap\nString\n,\n \ndynamic\n \nbody\n \n=\n \nawait\n \nrequest\n.\nbody\n.\ndecode\n();\n\n\n\n\n\n\nThe \ndecode\n method has a type argument that is inferred to be a \nMap\nString, dynamic\n. If the decoded body is not a \nMap\n, an exception is thrown that sends an appropriate error response to the client.\n\n\nYou may also bind the body of a request to an operation method parameter. Let's bind a \nHero\n instance to a request body in our \nHeroesController\n. Update the code in that file to the following:\n\n\n@\nOperation\n.\npost\n()\n\n\nFuture\nResponse\n \ncreateHero\n(\n@\nBind\n.\nbody\n()\n \nHero\n \ninputHero\n)\n \nasync\n \n{\n\n  \nfinal\n \nquery\n \n=\n \nQuery\nHero\n(\ncontext\n)\n\n    \n..\nvalues\n \n=\n \ninputHero\n;\n\n\n  \nfinal\n \ninsertedHero\n \n=\n \nawait\n \nquery\n.\ninsert\n();\n\n\n  \nreturn\n \nResponse\n.\nok\n(\ninsertedHero\n);\n\n\n}\n\n\n\n\n\n\nValues in the request body object are decoded into a \nHero\n object - each key in the request body maps to a property of our \nHero\n. For example, the value for the key 'name' is stored in the \ninputHero.name\n. If decoding the request body into a \nHero\n instance fails for any reason, a 400 Bad Request response is sent and the operation method is not called.\n\n\nAn object can only be bound to a request body if it implements \nSerializable\n - the good news is all \nManagedObject\ns implement this interface. You may create your own types that implement this interface, and you may also bind a \nList\nT\n, where \nT\n implements the interface.\n\n\nRe-run your \nheroes\n application. On \nhttp://aqueduct-tutorial.stablekernel.io\n, click on the \nHeroes\n button on the top of the screen. In the text field, enter a new hero name and click \nAdd\n. You'll see your new hero added to the list! You can shutdown your application and run it again and you'll still be able to fetch your new hero.\n\n\n\n\n\n\nQuery Construction\n\n\nProperties like \nvalues\n and \nwhere\n prevent errors by type and name checking columns with the analyzer. They're also great for speeding up writing code because your IDE will autocomplete property names. There is \nspecific behavior\n a query uses to decide whether it should include a value from these two properties in the SQL it generates.", 
            "title": "3. Storing Data in a Database"
        }, 
        {
            "location": "/tut/storing-data/#3-storing-data-in-a-database", 
            "text": "In the previous exercise, we loaded some heroes into the database our application reads from. Now, we will allow our application to store, delete and modify heroes in the database. Before we embark on this part of the journey, it's important that we understand how an HTTP API is intended to work.", 
            "title": "3. Storing Data in a Database"
        }, 
        {
            "location": "/tut/storing-data/#http-resources-and-methods", 
            "text": "The  HTTP specification  defines the concept of a  resource . A resource can be anything - a hero, a bank account, a light switch in your home, a temperature sensor in Antarctica, etc. Some of these things are physical objects (the light switch), and some are digital - and they are all resources. An HTTP server application is an interface to these resources; a client requests that something be done with a resource, and the server finds a way to get it done.  Resources are identified with a URI. A URI  universally identifies  a resource: it has the address of a server to connect to, and a path that identifies the resource on that server. When writing Aqueduct applications, we don't care much about the server part of a URL - the internet figures out that part. What we do care about is the path of the URL - like  /heroes .  An application uses the URL path to determine which resource the request wants to work with. Right now, our application works with hero resources. A request with the path  /heroes/1  wants to do something with an individual hero (that is identified by the number  1 ). A request with the path  /heroes  will act on the entire collection of heroes.  These actions are primarily described by the request method (like GET, POST, OR DELETE). Each of these methods has a general meaning that describes an action that can be applied to a resource. For example, a  GET /heroes  means \"get me all of the hero resources\". The meaning for each of these methods are as follows:   GET: returns a collection of some resource or an individual resource  POST: inserts or appends a resource to a collection of some resource; a representation of the resource is in the request body  PUT: replaces a resource with the contents of the request body (or in some cases, replaces the entire collection of some resource)  DELETE: deletes a resource (or in some cases, deletes the entire collection of some resource)   It turns out, we can create a lot of incredible behavior by just combining these methods and a request path. More importantly, by following these specifications, client applications can use generic libraries to access any HTTP API with very little effort. This allows us to create complex systems that are easily made available to a browser, mobile phone or any other internet-connected device.", 
            "title": "HTTP Resources and Methods"
        }, 
        {
            "location": "/tut/storing-data/#inserting-data", 
            "text": "We'll start by adding behavior that allows for new heroes to be inserted into the database. Following our previous discussion, the HTTP request must take the form  POST /heroes  - we are appending a new hero to the collection of heroes. This request will contain the JSON representation of a hero in its body, for example:  { \n   name :   Master of Aqueducts  }   Our  HeroesController  will handle this operation. In general, a single endpoint controller should handle every operation on a resource collection and its individual resources. In  heroes_controller.dart , add the following operation method:  @ Operation . post ()  Future Response   createHero ()   async   { \n   final   Map String ,   dynamic   body   =   await   request . body . decode (); \n   final   query   =   Query Hero ( context ) \n     .. values . name   =   body [ name ]   as   String ; \n\n   final   insertedHero   =   await   query . insert (); \n\n   return   Response . ok ( insertedHero );  }   This operation method decodes the hero from the request's body, constructs a query that inserts that hero, and then returns it in the response.  Using a  Query Hero  to insert a row isn't very different than using one to fetch rows. When inserting a row, we execute  query.insert()  instead of  query.fetch() . Instead of applying expressions with  where , we set the properties of  values . The  values  of a query is an empty instance of the type being inserted.  Each property we set on  values  is sent in an  INSERT  command to the database. The generated SQL for the above would be something like:  INSERT   INTO   _Hero   ( name )   VALUES   ( Hero Name );   The database automatically generates a value for the  id  property of a  Hero  (its  @primaryKey  annotation enables the \"auto-incrementing\" option). When the row has been successfully inserted, a new  Hero  object is returned - containing any values that were generated by the database. Most API endpoints return the created object in the response so that the client has the same information that the server has, and our application is no different.   Column Attributes  See  the API reference for Column  for column options like auto-incrementing.   Re-run your application. In the browser application, click on  Heroes  near the top of the page. Then, enter a name into the  Hero name:  field and click  Add . The new hero will appear. You can re-run the application and that hero will still be available, because it has been stored in the database on your machine.    Sub-resources  We mentioned that a single controller should handle every operation for a resource collection and its individual resources. Some resources are complex enough that they can have sub-resources. For example, an organization of heroes (like the X-Men or Fantastic Four) contains heroes, but it might also contain buildings and equipment owned by the organization. The heroes, buildings and equipment are sub-resources of an organization.  Each sub-resource should have its own route and controller instead of trying to shove everything into a single route and controller. See the following code snippet for an example.   @ override  Controller   get   entryPoint   { \n   return   Router () \n     .. route ( /organizations/[:orgName] ) \n       . link (()   =   OrganizationController ()); \n     .. route ( /organizations/:orgName/heroes/[:heroID] ) \n       . link (()   =   OrgHeroesController ()); \n     .. route ( /organizations/:orgName/buildings/[:buildingID] ) \n       . link (()   =   OrgBuildingController ());  }", 
            "title": "Inserting Data"
        }, 
        {
            "location": "/tut/storing-data/#request-and-response-bodies", 
            "text": "So far, we've largely glossed over how request and response bodies are handled, and now is a good time to dig in to this topic.", 
            "title": "Request and Response Bodies"
        }, 
        {
            "location": "/tut/storing-data/#response-body-encoding", 
            "text": "When we create a response, we specify its status code and optionally its headers and body. For example, the following creates a response with a status code of 200 OK with an empty list body:  Response . ok ([])   The first argument to  Response.ok  is a  body object . A body object is automatically encoded according to the  contentType  of its response. By default, the content type of a response is  application/json  - so by default, all of our response body objects are JSON-encoded in the response body.   Other Response Constructors  The default constructor for a  Response  takes a status code, map of headers and a body object:  Response(200, {}, \"body\") . There are many named constructors for  Response , like  Response.ok  or  Response.notFound . These constructors set the status code and expose parameters that are intended for that type of response. For example, a 200 OK response should have a body, so  Response.ok  has a required body object argument. See  the API reference for Response  for possible constructors and properties of a response.   To change the format a body object is encoded into, you set the  contentType  of the response. For example,  Response . ok ([]) \n   .. contentType   =   new   ContentType ( application ,   xml );   The default supported content types are JSON,  application/x-www-form-urlencoded  and all  text/*  types. To encode other content-types, you must register a  Codec  with  CodecRegistry.  A body object is only valid if the codec selected by the response's content-type can encode it. If it can't, an error will be thrown and a 500 Server Error response is sent instead.  Types that implement  Serializable  may also be body objects. Objects that implement this type provide an  asMap()  method that converts their properties into a  Map  before being passed to the encoder. This  Map  must be encodable for the response's content-type codec. You may also provide a  List  of  Serializable , for which the list of each object's  asMap()  is passed to the encoder.  ManagedObject  implements the  Serializable  interface, and therefore all managed objects (and lists of managed objects) can be body objects.", 
            "title": "Response Body Encoding"
        }, 
        {
            "location": "/tut/storing-data/#request-body-decoding", 
            "text": "Every  Request  has a  body  property of type  RequestBody . A  RequestBody  decodes the contents of the request body into Dart objects that you use in your application. This decoding is performed by the  Codec  that is associated with the request's content-type. The decoded object is determined by the format of the data - for example, a JSON array decodes into a  List , a JSON object into a  Map .  When you write code to decode a request body, you are also validating the request body is in the expected format. For example, your  HeroesController  invokes  decode  like this:  Map String ,   dynamic   body   =   await   request . body . decode ();   The  decode  method has a type argument that is inferred to be a  Map String, dynamic . If the decoded body is not a  Map , an exception is thrown that sends an appropriate error response to the client.  You may also bind the body of a request to an operation method parameter. Let's bind a  Hero  instance to a request body in our  HeroesController . Update the code in that file to the following:  @ Operation . post ()  Future Response   createHero ( @ Bind . body ()   Hero   inputHero )   async   { \n   final   query   =   Query Hero ( context ) \n     .. values   =   inputHero ; \n\n   final   insertedHero   =   await   query . insert (); \n\n   return   Response . ok ( insertedHero );  }   Values in the request body object are decoded into a  Hero  object - each key in the request body maps to a property of our  Hero . For example, the value for the key 'name' is stored in the  inputHero.name . If decoding the request body into a  Hero  instance fails for any reason, a 400 Bad Request response is sent and the operation method is not called.  An object can only be bound to a request body if it implements  Serializable  - the good news is all  ManagedObject s implement this interface. You may create your own types that implement this interface, and you may also bind a  List T , where  T  implements the interface.  Re-run your  heroes  application. On  http://aqueduct-tutorial.stablekernel.io , click on the  Heroes  button on the top of the screen. In the text field, enter a new hero name and click  Add . You'll see your new hero added to the list! You can shutdown your application and run it again and you'll still be able to fetch your new hero.    Query Construction  Properties like  values  and  where  prevent errors by type and name checking columns with the analyzer. They're also great for speeding up writing code because your IDE will autocomplete property names. There is  specific behavior  a query uses to decide whether it should include a value from these two properties in the SQL it generates.", 
            "title": "Request Body Decoding"
        }, 
        {
            "location": "/http/", 
            "text": "Tasks\n\n\nAn Aqueduct application serves HTTP clients by sending responses for requests.\n\n\nYou create and link \nController\n objects to handle requests. There are many subclasses of \nController\n that handle common tasks, and you often create your own subclasses of \nController\n to implement application logic. Most of your logic is implemented in subclasses of \nResourceController\n, a controller type geared for REST API endpoints.\n\n\nYou create a subclass of \nApplicationChannel\n to configure controllers used by your application. This subclass also initializes any services your application will use to fulfill requests, like database connections or third party API connections. Most often, you use a \nRouter\n controller at the entry point of your application channel to modularize your application logic.\n\n\nYour application may have many configurable options. This configuration is handled in your application channel. Configuration file management is provided by application-specific \nConfigurationItem\n subclasses that add type and name safety to your configuration files.\n\n\nYour application is run by using the \naqueduct serve\n command or the \nbin/main.dart\n script. In either case, your application starts by creating multiple, memory-isolated threads that replicate your \nApplicationChannel\n.\n\n\nGuides\n\n\n\n\nArchitecture and Organization of Aqueduct Applications\n\n\nRequest and Response Objects\n\n\nHandling Requests\n\n\nThe ApplicationChannel\n\n\nRouting\n\n\nResourceControllers\n\n\nConfiguration Files, CORS and SSL\n\n\nServing Files and Caching\n\n\nWebsockets\n\n\nMulti-threading", 
            "title": "Overview"
        }, 
        {
            "location": "/http/#tasks", 
            "text": "An Aqueduct application serves HTTP clients by sending responses for requests.  You create and link  Controller  objects to handle requests. There are many subclasses of  Controller  that handle common tasks, and you often create your own subclasses of  Controller  to implement application logic. Most of your logic is implemented in subclasses of  ResourceController , a controller type geared for REST API endpoints.  You create a subclass of  ApplicationChannel  to configure controllers used by your application. This subclass also initializes any services your application will use to fulfill requests, like database connections or third party API connections. Most often, you use a  Router  controller at the entry point of your application channel to modularize your application logic.  Your application may have many configurable options. This configuration is handled in your application channel. Configuration file management is provided by application-specific  ConfigurationItem  subclasses that add type and name safety to your configuration files.  Your application is run by using the  aqueduct serve  command or the  bin/main.dart  script. In either case, your application starts by creating multiple, memory-isolated threads that replicate your  ApplicationChannel .", 
            "title": "Tasks"
        }, 
        {
            "location": "/http/#guides", 
            "text": "Architecture and Organization of Aqueduct Applications  Request and Response Objects  Handling Requests  The ApplicationChannel  Routing  ResourceControllers  Configuration Files, CORS and SSL  Serving Files and Caching  Websockets  Multi-threading", 
            "title": "Guides"
        }, 
        {
            "location": "/http/structure/", 
            "text": "Aqueduct Application Architecture\n\n\nThe purpose of this document is to understand the objects that comprise an Aqueduct application, and how they work with one another to serve HTTP requests. It also discusses the project structure on the filesystem.\n\n\nControllers are Building Blocks\n\n\nThe building blocks of an Aqueduct application are \nControllers\n. Each controller type has logic to handle an HTTP request in some way. Controllers are linked together to form a \nchannel\n; an ordered series of controllers. A channel is a composition of its controllers' behaviors.\n\n\nFor example, consider an \nAuthorizer\n controller that verifies the request's authorization credentials are correct, and a \nSecretController\n that sends a response with secret information. By composing these two controllers together, we have a channel that verifies credentials before sending a secret. The benefit of controllers and channels is that controllers can be reused in multiple channels; the \nAuthorizer\n can protect other types of controllers without any change to its logic.\n\n\n\n\nThe last controller in a channel must always respond to a request. These types of controllers are called \nendpoint controllers\n and implement the business logic for your application's endpoints. For example, an endpoint controller might fetch a list of books from a database and send them in a response.\n\n\nThe other controllers in a channel are called \nmiddleware controllers\n. These types of controllers typically verify something about a request before letting the next controller in the channel handle it. Middleware controllers can respond to a request, but doing so prevents the rest of the controllers in the channel from handling the request.\n\n\nFor example, an \"authorization\" controller could send a \n401 Unauthorized\n response protecting the endpoint controller from unauthorized requests. A \"caching\" controller could send a response with information from a cache, preventing the endpoint controller from performing an expensive query.\n\n\nBoth middleware and endpoint controllers are instances of \nController\n (or a subclass). Middleware controllers are typically reusable, while endpoint controllers are typically not. If a middleware controller is not reusable, its logic might be better suited for the endpoint controller it precedes in the channel.\n\n\nMost endpoint controllers are created by subclassing \nResourceController\n (itself a subclass of \nController\n). This class allows you to implement methods for each HTTP method (like GET or POST) for a given endpoint.\n\n\nThe Application Channel and Entry Point\n\n\nEach application designates one controller as the \nentry point\n of the application. This controller is the first to receive a new request and is the head of the application's channel. In most applications, the entry point is a \nRouter\n; this controller allows multiple channels to be linked, effectively splitting the channel into sub-channels.\n\n\n\n\nThe diagram above looks like this in code:\n\n\nclass\n \nAppChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \n@\noverride\n\n  \nController\n \nget\n \nentry\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nnew\n \nRouter\n();\n\n\n    \nrouter\n\n      \n.\nroute\n(\n/a\n)\n\n      \n.\nlink\n(()\n \n=\n \nnew\n \nAController\n());\n\n\n    \nrouter\n\n      \n.\nroute\n(\n/b\n)\n\n      \n.\nlink\n(()\n \n=\n \nnew\n \nAuthorizer\n(...))\n\n      \n.\nlink\n(()\n \n=\n \nnew\n \nBController\n());\n\n\n    \nrouter\n\n      \n.\nroute\n(\n/c\n)\n\n      \n.\nlink\n(()\n \n=\n \nnew\n \nAuthorizer\n(...))\n\n      \n.\nlink\n(()\n \n=\n \nnew\n \nCController\n());\n   \n\n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nSee \nthis guide\n for more details on the application channel and entry point.\n\n\nAqueduct Project Structure and Organization\n\n\nAn Aqueduct project is a directory that contains, at minimum, the following file structure:\n\n\npubspec.yaml\nlib/\n  application_name.dart\n\n\n\n\n\nThe name of any Dart application is defined by the \nname\n key in \npubspec.yaml\n. In order for \naqueduct serve\n to run your application, there must be a \n.dart\n file in \nlib/\n with that same name. This is your application library file and it must declare a \nApplicationChannel\n subclass or import a file that does. This is the bare minimum requirement to run an Aqueduct application. (See \nDeploying\n for more details on running applications.)\n\n\nFor organizing applications of reasonable size, we recommend the following structure:\n\n\npubspec.yaml\nconfig.src.yaml\nconfig.yaml\nlib/\n  application_name.dart\n  channel.dart  \n  controller/\n    user_controller.dart\n  model/\n    user.dart\ntest/\n  user_controller_test.dart\n  harness/\n    app.dart\n\n\n\n\n\nThe required \npubspec.yaml\n and \nlib/application_name.dart\n files are present alongside a few others:\n\n\n\n\nconfig.yaml\n: A \nconfiguration file\n for the running application.\n\n\nconfig.src.yaml\n: A \ntemplate for config.yaml\n.\n\n\nchannel.dart\n: A file solely for the \nApplicationChannel\n of an application. This file should be \nexported\n from \napplication_name.dart\n.\n\n\ncontroller/\n: A directory for \nController\n subclass files.\n\n\nmodel/\n: A directory for \nManagedObject\nT\n subclass files.\n\n\ntest/harness/app.dart\n: A \ntest harness\n) for automated testing.\n\n\n\n\nFeel free to create other subdirectories in \nlib/\n for organizing other types of files.\n\n\nAqueduct and dart:io\n\n\nAqueduct runs on top of \ndart:io\n and relies on its \nHttpServer\n implementation. When an Aqueduct application is started, one or more \nHttpServer\n instances are bound to the port specified by \naqueduct serve\n. For each HTTP request, an instance of \nRequest\n is created to wrap the \nHttpRequest\n from \ndart:io\n. The \nRequest\n is added to a \nApplicationChannel\n, sending it through the channel of \nController\ns until it is responded to.\n\n\nIn rare circumstances, you may choose to remove a \nRequest\n from the application channel and manipulate the request with \ndart:io\n only. Once removed, it is your responsibility to respond to the request by setting properties on and closing the \nHttpRequest.response\n. To take a request out of the channel, simply return \nnull\n from a \nController\n:\n\n\n@\noverride\n\n\nController\n \nget\n \nentryPoint\n \n{\n\n  \nfinal\n \nrouter\n \n=\n \nnew\n \nRouter\n();\n\n\n  \nrouter\n\n    \n.\nroute\n(\n/bypass_aqueduct\n)\n\n    \n.\nlinkFunction\n((\nreq\n)\n \nasync\n \n{\n\n      \nreq\n.\nresponse\n.\nstatusCode\n \n=\n \n200\n;\n\n      \nreq\n.\nresponse\n.\nclose\n();\n\n\n      \nreturn\n \nnull\n;\n\n    \n});\n\n\n  \nreturn\n \nrouter\n;\n\n\n}\n\n\n\n\n\n\nThis technique is valuable when Aqueduct can't do something you want it to do or when using \nwebsockets\n.", 
            "title": "Application Structure"
        }, 
        {
            "location": "/http/structure/#aqueduct-application-architecture", 
            "text": "The purpose of this document is to understand the objects that comprise an Aqueduct application, and how they work with one another to serve HTTP requests. It also discusses the project structure on the filesystem.", 
            "title": "Aqueduct Application Architecture"
        }, 
        {
            "location": "/http/structure/#controllers-are-building-blocks", 
            "text": "The building blocks of an Aqueduct application are  Controllers . Each controller type has logic to handle an HTTP request in some way. Controllers are linked together to form a  channel ; an ordered series of controllers. A channel is a composition of its controllers' behaviors.  For example, consider an  Authorizer  controller that verifies the request's authorization credentials are correct, and a  SecretController  that sends a response with secret information. By composing these two controllers together, we have a channel that verifies credentials before sending a secret. The benefit of controllers and channels is that controllers can be reused in multiple channels; the  Authorizer  can protect other types of controllers without any change to its logic.   The last controller in a channel must always respond to a request. These types of controllers are called  endpoint controllers  and implement the business logic for your application's endpoints. For example, an endpoint controller might fetch a list of books from a database and send them in a response.  The other controllers in a channel are called  middleware controllers . These types of controllers typically verify something about a request before letting the next controller in the channel handle it. Middleware controllers can respond to a request, but doing so prevents the rest of the controllers in the channel from handling the request.  For example, an \"authorization\" controller could send a  401 Unauthorized  response protecting the endpoint controller from unauthorized requests. A \"caching\" controller could send a response with information from a cache, preventing the endpoint controller from performing an expensive query.  Both middleware and endpoint controllers are instances of  Controller  (or a subclass). Middleware controllers are typically reusable, while endpoint controllers are typically not. If a middleware controller is not reusable, its logic might be better suited for the endpoint controller it precedes in the channel.  Most endpoint controllers are created by subclassing  ResourceController  (itself a subclass of  Controller ). This class allows you to implement methods for each HTTP method (like GET or POST) for a given endpoint.", 
            "title": "Controllers are Building Blocks"
        }, 
        {
            "location": "/http/structure/#the-application-channel-and-entry-point", 
            "text": "Each application designates one controller as the  entry point  of the application. This controller is the first to receive a new request and is the head of the application's channel. In most applications, the entry point is a  Router ; this controller allows multiple channels to be linked, effectively splitting the channel into sub-channels.   The diagram above looks like this in code:  class   AppChannel   extends   ApplicationChannel   { \n   @ override \n   Controller   get   entry   { \n     final   router   =   new   Router (); \n\n     router \n       . route ( /a ) \n       . link (()   =   new   AController ()); \n\n     router \n       . route ( /b ) \n       . link (()   =   new   Authorizer (...)) \n       . link (()   =   new   BController ()); \n\n     router \n       . route ( /c ) \n       . link (()   =   new   Authorizer (...)) \n       . link (()   =   new   CController ());    \n\n     return   router ; \n   }  }   See  this guide  for more details on the application channel and entry point.", 
            "title": "The Application Channel and Entry Point"
        }, 
        {
            "location": "/http/structure/#aqueduct-project-structure-and-organization", 
            "text": "An Aqueduct project is a directory that contains, at minimum, the following file structure:  pubspec.yaml\nlib/\n  application_name.dart  The name of any Dart application is defined by the  name  key in  pubspec.yaml . In order for  aqueduct serve  to run your application, there must be a  .dart  file in  lib/  with that same name. This is your application library file and it must declare a  ApplicationChannel  subclass or import a file that does. This is the bare minimum requirement to run an Aqueduct application. (See  Deploying  for more details on running applications.)  For organizing applications of reasonable size, we recommend the following structure:  pubspec.yaml\nconfig.src.yaml\nconfig.yaml\nlib/\n  application_name.dart\n  channel.dart  \n  controller/\n    user_controller.dart\n  model/\n    user.dart\ntest/\n  user_controller_test.dart\n  harness/\n    app.dart  The required  pubspec.yaml  and  lib/application_name.dart  files are present alongside a few others:   config.yaml : A  configuration file  for the running application.  config.src.yaml : A  template for config.yaml .  channel.dart : A file solely for the  ApplicationChannel  of an application. This file should be  exported  from  application_name.dart .  controller/ : A directory for  Controller  subclass files.  model/ : A directory for  ManagedObject T  subclass files.  test/harness/app.dart : A  test harness ) for automated testing.   Feel free to create other subdirectories in  lib/  for organizing other types of files.", 
            "title": "Aqueduct Project Structure and Organization"
        }, 
        {
            "location": "/http/structure/#aqueduct-and-dartio", 
            "text": "Aqueduct runs on top of  dart:io  and relies on its  HttpServer  implementation. When an Aqueduct application is started, one or more  HttpServer  instances are bound to the port specified by  aqueduct serve . For each HTTP request, an instance of  Request  is created to wrap the  HttpRequest  from  dart:io . The  Request  is added to a  ApplicationChannel , sending it through the channel of  Controller s until it is responded to.  In rare circumstances, you may choose to remove a  Request  from the application channel and manipulate the request with  dart:io  only. Once removed, it is your responsibility to respond to the request by setting properties on and closing the  HttpRequest.response . To take a request out of the channel, simply return  null  from a  Controller :  @ override  Controller   get   entryPoint   { \n   final   router   =   new   Router (); \n\n   router \n     . route ( /bypass_aqueduct ) \n     . linkFunction (( req )   async   { \n       req . response . statusCode   =   200 ; \n       req . response . close (); \n\n       return   null ; \n     }); \n\n   return   router ;  }   This technique is valuable when Aqueduct can't do something you want it to do or when using  websockets .", 
            "title": "Aqueduct and dart:io"
        }, 
        {
            "location": "/http/request_and_response/", 
            "text": "Request and Response Objects\n\n\nIn Aqueduct, HTTP requests and responses are instances of \nRequest\n and \nResponse\n, respectively. For every HTTP request an application receives, an instance of \nRequest\n is created. A \nResponse\n must be created for each \nRequest\n. Requests pass through a channel of \nControllers\n to be validated, modified and finally responded to.\n\n\nThe Request Object\n\n\nAn instance of \nRequest\n represents an HTTP request and are automatically created when the application receives a request. A \nRequest\n is a wrapper around the Dart standard library \nHttpRequest\n and its values - such as its URI or headers - can be accessed through its \nraw\n property.\n\n\nA \nRequest\n has a \nbody\n property. This property decodes the HTTP request body into Dart objects based on the request's content type. The mechanism to decode the body is determined by \nCodecRegistry\n, which is covered in more detail in a later section. By default, decoders exist for text, JSON and form data. The size of a request body is limited to 10MB by default and can be changed by setting the value of \nRequestBody.maxSize\n during application initialization.\n\n\nA \nRequest\n is handled by one or more \nController\ns before to be responded to. \nController\ns may validate or add more information to the request, so that later controllers can use this information. For example, an \nAuthorizer\n controller will validate the Authorization header of a request. Once validated, it will add authorization info to the request - like the authorized user ID - and pass it to the next controller. The next controller in the channel has access to the authorization info without having to perform another fetch.\n\n\nThese additional values are added to a \nRequest.attachments\n property. A \nRequest\n also has two built-in attachments, \nauthorization\n and \npath\n. \nauthorization\n contains authorization information from an \nAuthorizer\n and \npath\n has request path information from a \nRouter\n.\n\n\nRequest\ns are responded to when a controller creates a \nResponse\n.\n\n\nResponse Objects and HTTP Body Encoding\n\n\nA \nResponse\n has a status code, HTTP headers and an HTTP body. There are a number of convenience constructors for \nResponse\n for commonly used status codes. For example, \nResponse.ok\n creates a 200 OK status code response.\n\n\nvar\n \nresponse\n \n=\n \nnew\n \nResponse\n.\nok\n({\nkey\n:\n \nvalue\n});\n\n\n\n\n\n\nWhen a \nResponse\n is returned from a controller, Aqueduct handles sending the HTTP response back to the client.\n\n\nAn HTTP response often contains a \nbody\n. For example, the body in response to \nGET /users/1\n might be JSON object that represents a user. To ensure the client understands that the body is a JSON object, it includes the header \nContent-Type: application/json; charset=utf-8\n.\n\n\nWhen creating a \nResponse\n that has a body, you provide a \nbody object\n and a \ncontentType\n. For example:\n\n\nvar\n \nmap\n \n=\n \n{\nkey\n:\n \nvalue\n};\n\n\n\n// ContentType.JSON is the default, setting it may be omitted.\n\n\n// ContentType.JSON == `application/json; charset=utf-8\n\n\nvar\n \nresponse\n \n=\n \nnew\n \nResponse\n.\nok\n(\nmap\n)\n\n  \n..\ncontentType\n \n=\n \nContentType\n.\nJSON\n;\n\n\n\n\n\n\nBody objects are encoded according to their content-type. In the above, \nmap\n is first encoded as a JSON string and then to a list of UTF8 bytes.\n\n\n\n\nA \nContentType\n is made up of three components: a primary type, a subtype and an optional character set.\n\n\n\n\nThe primary and subtype determine the first conversion step and the charset determines the next. Each step is performed by an instance of \nCodec\n (from \ndart:convert\n). For example, the content type \napplication/json\n selects \nJsonCodec\n, while charset \nutf-8\n selects \nUtf8Codec\n. These two codecs are run in succession to convert the \nMap\n to a list of bytes.\n\n\nThe body object must be a valid input selected codec. In the above example, a \nMap\nString, dynamic\n can be encoded by a \nJsonCodec\n. But if the body object was something silly - like an \nController\n - encoding would fail at runtime and the client would be sent a 500 Server Error response. A valid input for one \nCodec\n may not be valid for another; it is up to you to ensure that the body object is valid for the \ncontentType\n of the response.\n\n\nNot all content types require two conversion steps. For example, when serving an HTML file, the body object is already an HTML \nString\n. It will only be converted by a charset encoder:\n\n\nvar\n \nhtml\n \n=\n \nhtml\n/html\n;\n\n\nvar\n \nresponse\n \n=\n \nnew\n \nResponse\n.\nok\n(\nhtml\n)\n\n  \n..\ncontentType\n \n=\n \nContentType\n.\nHTML\n;\n\n\n\n\n\n\nAnd an image body object needs no conversion at all, since it is already a list of bytes:\n\n\nvar\n \nimageFile\n \n=\n \nnew\n \nFile\n(\nimage.jpg\n);\n\n\nvar\n \nimageBytes\n \n=\n \nawait\n \nimageFile\n.\nreadAsBytes\n();\n\n\nvar\n \nresponse\n \n=\n \nnew\n \nResponse\n.\nok\n(\nimageBytes\n)\n\n  \n..\ncontentType\n \n=\n \nnew\n \nContentType\n(\nimage\n,\n \njpeg\n);\n\n\n\n\n\n\nSee a later section for more details on content type to codec mappings. Also, see the documentation for \nCodecRegistry\n for details on built-in codecs and adding codecs.\n\n\nStreaming Response Bodies\n\n\nA body object may also be a \nStream\nT\n. \nStream\nT\n body objects are most often used when serving files. This allows the contents of the file to be streamed from disk to the HTTP client without having to load the whole file into memory first. (See also \nFileController\n.)\n\n\nvar\n \nimageFile\n \n=\n \nnew\n \nFile\n(\nimage.jpg\n);\n\n\nvar\n \nimageByteStream\n \n=\n \nimageFile\n.\nopenRead\n();\n\n\nvar\n \nresponse\n \n=\n \nnew\n \nResponse\n.\nok\n(\nimageByteStream\n)\n\n  \n..\ncontentType\n \n=\n \nnew\n \nContentType\n(\nimage\n,\n \njpeg\n);\n\n\n\n\n\n\nWhen a body object is a \nStream\nT\n, the response will not be sent until the stream is closed. For finite streams - like those from opened filed - this happens as soon as the entire file is read. For streams that you construct yourself, you must close the stream some time after the response has been returned.\n\n\nCustom Objects\n\n\nAny object may be the body object of a \nResponse\n if it implements \nSerializable\n. An object conforming to this type must implement \nasMap()\n, which gets invoked on the body object prior to it being sent to the first encoding step. For example, the following object can be used as a body object and is automatically converted into a \nMap\n and then JSON encoded:\n\n\nclass\n \nPerson\n \nimplements\n \nSerializable\n \n{\n\n  \nString\n \nname\n;\n\n  \nString\n \nemail\n;\n\n\n  \nMap\nString\n,\n \ndynamic\n \nasMap\n()\n \n{\n\n    \nreturn\n \n{\n\n      \nname\n:\n \nname\n,\n\n      \nemail\n:\n \nemail\n\n    \n};\n\n  \n}\n\n\n  \n...\n\n\n}\n\n\n\nvar\n \nperson\n \n=\n \nnew\n \nPerson\n();\n\n\nvar\n \nresponse\n \n=\n \nnew\n \nResponse\n.\nok\n(\nperson\n);\n\n\n\n\n\n\nManagedObject\nT\n, part of the Aqueduct ORM, implements \nSerializable\n so results from \nQuery\nT\n may be body objects:\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nPerson\n(\ncontext\n)..\nwhere\n((\np\n)\n \n=\n \np\n.\nid\n).\nequalTo\n(\n1\n);\n\n\nvar\n \nperson\n \n=\n \nawait\n \nquery\n.\nfetchOne\n();\n\n\nvar\n \nresponse\n \n=\n \nnew\n \nResponse\n.\nok\n(\nperson\n);\n\n\n\n// or List\nSerializable\n\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nPerson\n(\ncontext\n);\n\n\nvar\n \npeople\n \n=\n \nawait\n \nquery\n.\nfetch\n();\n\n\nvar\n \nresponse\n \n=\n \nnew\n \nResponse\n.\nok\n(\npeople\n);\n\n\n\n\n\n\nNote that a \nMap\n itself is not \nSerializable\n and can't have \nSerializable\n values. For example, the following wouldn't work:\n\n\nvar\n \nmap\n \n=\n \n{\n\n  \nperson\n:\n \nnew\n \nPerson\n()\n\n\n};\n\n\nvar\n \nresponse\n \n=\n \nnew\n \nResponse\n.\nok\n(\nmap\n);\n\n\n\n\n\n\nThe entire flow of a body object is shown in the following diagram. Each orange item is an allowed body object type and shows the steps it will go through when being encoded to the HTTP response body. For example, a \nSerializable\n goes through three steps, whereas a \nList\nint\n goes through zero steps and is added as-is to the HTTP response.\n\n\n\n\nCodecs and Content Types\n\n\nIn the above sections, we glossed over how a codec gets selected when preparing the response body. The common case of \nManagedObject\nT\n body objects that are sent as UTF8 encoded JSON 'just works' and is suitable for most applications. When serving assets for a web application or different data formats like XML, it becomes important to understand how Aqueduct's codec repository works.\n\n\nCodecRegistry\n contains mappings from content types to \nCodec\ns. These codecs encode response bodies and decode request bodies. There are three built-in codecs for \napplication/json\n, \napplication/x-www-form-urlencoded\n and \ntext/*\n. When a response is being sent, the repository is searched for an entry that exactly matches the primary and subtype of the \nResponse.contentType\n. If an entry exists, the associated \nCodec\n starts the conversion. For example, if the content type is \napplication/json; charset=utf-8\n, the built-in \napplication/json\n codec encodes the body object. The character set is not evaluated at this stage.\n\n\nIf there isn't an exact match, but there is an entry for the primary type with the wildcard (\n*\n) subtype, that codec is used. For example, the built-in codec for \ntext/*\n will be selected for both \ntext/plain\n and \ntext/html\n. If there was something special that had to be done for \ntext/html\n, a more specific codec may be added for that type:\n\n\nclass\n \nMyChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \nCodecRegistry\n.\ndefaultInstance\n.\nadd\n(\nnew\n \nContentType\n(\napplication\n,\n \nhtml\n),\n \nnew\n \nHTMLCodec\n());\n\n  \n}\n\n\n}\n\n\n\n\n\n\nCodecs must be added in your \nApplicationChannel.prepare\n method. The codec must implement \nCodec\n from \ndart:convert\n. In the above example, when a response's content type is \ntext/html\n, the \nHTMLCodec\n will encode the body object. This codec takes precedence over \ntext/*\n because it is more specific. When selecting a codec for a response body, the \nContentType.charset\n doesn't impact which codec is selected.\n\n\nIf a response's content-type has a charset, then a charset encoder like \nUTF8\n will be applied as a last encoding step. For example, a response with content-type \napplication/json; charset=utf-8\n will encode the body object as a JSON string, which is then encoded as a list of UTF8 bytes. It is required that a response body's eventually encoded type is a list of bytes, so it follows that a codec that produces a string must have a charset.\n\n\nIf there is no codec in the repository for the content type of a \nResponse\n, the body object must be a \nList\nint\n or \nStream\nList\nint\n. If you find yourself converting data prior to setting it as a body object, it may make sense to add your own codec to \nCodecRegistry\n.\n\n\nA request's body, on the other hand, always starts as a list of bytes. To decode a JSON request body, it first must be decoded from the list of UTF8 bytes into a string. It is possible that a client could omit the charset in its content-type header. Codecs added to \nCodecRegistry\n may specify a default charset to interpret a charset-less content-type. When a codec is added to the repository, if content-type's charset is non-null, that is the default. For example, the JSON codec is added like this:\n\n\nCodecRegistry\n.\ndefaultInstance\n.\nadd\n(\n\n  \nnew\n \nContentType\n(\napplication\n,\n \njson\n,\n \ncharset:\n \nutf-8\n),\n\n  \nconst\n \nJsonCodec\n(),\n\n  \nallowCompression:\n \ntrue\n);\n\n\n\n\n\n\nIf the charset is null, no charset decoding occurs on a request body if one doesn't exist. Content-types that are decoded from a \nString\n should not use a default charset because the repository would always attempt to decode the body as a string first.\n\n\nCompression with gzip\n\n\nBody objects may be compressed with \ngzip\n if the HTTP client allows it \nand\n the \nCodecRegistry\n has been configured to compress the content type of the response. The three built-in codecs - \napplication/json\n, \napplication/x-www-form-urlencoded\n and \ntext/*\n - are all configured to allow compression. Compression occurs as the last step of conversion and only if the HTTP client sends the \nAccept-Encoding: gzip\n header.\n\n\nContent types that are not in the codec repository will not trigger compression, even if the HTTP client allows compression with the \nAccept-Encoding\n header. This is to prevent binary contents like images from being 'compressed', since they are likely already compressed by a content-specific algorithm. In order for Aqueduct to compress a content type other than the built-in types, you may add a codec to the repository with the \nallowCompression\n flag. (The default value is \ntrue\n.)\n\n\nCodecRegistry\n.\nadd\n(\n\n  \nnew\n \nContentType\n(\napplication\n,\n \nx-special\n),\n\n  \nnew\n \nMyCodec\n(),\n\n  \nallowCompression:\n \ntrue\n);\n\n\n\n\n\n\nYou may also set whether or not a content type uses compression without having to specify a codec if no conversion step needs to occur:\n\n\nCodecRegistry\n.\nsetAllowsCompression\n(\nnew\n \nContentType\n(\napplication\n,\n \nx-special\n),\n \ntrue\n);", 
            "title": "Request and Response Objects"
        }, 
        {
            "location": "/http/request_and_response/#request-and-response-objects", 
            "text": "In Aqueduct, HTTP requests and responses are instances of  Request  and  Response , respectively. For every HTTP request an application receives, an instance of  Request  is created. A  Response  must be created for each  Request . Requests pass through a channel of  Controllers  to be validated, modified and finally responded to.", 
            "title": "Request and Response Objects"
        }, 
        {
            "location": "/http/request_and_response/#the-request-object", 
            "text": "An instance of  Request  represents an HTTP request and are automatically created when the application receives a request. A  Request  is a wrapper around the Dart standard library  HttpRequest  and its values - such as its URI or headers - can be accessed through its  raw  property.  A  Request  has a  body  property. This property decodes the HTTP request body into Dart objects based on the request's content type. The mechanism to decode the body is determined by  CodecRegistry , which is covered in more detail in a later section. By default, decoders exist for text, JSON and form data. The size of a request body is limited to 10MB by default and can be changed by setting the value of  RequestBody.maxSize  during application initialization.  A  Request  is handled by one or more  Controller s before to be responded to.  Controller s may validate or add more information to the request, so that later controllers can use this information. For example, an  Authorizer  controller will validate the Authorization header of a request. Once validated, it will add authorization info to the request - like the authorized user ID - and pass it to the next controller. The next controller in the channel has access to the authorization info without having to perform another fetch.  These additional values are added to a  Request.attachments  property. A  Request  also has two built-in attachments,  authorization  and  path .  authorization  contains authorization information from an  Authorizer  and  path  has request path information from a  Router .  Request s are responded to when a controller creates a  Response .", 
            "title": "The Request Object"
        }, 
        {
            "location": "/http/request_and_response/#response-objects-and-http-body-encoding", 
            "text": "A  Response  has a status code, HTTP headers and an HTTP body. There are a number of convenience constructors for  Response  for commonly used status codes. For example,  Response.ok  creates a 200 OK status code response.  var   response   =   new   Response . ok ({ key :   value });   When a  Response  is returned from a controller, Aqueduct handles sending the HTTP response back to the client.  An HTTP response often contains a  body . For example, the body in response to  GET /users/1  might be JSON object that represents a user. To ensure the client understands that the body is a JSON object, it includes the header  Content-Type: application/json; charset=utf-8 .  When creating a  Response  that has a body, you provide a  body object  and a  contentType . For example:  var   map   =   { key :   value };  // ContentType.JSON is the default, setting it may be omitted.  // ContentType.JSON == `application/json; charset=utf-8  var   response   =   new   Response . ok ( map ) \n   .. contentType   =   ContentType . JSON ;   Body objects are encoded according to their content-type. In the above,  map  is first encoded as a JSON string and then to a list of UTF8 bytes.   A  ContentType  is made up of three components: a primary type, a subtype and an optional character set.   The primary and subtype determine the first conversion step and the charset determines the next. Each step is performed by an instance of  Codec  (from  dart:convert ). For example, the content type  application/json  selects  JsonCodec , while charset  utf-8  selects  Utf8Codec . These two codecs are run in succession to convert the  Map  to a list of bytes.  The body object must be a valid input selected codec. In the above example, a  Map String, dynamic  can be encoded by a  JsonCodec . But if the body object was something silly - like an  Controller  - encoding would fail at runtime and the client would be sent a 500 Server Error response. A valid input for one  Codec  may not be valid for another; it is up to you to ensure that the body object is valid for the  contentType  of the response.  Not all content types require two conversion steps. For example, when serving an HTML file, the body object is already an HTML  String . It will only be converted by a charset encoder:  var   html   =   html /html ;  var   response   =   new   Response . ok ( html ) \n   .. contentType   =   ContentType . HTML ;   And an image body object needs no conversion at all, since it is already a list of bytes:  var   imageFile   =   new   File ( image.jpg );  var   imageBytes   =   await   imageFile . readAsBytes ();  var   response   =   new   Response . ok ( imageBytes ) \n   .. contentType   =   new   ContentType ( image ,   jpeg );   See a later section for more details on content type to codec mappings. Also, see the documentation for  CodecRegistry  for details on built-in codecs and adding codecs.", 
            "title": "Response Objects and HTTP Body Encoding"
        }, 
        {
            "location": "/http/request_and_response/#streaming-response-bodies", 
            "text": "A body object may also be a  Stream T .  Stream T  body objects are most often used when serving files. This allows the contents of the file to be streamed from disk to the HTTP client without having to load the whole file into memory first. (See also  FileController .)  var   imageFile   =   new   File ( image.jpg );  var   imageByteStream   =   imageFile . openRead ();  var   response   =   new   Response . ok ( imageByteStream ) \n   .. contentType   =   new   ContentType ( image ,   jpeg );   When a body object is a  Stream T , the response will not be sent until the stream is closed. For finite streams - like those from opened filed - this happens as soon as the entire file is read. For streams that you construct yourself, you must close the stream some time after the response has been returned.", 
            "title": "Streaming Response Bodies"
        }, 
        {
            "location": "/http/request_and_response/#custom-objects", 
            "text": "Any object may be the body object of a  Response  if it implements  Serializable . An object conforming to this type must implement  asMap() , which gets invoked on the body object prior to it being sent to the first encoding step. For example, the following object can be used as a body object and is automatically converted into a  Map  and then JSON encoded:  class   Person   implements   Serializable   { \n   String   name ; \n   String   email ; \n\n   Map String ,   dynamic   asMap ()   { \n     return   { \n       name :   name , \n       email :   email \n     }; \n   } \n\n   ...  }  var   person   =   new   Person ();  var   response   =   new   Response . ok ( person );   ManagedObject T , part of the Aqueduct ORM, implements  Serializable  so results from  Query T  may be body objects:  var   query   =   new   Query Person ( context ).. where (( p )   =   p . id ). equalTo ( 1 );  var   person   =   await   query . fetchOne ();  var   response   =   new   Response . ok ( person );  // or List Serializable  var   query   =   new   Query Person ( context );  var   people   =   await   query . fetch ();  var   response   =   new   Response . ok ( people );   Note that a  Map  itself is not  Serializable  and can't have  Serializable  values. For example, the following wouldn't work:  var   map   =   { \n   person :   new   Person ()  };  var   response   =   new   Response . ok ( map );   The entire flow of a body object is shown in the following diagram. Each orange item is an allowed body object type and shows the steps it will go through when being encoded to the HTTP response body. For example, a  Serializable  goes through three steps, whereas a  List int  goes through zero steps and is added as-is to the HTTP response.", 
            "title": "Custom Objects"
        }, 
        {
            "location": "/http/request_and_response/#codecs-and-content-types", 
            "text": "In the above sections, we glossed over how a codec gets selected when preparing the response body. The common case of  ManagedObject T  body objects that are sent as UTF8 encoded JSON 'just works' and is suitable for most applications. When serving assets for a web application or different data formats like XML, it becomes important to understand how Aqueduct's codec repository works.  CodecRegistry  contains mappings from content types to  Codec s. These codecs encode response bodies and decode request bodies. There are three built-in codecs for  application/json ,  application/x-www-form-urlencoded  and  text/* . When a response is being sent, the repository is searched for an entry that exactly matches the primary and subtype of the  Response.contentType . If an entry exists, the associated  Codec  starts the conversion. For example, if the content type is  application/json; charset=utf-8 , the built-in  application/json  codec encodes the body object. The character set is not evaluated at this stage.  If there isn't an exact match, but there is an entry for the primary type with the wildcard ( * ) subtype, that codec is used. For example, the built-in codec for  text/*  will be selected for both  text/plain  and  text/html . If there was something special that had to be done for  text/html , a more specific codec may be added for that type:  class   MyChannel   extends   ApplicationChannel   { \n   @ override \n   Future   prepare ()   async   { \n     CodecRegistry . defaultInstance . add ( new   ContentType ( application ,   html ),   new   HTMLCodec ()); \n   }  }   Codecs must be added in your  ApplicationChannel.prepare  method. The codec must implement  Codec  from  dart:convert . In the above example, when a response's content type is  text/html , the  HTMLCodec  will encode the body object. This codec takes precedence over  text/*  because it is more specific. When selecting a codec for a response body, the  ContentType.charset  doesn't impact which codec is selected.  If a response's content-type has a charset, then a charset encoder like  UTF8  will be applied as a last encoding step. For example, a response with content-type  application/json; charset=utf-8  will encode the body object as a JSON string, which is then encoded as a list of UTF8 bytes. It is required that a response body's eventually encoded type is a list of bytes, so it follows that a codec that produces a string must have a charset.  If there is no codec in the repository for the content type of a  Response , the body object must be a  List int  or  Stream List int . If you find yourself converting data prior to setting it as a body object, it may make sense to add your own codec to  CodecRegistry .  A request's body, on the other hand, always starts as a list of bytes. To decode a JSON request body, it first must be decoded from the list of UTF8 bytes into a string. It is possible that a client could omit the charset in its content-type header. Codecs added to  CodecRegistry  may specify a default charset to interpret a charset-less content-type. When a codec is added to the repository, if content-type's charset is non-null, that is the default. For example, the JSON codec is added like this:  CodecRegistry . defaultInstance . add ( \n   new   ContentType ( application ,   json ,   charset:   utf-8 ), \n   const   JsonCodec (), \n   allowCompression:   true );   If the charset is null, no charset decoding occurs on a request body if one doesn't exist. Content-types that are decoded from a  String  should not use a default charset because the repository would always attempt to decode the body as a string first.", 
            "title": "Codecs and Content Types"
        }, 
        {
            "location": "/http/request_and_response/#compression-with-gzip", 
            "text": "Body objects may be compressed with  gzip  if the HTTP client allows it  and  the  CodecRegistry  has been configured to compress the content type of the response. The three built-in codecs -  application/json ,  application/x-www-form-urlencoded  and  text/*  - are all configured to allow compression. Compression occurs as the last step of conversion and only if the HTTP client sends the  Accept-Encoding: gzip  header.  Content types that are not in the codec repository will not trigger compression, even if the HTTP client allows compression with the  Accept-Encoding  header. This is to prevent binary contents like images from being 'compressed', since they are likely already compressed by a content-specific algorithm. In order for Aqueduct to compress a content type other than the built-in types, you may add a codec to the repository with the  allowCompression  flag. (The default value is  true .)  CodecRegistry . add ( \n   new   ContentType ( application ,   x-special ), \n   new   MyCodec (), \n   allowCompression:   true );   You may also set whether or not a content type uses compression without having to specify a codec if no conversion step needs to occur:  CodecRegistry . setAllowsCompression ( new   ContentType ( application ,   x-special ),   true );", 
            "title": "Compression with gzip"
        }, 
        {
            "location": "/http/controller/", 
            "text": "Handling Requests: Fundamentals\n\n\nLearn how \nController\n objects are linked together to handle HTTP requests.\n\n\nOverview\n\n\nA controller is the basic building block of an Aqueduct application. A controller handles an HTTP request in some way. For example, a controller could return a 200 OK response with a JSON-encoded list of city names. A controller could also check a request to make sure it had the right credentials in its authorization header.\n\n\nControllers are linked together to compose their behaviors into a \nchannel\n. A channel handles a request by performing each of its controllers' behavior in order. For example, a channel with the aforementioned controllers would verify the credentials of a request and then returning a list of city names.\n\n\n\n\nThe \nController\n class provides the behavior for linking controllers together, and you subclass it to provide the logic for a particular controller behavior.\n\n\nLinking Controllers\n\n\nControllers are linked with their \nlink\n method. This method takes a closure that returns the next controller in the channel. The following shows a channel composed of two controllers:\n\n\nfinal\n \ncontrollerA\n \n=\n \nController\n();\n\n\ncontroller\n.\nlink\n(()\n \n=\n \nController\n());\n\n\n\n\n\n\nWhen \ncontrollerA\n handles a request, it can choose to respond to the request or let the request continue in the channel. When the request continues in this channel, the controller created by the closure passed to \nlink\n handles the request. Any number of controllers can be linked together in a channel, but the last controller must respond to the request. Controllers that always responder to request are called \nendpoint controllers\n, as opposed to \nmiddleware controllers\n that verify or modify the request and let the next controller in the channel handle it.\n\n\nLinking occurs in an \napplication channel\n, and is finalized during startup of your application (i.e., once you have set up your controllers, the cannot be changed once the application starts receiving requests). In a typical application, a \nRouter\n controller splits an application channel into multiple sub-channels.\n\n\nCreating Request Handling Behavior by Subclassing Controller\n\n\nEvery \nController\n implements its \nhandle\n method to handle a request. You override this method in your controllers to provide the logic for your application's controllers. The following is an example of an endpoint controller, because it always sends a response:\n\n\nclass\n \nNoteController\n \nextends\n \nController\n \n{\n\n  \n@\noverride\n\n  \nFuture\nRequestOrResponse\n \nhandle\n(\nRequest\n \nrequest\n)\n \nasync\n \n{\n\n    \nfinal\n \nnotes\n \n=\n \nawait\n \nfetchNotesFromDatabase\n();\n\n\n    \nreturn\n \nnew\n \nResponse\n.\nok\n(\nnotes\n);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nThis \nhandle\n method creates and returns a \nResponse\n object. When a \nhandle\n method returns a response, that response is sent to the client. Any linked controllers do not have their \nhandle\n method invoked; the request is removed from the channel.\n\n\nA middleware controller returns a response when the request is invalid. For example, an \nAuthorizer\n controller returns a \n401 Unauthorized\n response if the request's credentials are invalid (this removes the request from the channel). If a middleware controller deems the request acceptable, it returns the request from its \nhandle\n method. This signals to Aqueduct that the next controller in the channel should handle the request.\n\n\nAs an example, the pseudo-code for an \nAuthorizer\n looks like this:\n\n\nclass\n \nAuthorizer\n \nextends\n \nController\n \n{\n\n  \n@\noverride\n\n  \nFuture\nRequestOrResponse\n \nhandle\n(\nRequest\n \nrequest\n)\n \nasync\n \n{\n\n    \nif\n \n(\nisValid\n(\nrequest\n))\n \n{\n\n      \nreturn\n \nrequest\n;\n\n    \n}\n\n\n    \nreturn\n \nnew\n \nResponse\n.\nunauthorized\n();\n\n  \n}\n\n\n}\n\n\n\n\n\n\n\n\nEndpoint Controllers\n\n\nIn most cases, endpoint controllers are created by subclassing \nResourceController\n. This controller allows you to declare more than one handler method in a controller to better organize logic. For example, one method might handle POST requests, while another handles GET requests.\n\n\n\n\nModifying a Response with Middleware\n\n\nA middleware controller can add a \nresponse modifier\n to a request. When an endpoint controller eventually creates a response, these modifiers are applied to the response before it is sent. Modifiers are added by invoking \naddResponseModifier\n on a request.\n\n\nclass\n \nVersioner\n \nextends\n \nController\n \n{\n\n  \nFuture\nRequestOrResponse\n \nhandle\n(\nRequest\n \nrequest\n)\n \nasync\n \n{\n\n    \nrequest\n.\naddResponseModifier\n((\nresponse\n)\n \n{\n\n      \nresponse\n.\nheaders\n[\nx-api-version\n]\n \n=\n \n2.1\n;\n\n    \n});\n\n\n    \nreturn\n \nrequest\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nAny number of controllers can add a response modifier to a request; they will be processed in the order that they were added. Response modifiers are applied before the response body is encoded, allowing the body object to be manipulated. Response modifiers are invoked regardless of the response generated by the endpoint controller. If an uncaught error is thrown while adding response modifiers, any remaining response modifiers are not called and a 500 Server Error response is sent.\n\n\nLinking Functions\n\n\nFor simple behavior, functions with the same signature as \nhandle\n can be linked to controllers:\n\n\n  \nrouter\n\n    \n.\nroute\n(\n/path\n)\n\n    \n.\nlinkFunction\n((\nreq\n)\n \nasync\n \n=\n \nreq\n);\n\n    \n.\nlinkFunction\n((\nreq\n)\n \nasync\n \n=\n \nnew\n \nResponse\n.\nok\n(\nnull\n));\n\n\n\n\n\n\nLinking a function has all of the same behavior as \nController.handle\n: it can return a request or response, automatically handles exceptions, and can have controllers (and functions) linked to it.\n\n\nController Instantiation and Recycling\n\n\nIt is important to understand why \nlink\n takes a closure, instead of a controller object. Aqueduct is an object oriented framework. Objects have both state and behavior. An application will receive multiple requests that will be handled by the same type of controller. If a mutable controller object were reused to handle multiple requests, it could retain some of its state between requests. This would create problems that are difficult to debug.\n\n\nMost controllers are immutable - in other words, all of their properties are final and they have no setters. This (mostly) ensures that the controller won't change behavior between requests. When a controller is immutable, the \nlink\n closure is invoked once to create and link the controller object, and then the closure is discarded. The same controller object will be reused for every request.\n\n\nControllers can be mutable, with the caveat that they cannot be reused for multiple requests. For example, a \nResourceController\n can have properties that are bound to the values of a request, and therefore these properties will change and a new instance must be created for each request.\n\n\nA mutable \nController\n subclass must implement \nRecyclable\nT\n. The \nlink\n closure will be invoked for each request, creating a new instance of the recyclable controller to handle the request. If a controller has an expensive initialization process, the results of that initialization can be calculated once and reused for each controller instance by implementing the methods from \nRecyclable\nT\n.\n\n\nclass\n \nMyControllerState\n \n{\n\n  \ndynamic\n \nstuff\n;\n\n\n}\n\n\n\nclass\n \nMyController\n \nextends\n \nController\n \nimplements\n \nRecyclable\nMyControllerState\n \n{\n\n  \n@\noverride\n\n  \nMyControllerState\n \nget\n \nrecycledState\n \n=\n \nexpensiveCalculation\n();\n\n\n  \n@\noverride\n\n  \nvoid\n \nrestore\n(\nMyControllerState\n \nstate\n)\n \n{\n\n    \n_restoredState\n \n=\n \nstate\n;\n\n  \n}\n\n\n  \nMyControllerState\n \n_restoredState\n;\n\n\n  \n@\noverride\n\n  \nFutureOr\nRequestOrResponse\n \nhandle\n(\nRequest\n \nrequest\n)\n \nasync\n \n{\n\n    \n/* use _restoredState */\n\n    \nreturn\n \nnew\n \nResponse\n.\nok\n(...);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nThe \nrecycledState\n getter is called once, when the controller is first linked. Each new instance of a recyclable controller has its \nrestore\n method invoked prior to handling the request, and the data returned by \nrecycledState\n is passed as an argument. As an example, \nResourceController\n 'compiles' its operation methods. The compiled product is stored as recycled state so that future instances can bind request data more efficiently.\n\n\nException Handling\n\n\nIf an exception or error is thrown during the handling of a request, the controller currently handling the request will catch it. For the majority of values caught, a controller will send a 500 Server Response. The details of the exception or error will be \nlogged\n, and the request is removed from the channel (it will not be passed to a linked controller).\n\n\nThis is the default behavior for all thrown values except \nResponse\n and \nHandlerException\n.\n\n\nThrowing Responses\n\n\nA \nResponse\n can be thrown at any time; the controller handling the request will catch it and send it to the client. This completes the request. This might not seem useful, for example, the following shows a silly use of this behavior:\n\n\nclass\n \nThrower\n \nextends\n \nController\n \n{\n\n  \n@\noverride\n\n  \nFuture\nRequestOrResponse\n \nhandle\n(\nRequest\n \nrequest\n)\n \nasync\n \n{\n\n    \nif\n \n(\n!\nisForbidden\n(\nrequest\n))\n \n{\n\n      \nthrow\n \nnew\n \nResponse\n.\nforbidden\n();\n\n    \n}\n\n\n    \nreturn\n \nnew\n \nResponse\n.\nok\n(\nnull\n);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nHowever, it can be valuable to send error responses from elsewhere in code as an application's codebase becomes more layered.\n\n\nThrowing HandlerExceptions\n\n\nExceptions can implement \nHandlerException\n to provide a response other than the default when thrown. For example, an application that handles bank transactions might declare an exception for invalid withdrawals:\n\n\nenum\n \nWithdrawalProblem\n \n{\n\n  \ninsufficientFunds\n,\n\n  \nbankClosed\n\n\n}\n\n\nclass\n \nWithdrawalException\n \nimplements\n \nException\n \n{\n\n  \nAccountException\n(\nthis\n.\nproblem\n);\n\n\n  \nfinal\n \nWithdrawalProblem\n \nproblem\n;\n\n\n}\n\n\n\n\n\n\nController code can catch this exception to return a different status code depending on the exact problem with a withdrawal. If this code has to be written in multiple places, it is useful for \nWithdrawalException\n to implement \nHandlerException\n. An implementor must provide an implementation for \nresponse\n:\n\n\nclass\n \nWithdrawalException\n \nimplements\n \nHandlerException\n \n{\n\n  \nAccountException\n(\nthis\n.\nproblem\n);\n\n\n  \nfinal\n \nWithdrawalProblem\n \nproblem\n;\n\n\n  \n@\noverride\n\n  \nResponse\n \nget\n \nresponse\n \n{\n\n    \nswitch\n \n(\nproblem\n)\n \n{\n\n      \ncase\n \nWithdrawalProblem\n.\ninsufficientFunds:\n\n        \nreturn\n \nnew\n \nResponse\n.\nbadRequest\n(\nbody:\n \n{\nerror\n:\n \ninsufficient_funds\n});\n\n      \ncase\n \nWithdrawalProblem\n.\nbankClosed:\n\n        \nreturn\n \nnew\n \nResponse\n.\nbadRequest\n(\nbody:\n \n{\nerror\n:\n \nbank_closed\n});\n\n    \n}\n\n  \n}\n\n\n}\n\n\n\n\n\n\nThe Aqueduct ORM exceptions (\nQueryException\n) implement \nHandlerException\n to return a response that best represents the ORM exception. For example, if a unique constraint is violated by a query, the thrown exception implements \nresponse\n to return a 409 Conflict response.\n\n\nCORS Headers and Preflight Requests\n\n\nController\ns have built-in behavior for handling CORS requests. They will automatically respond to \nOPTIONS\n preflight requests and attach CORS headers to any other response. See \nthe chapter on CORS\n for more details.", 
            "title": "Handling Requests: Fundamentals"
        }, 
        {
            "location": "/http/controller/#handling-requests-fundamentals", 
            "text": "Learn how  Controller  objects are linked together to handle HTTP requests.", 
            "title": "Handling Requests: Fundamentals"
        }, 
        {
            "location": "/http/controller/#overview", 
            "text": "A controller is the basic building block of an Aqueduct application. A controller handles an HTTP request in some way. For example, a controller could return a 200 OK response with a JSON-encoded list of city names. A controller could also check a request to make sure it had the right credentials in its authorization header.  Controllers are linked together to compose their behaviors into a  channel . A channel handles a request by performing each of its controllers' behavior in order. For example, a channel with the aforementioned controllers would verify the credentials of a request and then returning a list of city names.   The  Controller  class provides the behavior for linking controllers together, and you subclass it to provide the logic for a particular controller behavior.", 
            "title": "Overview"
        }, 
        {
            "location": "/http/controller/#linking-controllers", 
            "text": "Controllers are linked with their  link  method. This method takes a closure that returns the next controller in the channel. The following shows a channel composed of two controllers:  final   controllerA   =   Controller ();  controller . link (()   =   Controller ());   When  controllerA  handles a request, it can choose to respond to the request or let the request continue in the channel. When the request continues in this channel, the controller created by the closure passed to  link  handles the request. Any number of controllers can be linked together in a channel, but the last controller must respond to the request. Controllers that always responder to request are called  endpoint controllers , as opposed to  middleware controllers  that verify or modify the request and let the next controller in the channel handle it.  Linking occurs in an  application channel , and is finalized during startup of your application (i.e., once you have set up your controllers, the cannot be changed once the application starts receiving requests). In a typical application, a  Router  controller splits an application channel into multiple sub-channels.", 
            "title": "Linking Controllers"
        }, 
        {
            "location": "/http/controller/#creating-request-handling-behavior-by-subclassing-controller", 
            "text": "Every  Controller  implements its  handle  method to handle a request. You override this method in your controllers to provide the logic for your application's controllers. The following is an example of an endpoint controller, because it always sends a response:  class   NoteController   extends   Controller   { \n   @ override \n   Future RequestOrResponse   handle ( Request   request )   async   { \n     final   notes   =   await   fetchNotesFromDatabase (); \n\n     return   new   Response . ok ( notes ); \n   }  }   This  handle  method creates and returns a  Response  object. When a  handle  method returns a response, that response is sent to the client. Any linked controllers do not have their  handle  method invoked; the request is removed from the channel.  A middleware controller returns a response when the request is invalid. For example, an  Authorizer  controller returns a  401 Unauthorized  response if the request's credentials are invalid (this removes the request from the channel). If a middleware controller deems the request acceptable, it returns the request from its  handle  method. This signals to Aqueduct that the next controller in the channel should handle the request.  As an example, the pseudo-code for an  Authorizer  looks like this:  class   Authorizer   extends   Controller   { \n   @ override \n   Future RequestOrResponse   handle ( Request   request )   async   { \n     if   ( isValid ( request ))   { \n       return   request ; \n     } \n\n     return   new   Response . unauthorized (); \n   }  }    Endpoint Controllers  In most cases, endpoint controllers are created by subclassing  ResourceController . This controller allows you to declare more than one handler method in a controller to better organize logic. For example, one method might handle POST requests, while another handles GET requests.", 
            "title": "Creating Request Handling Behavior by Subclassing Controller"
        }, 
        {
            "location": "/http/controller/#modifying-a-response-with-middleware", 
            "text": "A middleware controller can add a  response modifier  to a request. When an endpoint controller eventually creates a response, these modifiers are applied to the response before it is sent. Modifiers are added by invoking  addResponseModifier  on a request.  class   Versioner   extends   Controller   { \n   Future RequestOrResponse   handle ( Request   request )   async   { \n     request . addResponseModifier (( response )   { \n       response . headers [ x-api-version ]   =   2.1 ; \n     }); \n\n     return   request ; \n   }  }   Any number of controllers can add a response modifier to a request; they will be processed in the order that they were added. Response modifiers are applied before the response body is encoded, allowing the body object to be manipulated. Response modifiers are invoked regardless of the response generated by the endpoint controller. If an uncaught error is thrown while adding response modifiers, any remaining response modifiers are not called and a 500 Server Error response is sent.", 
            "title": "Modifying a Response with Middleware"
        }, 
        {
            "location": "/http/controller/#linking-functions", 
            "text": "For simple behavior, functions with the same signature as  handle  can be linked to controllers:     router \n     . route ( /path ) \n     . linkFunction (( req )   async   =   req ); \n     . linkFunction (( req )   async   =   new   Response . ok ( null ));   Linking a function has all of the same behavior as  Controller.handle : it can return a request or response, automatically handles exceptions, and can have controllers (and functions) linked to it.", 
            "title": "Linking Functions"
        }, 
        {
            "location": "/http/controller/#controller-instantiation-and-recycling", 
            "text": "It is important to understand why  link  takes a closure, instead of a controller object. Aqueduct is an object oriented framework. Objects have both state and behavior. An application will receive multiple requests that will be handled by the same type of controller. If a mutable controller object were reused to handle multiple requests, it could retain some of its state between requests. This would create problems that are difficult to debug.  Most controllers are immutable - in other words, all of their properties are final and they have no setters. This (mostly) ensures that the controller won't change behavior between requests. When a controller is immutable, the  link  closure is invoked once to create and link the controller object, and then the closure is discarded. The same controller object will be reused for every request.  Controllers can be mutable, with the caveat that they cannot be reused for multiple requests. For example, a  ResourceController  can have properties that are bound to the values of a request, and therefore these properties will change and a new instance must be created for each request.  A mutable  Controller  subclass must implement  Recyclable T . The  link  closure will be invoked for each request, creating a new instance of the recyclable controller to handle the request. If a controller has an expensive initialization process, the results of that initialization can be calculated once and reused for each controller instance by implementing the methods from  Recyclable T .  class   MyControllerState   { \n   dynamic   stuff ;  }  class   MyController   extends   Controller   implements   Recyclable MyControllerState   { \n   @ override \n   MyControllerState   get   recycledState   =   expensiveCalculation (); \n\n   @ override \n   void   restore ( MyControllerState   state )   { \n     _restoredState   =   state ; \n   } \n\n   MyControllerState   _restoredState ; \n\n   @ override \n   FutureOr RequestOrResponse   handle ( Request   request )   async   { \n     /* use _restoredState */ \n     return   new   Response . ok (...); \n   }  }   The  recycledState  getter is called once, when the controller is first linked. Each new instance of a recyclable controller has its  restore  method invoked prior to handling the request, and the data returned by  recycledState  is passed as an argument. As an example,  ResourceController  'compiles' its operation methods. The compiled product is stored as recycled state so that future instances can bind request data more efficiently.", 
            "title": "Controller Instantiation and Recycling"
        }, 
        {
            "location": "/http/controller/#exception-handling", 
            "text": "If an exception or error is thrown during the handling of a request, the controller currently handling the request will catch it. For the majority of values caught, a controller will send a 500 Server Response. The details of the exception or error will be  logged , and the request is removed from the channel (it will not be passed to a linked controller).  This is the default behavior for all thrown values except  Response  and  HandlerException .", 
            "title": "Exception Handling"
        }, 
        {
            "location": "/http/controller/#throwing-responses", 
            "text": "A  Response  can be thrown at any time; the controller handling the request will catch it and send it to the client. This completes the request. This might not seem useful, for example, the following shows a silly use of this behavior:  class   Thrower   extends   Controller   { \n   @ override \n   Future RequestOrResponse   handle ( Request   request )   async   { \n     if   ( ! isForbidden ( request ))   { \n       throw   new   Response . forbidden (); \n     } \n\n     return   new   Response . ok ( null ); \n   }  }   However, it can be valuable to send error responses from elsewhere in code as an application's codebase becomes more layered.", 
            "title": "Throwing Responses"
        }, 
        {
            "location": "/http/controller/#throwing-handlerexceptions", 
            "text": "Exceptions can implement  HandlerException  to provide a response other than the default when thrown. For example, an application that handles bank transactions might declare an exception for invalid withdrawals:  enum   WithdrawalProblem   { \n   insufficientFunds , \n   bankClosed  }  class   WithdrawalException   implements   Exception   { \n   AccountException ( this . problem ); \n\n   final   WithdrawalProblem   problem ;  }   Controller code can catch this exception to return a different status code depending on the exact problem with a withdrawal. If this code has to be written in multiple places, it is useful for  WithdrawalException  to implement  HandlerException . An implementor must provide an implementation for  response :  class   WithdrawalException   implements   HandlerException   { \n   AccountException ( this . problem ); \n\n   final   WithdrawalProblem   problem ; \n\n   @ override \n   Response   get   response   { \n     switch   ( problem )   { \n       case   WithdrawalProblem . insufficientFunds: \n         return   new   Response . badRequest ( body:   { error :   insufficient_funds }); \n       case   WithdrawalProblem . bankClosed: \n         return   new   Response . badRequest ( body:   { error :   bank_closed }); \n     } \n   }  }   The Aqueduct ORM exceptions ( QueryException ) implement  HandlerException  to return a response that best represents the ORM exception. For example, if a unique constraint is violated by a query, the thrown exception implements  response  to return a 409 Conflict response.", 
            "title": "Throwing HandlerExceptions"
        }, 
        {
            "location": "/http/controller/#cors-headers-and-preflight-requests", 
            "text": "Controller s have built-in behavior for handling CORS requests. They will automatically respond to  OPTIONS  preflight requests and attach CORS headers to any other response. See  the chapter on CORS  for more details.", 
            "title": "CORS Headers and Preflight Requests"
        }, 
        {
            "location": "/http/routing/", 
            "text": "Routing\n\n\nWhat is routing?\n\n\nEvery HTTP request has a URL. A URL identifies a \nresource\n. In the early days of the Internet, a resource was a file. For example, the URL \nhttp://www.geocities.com/my_page/image.jpg\n would return the file \nimage.jpg\n from the folder \nmy_page\n on the webserver located at \nwww.geocities.com\n. In a web application today, resources come from many other sources of data, like a database or a connected device. The job of a web application is to provide, create or modify a resource for a URL, wherever that resource might come from.\n\n\nA URL is made up of many parts, some of which are optional. The typical URL we see as humans looks like this: \nhttp://stablekernel.com/about\n. Most people recognize that typing this URL into a browser would take them to our company's \"About\" page. In other words, our \"About\" page is a resource and the URL identifies it.\n\n\nMore generally, the \"About\" page URL has the three required components of a URL: a \nscheme\n (\nhttp\n), a \nhost\n (\nstablekernel.com\n) and a \npath\n (\n/about\n). The host specifies the computer responsible for providing the resource, the path identifies the resource and the scheme lets both the requester and the host know how they should exchange information.\n\n\nAn Aqueduct application receives requests when the scheme is \nhttp\n (or \nhttps\n) and the host refers to a machine where the application is running. Therefore, once the application gets the request, it only cares about the remaining component: the path.\n\n\nIn Aqueduct, a \nRouter\n routes \nRequest\ns to a \nController\n based on the request path. This process is known as \nrouting\n. When an application starts up, routes are registered in a subclass of \nApplicationChannel\n. Each registered route creates a new \nchannel\n of \nController\ns that will handle the request.\n\n\nRoute Specifications Match HTTP Request Paths\n\n\nA route is registered by invoking \nRouter.route\n. This method takes a \nroute specification\n - a \nString\n with some syntax rules that will match the path of a request. This registration occurs when an application first starts by overriding \nApplicationChannel.entryPoint\n. For example:\n\n\nclass\n \nMyApplicationChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nnew\n \nRouter\n();\n\n\n    \nrouter\n\n      \n.\nroute\n(\n/users\n)\n\n      \n.\nlinkFunction\n((\nreq\n)\n \nasync\n \n=\n \nnew\n \nResponse\n.\nok\n(\nawait\n \ngetAllUsers\n());\n\n\n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nThe argument to \nroute\n is the route specification string. This particular route matches the path \n/users\n. That is, a request for the URL \nhttp://myserver.com/users\n will be handled by the \nlinkFunction\n closure. (Leading and trailing slashes are stripped out when routes are compiled, so including them has no effect, but it is good style to show a leading slash.)\n\n\nA path can have multiple segments (the characters between slashes). For example, the path \n/users/foo\n has two path segments: \nusers\n and \nfoo\n. A route specification matches each segment of a path against each of its segments. The path and the route must also have the same number of segments. Thus, the route specification \n/users/foo\n would match the path \n/users/foo\n, but it would not match the paths \n/users\n, \n/users/7\n or \n/users/foo/1\n.\n\n\nPath Variables\n\n\nA route specification may have \npath variables\n. A path variable captures the value from a path segment, so that your code can use it. A path variable is most often used to uniquely identify a resource by some identifier, like \n/users/1\n and \n/users/2\n.\n\n\nIn a route specification, a path variable starts with a colon (\n:\n). The name of the variable follows this colon. For example, consider the following route that declares a path variable named \nuserID\n:\n\n\nrouter\n.\nroute\n(\n/users/:userID\n)\n\n\n\n\n\n\nThis route specification will match \n/users/1\n, \n/users/2\n, \n/users/foo\n, etc. The value of \nuserID\n is \n1\n, \n2\n and \nfoo\n, respectively. This route won't match \n/users\n or \n/users/1/2\n.\n\n\nOptional Path Segments\n\n\nRoutes may have optional path segments. This allows a group of routes that all refer to a resource collection and its individual resources to go to the same controller. For example, the requests \n/users\n and \n/users/1\n can both be covered by a single route specification.\n\n\nAn optional path segment has square brackets (\n[]\n) around it. The brackets can go before or after slashes. For example, the following two syntaxes register a route that accepts both \n/users\n and \n/users/:userID\n:\n\n\nroute\n(\n/users/[:userID]\n)\n\n\nroute\n(\n/users[/:userID]\n)\n\n\n\n\n\n\nConceptually, a request with a path of \n/users/1\n identifies a single user, where \n/users\n identifies all users. Optional segments are used to create better code structure by forwarding requests that deal with a specific type of resource to the same controller. Therefore, the code to handle one user or multiple users is written in the same place.\n\n\nYou may have any number of optional segments in a route specification. Each optional segment must be nested. The following route would match \n/a\n, \n/a/b\n and \n/a/b/c\n. It would not match \n/a/c\n.\n\n\nroute\n(\n/a/[b/[c]]\n)\n\n\n\n\n\n\nIt's pretty rare to have more than one optional segment in a route. For example, consider the route:\n\n\nroute\n(\n/users/[:id/[:subresource/[:subresourceid]]]\n);\n\n\n\n\n\n\nThe code to handle one or more users is likely very different than the code to handle one of its subresources - different database tables will be queried and different authorization may be needed. Thus, a better approach is to split subresources into their own routes to keep controller logic modular:\n\n\n// Matches /users and /users/:id\n\n\nroute\n(\n/users/[:id]\n)...;\n\n\n\n// Matches /users/:userId/posts and /users/:userId/posts/:postId\n\n\nroute\n(\n/users/:userId/posts/[:postId]\n)...;\n\n\n\n// Matches /users/:userId/posts and /users/:userId/notes/:noteId\n\n\nroute\n(\n/users/:userId/notes/[:noteId]\n)...;\n\n\n\n\n\n\nRestricting Path Variable Values\n\n\nPath variables may restrict their possible values with a regular expression. The expression comes in parentheses following the path variable name. For example, the following route specification limits \nuserID\n to numbers only:\n\n\nroute\n(\n/users/:userID([0-9]+)\n)\n\n\n\n\n\n\nThis regular expression would only apply to the \n:userID\n segment. Note that capture groups and parentheses in general can't be included in a route's regular expression.\n\n\nEverything in between the parentheses is evaluated as the regular expression. Therefore, any additional spaces or characters will be a part of the regular expression. Since spaces aren't valid in a URL, you don't want spaces in a regular expression.\n\n\nMatching the Remaining Path\n\n\nFinally, a route specification may have a special 'match-all' token, the asterisk (\n*\n). This token allows for any remaining request path to be matched, regardless of its contents or length. For example, the route specification \n/users/*\n would match the following paths:\n\n\n/users\n/users/1\n/users/foo\n/users/foo/bar\n/users/foo/bar/something/else/and/this/goes/on/forever\n\n\n\n\n\nThis token is used when another medium is going to interpret the URL. For example, \nFileController\n - which reads a file from the filesystem - might have a route \n/file/*\n. It uses everything after \n/file\n to figure out the path on the filesystem.\n\n\nAccessing Path Variables\n\n\nInformation that a router parses from a request path - like path variables - are stored in \nRequest.path\n. When a \nRequest\n is handled by a router, its \npath\n is set to an instance of this type. Controllers deeper in the channel access \nRequest.path\n to help determine which resource the request is identifying. The \npath\n is an instance of \nRequestPath\n.\n\n\nA \nRequestPath\n contains an map of \nvariables\n, where the key is path variable name and the value is the value of that variable in the request. For example, consider a route specification \n/users/:id\n. When a request with path \n/users/1\n is routed, the value \n1\n is stored in this map for the key \nid\n:\n\n\nfinal\n \nidentifier\n \n=\n \nrequest\n.\npath\n.\nvariables\n[\nid\n];\n\n\n// identifier = \n1\n\n\n\n\n\n\nThe values in \nvariables\n are always \nString\ns, since a request path is a \nString\n. \nController\ns may parse path variables into types like \nint\n.\n\n\nResourceController\n uses path variables to select a operation method to handle a request.\n\n\nFailed Matches Return 404\n\n\nA \nRouter\n will return a \n404 Not Found\n if there is no matching route for the request. No linked controllers will handle the request. This behavior may be overridden by providing a closure to \nRouter\n's constructor.", 
            "title": "Routing"
        }, 
        {
            "location": "/http/routing/#routing", 
            "text": "", 
            "title": "Routing"
        }, 
        {
            "location": "/http/routing/#what-is-routing", 
            "text": "Every HTTP request has a URL. A URL identifies a  resource . In the early days of the Internet, a resource was a file. For example, the URL  http://www.geocities.com/my_page/image.jpg  would return the file  image.jpg  from the folder  my_page  on the webserver located at  www.geocities.com . In a web application today, resources come from many other sources of data, like a database or a connected device. The job of a web application is to provide, create or modify a resource for a URL, wherever that resource might come from.  A URL is made up of many parts, some of which are optional. The typical URL we see as humans looks like this:  http://stablekernel.com/about . Most people recognize that typing this URL into a browser would take them to our company's \"About\" page. In other words, our \"About\" page is a resource and the URL identifies it.  More generally, the \"About\" page URL has the three required components of a URL: a  scheme  ( http ), a  host  ( stablekernel.com ) and a  path  ( /about ). The host specifies the computer responsible for providing the resource, the path identifies the resource and the scheme lets both the requester and the host know how they should exchange information.  An Aqueduct application receives requests when the scheme is  http  (or  https ) and the host refers to a machine where the application is running. Therefore, once the application gets the request, it only cares about the remaining component: the path.  In Aqueduct, a  Router  routes  Request s to a  Controller  based on the request path. This process is known as  routing . When an application starts up, routes are registered in a subclass of  ApplicationChannel . Each registered route creates a new  channel  of  Controller s that will handle the request.", 
            "title": "What is routing?"
        }, 
        {
            "location": "/http/routing/#route-specifications-match-http-request-paths", 
            "text": "A route is registered by invoking  Router.route . This method takes a  route specification  - a  String  with some syntax rules that will match the path of a request. This registration occurs when an application first starts by overriding  ApplicationChannel.entryPoint . For example:  class   MyApplicationChannel   extends   ApplicationChannel   { \n   @ override \n   Controller   get   entryPoint   { \n     final   router   =   new   Router (); \n\n     router \n       . route ( /users ) \n       . linkFunction (( req )   async   =   new   Response . ok ( await   getAllUsers ()); \n\n     return   router ; \n   }  }   The argument to  route  is the route specification string. This particular route matches the path  /users . That is, a request for the URL  http://myserver.com/users  will be handled by the  linkFunction  closure. (Leading and trailing slashes are stripped out when routes are compiled, so including them has no effect, but it is good style to show a leading slash.)  A path can have multiple segments (the characters between slashes). For example, the path  /users/foo  has two path segments:  users  and  foo . A route specification matches each segment of a path against each of its segments. The path and the route must also have the same number of segments. Thus, the route specification  /users/foo  would match the path  /users/foo , but it would not match the paths  /users ,  /users/7  or  /users/foo/1 .", 
            "title": "Route Specifications Match HTTP Request Paths"
        }, 
        {
            "location": "/http/routing/#path-variables", 
            "text": "A route specification may have  path variables . A path variable captures the value from a path segment, so that your code can use it. A path variable is most often used to uniquely identify a resource by some identifier, like  /users/1  and  /users/2 .  In a route specification, a path variable starts with a colon ( : ). The name of the variable follows this colon. For example, consider the following route that declares a path variable named  userID :  router . route ( /users/:userID )   This route specification will match  /users/1 ,  /users/2 ,  /users/foo , etc. The value of  userID  is  1 ,  2  and  foo , respectively. This route won't match  /users  or  /users/1/2 .", 
            "title": "Path Variables"
        }, 
        {
            "location": "/http/routing/#optional-path-segments", 
            "text": "Routes may have optional path segments. This allows a group of routes that all refer to a resource collection and its individual resources to go to the same controller. For example, the requests  /users  and  /users/1  can both be covered by a single route specification.  An optional path segment has square brackets ( [] ) around it. The brackets can go before or after slashes. For example, the following two syntaxes register a route that accepts both  /users  and  /users/:userID :  route ( /users/[:userID] )  route ( /users[/:userID] )   Conceptually, a request with a path of  /users/1  identifies a single user, where  /users  identifies all users. Optional segments are used to create better code structure by forwarding requests that deal with a specific type of resource to the same controller. Therefore, the code to handle one user or multiple users is written in the same place.  You may have any number of optional segments in a route specification. Each optional segment must be nested. The following route would match  /a ,  /a/b  and  /a/b/c . It would not match  /a/c .  route ( /a/[b/[c]] )   It's pretty rare to have more than one optional segment in a route. For example, consider the route:  route ( /users/[:id/[:subresource/[:subresourceid]]] );   The code to handle one or more users is likely very different than the code to handle one of its subresources - different database tables will be queried and different authorization may be needed. Thus, a better approach is to split subresources into their own routes to keep controller logic modular:  // Matches /users and /users/:id  route ( /users/[:id] )...;  // Matches /users/:userId/posts and /users/:userId/posts/:postId  route ( /users/:userId/posts/[:postId] )...;  // Matches /users/:userId/posts and /users/:userId/notes/:noteId  route ( /users/:userId/notes/[:noteId] )...;", 
            "title": "Optional Path Segments"
        }, 
        {
            "location": "/http/routing/#restricting-path-variable-values", 
            "text": "Path variables may restrict their possible values with a regular expression. The expression comes in parentheses following the path variable name. For example, the following route specification limits  userID  to numbers only:  route ( /users/:userID([0-9]+) )   This regular expression would only apply to the  :userID  segment. Note that capture groups and parentheses in general can't be included in a route's regular expression.  Everything in between the parentheses is evaluated as the regular expression. Therefore, any additional spaces or characters will be a part of the regular expression. Since spaces aren't valid in a URL, you don't want spaces in a regular expression.", 
            "title": "Restricting Path Variable Values"
        }, 
        {
            "location": "/http/routing/#matching-the-remaining-path", 
            "text": "Finally, a route specification may have a special 'match-all' token, the asterisk ( * ). This token allows for any remaining request path to be matched, regardless of its contents or length. For example, the route specification  /users/*  would match the following paths:  /users\n/users/1\n/users/foo\n/users/foo/bar\n/users/foo/bar/something/else/and/this/goes/on/forever  This token is used when another medium is going to interpret the URL. For example,  FileController  - which reads a file from the filesystem - might have a route  /file/* . It uses everything after  /file  to figure out the path on the filesystem.", 
            "title": "Matching the Remaining Path"
        }, 
        {
            "location": "/http/routing/#accessing-path-variables", 
            "text": "Information that a router parses from a request path - like path variables - are stored in  Request.path . When a  Request  is handled by a router, its  path  is set to an instance of this type. Controllers deeper in the channel access  Request.path  to help determine which resource the request is identifying. The  path  is an instance of  RequestPath .  A  RequestPath  contains an map of  variables , where the key is path variable name and the value is the value of that variable in the request. For example, consider a route specification  /users/:id . When a request with path  /users/1  is routed, the value  1  is stored in this map for the key  id :  final   identifier   =   request . path . variables [ id ];  // identifier =  1   The values in  variables  are always  String s, since a request path is a  String .  Controller s may parse path variables into types like  int .  ResourceController  uses path variables to select a operation method to handle a request.", 
            "title": "Accessing Path Variables"
        }, 
        {
            "location": "/http/routing/#failed-matches-return-404", 
            "text": "A  Router  will return a  404 Not Found  if there is no matching route for the request. No linked controllers will handle the request. This behavior may be overridden by providing a closure to  Router 's constructor.", 
            "title": "Failed Matches Return 404"
        }, 
        {
            "location": "/http/channel/", 
            "text": "Understanding Application Initialization and the ApplicationChannel\n\n\nLearn how an application is initialized so it can serve requests.\n\n\nOverview\n\n\nApplications fulfill HTTP requests using \ncontrollers\n. A controller is an object that can handle a request in some way. In general, there are two types of controllers:\n\n\n\n\nEndpoint controllers fulfill a request (e.g., insert a row into a database and send a 200 OK response).\n\n\nMiddleware controllers verify something about a request (e.g., verifying the Authorization header has valid credentials) or modify the response created by an endpoint controller (e.g., add a response header).\n\n\n\n\nControllers are linked together - starting with zero or more middleware and ending with an endpoint controller - to form a series of steps a request will go through. Every controller can either pass the request on to its linked controller, or respond to the request itself (in which case, the linked controller never sees the request). For example, an authorizer middleware will let a request pass if it has valid credentials, but will respond with a 401 Unauthorized response if the credentials are invalid. Some controllers, like \nRouter\n, can have multiple controllers linked to it.\n\n\nThese linked controllers are called \nchannels\n. You create and link channels in a subclass of \nApplicationChannel\n. There is one \nApplicationChannel\n subclass per application.\n\n\nBuilding the ApplicationChannel\n\n\nYou must override \nApplicationChannel.entryPoint\n to return the first controller of your application's channel. In the implementation of this method, every controller that will be used in the application is linked to either the entry point in some way. Here's an example:\n\n\nclass\n \nAppChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nnew\n \nRouter\n();\n\n\n    \nrouter\n\n      \n.\nroute\n(\n/users\n)\n\n      \n.\nlink\n(()\n \n=\n \nAuthorizer\n())\n\n      \n.\nlink\n(()\n \n=\n \nUserController\n());\n\n\n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nThis method links together a \nRouter\n, \nAuthorizer\n and \nUserController\n in that order. A request is first handled by the \nRouter\n, and if its path matches '/users', it will be sent to an \nAuthorizer\n. If the \nAuthorizer\n verifies the request, the request is passed to a \nUserController\n for fulfillment.\n\n\nBy contrast, if the request's path doesn't match '/users', the \nRouter\n sends a 404 Not Found response and doesn't pass it to the \nAuthorizer\n. Likewise, if the request isn't authorized, the \nAuthorizer\n will send a 401 Unauthorized response and prevent it from being passed to the \nUserController\n. In other words, a request 'falls out' of the channel once a controller responds to it, so that no further controllers will receive it.\n\n\n\n\nLinking Controllers\n\n\nThe \nlink()\n method takes a closure that creates a new controller. Some controllers get instantiated for each request, and others get reused for every request. See \nthe chapter on controllers\n for more information.\n\n\n\n\nProviding Services for Controllers\n\n\nControllers often need to get (or create) information from outside the application. The most common example is database access, but it could be anything: another REST API, a connected device, etc. A \nservice object\n encapsulates the information and behavior needed to work with an external system. This separation of concerns between controllers and service objects allows for better structured and more testable code.\n\n\nService objects are passed to controllers through their constructor. A controller that needs a database connection, for example, would take a database connection object in its constructor and store it in a property. Services are created by overriding \nprepare()\n in an \nApplicationChannel\n. Here's an example:\n\n\nclass\n \nAppChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \nPostgreSQLConnection\n \ndatabase\n;\n\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \ndatabase\n \n=\n \nnew\n \nPostgreSQLConnection\n();\n\n  \n}\n\n\n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nnew\n \nRouter\n();\n\n\n    \nrouter\n\n      \n.\nroute\n(\n/users\n)\n\n      \n.\nlink\n(()\n \n=\n \nnew\n \nAuthorizer\n())\n\n      \n.\nlink\n(()\n \n=\n \nnew\n \nUserController\n(\ndatabase\n));\n\n\n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nNotice that \ndatabase\n is created in \nprepare()\n, stored in a property and passed to each new instance of \nUserController\n. The \nprepare()\n method is always executed before \nentryPoint\n is called.\n\n\nApplication Channel Configuration\n\n\nA benefit to using service objects is that they can be altered depending on the environment the application is running in without requiring changes to our controller code. For example, the database an application will connect to will be different when running in production than when running tests.\n\n\nBesides service configuration, there may be other types of initialization an application wants to take. Common tasks include adding codecs to \nCodecRegistry\n or setting the default \nCORSPolicy\n.\n\n\nAll of this initialization is done in \nprepare()\n.\n\n\nSome of the information needed to configure an application will come from a configuration file or environment variables. This information is available through the \noptions\n property of an application channel. For more information on using a configuration file and environment variables to guide initialization, see \nthis guide\n.\n\n\nMulti-threaded Aqueduct Applications\n\n\nAqueduct applications can - and should - be spread across a number of threads. This allows an application to take advantage of multiple CPUs and serve requests faster. In Dart, threads are called \nisolates\n. An instance of your \nApplicationChannel\n is created for each isolate. When your application receives an HTTP request, one of these instances receives the request and processes it. These instances are replicas of one another and it doesn't matter which instance processes the request. This isolate-channel architecture is very similar to running multiple servers that run the same application.\n\n\nThe number of isolates an application will use is configurable at startup when using the \naqueduct serve\n command.\n\n\nAn isolate can't share memory with another isolate. If an object is created on one isolate, it \ncannot\n be referenced by another. Therefore, each \nApplicationChannel\n instance has its own set of services that are configured in the same way. This behavior also makes design patterns like connection pooling implicit; instead of a pool of database connections, there is a pool of application channels that each have their own database connection.\n\n\nThis architecture intentionally prevents you from keeping state in your application. When you scale to multiple servers, you can trust that your cluster works correctly because you are already effectively clustering on a single server node. For further reading on writing multi-threaded applications, see \nthis guide\n.\n\n\nInitialization Callbacks\n\n\nBoth \nprepare()\n and \nentryPoint\n are part of the initialization process of an application channel. Most applications only ever need these two methods. Another method, that is rarely used, is \nwillStartReceivingRequests()\n. This method is called after \nprepare()\n and \nentryPoint\n have been executed, and right before your application will start receiving requests.\n\n\nThese three initialization callbacks are called once per isolate to initialize the channel running on that isolate. For initialization that should only occur \nonce per application start\n (regardless of how many isolates are running), an \nApplicationChannel\n subclass can implement a static method named \ninitializeApplication()\n.\n\n\nclass\n \nAppChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \nstatic\n \nFuture\n \ninitializeApplication\n(\nApplicationOptions\n \noptions\n)\n \nasync\n \n{\n\n    \n...\n \ndo\n \none\n \ntime\n \nsetup\n \n...\n\n  \n}\n\n\n  \n...\n\n\n}\n\n\n\n\n\n\nThis method is invoked before any \nApplicationChannel\n instances are created. Any changes made to \noptions\n will be available in each \nApplicationChannel\n's \noptions\n property.\n\n\nFor example:\n\n\nclass\n \nAppChannel\n \nextends\n \nApplicationChannel\n \n{\n\n\n  \nstatic\n \nFuture\n \ninitializeApplication\n(\nApplicationOptions\n \noptions\n)\n \nasync\n \n{\n        \n    \noptions\n.\ncontext\n[\nspecial item\n]\n \n=\n \nxyz\n;\n\n  \n}\n  \n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \nvar\n \nparsedConfigValues\n \n=\n \noptions\n.\ncontext\n[\nspecial item\n];\n \n// == xyz\n\n    \n...\n\n  \n}\n\n\n}\n\n\n\n\n\n\nIt is important to note the behavior of isolates as it relates to Aqueduct and the initialization process. Each isolate has its own heap. \ninitializeApplication\n is executed in the main isolate, whereas each \nApplicationChannel\n is instantiated in its own isolate. This means that any values stored in \nApplicationOptions\n must be safe to pass across isolates - i.e., they can't contain references to closures.\n\n\nAdditionally, any global variables or static properties that are set in the main isolate \nwill not be set\n in other isolates. Configuration types like \nCodecRegistry\n do not share values across isolates, because they use a static property to hold a reference to the repository of codecs. Therefore, they must be set up in \nApplicationChannel.prepare()\n.\n\n\nAlso, because static methods cannot be overridden in Dart, it is important that you ensure the name and signature of \ninitializeApplication\n exactly matches what is shown in these code samples. The analyzer can't help you here, unfortunately.\n\n\nApplication Channel File\n\n\nAn \nApplicationChannel\n subclass is most often declared in its own file named \nlib/channel.dart\n. This file must be exported from the application library file. For example, if the application is named \nwildfire\n, the application library file is \nlib/wildfire.dart\n. Here is a sample directory structure:\n\n\nwildfire/\n  lib/\n    wildfire.dart\n    channel.dart\n    controllers/\n      user_controller.dart      \n    ...\n\n\n\n\n\nSee \nthis guide\n for more details on how an Aqueduct application's files are structured.\n\n\nLazy Services\n\n\nMany service objects will establish a persistent network connection. A network connection can sometimes be interrupted and have to re-establish itself. If these connections are only opened when the application first starts, the application will not be able to reopen these connections without restarting the application. This would be very bad.\n\n\nFor that reason, services should manage their own connectivity behavior. For example, a database connection should connect it when it is asked to execute a query. If it already has a valid connection, it will go ahead and execute the query. Otherwise, it will establish the connection and then execute the query. The caller doesn't care - it gets a \nFuture\n with the desired result.\n\n\nThe pseudo-code looks something like this:\n\n\nFuture\n \nexecute\n(\nString\n \nsql\n)\n \nasync\n \n{\n\n  \nif\n \n(\nconnection\n \n==\n \nnull\n \n||\n \n!\nconnection\n.\nisAvailable\n)\n \n{\n\n    \nconnection\n \n=\n \nnew\n \nConnection\n(...);\n\n    \nawait\n \nconnection\n.\nopen\n();\n\n  \n}\n\n\n  \nreturn\n \nconnection\n.\nexecuteSQL\n(\nsql\n);\n\n\n}\n\n\n\n\n\n\nThe Application Object\n\n\nHidden in all of this discussion is the \nApplication\nT\n object. Because the \naqueduct serve\n command manages creating an \nApplication\nT\n instance, your code rarely concerns itself with this type.\n\n\nAn \nApplication\nT\n is the top-level object in an Aqueduct application; it sets up HTTP listeners and directs requests to \nApplicationChannel\ns. The \nApplication\nT\n itself is just a generic container for \nApplicationChannel\ns; it doesn't do much other than kick everything off.\n\n\nThe application's \nstart\n method will initialize at least one instance of the application's \nApplicationChannel\n. If something goes wrong during this initialization process, the application will throw an exception and halt starting the server. For example, setting up an invalid route in a \nApplicationChannel\n subclass would trigger this type of startup exception.\n\n\nAn \nApplication\nT\n has a number of options that determine how it will listen for HTTP requests, such as which port it is listening on or the SSL certificate it will use. These values are available in the channel's \noptions\n property, an instance of \nApplicationOptions\n.", 
            "title": "Initialization and the ApplicationChannel"
        }, 
        {
            "location": "/http/channel/#understanding-application-initialization-and-the-applicationchannel", 
            "text": "Learn how an application is initialized so it can serve requests.", 
            "title": "Understanding Application Initialization and the ApplicationChannel"
        }, 
        {
            "location": "/http/channel/#overview", 
            "text": "Applications fulfill HTTP requests using  controllers . A controller is an object that can handle a request in some way. In general, there are two types of controllers:   Endpoint controllers fulfill a request (e.g., insert a row into a database and send a 200 OK response).  Middleware controllers verify something about a request (e.g., verifying the Authorization header has valid credentials) or modify the response created by an endpoint controller (e.g., add a response header).   Controllers are linked together - starting with zero or more middleware and ending with an endpoint controller - to form a series of steps a request will go through. Every controller can either pass the request on to its linked controller, or respond to the request itself (in which case, the linked controller never sees the request). For example, an authorizer middleware will let a request pass if it has valid credentials, but will respond with a 401 Unauthorized response if the credentials are invalid. Some controllers, like  Router , can have multiple controllers linked to it.  These linked controllers are called  channels . You create and link channels in a subclass of  ApplicationChannel . There is one  ApplicationChannel  subclass per application.", 
            "title": "Overview"
        }, 
        {
            "location": "/http/channel/#building-the-applicationchannel", 
            "text": "You must override  ApplicationChannel.entryPoint  to return the first controller of your application's channel. In the implementation of this method, every controller that will be used in the application is linked to either the entry point in some way. Here's an example:  class   AppChannel   extends   ApplicationChannel   { \n   @ override \n   Controller   get   entryPoint   { \n     final   router   =   new   Router (); \n\n     router \n       . route ( /users ) \n       . link (()   =   Authorizer ()) \n       . link (()   =   UserController ()); \n\n     return   router ; \n   }  }   This method links together a  Router ,  Authorizer  and  UserController  in that order. A request is first handled by the  Router , and if its path matches '/users', it will be sent to an  Authorizer . If the  Authorizer  verifies the request, the request is passed to a  UserController  for fulfillment.  By contrast, if the request's path doesn't match '/users', the  Router  sends a 404 Not Found response and doesn't pass it to the  Authorizer . Likewise, if the request isn't authorized, the  Authorizer  will send a 401 Unauthorized response and prevent it from being passed to the  UserController . In other words, a request 'falls out' of the channel once a controller responds to it, so that no further controllers will receive it.   Linking Controllers  The  link()  method takes a closure that creates a new controller. Some controllers get instantiated for each request, and others get reused for every request. See  the chapter on controllers  for more information.", 
            "title": "Building the ApplicationChannel"
        }, 
        {
            "location": "/http/channel/#providing-services-for-controllers", 
            "text": "Controllers often need to get (or create) information from outside the application. The most common example is database access, but it could be anything: another REST API, a connected device, etc. A  service object  encapsulates the information and behavior needed to work with an external system. This separation of concerns between controllers and service objects allows for better structured and more testable code.  Service objects are passed to controllers through their constructor. A controller that needs a database connection, for example, would take a database connection object in its constructor and store it in a property. Services are created by overriding  prepare()  in an  ApplicationChannel . Here's an example:  class   AppChannel   extends   ApplicationChannel   { \n   PostgreSQLConnection   database ; \n\n   @ override \n   Future   prepare ()   async   { \n     database   =   new   PostgreSQLConnection (); \n   } \n\n   @ override \n   Controller   get   entryPoint   { \n     final   router   =   new   Router (); \n\n     router \n       . route ( /users ) \n       . link (()   =   new   Authorizer ()) \n       . link (()   =   new   UserController ( database )); \n\n     return   router ; \n   }  }   Notice that  database  is created in  prepare() , stored in a property and passed to each new instance of  UserController . The  prepare()  method is always executed before  entryPoint  is called.", 
            "title": "Providing Services for Controllers"
        }, 
        {
            "location": "/http/channel/#application-channel-configuration", 
            "text": "A benefit to using service objects is that they can be altered depending on the environment the application is running in without requiring changes to our controller code. For example, the database an application will connect to will be different when running in production than when running tests.  Besides service configuration, there may be other types of initialization an application wants to take. Common tasks include adding codecs to  CodecRegistry  or setting the default  CORSPolicy .  All of this initialization is done in  prepare() .  Some of the information needed to configure an application will come from a configuration file or environment variables. This information is available through the  options  property of an application channel. For more information on using a configuration file and environment variables to guide initialization, see  this guide .", 
            "title": "Application Channel Configuration"
        }, 
        {
            "location": "/http/channel/#multi-threaded-aqueduct-applications", 
            "text": "Aqueduct applications can - and should - be spread across a number of threads. This allows an application to take advantage of multiple CPUs and serve requests faster. In Dart, threads are called  isolates . An instance of your  ApplicationChannel  is created for each isolate. When your application receives an HTTP request, one of these instances receives the request and processes it. These instances are replicas of one another and it doesn't matter which instance processes the request. This isolate-channel architecture is very similar to running multiple servers that run the same application.  The number of isolates an application will use is configurable at startup when using the  aqueduct serve  command.  An isolate can't share memory with another isolate. If an object is created on one isolate, it  cannot  be referenced by another. Therefore, each  ApplicationChannel  instance has its own set of services that are configured in the same way. This behavior also makes design patterns like connection pooling implicit; instead of a pool of database connections, there is a pool of application channels that each have their own database connection.  This architecture intentionally prevents you from keeping state in your application. When you scale to multiple servers, you can trust that your cluster works correctly because you are already effectively clustering on a single server node. For further reading on writing multi-threaded applications, see  this guide .", 
            "title": "Multi-threaded Aqueduct Applications"
        }, 
        {
            "location": "/http/channel/#initialization-callbacks", 
            "text": "Both  prepare()  and  entryPoint  are part of the initialization process of an application channel. Most applications only ever need these two methods. Another method, that is rarely used, is  willStartReceivingRequests() . This method is called after  prepare()  and  entryPoint  have been executed, and right before your application will start receiving requests.  These three initialization callbacks are called once per isolate to initialize the channel running on that isolate. For initialization that should only occur  once per application start  (regardless of how many isolates are running), an  ApplicationChannel  subclass can implement a static method named  initializeApplication() .  class   AppChannel   extends   ApplicationChannel   { \n   static   Future   initializeApplication ( ApplicationOptions   options )   async   { \n     ...   do   one   time   setup   ... \n   } \n\n   ...  }   This method is invoked before any  ApplicationChannel  instances are created. Any changes made to  options  will be available in each  ApplicationChannel 's  options  property.  For example:  class   AppChannel   extends   ApplicationChannel   { \n\n   static   Future   initializeApplication ( ApplicationOptions   options )   async   {         \n     options . context [ special item ]   =   xyz ; \n   }   \n\n   Future   prepare ()   async   { \n     var   parsedConfigValues   =   options . context [ special item ];   // == xyz \n     ... \n   }  }   It is important to note the behavior of isolates as it relates to Aqueduct and the initialization process. Each isolate has its own heap.  initializeApplication  is executed in the main isolate, whereas each  ApplicationChannel  is instantiated in its own isolate. This means that any values stored in  ApplicationOptions  must be safe to pass across isolates - i.e., they can't contain references to closures.  Additionally, any global variables or static properties that are set in the main isolate  will not be set  in other isolates. Configuration types like  CodecRegistry  do not share values across isolates, because they use a static property to hold a reference to the repository of codecs. Therefore, they must be set up in  ApplicationChannel.prepare() .  Also, because static methods cannot be overridden in Dart, it is important that you ensure the name and signature of  initializeApplication  exactly matches what is shown in these code samples. The analyzer can't help you here, unfortunately.", 
            "title": "Initialization Callbacks"
        }, 
        {
            "location": "/http/channel/#application-channel-file", 
            "text": "An  ApplicationChannel  subclass is most often declared in its own file named  lib/channel.dart . This file must be exported from the application library file. For example, if the application is named  wildfire , the application library file is  lib/wildfire.dart . Here is a sample directory structure:  wildfire/\n  lib/\n    wildfire.dart\n    channel.dart\n    controllers/\n      user_controller.dart      \n    ...  See  this guide  for more details on how an Aqueduct application's files are structured.", 
            "title": "Application Channel File"
        }, 
        {
            "location": "/http/channel/#lazy-services", 
            "text": "Many service objects will establish a persistent network connection. A network connection can sometimes be interrupted and have to re-establish itself. If these connections are only opened when the application first starts, the application will not be able to reopen these connections without restarting the application. This would be very bad.  For that reason, services should manage their own connectivity behavior. For example, a database connection should connect it when it is asked to execute a query. If it already has a valid connection, it will go ahead and execute the query. Otherwise, it will establish the connection and then execute the query. The caller doesn't care - it gets a  Future  with the desired result.  The pseudo-code looks something like this:  Future   execute ( String   sql )   async   { \n   if   ( connection   ==   null   ||   ! connection . isAvailable )   { \n     connection   =   new   Connection (...); \n     await   connection . open (); \n   } \n\n   return   connection . executeSQL ( sql );  }", 
            "title": "Lazy Services"
        }, 
        {
            "location": "/http/channel/#the-application-object", 
            "text": "Hidden in all of this discussion is the  Application T  object. Because the  aqueduct serve  command manages creating an  Application T  instance, your code rarely concerns itself with this type.  An  Application T  is the top-level object in an Aqueduct application; it sets up HTTP listeners and directs requests to  ApplicationChannel s. The  Application T  itself is just a generic container for  ApplicationChannel s; it doesn't do much other than kick everything off.  The application's  start  method will initialize at least one instance of the application's  ApplicationChannel . If something goes wrong during this initialization process, the application will throw an exception and halt starting the server. For example, setting up an invalid route in a  ApplicationChannel  subclass would trigger this type of startup exception.  An  Application T  has a number of options that determine how it will listen for HTTP requests, such as which port it is listening on or the SSL certificate it will use. These values are available in the channel's  options  property, an instance of  ApplicationOptions .", 
            "title": "The Application Object"
        }, 
        {
            "location": "/http/resource_controller/", 
            "text": "ResourceController\n\n\nA \nResourceController\n is a \ncontroller\n that provide conveniences for implementing endpoint controllers. A \nResourceController\n must be subclassed, and in that subclass, you write a method for each operation on that type of resource. For example, a \nUserController\n might handle the following operations:\n\n\n\n\ncreating a new user (\nPOST /users\n)\n\n\ngetting all users (\nGET /users\n)\n\n\ngetting an individual user (\nGET /users/:id\n)\n\n\nupdating an individual user (\nPUT /users/:id\n)\n\n\ndeleting an individual user (\nDELETE /users/:id\n)\n\n\n\n\nThese methods that are invoked for an operation are called \noperation methods\n.\n\n\nOperation Methods\n\n\nAn operation method is an instance method of a \nResourceController\n subclass that has an \n@Operation\n annotation. It must return an instance of \nFuture\nResponse\n. Here's an example:\n\n\nclass\n \nCityController\n \nextends\n \nResourceController\n \n{\n\n  \n@\nOperation\n.\nget\n()\n\n  \nFuture\nResponse\n \ngetAllCities\n()\n \nasync\n \n{\n\n    \nreturn\n \nnew\n \nResponse\n.\nok\n([\nAtlanta\n,\n \nMadison\n,\n \nMountain View\n]);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nThe above operation method will be invoked when \nCityController\n handles \nGET\n requests without path variables. To handle operation methods with path variables, the name of the path variable is added to the \n@Operation\n annotation:\n\n\nclass\n \nCityController\n \nextends\n \nResourceController\n \n{\n\n  \n@\nOperation\n.\nget\n()\n\n  \nFuture\nResponse\n \ngetAllCities\n()\n \nasync\n \n{\n\n    \nreturn\n \nnew\n \nResponse\n.\nok\n([\nAtlanta\n,\n \nMadison\n,\n \nMountain View\n]);\n\n  \n}\n\n\n  \n@\nOperation\n.\nget\n(\nname\n)\n\n  \nFuture\nResponse\n \ngetCityByName\n()\n \nasync\n \n{\n\n    \nfinal\n \nid\n \n=\n \nrequest\n.\npath\n.\nvariables\n[\nname\n];\n\n    \nreturn\n \nnew\n \nResponse\n.\nok\n(\nfetchCityWithName\n(\nname\n));\n\n  \n}\n\n\n}\n\n\n\n\n\n\n\n\nPath Variables\n\n\nThis controller would be linked to the route specification \n/cities/[:name]\n, so that it can handle both of these operations. Read more about path variables in \nRouting\n.\n\n\n\n\nThe named constructor of \nOperation\n tells us which HTTP method the operation method handles. The following named constructors exist:\n\n\n\n\nOperation.post()\n\n\nOperation.get()\n\n\nOperation.put()\n\n\nOperation.delete()\n\n\n\n\nThe canonical \nOperation()\n constructor takes the HTTP method as its first argument for non-standard operations, e.g.:\n\n\n@\nOperation\n(\nPATCH\n,\n \nid\n)\n\n\nFuture\nResponse\n \npatchObjectWithID\n()\n \nasync\n \n=\n \n...;\n\n\n\n\n\n\nAll \nOperation\n constructors take a variable list of path variables. There can be multiple path variables for an operation. An operation method will only be invoked if all of its path variables are present in the request path. There can be multiple operation methods for a given HTTP method, as long as each expects a different set of path variables.\n\n\nHere's an example of an operation that requires two path variables:\n\n\n@\nOperation\n.\nget\n(\nuserID\n,\n \nitemID\n)\n\n\nFuture\nResponse\n \ngetUserItem\n()\n \nasync\n \n{\n\n  \nfinal\n \nuserID\n \n=\n \nrequest\n.\npath\n.\nvariables\n[\nuserID\n];\n\n  \nfinal\n \nitemID\n \n=\n \nrequest\n.\npath\n.\nvariables\n[\nitemID\n];\n\n  \nreturn\n \nnew\n \nResponse\n.\nok\n(...);\n\n\n}\n\n\n\n\n\n\nIf no operation method exists for a request, a 405 Method Not Allowed response is automatically sent and no operation method is invoked.\n\n\nRouting to a ResourceController\n\n\nA \nResourceController\n subclass must be preceded by a \nRouter\n in the application channel. The \nRouter\n will parse path variables so that the controller can use them to determine which operation method should be invoked. A typical route to a \nResourceController\n contains an optional identifying path variable:\n\n\nrouter\n\n  \n.\nroute\n(\n/cities/[:name]\n)\n\n  \n.\nlink\n(()\n \n=\n \nnew\n \nCityController\n());\n\n\n\n\n\n\nThis route would allow \nCityController\n to implement operation methods for all HTTP methods with both no path variables and the 'name' path variable.\n\n\nIt is considered good practice to break sub-resources into their own controller. For example, the following is preferred:\n\n\nrouter\n\n  \n.\nroute\n(\n/cities/[:name]\n)\n\n  \n.\nlink\n(()\n \n=\n \nnew\n \nCityController\n());\n\n\n\nrouter\n\n  \n.\nroute\n(\n/cities/:name/attractions/[:id]\n)\n\n  \n.\nlink\n(()\n \n=\n \nnew\n \nCityAttractionController\n());\n\n\n\n\n\n\nBy contrast, the route \n/cities/[:name/[attractions/[:id]]]\n, while valid, makes controller logic much more unwieldy.\n\n\nRequest Bindings\n\n\nOperation methods may \nbind\n properties of an HTTP request to its parameters. When the operation method is invoked, the value of that property is passed as an argument to the operation method. For example, the following binds the header named 'X-API-Key' to the argument \napiKey\n:\n\n\n@\nOperation\n.\nget\n(\nname\n)\n\n\nFuture\nResponse\n \ngetCityByName\n(\n@\nBind\n.\npath\n(\nx-api-key\n)\n \nString\n \napiKey\n)\n \nasync\n \n{\n\n  \nif\n \n(\n!\nisValid\n(\napiKey\n))\n \n{\n\n    \nreturn\n \nnew\n \nResponse\n.\nunauthorized\n();\n\n  \n}\n\n\n  \nreturn\n \nnew\n \nResponse\n.\nok\n(...);\n\n\n}\n\n\n\n\n\n\nThe following table shows the possible types of bindings:\n\n\n\n\n\n\n\n\nProperty\n\n\nBinding\n\n\n\n\n\n\n\n\n\n\nPath Variable\n\n\n@Bind.path(pathVariableName)\n\n\n\n\n\n\nURL Query Parameter\n\n\n@Bind.query(queryParameterName)\n\n\n\n\n\n\nHeader\n\n\n@Bind.header(headerName)\n\n\n\n\n\n\nRequest Body\n\n\n@Bind.body()\n\n\n\n\n\n\n\n\nYou may bind any number of HTTP request properties to a single operation method.\n\n\nOptional Bindings\n\n\nBindings can be made optional. If a binding is optional, the operation method will still be called even if the bound property isn't in a request. To make a binding optional, move it to the optional parameters of an operation method:\n\n\n@\nOperation\n.\nget\n()\n\n\nFuture\nResponse\n \ngetAllCities\n({\n@\nBind\n.\nheader\n(\nx-api-key\n)\n \nString\n \napiKey\n})\n \nasync\n \n{\n\n  \nif\n \n(\napiKey\n \n==\n \nnull\n)\n \n{\n\n    \n// No X-API-Key in request\n\n    \n...\n\n  \n}\n\n  \n...\n\n\n}\n\n\n\n\n\n\nA bound parameter will be null if not in the request. Like any other Dart optional parameter, you can provide a default value:\n\n\n@\nOperation\n.\nget\n()\n\n\nFuture\nResponse\n \ngetAllCities\n({\n@\nBind\n.\nheader\n(\nx-api-key\n)\n \nString\n \napiKey:\n \npublic\n})\n \nasync\n \n{\n\n  \n...\n\n\n}\n\n\n\n\n\n\nAutomatically Parsing Bindings\n\n\nQuery, header and path bindings can automatically be parsed into other types, such as \nint\n or \nDateTime\n. Simply declare the bound parameter's type to the desired type:\n\n\nFuture\nResponse\n \ngetCityByID\n(\n@\nBind\n.\nquery\n(\nid\n)\n \nint\n \ncityID\n)\n\n\n\n\n\n\nThe type of a bound parameter may be \nString\n or any type that implements \nparse\n (e.g., \nint\n, \nDateTime\n). Query parameters may also be bound to \nbool\n parameters; a boolean query parameter will be true if the query parameter has no value (e.g. \n/path?boolean\n).\n\n\nIf parsing fails for any reason, an error response is sent and the operation method is not called. For example, the above example binds \nint cityID\n - if the path variable 'id' can't be parsed into an \nint\n, a 404 Not Found response is sent. If a query parameter or header value cannot be parsed, a 400 Bad Request response is sent.\n\n\nYou may also bind \nList\nT\n parameters to headers and query parameters, where \nT\n must meet the same criteria as above. Query parameters and headers may appear more than once in a request. For example, the value of \nids\n is \n[1, 2]\n if the request URL ends with \n/path?id=1\nid=2\n and the operation method looks like this:\n\n\nFuture\nResponse\n \ngetCitiesByIDs\n(\n@\nBind\n.\nquery\n(\nid\n)\n \nList\nint\n \nids\n)\n\n\n\n\n\n\nNote that if a parameter is \nnot\n bound to a list and there are multiple occurrences of that property in the request, a 400 Bad Request response will be sent. If you want to allow multiple values, you must bind to a \nList\nT\n.\n\n\nHeader Bindings\n\n\nThe following operation method binds the header named \nX-API-Key\n to the \napiKey\n parameter:\n\n\nclass\n \nCityController\n \nextends\n \nResourceController\n \n{\n\n  \n@\nOperation\n.\nget\n()\n\n  \nFuture\nResponse\n \ngetAllCities\n(\n@\nBind\n.\nheader\n(\nx-api-key\n)\n \nString\n \napiKey\n)\n \nasync\n \n{\n\n    \nif\n \n(\n!\nisValid\n(\napiKey\n))\n \n{\n\n      \nreturn\n \nnew\n \nResponse\n.\nunauthorized\n();\n\n    \n}\n\n\n    \nreturn\n \nnew\n \nResponse\n.\nok\n([\nAtlanta\n,\n \nMadison\n,\n \nMountain View\n]);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nIf an \nX-API-Key\n header is present in the request, its value will be available in \napiKey\n. If it is not, \ngetAllCities(apiKey)\n would not be called and a 400 Bad Request response will be sent. If \napiKey\n were optional, the method is called as normal and \napiKey\n is null or a default value.\n\n\nHeader names are case-insensitive per the HTTP specification. Therefore, the header name may be 'X-API-KEY', 'X-Api-Key' 'x-api-key', etc. and \napiKey\n will be bound in all cases.\n\n\nQuery Parameter Bindings\n\n\nThe following operation methods binds the query parameter named 'name' to the parameter \ncityName\n:\n\n\nclass CityController extends ResourceController {\n  @Operation.get()\n  Future\n getAllCities(@Bind.query('name') String cityName) async {\n    return new Response.ok(cities.where((c) =\n c.name == cityName).toList());\n  }\n}\n\n\nQuery parameters can be required or optional. If required, a 400 Bad Request response is sent and no operation method is called if the query parameter is not present in the request URL. If optional, the bound variable is null or a default value.\n\n\nQuery parameters are case-sensitive; this binding will only match the query parameter 'name', but not 'Name' or 'NAME'.\n\n\nQuery parameters may also bound for query strings in the request body when the content-type is 'application/x-www-form-urlencoded'.\n\n\nPath Variable Bindings\n\n\nThe following operation method binds the path variable 'id' to the parameter \ncityID\n:\n\n\nclass\n \nCityController\n \nextends\n \nResourceController\n \n{\n\n  \n@\nOperation\n.\nget\n(\nid\n)\n\n  \nFuture\nResponse\n \ngetCityByID\n(\n@\nBind\n.\nquery\n(\nid\n)\n \nString\n \ncityID\n)\n \nasync\n \n{\n\n    \nreturn\n \nnew\n \nResponse\n.\nok\n(\ncities\n.\nwhere\n((\nc\n)\n \n=\n \nc\n.\nid\n \n==\n \ncityID\n).\ntoList\n());\n\n  \n}\n\n\n}\n\n\n\n\n\n\nPath variables are made available when creating \nroutes\n. A \nRouter\n must have a route that includes a path variable and that path variable must be listed in the \nOperation\n annotation. Path variables are case-sensitive and may not be optional.\n\n\nIf you attempt to bind a path variable that is not present in the \nOperation\n, you will get a runtime exception at startup. You do not have to bind path variables for an operation method to be invoked.\n\n\nHTTP Request Body Bindings\n\n\nThe body of an HTTP request can also be bound to a parameter:\n\n\nclass\n \nCityController\n \nextends\n \nResourceController\n \n{\n\n  \nCityController\n(\nthis\n.\ncontext\n);\n\n\n  \nfinal\n \nManagedContext\n \ncontext\n;\n\n\n  \n@\nOperation\n.\npost\n()\n\n  \nFuture\nResponse\n \naddCity\n(\n@\nBind\n.\nbody\n()\n \nCity\n \ncity\n)\n \nasync\n \n{\n\n    \nfinal\n \ninsertedCity\n \n=\n \nawait\n \nQuery\n.\ninsertObject\n(\ncontext\n,\n \ncity\n);\n\n\n    \nreturn\n \nnew\n \nResponse\n.\nok\n(\ninsertedCity\n);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nSince there is only one request body, \nBind.body()\n doesn't take any identifying arguments.\n\n\nThe bound parameter type (\nCity\n in this example) must implement \nSerializable\n. This interface requires two methods to be implemented: one to read data from a request body and another to write data to a response body. Here is an example:\n\n\nclass\n \nCity\n \nimplements\n \nSerializable\n \n{\n\n  \nint\n \nid\n;\n\n  \nString\n \nname\n;\n\n\n  \n@\noverride\n\n  \nvoid\n \nreadFromMap\n(\nMap\nString\n,\n \ndynamic\n \nmap\n)\n \n{\n\n    \nid\n \n=\n \nmap\n[\nid\n];\n\n    \nname\n \n=\n \nmap\n[\nname\n];\n\n  \n}\n\n\n  \n@\noverride\n\n  \nMap\nString\n,\n \ndynamic\n \nasMap\n()\n \n{\n\n    \nreturn\n \n{\n\n      \nid\n:\n \nid\n,\n\n      \nname\n:\n \nname\n\n    \n}\n\n  \n}\n\n\n}\n\n\n\n\n\n\n\n\nManagedObject and Serializable\n\n\nManagedObject\ns from Aqueduct's ORM implement \nSerializable\n without having to implement these two methods.\n\n\n\n\nAqueduct will automatically decode the request body from it's content-type, create a new instance of the bound parameter type, and invoke its \nreadFromMap\n method. In the above example, a valid request body would be the following JSON:\n\n\n{\n\n  \nid\n:\n \n1\n,\n\n  \nname\n:\n \nAtlanta\n\n\n}\n\n\n\n\n\n\n\n\nHTTP Body Decoding\n\n\nRequest bodies are decoded according to their content-type prior to being deserialized. For more information on request body decoding, including decoding content-types other than JSON, see \nthis guide\n.\n\n\n\n\nIf parsing fails or \nreadFromMap\n throws an exception, a 400 Bad Request response will be sent and the operation method won't be called.\n\n\nYou may also bind \nList\nSerializable\n parameters to the request body. Consider the following JSON that contains a list of cities:\n\n\n[\n\n  \n{\nid\n:\n \n1\n,\n \nname\n:\n \nAtlanta\n},\n\n  \n{\nid\n:\n \n2\n,\n \nname\n:\n \nMadison\n}\n\n\n]\n\n\n\n\n\n\nThis body can be bound by declaring the bound parameter to be a \nList\n of the desired type:\n\n\nFuture\nResponse\n \naddCity\n(\n@\nBind\n.\nbody\n()\n \nList\nCity\n \ncities\n)\n\n\n\n\n\n\n!!! tip 'List vs Object'\n    An endpoint should either take a single object or a list of objects, but not both. If the request body is a JSON list and the bound variable is not a list, a 400 Bad Request response will be sent (and vice versa). Declaring a body binding of the appropriate type validates the expected value and aids in automatically generating an OpenAPI specification for your application.\n\n\nNote that if the request's \nContent-Type\n is 'x-www-form-urlencoded', its must be bound with \nBind.query\n and not \nBind.body\n.\n\n\nProperty Binding\n\n\nThe properties of an \nResourceController\ns may also have \nBind.query\n and \nBind.header\n metadata. This binds values from the request to the \nResourceController\n instance itself, making them accessible from \nall\n operation methods.\n\n\nclass\n \nCityController\n \nextends\n \nResourceController\n \n{\n\n  \n@\nrequiredBinding\n\n  \n@\nBind\n.\nheader\n(\nx-timestamp\n)\n\n  \nDateTime\n \ntimestamp\n;\n\n\n  \n@\nBind\n.\nquery\n(\nlimit\n)\n\n  \nint\n \nlimit\n;\n\n\n  \n@\nOperation\n.\nget\n()\n\n  \nFuture\nResponse\n \ngetCities\n()\n \nasync\n \n{\n\n      \n// can use both limit and timestamp\n\n  \n}\n\n\n}\n\n\n\n\n\n\nIn the above, both \ntimestamp\n and \nlimit\n are bound prior to \ngetCities\n being invoked. By default, a bound property is optional. Adding an \nrequiredBinding\n annotation changes a property to required. If required, any request without the required property fails with a 400 Bad Request status code and none of the operation methods are invoked.\n\n\nOther ResourceController Behavior\n\n\nBesides binding, \nResourceController\ns have some other behavior that is important to understand.\n\n\nRequest and Response Bodies\n\n\nAn \nResourceController\n can limit the content type of HTTP request bodies it accepts. By default, an \nResourceController\n will accept only \napplication/json\n request bodies for its \nPOST\n and \nPUT\n methods. This can be modified by setting the \nacceptedContentTypes\n property in the constructor.\n\n\nclass\n \nUserController\n \nextends\n \nResourceController\n \n{\n\n  \nUserController\n()\n \n{\n\n    \nacceptedContentTypes\n \n=\n \n[\nContentType\n.\nJSON\n,\n \nContentType\n.\nXML\n];\n\n  \n}\n\n\n}\n\n\n\n\n\n\nIf a request is made with a content type other than the accepted content types, the controller automatically responds with a 415 Unsupported Media Type response.\n\n\nThe body of an HTTP request is decoded if the content type is accepted and there exists a operation method to handle the request. The body is not decoded if there is not a matching operation method for the request. The body is decoded by \nResourceController\n prior to your operation method being invoked. Therefore, you can always use the synchronous \nRequestBody.as\n method to access the body from within an operation method:\n\n\n@\nOperation\n.\npost\n()\n\n\nFuture\nResponse\n \ncreateThing\n()\n \nasync\n \n{\n\n  \n// do this:\n\n  \nMap\nString\n,\n \ndynamic\n \nbodyMap\n \n=\n \nrequest\n.\nbody\n.\nas\n();\n\n\n  \n// no need to do this:\n\n  \nMap\nString\n,\n \ndynamic\n \nbodyMap\n \n=\n \nawait\n \nrequest\n.\nbody\n.\ndecode\n();\n\n\n  \nreturn\n \n...;\n\n\n}\n\n\n\n\n\n\nAn \nResourceController\n can also have a default content type for its responses. By default, this is \napplication/json\n. This default can be changed by changing \nresponseContentType\n in the constructor:\n\n\nclass\n \nUserController\n \nextends\n \nResourceController\n \n{\n\n  \nUserController\n()\n \n{\n\n    \nresponseContentType\n \n=\n \nContentType\n.\nXML\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nThe \nresponseContentType\n is the \ndefault\n response content type. An individual \nResponse\n may set its own \ncontentType\n, which takes precedence over the \nresponseContentType\n. For example, the following controller returns JSON by default, but if the request specifically asks for XML, that's what it will return:\n\n\nclass\n \nUserController\n \nextends\n \nResourceController\n \n{\n\n  \nUserController\n()\n \n{\n\n    \nresponseContentType\n \n=\n \nContentType\n.\nJSON\n;\n\n  \n}\n\n\n  \n@\nOperation\n.\nget\n(\nid\n)\n\n  \nFuture\nResponse\n \ngetUserByID\n(\n@\nBind\n.\npath\n(\nid\n)\n \nint\n \nid\n)\n \nasync\n \n{\n\n    \nvar\n \nresponse\n \n=\n \nnew\n \nResponse\n.\nok\n(...);\n\n\n    \nif\n \n(\nrequest\n.\nheaders\n.\nvalue\n(\nBind\n.\nheaders\n.\nACCEPT\n).\nstartsWith\n(\napplication/xml\n))\n \n{\n\n      \nresponse\n.\ncontentType\n \n=\n \nContentType\n.\nXML\n;\n\n    \n}\n\n\n    \nreturn\n \nresponse\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nMore Specialized ResourceControllers\n\n\nMany \nResourceController\n subclasses will execute \nqueries\n. There are helpful \nResourceController\n subclasses for reducing boilerplate code.\n\n\nA \nQueryController\nT\n builds a \nQuery\nT\n based on the incoming request. If the request has a body, this \nQuery\nT\n's \nvalues\n property is read from that body. If the request has a path variable, the \nQuery\nT\n assigns an expression to the primary key value. For example, in a normal \nResourceController\n that responds to a PUT request, you might write the following:\n\n\n@\nOperation\n.\nput\n(\nid\n)\n\n\nFuture\nResponse\n \nupdateUser\n(\n@\nBind\n.\npath\n(\nid\n)\n \nint\n \nid\n,\n \n@\nBind\n.\nbody\n()\n \nUser\n \nuser\n)\n \nasync\n \n{\n\n  \nvar\n \nquery\n \n=\n \nnew\n \nQuery\nUser\n(\ncontext\n)\n\n    \n..\nwhere\n((\nu\n)\n \n=\n \nu\n.\nid\n).\nequalTo\n(\nid\n)\n\n    \n..\nvalues\n \n=\n \nuser\n;\n\n\n  \nreturn\n \nnew\n \nResponse\n.\nok\n(\nawait\n \nquery\n.\nupdateOne\n());\n\n\n}\n\n\n\n\n\n\nA \nQueryController\nT\n builds this query before a operation method is invoked, storing it in the inherited \nquery\n property. A \nManagedObject\nT\n subclass is the type argument to \nQueryController\nT\n.\n\n\nclass\n \nUserController\n \nextends\n \nQueryController\nUser\n \n{\n\n  \nUserController\n(\nManagedContext\n \ncontext\n)\n \n:\n \nsuper\n(\ncontext\n);\n\n\n  \n@\nOperation\n.\nput\n(\nid\n)\n\n  \nFuture\nResponse\n \nupdateUser\n(\n@\nBind\n.\npath\n(\nid\n)\n \nint\n \nid\n)\n \nasync\n \n{\n\n    \n// query already exists and is identical to the snippet above\n\n    \nvar\n \nresult\n \n=\n \nawait\n \nquery\n.\nupdateOne\n();\n\n    \nreturn\n \nnew\n \nResponse\n.\nok\n(\nresult\n);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nA \nManagedObjectController\nT\n is significantly more powerful; you don't even need to subclass it. It does all the things a CRUD endpoint does without any code. Here's an example usage:\n\n\nrouter\n\n  \n.\nroute\n(\n/users/[:id]\n)\n\n  \n.\nlink\n(()\n \n=\n \nnew\n \nManagedObjectController\nUser\n(\ncontext\n));\n\n\n\n\n\n\nThis controller has the following behavior:\n\n\n\n\n\n\n\n\nRequest\n\n\nAction\n\n\n\n\n\n\n\n\n\n\nPOST /users\n\n\nInserts a user into the database with values from the request body\n\n\n\n\n\n\nGET /users\n\n\nFetches all users in the database\n\n\n\n\n\n\nGET /users/:id\n\n\nFetches a single user by id\n\n\n\n\n\n\nDELETE /users/:id\n\n\nDeletes a single user by id\n\n\n\n\n\n\nPUT /users/:id\n\n\nUpdated a single user by id, using values from the request body\n\n\n\n\n\n\n\n\nThe objects returned from getting the collection - e.g, \nGET /users\n - can be modified with query parameters. For example, the following request will return the users sorted by their name in ascending order:\n\n\nGET /users?sortBy=name,asc\n\n\n\n\n\n\nThe results can be paged (see \nPaging in Advanced Queries\n) with query parameters \noffset\n, \ncount\n, \npageBy\n, \npageAfter\n and \npagePrior\n.\n\n\nA \nManagedObjectController\nT\n can also be subclassed. A subclass allows for callbacks to be overridden to adjust the query before execution, or the results before sending the respond. Each operation - fetch, update, delete, etc. - has a pair of methods to do this. For example, the following subclass alters the query and results before any update via \nPUT\n:\n\n\nclass\n \nUserController\n \nextends\n \nManagedObjectController\nUser\n \n{\n\n  \nUserController\n(\nManagedContext\n \ncontext\n)\n \n:\n \nsuper\n(\ncontext\n);\n\n\n  \nFuture\nQuery\nUser\n \nwillUpdateObjectWithQuery\n(\n\n      \nQuery\nUser\n \nquery\n)\n \nasync\n \n{\n\n    \nquery\n.\nvalues\n.\nlastUpdatedAt\n \n=\n \nnew\n \nDateTime\n.\nnow\n().\ntoUtc\n();\n\n    \nreturn\n \nquery\n;\n\n  \n}\n\n\n  \nFuture\nResponse\n \ndidUpdateObject\n(\nUser\n \nobject\n)\n \nasync\n \n{\n\n    \nobject\n.\nremovePropertyFromBackingMap\n(\nprivate\n);\n\n    \nreturn\n \nnew\n \nResponse\n.\nok\n(\nobject\n);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nSee the chapter on \nvalidations\n, which are powerful when combined with \nManagedObjectController\nT\n.", 
            "title": "Handling Requests: ResourceController"
        }, 
        {
            "location": "/http/resource_controller/#resourcecontroller", 
            "text": "A  ResourceController  is a  controller  that provide conveniences for implementing endpoint controllers. A  ResourceController  must be subclassed, and in that subclass, you write a method for each operation on that type of resource. For example, a  UserController  might handle the following operations:   creating a new user ( POST /users )  getting all users ( GET /users )  getting an individual user ( GET /users/:id )  updating an individual user ( PUT /users/:id )  deleting an individual user ( DELETE /users/:id )   These methods that are invoked for an operation are called  operation methods .", 
            "title": "ResourceController"
        }, 
        {
            "location": "/http/resource_controller/#operation-methods", 
            "text": "An operation method is an instance method of a  ResourceController  subclass that has an  @Operation  annotation. It must return an instance of  Future Response . Here's an example:  class   CityController   extends   ResourceController   { \n   @ Operation . get () \n   Future Response   getAllCities ()   async   { \n     return   new   Response . ok ([ Atlanta ,   Madison ,   Mountain View ]); \n   }  }   The above operation method will be invoked when  CityController  handles  GET  requests without path variables. To handle operation methods with path variables, the name of the path variable is added to the  @Operation  annotation:  class   CityController   extends   ResourceController   { \n   @ Operation . get () \n   Future Response   getAllCities ()   async   { \n     return   new   Response . ok ([ Atlanta ,   Madison ,   Mountain View ]); \n   } \n\n   @ Operation . get ( name ) \n   Future Response   getCityByName ()   async   { \n     final   id   =   request . path . variables [ name ]; \n     return   new   Response . ok ( fetchCityWithName ( name )); \n   }  }    Path Variables  This controller would be linked to the route specification  /cities/[:name] , so that it can handle both of these operations. Read more about path variables in  Routing .   The named constructor of  Operation  tells us which HTTP method the operation method handles. The following named constructors exist:   Operation.post()  Operation.get()  Operation.put()  Operation.delete()   The canonical  Operation()  constructor takes the HTTP method as its first argument for non-standard operations, e.g.:  @ Operation ( PATCH ,   id )  Future Response   patchObjectWithID ()   async   =   ...;   All  Operation  constructors take a variable list of path variables. There can be multiple path variables for an operation. An operation method will only be invoked if all of its path variables are present in the request path. There can be multiple operation methods for a given HTTP method, as long as each expects a different set of path variables.  Here's an example of an operation that requires two path variables:  @ Operation . get ( userID ,   itemID )  Future Response   getUserItem ()   async   { \n   final   userID   =   request . path . variables [ userID ]; \n   final   itemID   =   request . path . variables [ itemID ]; \n   return   new   Response . ok (...);  }   If no operation method exists for a request, a 405 Method Not Allowed response is automatically sent and no operation method is invoked.", 
            "title": "Operation Methods"
        }, 
        {
            "location": "/http/resource_controller/#routing-to-a-resourcecontroller", 
            "text": "A  ResourceController  subclass must be preceded by a  Router  in the application channel. The  Router  will parse path variables so that the controller can use them to determine which operation method should be invoked. A typical route to a  ResourceController  contains an optional identifying path variable:  router \n   . route ( /cities/[:name] ) \n   . link (()   =   new   CityController ());   This route would allow  CityController  to implement operation methods for all HTTP methods with both no path variables and the 'name' path variable.  It is considered good practice to break sub-resources into their own controller. For example, the following is preferred:  router \n   . route ( /cities/[:name] ) \n   . link (()   =   new   CityController ());  router \n   . route ( /cities/:name/attractions/[:id] ) \n   . link (()   =   new   CityAttractionController ());   By contrast, the route  /cities/[:name/[attractions/[:id]]] , while valid, makes controller logic much more unwieldy.", 
            "title": "Routing to a ResourceController"
        }, 
        {
            "location": "/http/resource_controller/#request-bindings", 
            "text": "Operation methods may  bind  properties of an HTTP request to its parameters. When the operation method is invoked, the value of that property is passed as an argument to the operation method. For example, the following binds the header named 'X-API-Key' to the argument  apiKey :  @ Operation . get ( name )  Future Response   getCityByName ( @ Bind . path ( x-api-key )   String   apiKey )   async   { \n   if   ( ! isValid ( apiKey ))   { \n     return   new   Response . unauthorized (); \n   } \n\n   return   new   Response . ok (...);  }   The following table shows the possible types of bindings:     Property  Binding      Path Variable  @Bind.path(pathVariableName)    URL Query Parameter  @Bind.query(queryParameterName)    Header  @Bind.header(headerName)    Request Body  @Bind.body()     You may bind any number of HTTP request properties to a single operation method.", 
            "title": "Request Bindings"
        }, 
        {
            "location": "/http/resource_controller/#optional-bindings", 
            "text": "Bindings can be made optional. If a binding is optional, the operation method will still be called even if the bound property isn't in a request. To make a binding optional, move it to the optional parameters of an operation method:  @ Operation . get ()  Future Response   getAllCities ({ @ Bind . header ( x-api-key )   String   apiKey })   async   { \n   if   ( apiKey   ==   null )   { \n     // No X-API-Key in request \n     ... \n   } \n   ...  }   A bound parameter will be null if not in the request. Like any other Dart optional parameter, you can provide a default value:  @ Operation . get ()  Future Response   getAllCities ({ @ Bind . header ( x-api-key )   String   apiKey:   public })   async   { \n   ...  }", 
            "title": "Optional Bindings"
        }, 
        {
            "location": "/http/resource_controller/#automatically-parsing-bindings", 
            "text": "Query, header and path bindings can automatically be parsed into other types, such as  int  or  DateTime . Simply declare the bound parameter's type to the desired type:  Future Response   getCityByID ( @ Bind . query ( id )   int   cityID )   The type of a bound parameter may be  String  or any type that implements  parse  (e.g.,  int ,  DateTime ). Query parameters may also be bound to  bool  parameters; a boolean query parameter will be true if the query parameter has no value (e.g.  /path?boolean ).  If parsing fails for any reason, an error response is sent and the operation method is not called. For example, the above example binds  int cityID  - if the path variable 'id' can't be parsed into an  int , a 404 Not Found response is sent. If a query parameter or header value cannot be parsed, a 400 Bad Request response is sent.  You may also bind  List T  parameters to headers and query parameters, where  T  must meet the same criteria as above. Query parameters and headers may appear more than once in a request. For example, the value of  ids  is  [1, 2]  if the request URL ends with  /path?id=1 id=2  and the operation method looks like this:  Future Response   getCitiesByIDs ( @ Bind . query ( id )   List int   ids )   Note that if a parameter is  not  bound to a list and there are multiple occurrences of that property in the request, a 400 Bad Request response will be sent. If you want to allow multiple values, you must bind to a  List T .", 
            "title": "Automatically Parsing Bindings"
        }, 
        {
            "location": "/http/resource_controller/#header-bindings", 
            "text": "The following operation method binds the header named  X-API-Key  to the  apiKey  parameter:  class   CityController   extends   ResourceController   { \n   @ Operation . get () \n   Future Response   getAllCities ( @ Bind . header ( x-api-key )   String   apiKey )   async   { \n     if   ( ! isValid ( apiKey ))   { \n       return   new   Response . unauthorized (); \n     } \n\n     return   new   Response . ok ([ Atlanta ,   Madison ,   Mountain View ]); \n   }  }   If an  X-API-Key  header is present in the request, its value will be available in  apiKey . If it is not,  getAllCities(apiKey)  would not be called and a 400 Bad Request response will be sent. If  apiKey  were optional, the method is called as normal and  apiKey  is null or a default value.  Header names are case-insensitive per the HTTP specification. Therefore, the header name may be 'X-API-KEY', 'X-Api-Key' 'x-api-key', etc. and  apiKey  will be bound in all cases.", 
            "title": "Header Bindings"
        }, 
        {
            "location": "/http/resource_controller/#query-parameter-bindings", 
            "text": "The following operation methods binds the query parameter named 'name' to the parameter  cityName :  class CityController extends ResourceController {\n  @Operation.get()\n  Future  getAllCities(@Bind.query('name') String cityName) async {\n    return new Response.ok(cities.where((c) =  c.name == cityName).toList());\n  }\n}  Query parameters can be required or optional. If required, a 400 Bad Request response is sent and no operation method is called if the query parameter is not present in the request URL. If optional, the bound variable is null or a default value.  Query parameters are case-sensitive; this binding will only match the query parameter 'name', but not 'Name' or 'NAME'.  Query parameters may also bound for query strings in the request body when the content-type is 'application/x-www-form-urlencoded'.", 
            "title": "Query Parameter Bindings"
        }, 
        {
            "location": "/http/resource_controller/#path-variable-bindings", 
            "text": "The following operation method binds the path variable 'id' to the parameter  cityID :  class   CityController   extends   ResourceController   { \n   @ Operation . get ( id ) \n   Future Response   getCityByID ( @ Bind . query ( id )   String   cityID )   async   { \n     return   new   Response . ok ( cities . where (( c )   =   c . id   ==   cityID ). toList ()); \n   }  }   Path variables are made available when creating  routes . A  Router  must have a route that includes a path variable and that path variable must be listed in the  Operation  annotation. Path variables are case-sensitive and may not be optional.  If you attempt to bind a path variable that is not present in the  Operation , you will get a runtime exception at startup. You do not have to bind path variables for an operation method to be invoked.", 
            "title": "Path Variable Bindings"
        }, 
        {
            "location": "/http/resource_controller/#http-request-body-bindings", 
            "text": "The body of an HTTP request can also be bound to a parameter:  class   CityController   extends   ResourceController   { \n   CityController ( this . context ); \n\n   final   ManagedContext   context ; \n\n   @ Operation . post () \n   Future Response   addCity ( @ Bind . body ()   City   city )   async   { \n     final   insertedCity   =   await   Query . insertObject ( context ,   city ); \n\n     return   new   Response . ok ( insertedCity ); \n   }  }   Since there is only one request body,  Bind.body()  doesn't take any identifying arguments.  The bound parameter type ( City  in this example) must implement  Serializable . This interface requires two methods to be implemented: one to read data from a request body and another to write data to a response body. Here is an example:  class   City   implements   Serializable   { \n   int   id ; \n   String   name ; \n\n   @ override \n   void   readFromMap ( Map String ,   dynamic   map )   { \n     id   =   map [ id ]; \n     name   =   map [ name ]; \n   } \n\n   @ override \n   Map String ,   dynamic   asMap ()   { \n     return   { \n       id :   id , \n       name :   name \n     } \n   }  }    ManagedObject and Serializable  ManagedObject s from Aqueduct's ORM implement  Serializable  without having to implement these two methods.   Aqueduct will automatically decode the request body from it's content-type, create a new instance of the bound parameter type, and invoke its  readFromMap  method. In the above example, a valid request body would be the following JSON:  { \n   id :   1 , \n   name :   Atlanta  }    HTTP Body Decoding  Request bodies are decoded according to their content-type prior to being deserialized. For more information on request body decoding, including decoding content-types other than JSON, see  this guide .   If parsing fails or  readFromMap  throws an exception, a 400 Bad Request response will be sent and the operation method won't be called.  You may also bind  List Serializable  parameters to the request body. Consider the following JSON that contains a list of cities:  [ \n   { id :   1 ,   name :   Atlanta }, \n   { id :   2 ,   name :   Madison }  ]   This body can be bound by declaring the bound parameter to be a  List  of the desired type:  Future Response   addCity ( @ Bind . body ()   List City   cities )   !!! tip 'List vs Object'\n    An endpoint should either take a single object or a list of objects, but not both. If the request body is a JSON list and the bound variable is not a list, a 400 Bad Request response will be sent (and vice versa). Declaring a body binding of the appropriate type validates the expected value and aids in automatically generating an OpenAPI specification for your application.  Note that if the request's  Content-Type  is 'x-www-form-urlencoded', its must be bound with  Bind.query  and not  Bind.body .", 
            "title": "HTTP Request Body Bindings"
        }, 
        {
            "location": "/http/resource_controller/#property-binding", 
            "text": "The properties of an  ResourceController s may also have  Bind.query  and  Bind.header  metadata. This binds values from the request to the  ResourceController  instance itself, making them accessible from  all  operation methods.  class   CityController   extends   ResourceController   { \n   @ requiredBinding \n   @ Bind . header ( x-timestamp ) \n   DateTime   timestamp ; \n\n   @ Bind . query ( limit ) \n   int   limit ; \n\n   @ Operation . get () \n   Future Response   getCities ()   async   { \n       // can use both limit and timestamp \n   }  }   In the above, both  timestamp  and  limit  are bound prior to  getCities  being invoked. By default, a bound property is optional. Adding an  requiredBinding  annotation changes a property to required. If required, any request without the required property fails with a 400 Bad Request status code and none of the operation methods are invoked.", 
            "title": "Property Binding"
        }, 
        {
            "location": "/http/resource_controller/#other-resourcecontroller-behavior", 
            "text": "Besides binding,  ResourceController s have some other behavior that is important to understand.", 
            "title": "Other ResourceController Behavior"
        }, 
        {
            "location": "/http/resource_controller/#request-and-response-bodies", 
            "text": "An  ResourceController  can limit the content type of HTTP request bodies it accepts. By default, an  ResourceController  will accept only  application/json  request bodies for its  POST  and  PUT  methods. This can be modified by setting the  acceptedContentTypes  property in the constructor.  class   UserController   extends   ResourceController   { \n   UserController ()   { \n     acceptedContentTypes   =   [ ContentType . JSON ,   ContentType . XML ]; \n   }  }   If a request is made with a content type other than the accepted content types, the controller automatically responds with a 415 Unsupported Media Type response.  The body of an HTTP request is decoded if the content type is accepted and there exists a operation method to handle the request. The body is not decoded if there is not a matching operation method for the request. The body is decoded by  ResourceController  prior to your operation method being invoked. Therefore, you can always use the synchronous  RequestBody.as  method to access the body from within an operation method:  @ Operation . post ()  Future Response   createThing ()   async   { \n   // do this: \n   Map String ,   dynamic   bodyMap   =   request . body . as (); \n\n   // no need to do this: \n   Map String ,   dynamic   bodyMap   =   await   request . body . decode (); \n\n   return   ...;  }   An  ResourceController  can also have a default content type for its responses. By default, this is  application/json . This default can be changed by changing  responseContentType  in the constructor:  class   UserController   extends   ResourceController   { \n   UserController ()   { \n     responseContentType   =   ContentType . XML ; \n   }  }   The  responseContentType  is the  default  response content type. An individual  Response  may set its own  contentType , which takes precedence over the  responseContentType . For example, the following controller returns JSON by default, but if the request specifically asks for XML, that's what it will return:  class   UserController   extends   ResourceController   { \n   UserController ()   { \n     responseContentType   =   ContentType . JSON ; \n   } \n\n   @ Operation . get ( id ) \n   Future Response   getUserByID ( @ Bind . path ( id )   int   id )   async   { \n     var   response   =   new   Response . ok (...); \n\n     if   ( request . headers . value ( Bind . headers . ACCEPT ). startsWith ( application/xml ))   { \n       response . contentType   =   ContentType . XML ; \n     } \n\n     return   response ; \n   }  }", 
            "title": "Request and Response Bodies"
        }, 
        {
            "location": "/http/resource_controller/#more-specialized-resourcecontrollers", 
            "text": "Many  ResourceController  subclasses will execute  queries . There are helpful  ResourceController  subclasses for reducing boilerplate code.  A  QueryController T  builds a  Query T  based on the incoming request. If the request has a body, this  Query T 's  values  property is read from that body. If the request has a path variable, the  Query T  assigns an expression to the primary key value. For example, in a normal  ResourceController  that responds to a PUT request, you might write the following:  @ Operation . put ( id )  Future Response   updateUser ( @ Bind . path ( id )   int   id ,   @ Bind . body ()   User   user )   async   { \n   var   query   =   new   Query User ( context ) \n     .. where (( u )   =   u . id ). equalTo ( id ) \n     .. values   =   user ; \n\n   return   new   Response . ok ( await   query . updateOne ());  }   A  QueryController T  builds this query before a operation method is invoked, storing it in the inherited  query  property. A  ManagedObject T  subclass is the type argument to  QueryController T .  class   UserController   extends   QueryController User   { \n   UserController ( ManagedContext   context )   :   super ( context ); \n\n   @ Operation . put ( id ) \n   Future Response   updateUser ( @ Bind . path ( id )   int   id )   async   { \n     // query already exists and is identical to the snippet above \n     var   result   =   await   query . updateOne (); \n     return   new   Response . ok ( result ); \n   }  }   A  ManagedObjectController T  is significantly more powerful; you don't even need to subclass it. It does all the things a CRUD endpoint does without any code. Here's an example usage:  router \n   . route ( /users/[:id] ) \n   . link (()   =   new   ManagedObjectController User ( context ));   This controller has the following behavior:     Request  Action      POST /users  Inserts a user into the database with values from the request body    GET /users  Fetches all users in the database    GET /users/:id  Fetches a single user by id    DELETE /users/:id  Deletes a single user by id    PUT /users/:id  Updated a single user by id, using values from the request body     The objects returned from getting the collection - e.g,  GET /users  - can be modified with query parameters. For example, the following request will return the users sorted by their name in ascending order:  GET /users?sortBy=name,asc   The results can be paged (see  Paging in Advanced Queries ) with query parameters  offset ,  count ,  pageBy ,  pageAfter  and  pagePrior .  A  ManagedObjectController T  can also be subclassed. A subclass allows for callbacks to be overridden to adjust the query before execution, or the results before sending the respond. Each operation - fetch, update, delete, etc. - has a pair of methods to do this. For example, the following subclass alters the query and results before any update via  PUT :  class   UserController   extends   ManagedObjectController User   { \n   UserController ( ManagedContext   context )   :   super ( context ); \n\n   Future Query User   willUpdateObjectWithQuery ( \n       Query User   query )   async   { \n     query . values . lastUpdatedAt   =   new   DateTime . now (). toUtc (); \n     return   query ; \n   } \n\n   Future Response   didUpdateObject ( User   object )   async   { \n     object . removePropertyFromBackingMap ( private ); \n     return   new   Response . ok ( object ); \n   }  }   See the chapter on  validations , which are powerful when combined with  ManagedObjectController T .", 
            "title": "More Specialized ResourceControllers"
        }, 
        {
            "location": "/http/configure/", 
            "text": "Configuring an Aqueduct Application\n\n\nThis guide covers configuring an Aqueduct application.\n\n\nConfiguration Files\n\n\nAqueduct applications use YAML configuration files to provide environment-specific values like database connection information. Use separate configuration files for testing and different deployment environments.\n\n\nThe path of a configuration file is available to an \nApplicationChannel\n through its \noptions\n property.\n\n\nclass\n \nTodoAppChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \nvar\n \nconfig\n \n=\n \nnew\n \nTodoConfiguration\n(\noptions\n.\nconfigurationFilePath\n);\n\n    \n...\n\n  \n}\n\n\n}\n\n\n\n\n\n\nThe default value is \nconfig.yaml\n.\n\n\nThe best practice for reading a configuration file is to subclass \nConfigurationItem\n. A \nConfigurationItem\n declares a property for each key in a configuration file. For example, see the following \nConfigurationItem\n subclass:\n\n\nclass\n \nTodoConfiguration\n \nextends\n \nConfigurationItem\n \n{\n\n  \nTodoConfiguration\n(\nString\n \nfileName\n)\n \n:\n \nsuper\n.\nfromFile\n(\nfileName\n);\n\n\n  \nDatabaseConnectionConfiguration\n \ndatabase\n;\n\n  \nString\n \napiBaseURL\n;\n\n\n  \n@\noptionalConfiguration\n\n  \nint\n \nidentifier\n;\n\n\n}\n\n\n\n\n\n\nThis would read a YAML file like this:\n\n\ndatabase\n:\n\n  \nusername\n:\n \nfred\n\n  \npassword\n:\n \nfredspassword\n\n  \nhost\n:\n \ndb\n.\nmyapp\n.\ncom\n\n  \nport\n:\n \n5432\n\n  \ndatabaseName\n:\n \nfredsdb\n\n\napiBaseURL\n:\n \n/\napi\n\n\nidentifier\n:\n \n2\n\n\n\n\n\n\nIf required properties are omitted from the YAML file being read, application startup will fail and throw an informative error.\n\n\nYou may use \nConfigurationItem\ns to read values from environment variables. In \nconfig.yaml\n, use a \n$\n-prefixed environment variable name instead of a value:\n\n\ndatabase: $DATABASE_CONNECTION_URL\napiBaseURL: /api\n\n\n\n\n\nIf the environment variable \nDATABASE_CONNECTION_URL\n's value were \n\"postgres://user:password@localhost:5432/test\"\n, the value of \nTodoConfigurationItem.database\n will be that string at runtime. (Note that \nDatabaseConnectionConfiguration\n may either have a YAML object for each connection attribute, or a database connection string.)\n\n\nThe \nsafe_config package\n has instructions for more additional usages.\n\n\nConfiguration Conventions and Deployment Options\n\n\nAqueduct uses two configuration files for a project: \nconfig.yaml\n and \nconfig.src.yaml\n. The latter is the \nconfiguration source file\n. The configuration source file declares key-value pairs that will be used when running the application tests. Deployed instances use \nconfig.yaml\n.\n\n\nThis pattern is used for two reasons:\n\n\n\n\nIt is the template for the \nconfig.yaml\n that will be read on deployed applications, providing documentation for your application's configuration.\n\n\nIt has the configuration values used during testing to inject mock dependencies.\n\n\n\n\nFor example, a production API instance might have the following \nconfig.yaml\n file with connection info for a production database:\n\n\ndatabase\n:\n \npostgres\n://\napp_user\n:\n$\n%\n4\njlkn\n#\nan\n*\n@\nmOZkea2\n@\nsomedns\n.\nname\n.\ncom\n:\n5432\n/\nproduction_db\n\n\n\n\n\n\nWhereas \nconfig.src.yaml\n would have connection info for a local, test database:\n\n\ndatabase\n:\n \npostgres\n://\ntest\n:\ntest\n@\nlocalhost\n:\n5432\n/\ntemporary_db\n\n\n\n\n\n\nThe source configuration file should be checked into version control. Whether or not \nconfig.yaml\n is checked in depends on how you are deploying your code. If you are using environment variables to control application configuration, you should check \nconfig.yaml\n into source control and provide \n$\n-prefixed environment variable values. If you are using managing configuration files on each deployed instance, do not check \nconfig.yaml\n into source control because it'll be a different file for each instance.\n\n\nIt can sometimes makes sense to have a \nlocal.yaml\n with values for running the application locally, e.g. when doing client testing. Use \n--config-path\n with \naqueduct serve\n to use a non-default name.\n\n\nPreventing Resource Leaks\n\n\nWhen an Aqueduct application starts, the application and its \nApplicationChannel\ns will likely create services that they use to respond to requests. In order for application tests to complete successfully, these services must be \"closed\" when the application stops. For built-in services, like \nPostgreSQLPersistentStore\n, this happens automatically when \nApplication.stop()\n is invoked.\n\n\nA \nServiceRegistry\n automatically stops registered services. Registration looks like this:\n\n\nvar\n \nconnection\n \n=\n \nnew\n \nConnectionOfSomeKind\n();\n\n\nawait\n \nconnection\n.\nopen\n();\n\n\nServiceRegistry\n.\ndefaultInstance\n\n  \n.\nregister\nConnectionOfSomeKind\n(\nconnection\n,\n \n(\nc\n)\n \n=\n \nc\n.\nclose\n());\n\n\n\n\n\n\nThis method takes the service to be closed and a closure that closes it. The service is passed as an argument to the closure. If the closure returns a \nFuture\n, \nServiceRegistry.close\n will not complete until the \nFuture\n completes. \nServiceRegistry.defaultInstance\n is closed in \nApplication.stop()\n, any registries created by the programmer must be closed manually.\n\n\nThe return type of \nServiceRegistry.register\n is the object being registered. This makes registration syntax a bit more palatable:\n\n\nvar\n \nconnection\n \n=\n \nServiceRegistry\n.\ndefaultInstance\n\n  \n.\nregister\nConnectionOfSomeKind\n(\n\n    \nnew\n \nConnectionOfSomeKind\n(),\n \n(\nc\n)\n \n=\n \nc\n.\nclose\n());\n\n\n\nawait\n \nconnection\n.\nopen\n();\n\n\n\n\n\n\nConfiguring CORS Headers\n\n\nAll controllers have built-in behavior for handling CORS requests from a browser. When a preflight request is received from a browser (an OPTIONS request with Access-Control-Request-Method header and Origin headers), the response is created by evaluating the policy of the \nController\n that will respond to the real request.\n\n\nIn practice, this means that the policy of the last controller in a channel is used. For example, the policy of \nFooController\n generates the preflight response:\n\n\nrouter\n\n  \n.\nroute\n(\n/foo\n)\n\n  \n.\nlink\n(()\n \n=\n \nnew\n \nAuthorizer\n(...))\n\n  \n.\nlink\n(()\n \n=\n \nnew\n \nFooController\n());\n\n\n\n\n\n\nEvery \nController\n has a \npolicy\n property (a \nCORSPolicy\n instance). The \npolicy\n has properties for configuring CORS options for that particular endpoint. By having a \npolicy\n, every \nController\n automatically implements logic to respond to preflight requests without any additional code.\n\n\nPolicies can be set at the controller level or at the application level. The static property \nCORSPolicy.defaultPolicy\n can be modified at initialization time to set the CORS options for every controller.\n\n\nclass\n \nMyApplicationChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \nCORSPolicy\n.\ndefaultPolicy\n.\nallowedOrigins\n \n=\n \n[\nhttp://mywebsite.com/\n];\n\n  \n}\n\n\n}\n\n\n\n\n\n\nThe default policy is very permissive: POST, PUT, DELETE and GET are allowed methods. All origins are valid (*).\n\n\nEach individual controller can override or replace the default policy by modifying its own \npolicy\n in its constructor.\n\n\nclass\n \nMyResourceController\n \nextends\n \nResourceController\n \n{\n\n  \nMyResourceController\n()\n \n{\n\n    \npolicy\n.\nallowedMethods\n \n=\n \n[\nPOST\n];\n\n  \n}\n\n\n}\n\n\n\n\n\n\nConfiguring HTTPS\n\n\nBy default, an Aqueduct application does not use HTTPS. In many cases, an Aqueduct application sits behind an SSL-enabled load balancer or some other proxy. The traffic from the load balancer is sent to the Aqueduct application unencrypted over HTTP.\n\n\nHowever, Aqueduct may be configured to manage HTTPS connections itself. By passing the value private key and SSL certificate paths as options to \n--ssl-key-path\n \nand\n \n--ssl-certificate-path\n in \naqueduct serve\n, an Aqueduct application will configure itself to only allow HTTPS connections.\n\n\naqueduct serve --ssl-key-path server.key.pem --ssl-certificate-path server.cert.pem\n\n\n\n\n\nBoth the key and certificate file must be unencrypted PEM files, and both must be provided to this command. These files are typically issued by a \"Certificate Authority\", such as \nletsencrypt.org\n.\n\n\nWhen an application is started with these options, the \ncertificateFilePath\n and \nkeyFilePath\n are set on the \nApplicationOptions\n your application is being run with. (If you are not using \naqueduct serve\n, you can set these values directly when instantiating \nApplicationOptions\n.)\n\n\nFor more granular control over setting up an HTTPS server, you may override \nsecurityContext\n in \nApplicationChannel\n. By default, this property will create a \nSecurityContext\n from the \ncertificateFilePath\n and \nkeyFilePath\n in the channels's \noptions\n. A \nSecurityContext\n allows for password-encrypted credential files, configuring client certificates and other less used HTTPS schemes.\n\n\nclass\n \nMyApplicationChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \n@\noverride\n\n  \nSecurityContext\n \nget\n \nsecurityContext\n \n{\n\n    \nreturn\n \nnew\n \nSecurityContext\n()\n\n      \n..\nusePrivateKey\n(\nserver.key\n,\n \npassword:\n \n1234\n)\n\n      \n..\nuseCertificateChain\n(\nserver.crt\n,\n \npassword:\n \n1234\n);\n\n  \n}\n\n\n}", 
            "title": "Configuration"
        }, 
        {
            "location": "/http/configure/#configuring-an-aqueduct-application", 
            "text": "This guide covers configuring an Aqueduct application.", 
            "title": "Configuring an Aqueduct Application"
        }, 
        {
            "location": "/http/configure/#configuration-files", 
            "text": "Aqueduct applications use YAML configuration files to provide environment-specific values like database connection information. Use separate configuration files for testing and different deployment environments.  The path of a configuration file is available to an  ApplicationChannel  through its  options  property.  class   TodoAppChannel   extends   ApplicationChannel   { \n   @ override \n   Future   prepare ()   async   { \n     var   config   =   new   TodoConfiguration ( options . configurationFilePath ); \n     ... \n   }  }   The default value is  config.yaml .  The best practice for reading a configuration file is to subclass  ConfigurationItem . A  ConfigurationItem  declares a property for each key in a configuration file. For example, see the following  ConfigurationItem  subclass:  class   TodoConfiguration   extends   ConfigurationItem   { \n   TodoConfiguration ( String   fileName )   :   super . fromFile ( fileName ); \n\n   DatabaseConnectionConfiguration   database ; \n   String   apiBaseURL ; \n\n   @ optionalConfiguration \n   int   identifier ;  }   This would read a YAML file like this:  database : \n   username :   fred \n   password :   fredspassword \n   host :   db . myapp . com \n   port :   5432 \n   databaseName :   fredsdb  apiBaseURL :   / api  identifier :   2   If required properties are omitted from the YAML file being read, application startup will fail and throw an informative error.  You may use  ConfigurationItem s to read values from environment variables. In  config.yaml , use a  $ -prefixed environment variable name instead of a value:  database: $DATABASE_CONNECTION_URL\napiBaseURL: /api  If the environment variable  DATABASE_CONNECTION_URL 's value were  \"postgres://user:password@localhost:5432/test\" , the value of  TodoConfigurationItem.database  will be that string at runtime. (Note that  DatabaseConnectionConfiguration  may either have a YAML object for each connection attribute, or a database connection string.)  The  safe_config package  has instructions for more additional usages.", 
            "title": "Configuration Files"
        }, 
        {
            "location": "/http/configure/#configuration-conventions-and-deployment-options", 
            "text": "Aqueduct uses two configuration files for a project:  config.yaml  and  config.src.yaml . The latter is the  configuration source file . The configuration source file declares key-value pairs that will be used when running the application tests. Deployed instances use  config.yaml .  This pattern is used for two reasons:   It is the template for the  config.yaml  that will be read on deployed applications, providing documentation for your application's configuration.  It has the configuration values used during testing to inject mock dependencies.   For example, a production API instance might have the following  config.yaml  file with connection info for a production database:  database :   postgres :// app_user : $ % 4 jlkn # an * @ mOZkea2 @ somedns . name . com : 5432 / production_db   Whereas  config.src.yaml  would have connection info for a local, test database:  database :   postgres :// test : test @ localhost : 5432 / temporary_db   The source configuration file should be checked into version control. Whether or not  config.yaml  is checked in depends on how you are deploying your code. If you are using environment variables to control application configuration, you should check  config.yaml  into source control and provide  $ -prefixed environment variable values. If you are using managing configuration files on each deployed instance, do not check  config.yaml  into source control because it'll be a different file for each instance.  It can sometimes makes sense to have a  local.yaml  with values for running the application locally, e.g. when doing client testing. Use  --config-path  with  aqueduct serve  to use a non-default name.", 
            "title": "Configuration Conventions and Deployment Options"
        }, 
        {
            "location": "/http/configure/#preventing-resource-leaks", 
            "text": "When an Aqueduct application starts, the application and its  ApplicationChannel s will likely create services that they use to respond to requests. In order for application tests to complete successfully, these services must be \"closed\" when the application stops. For built-in services, like  PostgreSQLPersistentStore , this happens automatically when  Application.stop()  is invoked.  A  ServiceRegistry  automatically stops registered services. Registration looks like this:  var   connection   =   new   ConnectionOfSomeKind ();  await   connection . open ();  ServiceRegistry . defaultInstance \n   . register ConnectionOfSomeKind ( connection ,   ( c )   =   c . close ());   This method takes the service to be closed and a closure that closes it. The service is passed as an argument to the closure. If the closure returns a  Future ,  ServiceRegistry.close  will not complete until the  Future  completes.  ServiceRegistry.defaultInstance  is closed in  Application.stop() , any registries created by the programmer must be closed manually.  The return type of  ServiceRegistry.register  is the object being registered. This makes registration syntax a bit more palatable:  var   connection   =   ServiceRegistry . defaultInstance \n   . register ConnectionOfSomeKind ( \n     new   ConnectionOfSomeKind (),   ( c )   =   c . close ());  await   connection . open ();", 
            "title": "Preventing Resource Leaks"
        }, 
        {
            "location": "/http/configure/#configuring-cors-headers", 
            "text": "All controllers have built-in behavior for handling CORS requests from a browser. When a preflight request is received from a browser (an OPTIONS request with Access-Control-Request-Method header and Origin headers), the response is created by evaluating the policy of the  Controller  that will respond to the real request.  In practice, this means that the policy of the last controller in a channel is used. For example, the policy of  FooController  generates the preflight response:  router \n   . route ( /foo ) \n   . link (()   =   new   Authorizer (...)) \n   . link (()   =   new   FooController ());   Every  Controller  has a  policy  property (a  CORSPolicy  instance). The  policy  has properties for configuring CORS options for that particular endpoint. By having a  policy , every  Controller  automatically implements logic to respond to preflight requests without any additional code.  Policies can be set at the controller level or at the application level. The static property  CORSPolicy.defaultPolicy  can be modified at initialization time to set the CORS options for every controller.  class   MyApplicationChannel   extends   ApplicationChannel   { \n   @ override \n   Future   prepare ()   async   { \n     CORSPolicy . defaultPolicy . allowedOrigins   =   [ http://mywebsite.com/ ]; \n   }  }   The default policy is very permissive: POST, PUT, DELETE and GET are allowed methods. All origins are valid (*).  Each individual controller can override or replace the default policy by modifying its own  policy  in its constructor.  class   MyResourceController   extends   ResourceController   { \n   MyResourceController ()   { \n     policy . allowedMethods   =   [ POST ]; \n   }  }", 
            "title": "Configuring CORS Headers"
        }, 
        {
            "location": "/http/configure/#configuring-https", 
            "text": "By default, an Aqueduct application does not use HTTPS. In many cases, an Aqueduct application sits behind an SSL-enabled load balancer or some other proxy. The traffic from the load balancer is sent to the Aqueduct application unencrypted over HTTP.  However, Aqueduct may be configured to manage HTTPS connections itself. By passing the value private key and SSL certificate paths as options to  --ssl-key-path   and   --ssl-certificate-path  in  aqueduct serve , an Aqueduct application will configure itself to only allow HTTPS connections.  aqueduct serve --ssl-key-path server.key.pem --ssl-certificate-path server.cert.pem  Both the key and certificate file must be unencrypted PEM files, and both must be provided to this command. These files are typically issued by a \"Certificate Authority\", such as  letsencrypt.org .  When an application is started with these options, the  certificateFilePath  and  keyFilePath  are set on the  ApplicationOptions  your application is being run with. (If you are not using  aqueduct serve , you can set these values directly when instantiating  ApplicationOptions .)  For more granular control over setting up an HTTPS server, you may override  securityContext  in  ApplicationChannel . By default, this property will create a  SecurityContext  from the  certificateFilePath  and  keyFilePath  in the channels's  options . A  SecurityContext  allows for password-encrypted credential files, configuring client certificates and other less used HTTPS schemes.  class   MyApplicationChannel   extends   ApplicationChannel   { \n   @ override \n   SecurityContext   get   securityContext   { \n     return   new   SecurityContext () \n       .. usePrivateKey ( server.key ,   password:   1234 ) \n       .. useCertificateChain ( server.crt ,   password:   1234 ); \n   }  }", 
            "title": "Configuring HTTPS"
        }, 
        {
            "location": "/http/serving_files/", 
            "text": "Serving Files and Caching\n\n\nAqueduct can serve files by returning the contents of a file as an HTTP response body.\n\n\nFileController\n\n\nInstances of \nFileController\n serve a directory from the filesystem through an HTTP interface. Any route that channels requests to an \nFileController\n \nmust\n contain a \n*\n match-all token.\n\n\n@\noverride\n\n\nController\n \nget\n \nentryPoint\n \n{\n\n  \nfinal\n \nrouter\n \n=\n \nnew\n \nRouter\n();\n\n\n  \nrouter\n.\nroute\n(\n/files/*\n).\nlink\n(()\n \n=\n \nnew\n \nFileController\n(\npublic/\n));\n\n\n  \nreturn\n \nrouter\n;\n\n\n}\n\n\n\n\n\n\nThe argument to \nFileController\n is the directory on the filesystem in which request paths will be resolved against. In the above example, an HTTP request with the path \n/files/image.jpg\n would return the contents of the file \npublic/image.jpg\n.\n\n\nNote that \npublic/\n does not have a leading slash - therefore, the directory \npublic\n must be relative to the directory that the Aqueduct application was served from. In practice, this means you might have a directory structure like:\n\n\nproject/\n  pubspec.yaml  \n  lib/\n    channel.dart\n    ...\n  test/\n    ...\n  public/\n    image.jpg\n\n\n\n\n\nAdding a leading slash to the directory served by \nFileController\n will resolve it relative to the filesystem root.\n\n\nIf the requested path was a directory, the filename \nindex.html\n will be appended to the path when searching for a file to return.\n\n\nIf a file does not exist, an \nFileController\n returns a 404 Not Found response.\n\n\nContent-Type of Files\n\n\nAn \nFileController\n will set the content-type of the HTTP response based on the served files path extension. By default, it recognizes many common extensions like \n.html\n, \n.css\n, \n.jpg\n, \n.js\n. You may add content-types for extensions to an instance:\n\n\nvar\n \ncontroller\n \n=\n \nnew\n \nFileController\n(\npublic/\n)\n\n  \n..\nsetContentTypeForExtension\n(\nxml\n,\n \nnew\n \nContentType\n(\napplication\n,\n \nxml\n));\n\n\n\n\n\n\nIf there is no entry for an extension of a file being served, the content-type defaults to \napplication/octet-stream\n. An \nFileController\n will never invoke any encoders from \nCodecRegistry\n, but it will GZIP data if the repository allows compression for the content-type of the file (see \nCodecRegistry.add\n and \nCodecRegistry.setAllowsCompression\n).\n\n\nCaching\n\n\nAn \nFileController\n always sets the the Last-Modified header of the response to the last modified date according to the filesystem. If a request sends an If-Modified-Since header and the file has not been modified since that date, a 304 Not Modified response is sent with the appropriate headers.\n\n\nYou may provide Cache-Control headers depending on the path of the file being served. Here's an example that adds \nCache-Control: public, max-age=31536000\n\n\nvar\n \npolicy\n \n=\n \nnew\n \nCachePolicy\n(\nexpirationFromNow:\n \nnew\n \nDuration\n(\ndays:\n \n365\n));\n\n\nvar\n \ncontroller\n \n=\n \nnew\n \nFileController\n(\npublic/\n)\n\n  \n..\naddCachePolicy\n(\npolicy\n,\n \n(\npath\n)\n \n=\n \npath\n.\nendsWith\n(\n.css\n));\n\n\n\n\n\n\nFile Serving and Caching Outside of FileController\n\n\nA file can be served by any controller by setting the body object of a \nResponse\n with its contents:\n\n\nvar\n \nfile\n \n=\n \nnew\n \nFile\n(\nindex.html\n);\n\n\n\n// By loading contents into memory first...\n\n\nvar\n \nresponse\n \n=\n \nnew\n \nResponse\n.\nok\n(\nfile\n.\nreadAsStringSync\n())\n\n  \n..\ncontentType\n \n=\n \nnew\n \nContentType\n(\napplication\n,\n \nhtml\n);\n\n\n\n// Or by streaming the contents from disk\n\n\nvar\n \nresponse\n \n=\n \nnew\n \nResponse\n.\nok\n(\nfile\n.\nopenRead\n())\n\n  \n..\nencodeBody\n \n=\n \nfalse\n\n  \n..\ncontentType\n \n=\n \nnew\n \nContentType\n(\napplication\n,\n \nhtml\n);\n\n\n\n\n\n\nIt is important to understand the how Aqueduct \nuses content-types to manipulate response bodies\n to serve file contents.\n\n\nYou may set the \nCachePolicy\n of any \nResponse\n. Note that \nCachePolicy\n only modifies the Cache-Control header of a response - headers like Last-Modified and ETag are not added.\n\n\nvar\n \nresponse\n \n=\n \nnew\n \nResponse\n.\nok\n(\ncontents\n)\n\n  \n..\ncachePolicy\n \n=\n \nnew\n \nCachePolicy\n();", 
            "title": "Serving Files and Caching"
        }, 
        {
            "location": "/http/serving_files/#serving-files-and-caching", 
            "text": "Aqueduct can serve files by returning the contents of a file as an HTTP response body.", 
            "title": "Serving Files and Caching"
        }, 
        {
            "location": "/http/serving_files/#filecontroller", 
            "text": "Instances of  FileController  serve a directory from the filesystem through an HTTP interface. Any route that channels requests to an  FileController   must  contain a  *  match-all token.  @ override  Controller   get   entryPoint   { \n   final   router   =   new   Router (); \n\n   router . route ( /files/* ). link (()   =   new   FileController ( public/ )); \n\n   return   router ;  }   The argument to  FileController  is the directory on the filesystem in which request paths will be resolved against. In the above example, an HTTP request with the path  /files/image.jpg  would return the contents of the file  public/image.jpg .  Note that  public/  does not have a leading slash - therefore, the directory  public  must be relative to the directory that the Aqueduct application was served from. In practice, this means you might have a directory structure like:  project/\n  pubspec.yaml  \n  lib/\n    channel.dart\n    ...\n  test/\n    ...\n  public/\n    image.jpg  Adding a leading slash to the directory served by  FileController  will resolve it relative to the filesystem root.  If the requested path was a directory, the filename  index.html  will be appended to the path when searching for a file to return.  If a file does not exist, an  FileController  returns a 404 Not Found response.", 
            "title": "FileController"
        }, 
        {
            "location": "/http/serving_files/#content-type-of-files", 
            "text": "An  FileController  will set the content-type of the HTTP response based on the served files path extension. By default, it recognizes many common extensions like  .html ,  .css ,  .jpg ,  .js . You may add content-types for extensions to an instance:  var   controller   =   new   FileController ( public/ ) \n   .. setContentTypeForExtension ( xml ,   new   ContentType ( application ,   xml ));   If there is no entry for an extension of a file being served, the content-type defaults to  application/octet-stream . An  FileController  will never invoke any encoders from  CodecRegistry , but it will GZIP data if the repository allows compression for the content-type of the file (see  CodecRegistry.add  and  CodecRegistry.setAllowsCompression ).", 
            "title": "Content-Type of Files"
        }, 
        {
            "location": "/http/serving_files/#caching", 
            "text": "An  FileController  always sets the the Last-Modified header of the response to the last modified date according to the filesystem. If a request sends an If-Modified-Since header and the file has not been modified since that date, a 304 Not Modified response is sent with the appropriate headers.  You may provide Cache-Control headers depending on the path of the file being served. Here's an example that adds  Cache-Control: public, max-age=31536000  var   policy   =   new   CachePolicy ( expirationFromNow:   new   Duration ( days:   365 ));  var   controller   =   new   FileController ( public/ ) \n   .. addCachePolicy ( policy ,   ( path )   =   path . endsWith ( .css ));", 
            "title": "Caching"
        }, 
        {
            "location": "/http/serving_files/#file-serving-and-caching-outside-of-filecontroller", 
            "text": "A file can be served by any controller by setting the body object of a  Response  with its contents:  var   file   =   new   File ( index.html );  // By loading contents into memory first...  var   response   =   new   Response . ok ( file . readAsStringSync ()) \n   .. contentType   =   new   ContentType ( application ,   html );  // Or by streaming the contents from disk  var   response   =   new   Response . ok ( file . openRead ()) \n   .. encodeBody   =   false \n   .. contentType   =   new   ContentType ( application ,   html );   It is important to understand the how Aqueduct  uses content-types to manipulate response bodies  to serve file contents.  You may set the  CachePolicy  of any  Response . Note that  CachePolicy  only modifies the Cache-Control header of a response - headers like Last-Modified and ETag are not added.  var   response   =   new   Response . ok ( contents ) \n   .. cachePolicy   =   new   CachePolicy ();", 
            "title": "File Serving and Caching Outside of FileController"
        }, 
        {
            "location": "/http/websockets/", 
            "text": "Using Websockets in Aqueduct\n\n\nA standard HTTP request will yield an HTTP response from a web server. In order for the server to send data to a client, the client must have sent a request for that data. A \nwebsocket\n is a special type of HTTP request that stays open, and both the server and client can send data to one another whenever they please.\n\n\nFor example, a chat application might use websockets to send messages to everyone in a chatroom. In this scenario, the chat client application opens a websocket connection to the server application. When the user types a message, their chat client sends that message on its websocket. The payload might be JSON data that looks like this:\n\n\n{\n\n  \naction\n:\n \nsend_message\n,\n\n  \nroom\n:\n \ngeneral\n,\n\n  \ntext\n:\n \nHi everyone\n\n\n}\n\n\n\n\n\n\nThe server will receive this data, then turn around and send a modified version to \nevery\n websocket connection it has. That data might look like this:\n\n\n{\n\n  \naction\n:\n \nreceive_message\n,\n\n  \nroom\n:\n \ngeneral\n,\n\n  \nfrom\n:\n \nBob\n,\n\n  \ntext\n:\n \nHi everyone\n\n\n}\n\n\n\n\n\n\nEvery connected user will receive this data and draw \nBob: Hi everyone\n to the screen.\n\n\nNote that there's nothing about websockets that says you have to use JSON data - you can use any data format you like.\n\n\nUpgrading an HTTP Request to a WebSocket\n\n\nIn Aqueduct, websockets are handled by Dart's standard library \nWebSocket\n type. Here's an example:\n\n\nrouter\n\n  \n.\nroute\n(\n/connect\n)\n\n  \n.\nlinkFunction\n((\nrequest\n)\n \nasync\n \n{\n\n    \nvar\n \nsocket\n \n=\n \nawait\n \nWebSocketTransformer\n.\nupgrade\n(\nrequest\n.\nraw\n);\n\n    \nsocket\n.\nlisten\n(\nlistener\n);\n\n\n    \nreturn\n \nnull\n;\n\n  \n});\n\n\n\n\n\n\nIt's important that a request that is upgraded to a websocket is removed from the channel by returning null from the controller. (See the section on \nAqueduct and dart:io\n \nin this guide\n for more details.)\n\n\nA client application can connect to the URL \nws://localhost:8888/connect\n. A Dart application would make this connection like so:\n\n\nvar\n \nsocket\n \n=\n \nawait\n \nWebSocket\n.\nconnect\n(\nws://localhost:8888/connect\n);\n\n\nsocket\n.\nlisten\n(...);\n\n\n\n\n\n\nBi-directional Communication\n\n\nIn the simple example above, the server only listens for data from the client. For data to be sent to the client, a reference must be kept to the \nWebSocket\n so that data can be added to it. How an Aqueduct application manages its websocket connections depends greatly on the behavior of the application, the number of isolates the application is running on and the infrastructure of the system as a whole.\n\n\nA simple application might keep track of websocket connections in a \nMap\n, where the key is a user identifier acquired from the authorization of the request:\n\n\nrouter\n\n  \n.\nroute\n(\n/connect\n)\n\n  \n.\nlink\n(()\n \n=\n \nnew\n \nAuthorizer\n(\nauthServer\n));\n\n  \n.\nlinkFunction\n((\nrequest\n)\n \nasync\n \n{\n\n    \nvar\n \nuserID\n \n=\n \nrequest\n.\nauthorization\n.\nownerID\n;\n\n    \nvar\n \nsocket\n \n=\n \nawait\n \nWebSocketTransformer\n.\nupgrade\n(\nrequest\n.\nraw\n);\n\n    \nsocket\n.\nlisten\n((\nevent\n)\n \n=\n \nhandleEvent\n(\nevent\n,\n \nfromUserID:\n \nuserID\n));\n\n\n    \nconnections\n[\nuserID\n]\n \n=\n \nsocket\n;\n\n\n    \nreturn\n \nnull\n;\n\n  \n});\n\n\n\n\n\n\nIf we continue with the 'chat application' example, the code for \nhandleEvent\n may be something like:\n\n\nvoid\n \nhandleEvent\n(\ndynamic\n \nevent\n,\n \n{\nint\n \nfromUserID\n})\n \n{\n\n  \nvar\n \nincoming\n \n=\n \njson\n.\ndecode\n(\nUTF8\n.\ndecode\n(\nevent\n));\n\n  \nvar\n \noutgoing\n \n=\n \nutf8\n.\nencode\n(\njson\n.\nencode\n({\n\n    \ntext\n:\n \nincoming\n[\ntext\n],\n\n    \n...\n\n  \n}));\n\n\n  \nconnections\n.\nkeys\n\n    \n.\nwhere\n((\nuserID\n)\n \n=\n \nuserID\n \n!=\n \nfromUserID\n)\n\n    \n.\nforEach\n((\nuserID\n)\n \n{\n\n      \nvar\n \nconnection\n \n=\n \nconnections\n[\nuserID\n];\n\n      \nconnection\n.\nadd\n(\noutgoing\n);\n\n    \n});\n\n\n}\n\n\n\n\n\n\nNote that this simple implementation doesn't account for multiple connections from the same user or multi-isolate applications.\n\n\nConsiderations for Multi-Isolate and Multi-Instance Applications\n\n\nBy default, an Aqueduct application runs on multiple isolates. Since each isolate has its own heap, a websocket created on one isolate is not directly accessible by another isolate. In the example above, each isolate would have its own map of connections - therefore, a message is only sent to connections that were opened on the same isolate that the chat message originated from.\n\n\nA simple solution is to only run the application on a single isolate, ensuring that all websockets are on a single isolate and accessible to one another:\n\n\naqueduct\n \nserve\n \n-\nn\n \n1\n\n\n\n\n\n\nFor many applications, this is a fine solution. For others, it may not be.\n\n\nRecall that one of the benefits of Aqueduct's multi-isolate architecture is that code tested on a single instance will scale to multiple instances behind a load balancer. If an Aqueduct application runs correctly on a single, multi-isolate instance, it will will correctly on multiple instances. This (somewhat) enforced structure prevents us from naively keeping track of websocket connections on a single isolate, which would cause issues when we scale out to a multi-instance system.\n\n\nIf you find yourself in a situation where your application is so popular you need multiple servers to efficiently serve requests, you'll have a good idea on how to architect an appropriate solution (or you'll have the money to hire someone that does). In many situations, the REST API and websocket server are separate instances anyhow - they have different lifecycles and deployment behavior. It may make sense to run a websocket server on a single isolate, since you are likely IO-bound instead of CPU bound.\n\n\nIf you still prefer to have a multi-isolate server with websockets, the \nApplicationMessageHub\n will come in handy. When broadcasting messages to connected websockets across the application, you first send the data to each websocket connected to the isolate that is originating the message. Then, the message is added to the \nApplicationMessageHub\n:\n\n\nvoid\n \nonChatMessage\n(\nString\n \nmessage\n)\n \n{\n\n  \nconnectedSockets\n.\nforEach\n((\nsocket\n)\n \n{\n\n    \nsocket\n.\nadd\n(\nmessage\n);\n\n  \n});\n\n\n  \nApplicationChannel\n.\nmessageHub\n.\nadd\n({\nevent\n:\n \nwebsocket_broadcast\n,\n \nmessage\n:\n \nmessage\n});\n\n\n}\n\n\n\n\n\n\nAnything added to the \nmessageHub\n will be delivered to the listener for every other message hub - i.e., every other isolate will receive this data. The other isolates then send the message to each of their connected websockets:\n\n\nclass\n \nChatChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \nmessageHub\n.\nlisten\n((\nevent\n)\n \n{\n\n      \nif\n \n(\nevent\n \nis\n \nMap\n \n \nevent\n[\nevent\n]\n \n==\n \nwebsocket_broadcast\n)\n \n{\n\n        \nconnectedSockets\n.\nforEach\n((\nsocket\n)\n \n{\n\n          \nsocket\n.\nadd\n(\nevent\n[\nmessage\n]);\n\n        \n});\n\n      \n}\n\n    \n});\n\n  \n}\n\n\n}", 
            "title": "Websockets"
        }, 
        {
            "location": "/http/websockets/#using-websockets-in-aqueduct", 
            "text": "A standard HTTP request will yield an HTTP response from a web server. In order for the server to send data to a client, the client must have sent a request for that data. A  websocket  is a special type of HTTP request that stays open, and both the server and client can send data to one another whenever they please.  For example, a chat application might use websockets to send messages to everyone in a chatroom. In this scenario, the chat client application opens a websocket connection to the server application. When the user types a message, their chat client sends that message on its websocket. The payload might be JSON data that looks like this:  { \n   action :   send_message , \n   room :   general , \n   text :   Hi everyone  }   The server will receive this data, then turn around and send a modified version to  every  websocket connection it has. That data might look like this:  { \n   action :   receive_message , \n   room :   general , \n   from :   Bob , \n   text :   Hi everyone  }   Every connected user will receive this data and draw  Bob: Hi everyone  to the screen.  Note that there's nothing about websockets that says you have to use JSON data - you can use any data format you like.", 
            "title": "Using Websockets in Aqueduct"
        }, 
        {
            "location": "/http/websockets/#upgrading-an-http-request-to-a-websocket", 
            "text": "In Aqueduct, websockets are handled by Dart's standard library  WebSocket  type. Here's an example:  router \n   . route ( /connect ) \n   . linkFunction (( request )   async   { \n     var   socket   =   await   WebSocketTransformer . upgrade ( request . raw ); \n     socket . listen ( listener ); \n\n     return   null ; \n   });   It's important that a request that is upgraded to a websocket is removed from the channel by returning null from the controller. (See the section on  Aqueduct and dart:io   in this guide  for more details.)  A client application can connect to the URL  ws://localhost:8888/connect . A Dart application would make this connection like so:  var   socket   =   await   WebSocket . connect ( ws://localhost:8888/connect );  socket . listen (...);", 
            "title": "Upgrading an HTTP Request to a WebSocket"
        }, 
        {
            "location": "/http/websockets/#bi-directional-communication", 
            "text": "In the simple example above, the server only listens for data from the client. For data to be sent to the client, a reference must be kept to the  WebSocket  so that data can be added to it. How an Aqueduct application manages its websocket connections depends greatly on the behavior of the application, the number of isolates the application is running on and the infrastructure of the system as a whole.  A simple application might keep track of websocket connections in a  Map , where the key is a user identifier acquired from the authorization of the request:  router \n   . route ( /connect ) \n   . link (()   =   new   Authorizer ( authServer )); \n   . linkFunction (( request )   async   { \n     var   userID   =   request . authorization . ownerID ; \n     var   socket   =   await   WebSocketTransformer . upgrade ( request . raw ); \n     socket . listen (( event )   =   handleEvent ( event ,   fromUserID:   userID )); \n\n     connections [ userID ]   =   socket ; \n\n     return   null ; \n   });   If we continue with the 'chat application' example, the code for  handleEvent  may be something like:  void   handleEvent ( dynamic   event ,   { int   fromUserID })   { \n   var   incoming   =   json . decode ( UTF8 . decode ( event )); \n   var   outgoing   =   utf8 . encode ( json . encode ({ \n     text :   incoming [ text ], \n     ... \n   })); \n\n   connections . keys \n     . where (( userID )   =   userID   !=   fromUserID ) \n     . forEach (( userID )   { \n       var   connection   =   connections [ userID ]; \n       connection . add ( outgoing ); \n     });  }   Note that this simple implementation doesn't account for multiple connections from the same user or multi-isolate applications.", 
            "title": "Bi-directional Communication"
        }, 
        {
            "location": "/http/websockets/#considerations-for-multi-isolate-and-multi-instance-applications", 
            "text": "By default, an Aqueduct application runs on multiple isolates. Since each isolate has its own heap, a websocket created on one isolate is not directly accessible by another isolate. In the example above, each isolate would have its own map of connections - therefore, a message is only sent to connections that were opened on the same isolate that the chat message originated from.  A simple solution is to only run the application on a single isolate, ensuring that all websockets are on a single isolate and accessible to one another:  aqueduct   serve   - n   1   For many applications, this is a fine solution. For others, it may not be.  Recall that one of the benefits of Aqueduct's multi-isolate architecture is that code tested on a single instance will scale to multiple instances behind a load balancer. If an Aqueduct application runs correctly on a single, multi-isolate instance, it will will correctly on multiple instances. This (somewhat) enforced structure prevents us from naively keeping track of websocket connections on a single isolate, which would cause issues when we scale out to a multi-instance system.  If you find yourself in a situation where your application is so popular you need multiple servers to efficiently serve requests, you'll have a good idea on how to architect an appropriate solution (or you'll have the money to hire someone that does). In many situations, the REST API and websocket server are separate instances anyhow - they have different lifecycles and deployment behavior. It may make sense to run a websocket server on a single isolate, since you are likely IO-bound instead of CPU bound.  If you still prefer to have a multi-isolate server with websockets, the  ApplicationMessageHub  will come in handy. When broadcasting messages to connected websockets across the application, you first send the data to each websocket connected to the isolate that is originating the message. Then, the message is added to the  ApplicationMessageHub :  void   onChatMessage ( String   message )   { \n   connectedSockets . forEach (( socket )   { \n     socket . add ( message ); \n   }); \n\n   ApplicationChannel . messageHub . add ({ event :   websocket_broadcast ,   message :   message });  }   Anything added to the  messageHub  will be delivered to the listener for every other message hub - i.e., every other isolate will receive this data. The other isolates then send the message to each of their connected websockets:  class   ChatChannel   extends   ApplicationChannel   { \n   @ override \n   Future   prepare ()   async   { \n     messageHub . listen (( event )   { \n       if   ( event   is   Map     event [ event ]   ==   websocket_broadcast )   { \n         connectedSockets . forEach (( socket )   { \n           socket . add ( event [ message ]); \n         }); \n       } \n     }); \n   }  }", 
            "title": "Considerations for Multi-Isolate and Multi-Instance Applications"
        }, 
        {
            "location": "/http/threading/", 
            "text": "Multi-threading in Aqueduct\n\n\nOne of the primary differentiators between Aqueduct and other server frameworks is its multi-threaded behavior. When an Aqueduct application starts, it replicates the application logic across a number of threads.\n\n\nIn Dart, threads are called \nisolates\n. The difference in naming isn't just to be cute - an isolate is a little bit different than a thread in that memory is not shared between isolates. Each isolate has its own heap (this is where memory for objects is allocated from) that other isolates can't access.\n\n\nAn isolated thread is very valuable. Many multi-threaded applications share memory across threads, which require difficult design patterns and can easily introduce hard to track bugs that even the most experienced programmer will have a hard time avoiding.\n\n\nHow Aqueduct Uses Isolates\n\n\nAn application is initialized by invoking a series of initialization methods in a \nApplicationChannel\n. Once these methods are finished executing, the application starts sending HTTP requests through the channel created by the \nApplicationChannel\n.\n\n\nBecause an \nApplicationChannel\n is a type - and can be instantiated - Aqueduct simply creates a number of isolates and instantiates \nApplicationChannel\n for each. The initialization code is therefore identical for each isolate, which means that the ongoing behavior of each isolate is also identical.\n\n\nMore importantly, you - the programmer - have to do absolutely nothing to take advantage of Aqueduct's multi-threaded behavior. You simply have to pick the number of isolates you want to run the application on (see \nthis section\n).\n\n\nWhile you don't have to do anything in an Aqueduct application to take advantage of multiple processors, there are things you shouldn't do or should do in another way.\n\n\nFirst, you must be careful of keeping any state in your application. After initialization, any objects created while handling a request should be destroyed once the request is fulfilled. Any data that needs to be persisted must be stored in a database or other data store. This is just good practice for a REST API anyhow, so nothing is really lost here.\n\n\nHowever, there are times where you do need to track state. For example, if you are managing websocket connections, you do need to store some state after initialization - a reference to the websocket. \nThis guide\n covers this topic in detail; the simple explanation is to use the \nApplicationMessageHub\n.\n\n\nAnother thing that is important to consider is initialization. The methods \nprepare()\n and \nentryPoint\n in an application channel will be invoked on each isolate. This behavior is guaranteed to occur for each isolate and there is often little to worry about.\n\n\nHowever, when implementing \nApplicationChannel.initializeApplication\n, code runs on the main isolate. Any changes to static variables or singletons will not be replicated to the isolates running the application logic. The use case for this method is rather minimal, but it is very important that types like \nCodecRegistry\n aren't configured in this method.\n\n\nHow Many Isolates Should I Use\n\n\nTo give you a starting point, the default number of isolates for an application is 3 when started with \naqueduct serve\n. While less than 3 isolates will most certainly degrade performance, more than 3 doesn't necessarily improve performance. (And many more will certainly degrade performance.)\n\n\nThere are a number of variables that factor into the isolate count decision. First, recall a computer essentially does two things: it executes instructions and transmits data. Both of these tasks take time, especially when that data is transmitted to another computer thousands of miles away. (It is a modern marvel that these tasks occur as fast as they do - one that we often take for granted.)\n\n\nWhile a few milliseconds difference in speed to handle a single request isn't all that meaningful, when you start receiving thousands of requests at a time, these milliseconds add up. When your application is struggling to keep up with executing instructions, it it said to be \nCPU-bound\n. (When your application is struggling to transmit data, it is said to be \nIO-bound\n.)\n\n\nA CPU-bound application has two choices: execute less instructions or have more processors (or cores) to execute instructions with. Most computers these days have multiple processors. When only using a single isolate, an Aqueduct application can only use one of those processors at a time. As the number of isolates increases, so too do the number of processors that can be used at a time.\n\n\nThus, more isolates means more processors means more instructions and your application bound less by the CPU. However, there is a limit - creating 100 isolates when there are only two processors doesn't yield any greater performance, because 50 isolates will fight over a single processor. In fact, the amount of work to schedule these instructions and the amount of memory this many isolates will consume will hurt performance.\n\n\nFor example, when running benchmarks with \nwrk\n on my four-core machine, I get significantly better results as I add isolates 1 through 4, but then I get marginal gains and finally less or equal performance as I increase the number of isolates past 4. The blue bar represents the number of requests per second for each isolate count when making a simple HTTP call to Aqueduct.\n\n\n\n\n(Note that benchmarks are a good way of measuring relative performance of an application and identifying bottlenecks, but real world usability performance across a network is the only measurement that matters. The absolute value of these benchmarks should not be taken seriously, as they entirely remove the network portion of the transmission.)\n\n\nBut this isn't the whole story. Server applications are rarely CPU-bound, but instead IO-bound. The red bar represents the number of requests per second when making a database query and returning the results of that query as JSON in the response body. When using Observatory, the measurements indicate that the overwhelming majority of the time is spent transmitting data to and from the database. This is an example of being bound by IO (and the speed of the query).\n\n\nRecall that each isolate has its own database connection. A database connection is a serial queue - it can only handle one query at a time. Increasing the number of database connections means handling more queries at a time. This is no more apparent than when looking at the following graph, which measures the latency of requests with and without a database call.\n\n\n\n\nWhen there is only one database connection (one isolate), the latency is significantly higher per request - the application is entirely bound by the speed of the database serial queue. Adding a second isolate, and therefore a second database connection, drops the latency by more than half.\n\n\nThere are diminishing returns as more database connections are added. That's because the same thing about the number of threads per processor also applies to the number of database connections. Adding more database connections doesn't magically make the database server run any faster.\n\n\nAs a general rule, start with N-1 isolates, where N is the number of processors on the machine. Use \nwrk\n and Observatory to profile your application and tune accordingly. In a multi-instance environment, remember that the total number of database connections is MxN, where M is the number of machines and N is the number of isolates.\n\n\nIf you find yourself in a jam where IO would be better served by less isolates, but CPU would be better served by more isolates, you may consider using a database connection pool isolate.", 
            "title": "Multi-threading"
        }, 
        {
            "location": "/http/threading/#multi-threading-in-aqueduct", 
            "text": "One of the primary differentiators between Aqueduct and other server frameworks is its multi-threaded behavior. When an Aqueduct application starts, it replicates the application logic across a number of threads.  In Dart, threads are called  isolates . The difference in naming isn't just to be cute - an isolate is a little bit different than a thread in that memory is not shared between isolates. Each isolate has its own heap (this is where memory for objects is allocated from) that other isolates can't access.  An isolated thread is very valuable. Many multi-threaded applications share memory across threads, which require difficult design patterns and can easily introduce hard to track bugs that even the most experienced programmer will have a hard time avoiding.", 
            "title": "Multi-threading in Aqueduct"
        }, 
        {
            "location": "/http/threading/#how-aqueduct-uses-isolates", 
            "text": "An application is initialized by invoking a series of initialization methods in a  ApplicationChannel . Once these methods are finished executing, the application starts sending HTTP requests through the channel created by the  ApplicationChannel .  Because an  ApplicationChannel  is a type - and can be instantiated - Aqueduct simply creates a number of isolates and instantiates  ApplicationChannel  for each. The initialization code is therefore identical for each isolate, which means that the ongoing behavior of each isolate is also identical.  More importantly, you - the programmer - have to do absolutely nothing to take advantage of Aqueduct's multi-threaded behavior. You simply have to pick the number of isolates you want to run the application on (see  this section ).  While you don't have to do anything in an Aqueduct application to take advantage of multiple processors, there are things you shouldn't do or should do in another way.  First, you must be careful of keeping any state in your application. After initialization, any objects created while handling a request should be destroyed once the request is fulfilled. Any data that needs to be persisted must be stored in a database or other data store. This is just good practice for a REST API anyhow, so nothing is really lost here.  However, there are times where you do need to track state. For example, if you are managing websocket connections, you do need to store some state after initialization - a reference to the websocket.  This guide  covers this topic in detail; the simple explanation is to use the  ApplicationMessageHub .  Another thing that is important to consider is initialization. The methods  prepare()  and  entryPoint  in an application channel will be invoked on each isolate. This behavior is guaranteed to occur for each isolate and there is often little to worry about.  However, when implementing  ApplicationChannel.initializeApplication , code runs on the main isolate. Any changes to static variables or singletons will not be replicated to the isolates running the application logic. The use case for this method is rather minimal, but it is very important that types like  CodecRegistry  aren't configured in this method.", 
            "title": "How Aqueduct Uses Isolates"
        }, 
        {
            "location": "/http/threading/#how-many-isolates-should-i-use", 
            "text": "To give you a starting point, the default number of isolates for an application is 3 when started with  aqueduct serve . While less than 3 isolates will most certainly degrade performance, more than 3 doesn't necessarily improve performance. (And many more will certainly degrade performance.)  There are a number of variables that factor into the isolate count decision. First, recall a computer essentially does two things: it executes instructions and transmits data. Both of these tasks take time, especially when that data is transmitted to another computer thousands of miles away. (It is a modern marvel that these tasks occur as fast as they do - one that we often take for granted.)  While a few milliseconds difference in speed to handle a single request isn't all that meaningful, when you start receiving thousands of requests at a time, these milliseconds add up. When your application is struggling to keep up with executing instructions, it it said to be  CPU-bound . (When your application is struggling to transmit data, it is said to be  IO-bound .)  A CPU-bound application has two choices: execute less instructions or have more processors (or cores) to execute instructions with. Most computers these days have multiple processors. When only using a single isolate, an Aqueduct application can only use one of those processors at a time. As the number of isolates increases, so too do the number of processors that can be used at a time.  Thus, more isolates means more processors means more instructions and your application bound less by the CPU. However, there is a limit - creating 100 isolates when there are only two processors doesn't yield any greater performance, because 50 isolates will fight over a single processor. In fact, the amount of work to schedule these instructions and the amount of memory this many isolates will consume will hurt performance.  For example, when running benchmarks with  wrk  on my four-core machine, I get significantly better results as I add isolates 1 through 4, but then I get marginal gains and finally less or equal performance as I increase the number of isolates past 4. The blue bar represents the number of requests per second for each isolate count when making a simple HTTP call to Aqueduct.   (Note that benchmarks are a good way of measuring relative performance of an application and identifying bottlenecks, but real world usability performance across a network is the only measurement that matters. The absolute value of these benchmarks should not be taken seriously, as they entirely remove the network portion of the transmission.)  But this isn't the whole story. Server applications are rarely CPU-bound, but instead IO-bound. The red bar represents the number of requests per second when making a database query and returning the results of that query as JSON in the response body. When using Observatory, the measurements indicate that the overwhelming majority of the time is spent transmitting data to and from the database. This is an example of being bound by IO (and the speed of the query).  Recall that each isolate has its own database connection. A database connection is a serial queue - it can only handle one query at a time. Increasing the number of database connections means handling more queries at a time. This is no more apparent than when looking at the following graph, which measures the latency of requests with and without a database call.   When there is only one database connection (one isolate), the latency is significantly higher per request - the application is entirely bound by the speed of the database serial queue. Adding a second isolate, and therefore a second database connection, drops the latency by more than half.  There are diminishing returns as more database connections are added. That's because the same thing about the number of threads per processor also applies to the number of database connections. Adding more database connections doesn't magically make the database server run any faster.  As a general rule, start with N-1 isolates, where N is the number of processors on the machine. Use  wrk  and Observatory to profile your application and tune accordingly. In a multi-instance environment, remember that the total number of database connections is MxN, where M is the number of machines and N is the number of isolates.  If you find yourself in a jam where IO would be better served by less isolates, but CPU would be better served by more isolates, you may consider using a database connection pool isolate.", 
            "title": "How Many Isolates Should I Use"
        }, 
        {
            "location": "/db/", 
            "text": "Tasks\n\n\nAqueduct's ORM stores data in a database and maps database data to Dart objects.\n\n\nYou create subclasses of \nManagedObject\nT\n in your application code to define the database tables your application uses. The properties of these types have annotations like \nColumn\n and \nValidate\n to customize the behavior of tables in your database.\n\n\nYour application creates a \nManagedContext\n service object during initialization that manages database access for your application. This service is injected into controllers that make database queries.\n\n\nInstances of \nQuery\nT\n are created to insert, update, read and delete data from a database. A \nQuery\nT\n has many configurable options for filtering, joining, paging, sorting and performing aggregate functions on database rows.\n\n\nThe \naqueduct db\n command-line tool manages databases that your application connects. This tool creates and executes migration scripts that update the schema of a database to match the requirements of your application. \n\n\nGuides\n\n\n\n\nConnecting to a Database\n\n\nModeling Data\n\n\nStorage, Serialization and Deserialization\n\n\nExecuting Queries\n\n\nJoins, Filtering and Paging\n\n\nExecuting Queries in a Transaction\n\n\nAdding Validations and Callbacks to ManagedObject\n\n\nAqueduct Database Tool\n\n\nJSON Document Columns and Operations", 
            "title": "Overview"
        }, 
        {
            "location": "/db/#tasks", 
            "text": "Aqueduct's ORM stores data in a database and maps database data to Dart objects.  You create subclasses of  ManagedObject T  in your application code to define the database tables your application uses. The properties of these types have annotations like  Column  and  Validate  to customize the behavior of tables in your database.  Your application creates a  ManagedContext  service object during initialization that manages database access for your application. This service is injected into controllers that make database queries.  Instances of  Query T  are created to insert, update, read and delete data from a database. A  Query T  has many configurable options for filtering, joining, paging, sorting and performing aggregate functions on database rows.  The  aqueduct db  command-line tool manages databases that your application connects. This tool creates and executes migration scripts that update the schema of a database to match the requirements of your application.", 
            "title": "Tasks"
        }, 
        {
            "location": "/db/#guides", 
            "text": "Connecting to a Database  Modeling Data  Storage, Serialization and Deserialization  Executing Queries  Joins, Filtering and Paging  Executing Queries in a Transaction  Adding Validations and Callbacks to ManagedObject  Aqueduct Database Tool  JSON Document Columns and Operations", 
            "title": "Guides"
        }, 
        {
            "location": "/db/connecting/", 
            "text": "Connecting to a Database from Aqueduct\n\n\nThe interface to a database from Aqueduct is an instance of \nManagedContext\n, which contains the following two objects:\n\n\n\n\na \nManagedDataModel\n that describes your application's data model\n\n\na \nPersistentStore\n that creates database connections and transmits data across that connection.\n\n\n\n\nA \nManagedContext\n uses these two objects to coordinate moving data to and from your application and a database when executing \nQuery\nT\ns. A \nManagedContext\n - and its store and data model - are created in a \nApplicationChannel\n constructor.\n\n\nclass\n \nMyApplicationChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \nManagedContext\n \ncontext\n;\n\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \nvar\n \ndataModel\n \n=\n \nManagedDataModel\n.\nfromCurrentMirrorSystem\n();\n\n    \nvar\n \npsc\n \n=\n \nPostgreSQLPersistentStore\n.\nfromConnectionInfo\n(\n\n        \nusername\n,\n \npassword\n,\n \nhost\n,\n \n5432\n,\n \ndatabaseName\n);\n\n\n    \ncontext\n \n=\n \nManagedContext\n(\ndataModel\n,\n \npsc\n);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nA \nManagedDataModel\n should be instantiated with its \nfromCurrentMirrorSystem\n convenience constructor. You may optionally pass a list of \nManagedObject\nT\n subclasses to its default constructor.\n\n\nvar\n \ndataModel\n \n=\n \nManagedDataModel\n([\nUser\n,\n \nPost\n,\n \nFriendship\n]);\n\n\n\n\n\n\nA \nManagedContext\n is required to create and execute a \nQuery\nT\n. The context determines which database the query is executed in. A context must exist before creating instances of any \nManagedObject\n subclass in your application. Controllers that need to execute database queries must have a reference to a context; this is typically accomplished by passing the context to a controller's constructor.\n\n\nUsing a Configuration File\n\n\nConnection information for a database is most often configured through a configuration file. This allows you to build configurations for different environments (production, testing, etc.), without having to modify code.\n\n\nclass\n \nMyConfigurationItem\n \nextends\n \nConfigurationItem\n \n{\n\n  \nMyConfigurationItem\n(\nString\n \nconfigPath\n)\n \n:\n \nsuper\n.\nfromFile\n(\nconfigPath\n);\n\n\n  \nDatabaseConnectionConfiguration\n \ndatabase\n;\n\n\n}\n\n\n\nclass\n \nMyApplicationChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \nManagedContext\n \ncontext\n;\n\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \nfinal\n \nconfig\n \n=\n \nMyConfigurationItem\n(\noptions\n.\nconfigurationFilePath\n);\n\n\n    \nfinal\n \ndataModel\n \n=\n \nManagedDataModel\n.\nfromCurrentMirrorSystem\n();\n\n    \nfinal\n \npsc\n \n=\n \nPostgreSQLPersistentStore\n.\nfromConnectionInfo\n(\n\n        \nconfig\n.\ndatabase\n.\nusername\n,\n\n        \nconfig\n.\ndatabase\n.\npassword\n,\n\n        \nconfig\n.\ndatabase\n.\nhost\n,\n\n        \nconfig\n.\ndatabase\n.\nport\n,\n\n        \nconfig\n.\ndatabase\n.\ndatabaseName\n);\n        \n\n    \ncontext\n \n=\n \nManagedContext\n(\ndataModel\n,\n \npsc\n);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nA YAML configuration file loaded by this application must look like this:\n\n\ndatabase\n:\n\n  \nusername\n:\n \nbob\n\n  \npassword\n:\n \nbobspassword\n\n  \nhost\n:\n \nlocalhost\n\n  \nport\n:\n \n5432\n\n  \ndatabaseName\n:\n \nmy_app\n\n\n\n\n\n\nA \nPersistentStore\n is an interface. Concrete implementations - like \nPostgreSQLPersistentStore\n - implement that interface to transmit data to a database in the format it expects. A \nPostgreSQLPersistentStore\n will automatically connect and maintain a persistent connection to a database. If the connection is lost for some reason, it will automatically reconnect the next time a query is executed. If a connection cannot be established, an exception is thrown that sends a 503 status code response by default.", 
            "title": "Connecting to a Database"
        }, 
        {
            "location": "/db/connecting/#connecting-to-a-database-from-aqueduct", 
            "text": "The interface to a database from Aqueduct is an instance of  ManagedContext , which contains the following two objects:   a  ManagedDataModel  that describes your application's data model  a  PersistentStore  that creates database connections and transmits data across that connection.   A  ManagedContext  uses these two objects to coordinate moving data to and from your application and a database when executing  Query T s. A  ManagedContext  - and its store and data model - are created in a  ApplicationChannel  constructor.  class   MyApplicationChannel   extends   ApplicationChannel   { \n   ManagedContext   context ; \n\n   @ override \n   Future   prepare ()   async   { \n     var   dataModel   =   ManagedDataModel . fromCurrentMirrorSystem (); \n     var   psc   =   PostgreSQLPersistentStore . fromConnectionInfo ( \n         username ,   password ,   host ,   5432 ,   databaseName ); \n\n     context   =   ManagedContext ( dataModel ,   psc ); \n   }  }   A  ManagedDataModel  should be instantiated with its  fromCurrentMirrorSystem  convenience constructor. You may optionally pass a list of  ManagedObject T  subclasses to its default constructor.  var   dataModel   =   ManagedDataModel ([ User ,   Post ,   Friendship ]);   A  ManagedContext  is required to create and execute a  Query T . The context determines which database the query is executed in. A context must exist before creating instances of any  ManagedObject  subclass in your application. Controllers that need to execute database queries must have a reference to a context; this is typically accomplished by passing the context to a controller's constructor.", 
            "title": "Connecting to a Database from Aqueduct"
        }, 
        {
            "location": "/db/connecting/#using-a-configuration-file", 
            "text": "Connection information for a database is most often configured through a configuration file. This allows you to build configurations for different environments (production, testing, etc.), without having to modify code.  class   MyConfigurationItem   extends   ConfigurationItem   { \n   MyConfigurationItem ( String   configPath )   :   super . fromFile ( configPath ); \n\n   DatabaseConnectionConfiguration   database ;  }  class   MyApplicationChannel   extends   ApplicationChannel   { \n   ManagedContext   context ; \n\n   @ override \n   Future   prepare ()   async   { \n     final   config   =   MyConfigurationItem ( options . configurationFilePath ); \n\n     final   dataModel   =   ManagedDataModel . fromCurrentMirrorSystem (); \n     final   psc   =   PostgreSQLPersistentStore . fromConnectionInfo ( \n         config . database . username , \n         config . database . password , \n         config . database . host , \n         config . database . port , \n         config . database . databaseName );         \n\n     context   =   ManagedContext ( dataModel ,   psc ); \n   }  }   A YAML configuration file loaded by this application must look like this:  database : \n   username :   bob \n   password :   bobspassword \n   host :   localhost \n   port :   5432 \n   databaseName :   my_app   A  PersistentStore  is an interface. Concrete implementations - like  PostgreSQLPersistentStore  - implement that interface to transmit data to a database in the format it expects. A  PostgreSQLPersistentStore  will automatically connect and maintain a persistent connection to a database. If the connection is lost for some reason, it will automatically reconnect the next time a query is executed. If a connection cannot be established, an exception is thrown that sends a 503 status code response by default.", 
            "title": "Using a Configuration File"
        }, 
        {
            "location": "/db/modeling_data/", 
            "text": "Modeling Data\n\n\nIn this guide, you will learn how to create \nManagedObject\nT\n subclasses that can be stored in and retrieved from a database.\n\n\nDefining a Table\n\n\nIn your application, you define types whose instances can be stored in a database. Each type you create for this purpose corresponds to a database table. The properties of these types are columns of the corresponding table. Instances of these types represent a row in that table.\n\n\nFor example, consider a \nArticle\n type. When you create articles and store them in a database, they are inserted into an 'article' table. That table has a column to store the properties of the article, like its category and contents. Each individual article is a row in this table.\n\n\nA type that can be stored in a database is created by declaring two classes. The first class is a \ntable definition\n. A table definition is a plain Dart type that represents a table in the database. Each property of a table definition type is a column in that database. These properties often have annotations to further define the behavior of the column. An example looks like this:\n\n\n// This is a table definition of an \narticle\n\n\nclass\n \n_Article\n \n{\n\n  \n@\nprimaryKey\n\n  \nint\n \nid\n;\n\n\n  \nString\n \ncontents\n;\n\n\n  \n@\nColumn\n(\nindexed:\n \ntrue\n)\n\n  \nString\n \ncategory\n;\n\n\n}\n\n\n\n\n\n\nThis class declares a table named \n_Article\n with three columns:\n\n\n\n\nid\n: an integer column that is the primary key of the table\n\n\ncontents\n: a text column\n\n\ncategory\n: a text column that has an index so that it can more efficiently be searched\n\n\n\n\nA property's type determines the type of column in the table.\n\n\n\n\n\n\n\n\nDart Type\n\n\nGeneral Column Type\n\n\nPostgreSQL Column Type\n\n\n\n\n\n\n\n\n\n\nint\n\n\ninteger number\n\n\nINT\n or \nSERIAL\n\n\n\n\n\n\ndouble\n\n\nfloating point number\n\n\nDOUBLE PRECISION\n\n\n\n\n\n\nString\n\n\ntext\n\n\nTEXT\n\n\n\n\n\n\nDateTime\n\n\ntimestamp\n\n\nTIMESTAMP\n\n\n\n\n\n\nbool\n\n\nboolean\n\n\nBOOLEAN\n\n\n\n\n\n\nDocument\n\n\na JSON object or array\n\n\nJSONB\n\n\n\n\n\n\nAny \nenum\n\n\ntext, restricted to enum cases\n\n\nTEXT\n\n\n\n\n\n\n\n\nSome types can be represented by many database types; for example, an integer can be stored as 2, 4 or 8 bytes. The \nColumn\n annotation can be applied to a table definition's property to further specify the type. This same annotation allows for the customization of indices, uniqueness and other column behavior. Available options are optional arguments to the \nColumn\n constructor and shown in the following table:\n\n\n\n\n\n\n\n\nOption\n\n\nType\n\n\nBehavior\n\n\nDefault\n\n\n\n\n\n\n\n\n\n\nprimaryKey\n\n\nbool\n\n\nsets primary key column\n\n\nfalse (not primary key)\n\n\n\n\n\n\ndatabaseType\n\n\nManagedPropertyType\n\n\nsets underlying column type\n\n\ninferred from Dart type\n\n\n\n\n\n\nnullable\n\n\nbool\n\n\ntoggles whether column can be null\n\n\nfalse (not nullable)\n\n\n\n\n\n\nunique\n\n\nbool\n\n\ntoggles whether column is unique across all rows\n\n\nfalse (not unique)\n\n\n\n\n\n\ndefaultValue\n\n\nString\n\n\nprovides default value for new rows when value is undefined\n\n\nnull\n\n\n\n\n\n\nindexed\n\n\nbool\n\n\nwhether an index should be created for the column\n\n\nfalse (no index)\n\n\n\n\n\n\nomitByDefault\n\n\nbool\n\n\nwhether this column should be fetched by default\n\n\ntrue (fetch column value)\n\n\n\n\n\n\nautoincrement\n\n\nbool\n\n\nwhether this column's value is automatically generated from a series\n\n\nfalse (not generated)\n\n\n\n\n\n\n\n\nExactly one property per table definition must have a \nColumn\n annotation with the 'primary key' option. That property's column is the primary key of the database table. It is common for primary keys to be 64-bit, auto-incrementing integers; therefore, the \nprimaryKey\n constant exists as a convenience for a \nColumn\n with these options. The \n_Article\n type from above is equivalent to:\n\n\n// This is a table definition of an \narticle\n\n\nclass\n \n_Article\n \n{\n\n  \n@\nColumn\n(\nprimaryKey:\n \ntrue\n,\n \ndatabaseType:\n \nManagedPropertyType\n.\nbigInteger\n,\n \nautoincrement:\n \ntrue\n)\n\n  \nint\n \nid\n;\n\n\n  \nString\n \ncontents\n;\n\n\n  \n@\nColumn\n(\nindexed:\n \ntrue\n)\n\n  \nString\n \ncategory\n;\n\n\n}\n\n\n\n\n\n\n\n\nCreating Tables\n\n\nTables are created in a database by using the \naqueduct\n command line tool to generate and execute migration scripts. The tool inspects your database types and automatically synchronizes a databases schema to match your them.\n\n\n\n\nThe ORM assumes that a database table has the same name as a table definition, i.e. the \n_Article\n table definition instructs the ORM that there is a table named \n_Article\n. You may provide another name for the table by implementing a \nstatic\n \ntableName\n method in your table definition to return this name:\n\n\nclass\n \n_Article\n \n{\n\n  \nstatic\n \nString\n \ntableName\n()\n \n=\n \nArticleTable\n;\n\n\n  \n@\nprimaryKey\n\n  \nint\n \nid\n;\n\n\n  \nString\n \ncontents\n;\n\n\n  \n@\nColumn\n(\nindexed:\n \ntrue\n)\n\n  \nString\n \ncategory\n;\n\n\n}\n\n\n\n\n\n\nDefining an Instance Type\n\n\nAlongside the table definition, you must create an \ninstance type\n. An instance type is used in your application code. It must be a subclass of \nManagedObject\nT\n \nand\n implement \nT\n, where \nT\n is your table definition. The instance type for \n_Article\n is declared like so:\n\n\nclass\n \nArticle\n \nextends\n \nManagedObject\n_Article\n \nimplements\n \n_Article\n \n{}\n\n\n\n\n\n\nThis \nArticle\n instance type inherits all of the properties from the \n_Article\n table definition; i.e., an \nArticle\n has an \nid\n, \ncontents\n and \ncategory\n. You create instances of an instance type like any other type.\n\n\nfinal\n \narticle\n \n=\n \nnew\n \nArticle\n();\n\n\narticle\n.\nid\n \n=\n \n1\n;\n\n\narticle\n.\ncategory\n \n=\n \nBaseball\n;\n\n\n\n\n\n\nWhen you fetch rows from a database, you will be returned instances of your instance type that are automatically created for you by the ORM.\n\n\n\n\nInstance Type Constructors\n\n\nYou can add new constructors to an instance type, but you must always have a default, no-argument constructor that properly instantiates your object. This default constructor is used when the ORM creates instances from rows in your database.\n\n\n\n\nTransient Properties\n\n\nAn instance type can declare additional properties and methods. Any property declared in the instance type is \nnot\n stored in the database, and are often used for computed or derived values for an object. Properties declared on the instance type are called \ntransient properties\n.\n\n\nFor example, consider an \nAuthor\n type whose table definition stores first and last name as separate columns. Instead of redundantly storing a 'full name' in the database, a transient property can be derived from properties stored in the database:\n\n\nclass\n \nAuthor\n \nextends\n \nManagedObject\n_Author\n \nimplements\n \n_Author\n \n{\n\n  \nString\n \nget\n \nname\n \n=\n \n$\nfirstName\n \n$\nlastName\n;\n\n  \nset\n \nname\n(\nString\n \nfullName\n)\n \n{\n\n    \nfirstName\n \n=\n \nfullName\n.\nsplit\n(\n \n).\nfirst\n;\n\n    \nlastName\n \n=\n \nfullName\n.\nsplit\n(\n \n).\nlast\n;\n\n  \n}\n\n\n}\n\n\nclass\n \n_Author\n \n{\n\n  \n@\nprimaryKey\n\n  \nint\n \nid\n;\n\n\n  \nString\n \nfirstName\n;\n\n  \nString\n \nlastName\n;\n\n\n}\n\n\n\n\n\n\nTransient properties don't necessarily have to access columns of the underlying table, but note that if an object has a transient property, that value is not available on another object that represents the same row.\n\n\nBy default, a transient property is ignored when reading an object from a request body or writing the object to a response body. You can annotate a transient property with \nSerialize\n so that it is able to be read from a request body, written to a response body, or both. The following allows \nname\n to be both read and written over HTTP:\n\n\nclass\n \nAuthor\n \nextends\n \nManagedObject\n_Author\n \nimplements\n \n_Author\n \n{\n\n  \n@\nSerialize\n()\n\n  \nString\n \nget\n \nname\n \n=\n \n$\nfirstName\n \n$\nlastName\n;\n\n\n  \n@\nSerialize\n()\n\n  \nset\n \nname\n(\nString\n \nfullName\n)\n \n{\n\n    \nfirstName\n \n=\n \nfullName\n.\nsplit\n(\n \n).\nfirst\n;\n\n    \nlastName\n \n=\n \nfullName\n.\nsplit\n(\n \n).\nlast\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nProject Structure\n\n\nThe combination of an instance type and its table definition is called an \nentity\n. Each entity should be declared in the same file, and the table definition should be prefixed with an \n_\n to prevent it from being used elsewhere in the project. It is preferable to declare one entity per file, and store all entities in the \nlib/model/\n directory of your project.\n\n\nThe files your model definitions are declared in must be visible to Aqueduct tooling. In normal circumstances, this happens automatically because of the following:\n\n\n\n\nAqueduct tooling can find any file that is imported (directly or transitively) from your library file.\n\n\nYour library file, by default, can see the file your \nApplicationChannel\n is declared in.\n\n\nYour application channel file must import any controller that it links.\n\n\nYour controllers must import any model file they use.\n\n\n\n\nWhen you use the \naqueduct\n CLI to generate database migration scripts, it will report all of the \nManagedObject\ns in your application that it was able to find. If a particular type is not listed, it may reveal that you aren't using that type. If you need to ensure that the tooling can see a particular model file that it is not locating, you may import it in your \nchannel.dart\n file.\n\n\nModeling Relationships\n\n\nSo far, we've shown that table definitions can declare scalar properties like integers and strings, and that those properties are backed by a column in a database table. These types of properties are called \nattributes\n. Table definitions may also contain \nrelationship\n properties that are references to another entity in your application.\n\n\nFor example, an \nAuthor\n can have a property that holds all of the \nArticle\ns they have written. There are two types of relationships: \nhas-many\n and \nhas-one\n. A has-one relationship restricts a relationship to a single object (e.g., an author may have one article), whereas a has-many relationship allows for any number of related objects (e.g., an author has multiple articles).\n\n\nRelationship properties are also declared in a table definition. The type of the property must either be a \nManagedSet\nT\n or a \nT\n, where \nT\n is another instance type. If the type is \nManagedSet\nT\n, the relationship is a has-many relationship, otherwise, it is a has-one relationship. The following shows an \narticles\n relationship that allows an author to have many \nArticle\ns:\n\n\nclass\n \n_Author\n \n{\n\n  \n@\nprimaryKey\n\n  \nint\n \nid\n;\n\n\n  \nString\n \nname\n;\n\n\n  \n// a has-many relationship to Article\n\n  \nManagedSet\nArticle\n \narticles\n;\n\n\n  \n// If we were declaring a has-one relationship:\n\n  \n// Article article;\n\n\n}\n\n\n\n\n\n\nA \nManagedSet\n is a special type of \nList\n used in the Aqueduct ORM. It can do everything a list can do, but adds some additional behavior for the ORM.\n\n\nAll relationships must have an inverse. For example, if an author has articles, an article must have an author. This is true regardless of whether or not the relationship is has-many or has-one. An inverse is declared in the related table definition with a \nRelate\n annotation:\n\n\nclass\n \n_Article\n \n{\n\n  \n@\nprimaryKey\n\n  \nint\n \nid\n;\n\n\n  \n@\nRelate\n(\n#\narticles\n)\n\n  \nAuthor\n \nauthor\n;\n\n\n  \n...\n\n\n}\n\n\n\n\n\n\nA relationship property with this annotation is neither has-one or has-many; it \nbelongs to\n the related entity. The argument to \nRelate\n is the symbolic name of the property on the 'has' side of the relationship. In our examples, an author has many articles, and an article belongs to an author.\n\n\n\n\nSymbols\n\n\nA symbol is a name identifier in Dart; a symbol can refer to a class, method, or property. Symbols are objects can be instantiated like all objects, but the \n#\n identifier is shorthand for creating a symbol.\n\n\n\n\nOnly one side of a relationship may have the \nRelate\n annotation on its relationship property. The property with this annotation is a \nforeign key column\n on the table definition it is defined in. In this example, the \n_Article\n table has a foreign key reference to the \nid\n of the \n_Author\n table.\n\n\nChoosing which side of the relationship has the \nRelate\n annotation depends on how you wish to model your data. In has-many relationships, this is easy - a \nManagedSet\nT\n may \nnot\n have the \nRelate\n annotation. In a has-one relationship, you must determine which side of the relationship should have the foreign key reference.\n\n\nWhen making this decision, it is important to understand how objects are fetched with \nQuery\ns. In a default query, the objects that are returned will contain 'null' for every 'has' relationship, and only contain the foreign key of any 'belongs to' relationships. To fetch a related object in its entirety, you must use \nQuery.join\n.\n\n\n\n\nForeign Keys\n\n\nThe foreign key column always references the primary key of the related table, and its name is derived by combining the name of the relationship property and the primary key of the related table. For example, the above definitions would add a column named \nauthor_id\n to the \n_Article\n table.\n\n\n\n\nThe \nRelate\n annotation has optional arguments to further define the relationship.\n\n\nA relationship may be be required or optional. For example, if \nArticle.author\n were required, than an \nArticle\n must always have an \nAuthor\n. By default, relationships are optional.\n\n\nA relationship has a delete rule. When an object is deleted, any objects that belong to its relationships are subject to this rule. The following table shows the rules and their behavior:\n\n\n\n\n\n\n\n\nRule\n\n\nBehavior\n\n\nExample\n\n\n\n\n\n\n\n\n\n\nnullify (default)\n\n\ninverse is set to null\n\n\nWhen deleting an author, its articles' author becomes null\n\n\n\n\n\n\ncascade\n\n\nrelated objects are also deleted\n\n\nWhen deleting an author, its articles are deleted\n\n\n\n\n\n\nrestrict\n\n\ndelete fails\n\n\nWhen attempting to delete an author with articles, the delete operation fails\n\n\n\n\n\n\ndefault\n\n\ninverse set to a default value\n\n\nWhen deleting an author, its articles author is set to the default value of the column\n\n\n\n\n\n\n\n\nAdditional Data Modeling\n\n\nThis section covers additional features when defining your data model.\n\n\nEnum Types\n\n\nWhen a table definition property is an \nenum\n type, the enumeration is stored as a string in the database. Consider the following definition where a user can be an admin or a normal user:\n\n\nenum\n \nUserType\n \n{\n\n  \nadmin\n,\n \nuser\n\n\n}\n\n\n\nclass\n \nUser\n \nextends\n \nManagedObject\n_User\n \nimplements\n \n_User\n \n{}\n\n\nclass\n \n_User\n \n{\n\n  \n@\nprimaryKey\n\n  \nint\n \nid\n;\n\n\n  \nString\n \nname\n;\n\n\n  \nUserType\n \ntype\n;\n\n\n}\n\n\n\n\n\n\nYou may assign valid enumeration cases to the \nUser.type\n property:\n\n\nvar\n \nquery\n \n=\n \nQuery\nUser\n(\ncontext\n)\n\n  \n..\nvalues\n.\nname\n \n=\n \nBob\n\n  \n..\nvalues\n.\ntype\n \n=\n \nUserType\n.\nadmin\n;\n\n\nvar\n \nbob\n \n=\n \nawait\n \nquery\n.\ninsert\n();\n\n\n\nquery\n \n=\n \nQuery\nUser\n(\ncontext\n)\n\n  \n..\nwhere\n((\nu\n)\n \n=\n \nu\n.\ntype\n).\nequalTo\n(\nUserType\n.\nadmin\n);\n\n\nvar\n \nallAdmins\n \n=\n \nawait\n \nquery\n.\nfetch\n();\n\n\n\n\n\n\nIn the database, the \ntype\n column is stored as a string. Its value is either \"admin\" or \"user\" - which is derived from the two enumeration case names. A enumerated type property has an implicit \nValidate.oneOf\n validator that asserts the value is one of the valid enumeration cases.\n\n\nPrivate Variables\n\n\nA property of a table definition that is Dart private (prefixed with an \n_\n) will not be included when writing a \nManagedObject\nT\n to an HTTP response. It also may not be read from an HTTP request body. This behavior differs slightly from the \nomitByDefault\n flag of \nColumn\n. When omitting by default, the value is simply not fetched from the database. When a property is private, it is fetched, but it is just not accessible from outside the object. This can be useful when combined with transient accessors. For example, the following ensures that the \ntitle\n property is uppercased before storage:\n\n\nclass\n \nUser\n \nextends\n \nManagedObject\n_User\n \nimplements\n \n_User\n \n{\n\n  \n@\nSerialize\n()\n\n  \nset\n \ntitle\n(\nString\n \ntitle\n)\n \n{\n\n    \n_title\n \n=\n \ntitle\n.\ntoUpperCase\n();\n\n  \n}\n\n\n  \n@\nSerialize\n()\n\n  \nString\n \nget\n \ntitle\n \n=\n \n_title\n;\n\n\n}\n\n\n\nclass\n \n_User\n \n{\n\n  \nString\n \n_title\n;\n\n\n  \n...\n\n\n}", 
            "title": "Modeling Data"
        }, 
        {
            "location": "/db/modeling_data/#modeling-data", 
            "text": "In this guide, you will learn how to create  ManagedObject T  subclasses that can be stored in and retrieved from a database.", 
            "title": "Modeling Data"
        }, 
        {
            "location": "/db/modeling_data/#defining-a-table", 
            "text": "In your application, you define types whose instances can be stored in a database. Each type you create for this purpose corresponds to a database table. The properties of these types are columns of the corresponding table. Instances of these types represent a row in that table.  For example, consider a  Article  type. When you create articles and store them in a database, they are inserted into an 'article' table. That table has a column to store the properties of the article, like its category and contents. Each individual article is a row in this table.  A type that can be stored in a database is created by declaring two classes. The first class is a  table definition . A table definition is a plain Dart type that represents a table in the database. Each property of a table definition type is a column in that database. These properties often have annotations to further define the behavior of the column. An example looks like this:  // This is a table definition of an  article  class   _Article   { \n   @ primaryKey \n   int   id ; \n\n   String   contents ; \n\n   @ Column ( indexed:   true ) \n   String   category ;  }   This class declares a table named  _Article  with three columns:   id : an integer column that is the primary key of the table  contents : a text column  category : a text column that has an index so that it can more efficiently be searched   A property's type determines the type of column in the table.     Dart Type  General Column Type  PostgreSQL Column Type      int  integer number  INT  or  SERIAL    double  floating point number  DOUBLE PRECISION    String  text  TEXT    DateTime  timestamp  TIMESTAMP    bool  boolean  BOOLEAN    Document  a JSON object or array  JSONB    Any  enum  text, restricted to enum cases  TEXT     Some types can be represented by many database types; for example, an integer can be stored as 2, 4 or 8 bytes. The  Column  annotation can be applied to a table definition's property to further specify the type. This same annotation allows for the customization of indices, uniqueness and other column behavior. Available options are optional arguments to the  Column  constructor and shown in the following table:     Option  Type  Behavior  Default      primaryKey  bool  sets primary key column  false (not primary key)    databaseType  ManagedPropertyType  sets underlying column type  inferred from Dart type    nullable  bool  toggles whether column can be null  false (not nullable)    unique  bool  toggles whether column is unique across all rows  false (not unique)    defaultValue  String  provides default value for new rows when value is undefined  null    indexed  bool  whether an index should be created for the column  false (no index)    omitByDefault  bool  whether this column should be fetched by default  true (fetch column value)    autoincrement  bool  whether this column's value is automatically generated from a series  false (not generated)     Exactly one property per table definition must have a  Column  annotation with the 'primary key' option. That property's column is the primary key of the database table. It is common for primary keys to be 64-bit, auto-incrementing integers; therefore, the  primaryKey  constant exists as a convenience for a  Column  with these options. The  _Article  type from above is equivalent to:  // This is a table definition of an  article  class   _Article   { \n   @ Column ( primaryKey:   true ,   databaseType:   ManagedPropertyType . bigInteger ,   autoincrement:   true ) \n   int   id ; \n\n   String   contents ; \n\n   @ Column ( indexed:   true ) \n   String   category ;  }    Creating Tables  Tables are created in a database by using the  aqueduct  command line tool to generate and execute migration scripts. The tool inspects your database types and automatically synchronizes a databases schema to match your them.   The ORM assumes that a database table has the same name as a table definition, i.e. the  _Article  table definition instructs the ORM that there is a table named  _Article . You may provide another name for the table by implementing a  static   tableName  method in your table definition to return this name:  class   _Article   { \n   static   String   tableName ()   =   ArticleTable ; \n\n   @ primaryKey \n   int   id ; \n\n   String   contents ; \n\n   @ Column ( indexed:   true ) \n   String   category ;  }", 
            "title": "Defining a Table"
        }, 
        {
            "location": "/db/modeling_data/#defining-an-instance-type", 
            "text": "Alongside the table definition, you must create an  instance type . An instance type is used in your application code. It must be a subclass of  ManagedObject T   and  implement  T , where  T  is your table definition. The instance type for  _Article  is declared like so:  class   Article   extends   ManagedObject _Article   implements   _Article   {}   This  Article  instance type inherits all of the properties from the  _Article  table definition; i.e., an  Article  has an  id ,  contents  and  category . You create instances of an instance type like any other type.  final   article   =   new   Article ();  article . id   =   1 ;  article . category   =   Baseball ;   When you fetch rows from a database, you will be returned instances of your instance type that are automatically created for you by the ORM.   Instance Type Constructors  You can add new constructors to an instance type, but you must always have a default, no-argument constructor that properly instantiates your object. This default constructor is used when the ORM creates instances from rows in your database.", 
            "title": "Defining an Instance Type"
        }, 
        {
            "location": "/db/modeling_data/#transient-properties", 
            "text": "An instance type can declare additional properties and methods. Any property declared in the instance type is  not  stored in the database, and are often used for computed or derived values for an object. Properties declared on the instance type are called  transient properties .  For example, consider an  Author  type whose table definition stores first and last name as separate columns. Instead of redundantly storing a 'full name' in the database, a transient property can be derived from properties stored in the database:  class   Author   extends   ManagedObject _Author   implements   _Author   { \n   String   get   name   =   $ firstName   $ lastName ; \n   set   name ( String   fullName )   { \n     firstName   =   fullName . split (   ). first ; \n     lastName   =   fullName . split (   ). last ; \n   }  }  class   _Author   { \n   @ primaryKey \n   int   id ; \n\n   String   firstName ; \n   String   lastName ;  }   Transient properties don't necessarily have to access columns of the underlying table, but note that if an object has a transient property, that value is not available on another object that represents the same row.  By default, a transient property is ignored when reading an object from a request body or writing the object to a response body. You can annotate a transient property with  Serialize  so that it is able to be read from a request body, written to a response body, or both. The following allows  name  to be both read and written over HTTP:  class   Author   extends   ManagedObject _Author   implements   _Author   { \n   @ Serialize () \n   String   get   name   =   $ firstName   $ lastName ; \n\n   @ Serialize () \n   set   name ( String   fullName )   { \n     firstName   =   fullName . split (   ). first ; \n     lastName   =   fullName . split (   ). last ; \n   }  }", 
            "title": "Transient Properties"
        }, 
        {
            "location": "/db/modeling_data/#project-structure", 
            "text": "The combination of an instance type and its table definition is called an  entity . Each entity should be declared in the same file, and the table definition should be prefixed with an  _  to prevent it from being used elsewhere in the project. It is preferable to declare one entity per file, and store all entities in the  lib/model/  directory of your project.  The files your model definitions are declared in must be visible to Aqueduct tooling. In normal circumstances, this happens automatically because of the following:   Aqueduct tooling can find any file that is imported (directly or transitively) from your library file.  Your library file, by default, can see the file your  ApplicationChannel  is declared in.  Your application channel file must import any controller that it links.  Your controllers must import any model file they use.   When you use the  aqueduct  CLI to generate database migration scripts, it will report all of the  ManagedObject s in your application that it was able to find. If a particular type is not listed, it may reveal that you aren't using that type. If you need to ensure that the tooling can see a particular model file that it is not locating, you may import it in your  channel.dart  file.", 
            "title": "Project Structure"
        }, 
        {
            "location": "/db/modeling_data/#modeling-relationships", 
            "text": "So far, we've shown that table definitions can declare scalar properties like integers and strings, and that those properties are backed by a column in a database table. These types of properties are called  attributes . Table definitions may also contain  relationship  properties that are references to another entity in your application.  For example, an  Author  can have a property that holds all of the  Article s they have written. There are two types of relationships:  has-many  and  has-one . A has-one relationship restricts a relationship to a single object (e.g., an author may have one article), whereas a has-many relationship allows for any number of related objects (e.g., an author has multiple articles).  Relationship properties are also declared in a table definition. The type of the property must either be a  ManagedSet T  or a  T , where  T  is another instance type. If the type is  ManagedSet T , the relationship is a has-many relationship, otherwise, it is a has-one relationship. The following shows an  articles  relationship that allows an author to have many  Article s:  class   _Author   { \n   @ primaryKey \n   int   id ; \n\n   String   name ; \n\n   // a has-many relationship to Article \n   ManagedSet Article   articles ; \n\n   // If we were declaring a has-one relationship: \n   // Article article;  }   A  ManagedSet  is a special type of  List  used in the Aqueduct ORM. It can do everything a list can do, but adds some additional behavior for the ORM.  All relationships must have an inverse. For example, if an author has articles, an article must have an author. This is true regardless of whether or not the relationship is has-many or has-one. An inverse is declared in the related table definition with a  Relate  annotation:  class   _Article   { \n   @ primaryKey \n   int   id ; \n\n   @ Relate ( # articles ) \n   Author   author ; \n\n   ...  }   A relationship property with this annotation is neither has-one or has-many; it  belongs to  the related entity. The argument to  Relate  is the symbolic name of the property on the 'has' side of the relationship. In our examples, an author has many articles, and an article belongs to an author.   Symbols  A symbol is a name identifier in Dart; a symbol can refer to a class, method, or property. Symbols are objects can be instantiated like all objects, but the  #  identifier is shorthand for creating a symbol.   Only one side of a relationship may have the  Relate  annotation on its relationship property. The property with this annotation is a  foreign key column  on the table definition it is defined in. In this example, the  _Article  table has a foreign key reference to the  id  of the  _Author  table.  Choosing which side of the relationship has the  Relate  annotation depends on how you wish to model your data. In has-many relationships, this is easy - a  ManagedSet T  may  not  have the  Relate  annotation. In a has-one relationship, you must determine which side of the relationship should have the foreign key reference.  When making this decision, it is important to understand how objects are fetched with  Query s. In a default query, the objects that are returned will contain 'null' for every 'has' relationship, and only contain the foreign key of any 'belongs to' relationships. To fetch a related object in its entirety, you must use  Query.join .   Foreign Keys  The foreign key column always references the primary key of the related table, and its name is derived by combining the name of the relationship property and the primary key of the related table. For example, the above definitions would add a column named  author_id  to the  _Article  table.   The  Relate  annotation has optional arguments to further define the relationship.  A relationship may be be required or optional. For example, if  Article.author  were required, than an  Article  must always have an  Author . By default, relationships are optional.  A relationship has a delete rule. When an object is deleted, any objects that belong to its relationships are subject to this rule. The following table shows the rules and their behavior:     Rule  Behavior  Example      nullify (default)  inverse is set to null  When deleting an author, its articles' author becomes null    cascade  related objects are also deleted  When deleting an author, its articles are deleted    restrict  delete fails  When attempting to delete an author with articles, the delete operation fails    default  inverse set to a default value  When deleting an author, its articles author is set to the default value of the column", 
            "title": "Modeling Relationships"
        }, 
        {
            "location": "/db/modeling_data/#additional-data-modeling", 
            "text": "This section covers additional features when defining your data model.", 
            "title": "Additional Data Modeling"
        }, 
        {
            "location": "/db/modeling_data/#enum-types", 
            "text": "When a table definition property is an  enum  type, the enumeration is stored as a string in the database. Consider the following definition where a user can be an admin or a normal user:  enum   UserType   { \n   admin ,   user  }  class   User   extends   ManagedObject _User   implements   _User   {}  class   _User   { \n   @ primaryKey \n   int   id ; \n\n   String   name ; \n\n   UserType   type ;  }   You may assign valid enumeration cases to the  User.type  property:  var   query   =   Query User ( context ) \n   .. values . name   =   Bob \n   .. values . type   =   UserType . admin ;  var   bob   =   await   query . insert ();  query   =   Query User ( context ) \n   .. where (( u )   =   u . type ). equalTo ( UserType . admin );  var   allAdmins   =   await   query . fetch ();   In the database, the  type  column is stored as a string. Its value is either \"admin\" or \"user\" - which is derived from the two enumeration case names. A enumerated type property has an implicit  Validate.oneOf  validator that asserts the value is one of the valid enumeration cases.", 
            "title": "Enum Types"
        }, 
        {
            "location": "/db/modeling_data/#private-variables", 
            "text": "A property of a table definition that is Dart private (prefixed with an  _ ) will not be included when writing a  ManagedObject T  to an HTTP response. It also may not be read from an HTTP request body. This behavior differs slightly from the  omitByDefault  flag of  Column . When omitting by default, the value is simply not fetched from the database. When a property is private, it is fetched, but it is just not accessible from outside the object. This can be useful when combined with transient accessors. For example, the following ensures that the  title  property is uppercased before storage:  class   User   extends   ManagedObject _User   implements   _User   { \n   @ Serialize () \n   set   title ( String   title )   { \n     _title   =   title . toUpperCase (); \n   } \n\n   @ Serialize () \n   String   get   title   =   _title ;  }  class   _User   { \n   String   _title ; \n\n   ...  }", 
            "title": "Private Variables"
        }, 
        {
            "location": "/db/serialization/", 
            "text": "Storage, Serialization and Deserialization\n\n\nIn the previous chapter, you have seen that \nManagedObject\nT\ns subclasses are responsible for representing database rows and can be encoded to or decoded from formats like JSON or XML. This chapter explains the behavior of those transformations.\n\n\nManagedObject\nT\n implements \nSerializable\n so that they can read from a \nMap\n or converted to a \nMap\n. A \nManagedObject\nT\n can be passed as the body object of a \nResponse\n and bound to \nBind.body\n variables in \nResourceController\n:\n\n\nclass\n \nUserController\n \nextends\n \nResourceController\n \n{\n\n  \n@\nOperation\n.\npost\n()\n\n  \nFuture\nResponse\n \ncreateUser\n(\n@\nBind\n.\nbody\n()\n \nUser\n \nuser\n)\n \nasync\n \n{\n\n    \nvar\n \nquery\n \n=\n \nQuery\nUser\n(\ncontext\n)\n\n      \n..\nvalues\n \n=\n \nuser\n;\n\n\n    \nreturn\n \nResponse\n.\nok\n(\nawait\n \nquery\n.\ninsert\n());\n\n  \n}\n\n\n}\n\n\n\n\n\n\nNote that \nManagedObject\nT\ns don't have anything to do with JSON, XML or some other format here. Other parts of Aqueduct manage moving data back and forth between JSON and \nMap\ns - \nManagedObject\nT\n doesn't care about the transmission format as long as its a \nMap\n or \nList\nMap\n.\n\n\nNull Behavior\n\n\nIt's important to understand how \nnull\n works when reading from or writing to a \nMap\n with a \nManagedObject\nT\n. Consider the following managed object:\n\n\nclass\n \nUser\n \nextends\n \nManagedObject\n_User\n \nimplements\n \n_User\n \n{}\n\n\nclass\n \n_User\n \n{\n\n  \n@\nprimaryKey\n\n  \nint\n \nid\n;\n\n\n  \nString\n \nname\n;\n\n\n}\n\n\n\n\n\n\nUser\n has two properties, \nid\n and \nname\n. If we read a \nUser\n from a \nMap\n that does not contain an \nid\n key, its \nid\n will be null. If we convert \nUser\n to a \nMap\n, the key \nid\n will not be present:\n\n\nvar\n \nuserMap\n \n=\n \n{\n\n  \nname\n \n:\n \nBob\n\n\n};\n\n\n\nvar\n \nuser\n \n=\n \nUser\n()..\nreadFromMap\n(\nuserMap\n);\n\n\n\nuser\n.\nid\n \n==\n \nnull\n;\n \n// yup\n\n\nuser\n.\nname\n \n==\n \nBob\n;\n \n// yup\n\n\n\nvar\n \noutUserMap\n \n=\n \nuser\n.\nasMap\n();\n\n\noutUserMap\n \n==\n \n{\n\n  \nname\n \n:\n \nBob\n\n\n};\n\n\n\n\n\n\nHowever, if we read \nUser\n from a \nMap\n where the \nid\n key is the \nvalue\n null, when we transform it back to a \nMap\n the \nid\n is present and its value is null:\n\n\nvar\n \nuserMap\n \n=\n \n{\n\n  \nid\n \n:\n \nnull\n\n  \nname\n \n:\n \nBob\n\n\n};\n\n\n\nvar\n \nuser\n \n=\n \nUser\n()..\nreadFromMap\n(\nuserMap\n);\n\n\n\nuser\n.\nid\n \n==\n \nnull\n;\n \n// yup\n\n\nuser\n.\nname\n \n==\n \nBob\n;\n \n// yup\n\n\n\nvar\n \noutUserMap\n \n=\n \nuser\n.\nasMap\n();\n\n\noutUserMap\n \n==\n \n{\n\n  \nid\n \n:\n \nnull\n\n  \nname\n \n:\n \nBob\n\n\n};\n\n\n\n\n\n\nA \nManagedObject\nT\n like \nUser\n makes the distinction between a value that is \nnull\n and a value that it \ndoesn't have enough information for\n. A property of a \nManagedObject\nT\n can get set in three ways: it is read from a map, its setter is invoked or it is read from the database. In all three of these situations, not every property is available. This is no more obvious than when  creating a brand new instance:\n\n\nvar\n \nuser\n \n=\n \nUser\n();\n\n\nuser\n.\nid\n \n==\n \nnull\n;\n \n// yup\n\n\nuser\n.\nname\n \n==\n \nnull\n;\n \n// yup\n\n\n\nuser\n.\nasMap\n()\n \n==\n \n{};\n \n// yup\n\n\n\n\n\n\nA \nManagedObject\nT\n will not include keys in its \nasMap()\n if it doesn't have a value for them. The value may exist somewhere else - like in the database - but if it doesn't have it, it won't include it. This distinction is useful information for clients of Aqueduct applications.\n\n\nSo what about values that are actually \nnull\n? A property with the value \nnull\n will be included in \nasMap()\n if its been read from the database, read using \nreadFromMap()\n or explicitly assigned with a setter. The following three user objects will all have \n{\"name\": null}\n:\n\n\nvar\n \nuser1\n \n=\n \nUser\n()\n\n  \n..\nid\n \n=\n \n1\n\n  \n..\nname\n \n=\n \nnull\n;\n\n\n\nvar\n \nuser2\n \n=\n \nUser\n()..\nreadFromMap\n({\n\n  \nid\n:\n \n2\n\n  \nname\n:\n \nnull\n\n\n});\n\n\n\nvar\n \nquery\n \n=\n \nQuery\nUser\n(\ncontext\n)\n\n  \n..\nwhere\n((\nu\n)\n \n=\n \nu\n.\nid\n).\nequalTo\n(\n3\n)\n\n  \n..\nwhere\n((\nu\n)\n \n=\n \nu\n.\nname\n).\nisNull\n();\n\n\nvar\n \nuser3\n \n=\n \nawait\n \nquery\n.\nfetchOne\n();\n\n\n\n\n\n\nNote that an unset value that is returned from a getter will be \nnull\n. If using an object's values to perform some calculation, it's your job to know if the value has been fetched or not. (While \nManagedObject\nT\n.hasValueForProperty()\n checks this at runtime, that isn't a good practice.)\n\n\nOne last thing to note: if you wish to remove a value from a \nManagedObject\nT\ns storage (and likewise, its \nasMap()\n), you must use \nManagedObject\nT\n.removePropertyFromBackingMap()\n.\n\n\nIt is helpful to think of a \nManagedObject\nT\n as a proxy to a database row that may or may not exist yet, and may have less data than actually exists in the database row.\n\n\nTransient Properties and Serialization/Deserialization\n\n\nBy default, transient properties and getters - those declared in the subclass of \nManagedObject\nT\n - are \nnot\n included in the \nasMap()\n. (Setters are obviously not included, as you can't get a value from them.) To include a transient property or getter in \nasMap()\n, you may mark it with \n@Serialize()\n metadata. Properties marked with this metadata will be included in \nasMap()\n if and only if they are not null. A good reason to use this feature is when you want to provide a value to the consumer of the API that is derived from persistent properties:\n\n\nclass\n \nUser\n \nextends\n \nManagedObject\n_User\n \nimplements\n \n_User\n \n{\n\n  \n@\nSerialize\n()\n\n  \nString\n \nget\n \nfullName\n \n=\n \n$\nfirstName\n \n$\nlastName\n;\n\n\n}\n\n\n\nclass\n \n_User\n \n{\n\n  \nString\n \nfirstName\n;\n\n  \nString\n \nlastName\n;\n\n\n  \n...\n\n\n}\n\n\n\nvar\n \nuser\n \n=\n \nUser\n()\n\n  \n..\nfirstName\n \n=\n \nBob\n\n  \n..\nlastName\n \n=\n \nBoberson\n;\n\n\n\nvar\n \nmap\n \n=\n \nuser\n.\nasMap\n();\n\n\nmap\n \n==\n \n{\n\n  \nfirstName\n \n:\n \nBob\n,\n\n  \nlastName\n \n:\n \nBoberson\n,\n\n  \nfullName\n \n:\n \nBob Boberson\n\n\n};\n\n\n\n\n\n\nTransient properties with this annotation may also be used as inputs when reading with \nreadFromMap()\n. For example, consider how to handle user passwords. A password is not stored in plain-text in a database, but they are sent in requests. Thus, a password could read from a request body, but it needs to be salted, hashed and stored in two columns in the database. An instance type could then define a password property, which automatically set the salt and hash of the password in the table definition:\n\n\nclass\n \nUser\n \nextends\n \nManagedObject\n_User\n \nimplements\n \n_User\n \n{\n\n  \n@\nSerialize\n()\n\n  \nvoid\n \nset\n \npassword\n(\nString\n \npw\n)\n \n{\n\n    \nsalt\n \n=\n \ngenerateSalt\n();\n\n    \nhashedPassword\n \n=\n \nhash\n(\npw\n,\n \nsalt\n);\n\n  \n}\n\n\n}\n\n\nclass\n \n_User\n \n{\n\n  \nString\n \nsalt\n;\n\n  \nString\n \nhashedPassword\n;\n\n  \n...\n\n\n}\n\n\n\nvar\n \nmap\n \n=\n \n{\n\n  \npassword\n \n:\n \nmypassword\n\n\n};\n\n\nvar\n \nuser\n \n=\n \nUser\n()..\nreadFromMap\n(\nmap\n);\n\n\nvar\n \nsalt\n \n=\n \nuser\n.\nsalt\n;\n \n// \nsomerandomstring\n\n\nvar\n \nhashedPassword\n \n=\n \nuser\n.\nhashedPassword\n;\n \n// \nsomehashedstring\n\n\n\nvar\n \npassword\n \n=\n \nuser\n.\npassword\n;\n \n// Analyzer error - user.password doesn\nt exist!\n\n\n\n\n\n\nA transient property can also be used only when reading or only when writing.\n\n\nclass\n \nUser\n \nextends\n \nManagedObject\n_User\n \nimplements\n \n_User\n \n{\n\n  \n@\nSerialize\n(\ninput:\n \ntrue\n,\n \noutput:\n \nfalse\n)\n\n  \nString\n \nreadable\n;\n \n// Can be readFromMap, but not emitted in asMap\n\n\n  \n@\nSerialize\n(\ninput:\n \nfalse\n,\n \noutput:\n \ntrue\n)\n\n  \nString\n \nwritable\n;\n \n// Is emitted in asMap, but cannot be readFromMap.\n\n\n}\n\n\n\n\n\n\nAlso, a separate getter and setter may exist for the same name to allow both input and output:\n\n\nclass\n \nUser\n \nextends\n \nManagedObject\n_User\n \nimplements\n \n_User\n \n{\n\n  \n@\nSerialize\n()\n\n  \nvoid\n \nset\n \ntransientValue\n(\nString\n \ns\n)\n \n{\n\n    \n...\n\n  \n}\n\n\n  \n@\nSerialize\n()\n\n  \nString\n \nget\n \ntransientValue\n \n=\n \n...;\n\n\n}\n\n\n\n\n\n\nOn a related note, persistent properties are always included in \nasMap()\n by default, but can be omitted by adding \nColumn\n metadata with the \nomitByDefault\n option:\n\n\nclass\n \n_User\n \n{\n\n  \n@\nColumn\n(\nomitByDefault:\n \ntrue\n)\n\n  \nString\n \nsalt\n;\n\n\n  \n@\nColumn\n(\nomitByDefault:\n \ntrue\n)\n\n  \nString\n \nhashedPassword\n;\n\n  \n...\n\n\n}\n\n\n\n\n\n\nSerialization and Deserialization of Relationship Properties\n\n\nRelationship properties - references to other \nManagedObject\nT\n subclasses - can also be included in \nasMap()\n and read from \nreadFromMap()\n. Relationship properties are populated when using \nQuery.join\n - aka, a SQL JOIN.\n\n\nIf a relationship property has been set or read from the database, its \nasMap()\n will contain the nested \nMap\n produced by the related objects \nasMap()\n. For example, recall the \nUser\n with a \njob\n:\n\n\nvar\n \njob\n \n=\n \nJob\n()\n\n  \n..\ntitle\n \n=\n \nProgrammer\n;\n\n\nvar\n \nuser\n \n=\n \nUser\n()\n\n  \n..\nname\n \n=\n \nBob\n\n  \n..\njob\n \n=\n \njob\n;\n\n\n\nvar\n \nuserMap\n \n=\n \nuser\n.\nasMap\n();\n\n\nuserMap\n \n==\n \n{\n\n  \nid\n:\n \n1\n,\n\n  \nname\n:\n \nBob\n,\n\n  \njob\n:\n \n{\n\n    \nid\n:\n \n1\n\n    \ntitle\n:\n \nProgrammer\n\n  \n}\n\n\n};\n \n// yup\n\n\n\n\n\n\nNotice that the names of the keys - including relationship properties and properties of the related object - all match the names of their declared properties.\n\n\nIt's important to note that \"belongs to\" relationships - those with \nRelate\n metadata - are always returned in \nasMap()\n when fetching an object from the database. However, the full object is not returned - only its primary key. Therefore, you will get the following result:\n\n\nvar\n \njobQuery\n \n=\n \nQuery\nJob\n(\ncontext\n);\n\n\nvar\n \njob\n \n=\n \nawait\n \njobQuery\n.\nfetchOne\n();\n\n\n\njob\n.\nasMap\n()\n \n==\n \n{\n\n  \nid\n:\n \n1\n,\n\n  \ntitle\n:\n \nProgrammer\n,\n\n  \nuser\n:\n \n{\n\n    \nid\n:\n \n1\n\n  \n}\n\n\n};\n \n// yup\n\n\n\n\n\n\nThis behavior might be different than some ORMs, which may collapse the \nuser\n into a scalar \nuser_id\n:\n\n\njob\n.\nasMap\n()\n \n==\n \n{\n\n  \nid\n:\n \n1\n,\n\n  \ntitle\n:\n \nProgrammer\n,\n\n  \nuser_id\n:\n \n1\n\n\n};\n \n// nope\n\n\n\n\n\n\nAqueduct treats relationships consistently and chooses not to expose any of the underlying database details to the API consumer. An iOS app, for example, shouldn't care - a relationship could be maintained by foreign key references or by witchcraft. The interesting piece to the API consumer is that job's have a user, and user's have a job.\n\n\n\"Has-many\" relationships, which are represented as \nManagedSet\nT\ns, are written as \nList\nMap\ns in \nasMap()\n.\n\n\nvar\n \nuser\n \n=\n \nUser\n()\n\n  \n..\nid\n \n=\n \n1\n;\n\n  \n..\nposts\n \n=\n \nManagedSet\n.\nfrom\n([\n\n      \nPost\n()..\nid\n \n=\n \n2\n,\n\n      \nPost\n()..\nid\n \n=\n \n3\n\n  \n]);\n\n\n\nvar\n \nuserMap\n \n=\n \nuser\n.\nasMap\n();\n\n\nuserMap\n \n==\n \n{\n\n  \nid\n \n:\n \n1\n,\n\n  \nposts\n \n:\n \n[\n\n    \n{\n\n      \nid\n \n:\n \n2\n\n    \n},\n\n    \n{\n\n      \nid\n \n:\n \n3\n\n    \n}\n\n  \n]\n\n\n};\n\n\n\n\n\n\nIt is important to note the potential for cyclic object graphs. Since all relationship properties are two-sided, the two properties in that relationship are references to one another. That is, you could do something like this:\n\n\nidentical\n(\nuser\n.\nprofile\n.\nuser\n,\n \nuser\n);\n\n\nidentical\n(\nuser\n.\nposts\n.\nfirst\n.\nuser\n,\n \nuser\n);\n\n\n\n\n\n\nWhen fetching objects from a database, this won't happen - Aqueduct will create multiple instances of the same row when necessary to avoid this. Therefore, the previous code snippet would not be true, but the following two statements that check the values inside those objects would be:\n\n\nuser.profile.user.id == user.id;\n\nuser.posts.first.user.id == user.id\n\n\n\n\n\nWhile managed objects from a database will not have cyclic references, managed objects you instantiate yourself can if you mistakenly do so. When you invoke \nasMap()\n on a cyclic graph, you'll get a stack overflow error. It's best to avoid creating cyclic graphs altogether. For example:\n\n\n// do:\n\n\nvar\n \nuser\n \n=\n \nUser\n();\n\n\nposts\n.\nforEach\n((\np\n)\n \n{\n\n  \np\n.\nuser\n \n=\n \nUser\n()..\nid\n \n=\n \nuser\n.\nid\n;\n\n\n});\n\n\n\n// do not:\n\n\nvar\n \nuser\n \n=\n \nUser\n();\n\n\nposts\n.\nforEach\n((\np\n)\n \n{\n\n  \np\n.\nuser\n \n=\n \nuser\n;\n\n\n});\n\n\n\n\n\n\nWhen reading the values of a \nManagedObject\nT\n with \nreadFromMap()\n, relationship properties must also be represented as nested \nMap\ns or \nList\nMap\n. Thus:\n\n\nvar\n \nuserMap\n \n=\n \n{\n\n  \nid\n:\n \n1\n,\n\n  \nname\n:\n \nBob\n,\n\n  \nposts\n:\n \n[\n\n    \n{\nid\n:\n \n1\n,\n \ntext\n:\n \nhello\n}\n\n  \n]\n\n\n};\n\n\n\nvar\n \nuser\n \n=\n \nUser\n()..\nreadFromMap\n(\nuserMap\n);\n\n\nuser\n.\nposts\n \n==\n \nManagedSet\nPost\n[\n\n  \nPost\n()\n\n    \n..\nid\n \n=\n \n1\n\n    \n..\ntext\n \n=\n \nhello\n\n\n];\n \n// yup, other Post doesn\nt implement == to check property equality", 
            "title": "Storage, Serialization and Deserialization"
        }, 
        {
            "location": "/db/serialization/#storage-serialization-and-deserialization", 
            "text": "In the previous chapter, you have seen that  ManagedObject T s subclasses are responsible for representing database rows and can be encoded to or decoded from formats like JSON or XML. This chapter explains the behavior of those transformations.  ManagedObject T  implements  Serializable  so that they can read from a  Map  or converted to a  Map . A  ManagedObject T  can be passed as the body object of a  Response  and bound to  Bind.body  variables in  ResourceController :  class   UserController   extends   ResourceController   { \n   @ Operation . post () \n   Future Response   createUser ( @ Bind . body ()   User   user )   async   { \n     var   query   =   Query User ( context ) \n       .. values   =   user ; \n\n     return   Response . ok ( await   query . insert ()); \n   }  }   Note that  ManagedObject T s don't have anything to do with JSON, XML or some other format here. Other parts of Aqueduct manage moving data back and forth between JSON and  Map s -  ManagedObject T  doesn't care about the transmission format as long as its a  Map  or  List Map .", 
            "title": "Storage, Serialization and Deserialization"
        }, 
        {
            "location": "/db/serialization/#null-behavior", 
            "text": "It's important to understand how  null  works when reading from or writing to a  Map  with a  ManagedObject T . Consider the following managed object:  class   User   extends   ManagedObject _User   implements   _User   {}  class   _User   { \n   @ primaryKey \n   int   id ; \n\n   String   name ;  }   User  has two properties,  id  and  name . If we read a  User  from a  Map  that does not contain an  id  key, its  id  will be null. If we convert  User  to a  Map , the key  id  will not be present:  var   userMap   =   { \n   name   :   Bob  };  var   user   =   User ().. readFromMap ( userMap );  user . id   ==   null ;   // yup  user . name   ==   Bob ;   // yup  var   outUserMap   =   user . asMap ();  outUserMap   ==   { \n   name   :   Bob  };   However, if we read  User  from a  Map  where the  id  key is the  value  null, when we transform it back to a  Map  the  id  is present and its value is null:  var   userMap   =   { \n   id   :   null \n   name   :   Bob  };  var   user   =   User ().. readFromMap ( userMap );  user . id   ==   null ;   // yup  user . name   ==   Bob ;   // yup  var   outUserMap   =   user . asMap ();  outUserMap   ==   { \n   id   :   null \n   name   :   Bob  };   A  ManagedObject T  like  User  makes the distinction between a value that is  null  and a value that it  doesn't have enough information for . A property of a  ManagedObject T  can get set in three ways: it is read from a map, its setter is invoked or it is read from the database. In all three of these situations, not every property is available. This is no more obvious than when  creating a brand new instance:  var   user   =   User ();  user . id   ==   null ;   // yup  user . name   ==   null ;   // yup  user . asMap ()   ==   {};   // yup   A  ManagedObject T  will not include keys in its  asMap()  if it doesn't have a value for them. The value may exist somewhere else - like in the database - but if it doesn't have it, it won't include it. This distinction is useful information for clients of Aqueduct applications.  So what about values that are actually  null ? A property with the value  null  will be included in  asMap()  if its been read from the database, read using  readFromMap()  or explicitly assigned with a setter. The following three user objects will all have  {\"name\": null} :  var   user1   =   User () \n   .. id   =   1 \n   .. name   =   null ;  var   user2   =   User ().. readFromMap ({ \n   id :   2 \n   name :   null  });  var   query   =   Query User ( context ) \n   .. where (( u )   =   u . id ). equalTo ( 3 ) \n   .. where (( u )   =   u . name ). isNull ();  var   user3   =   await   query . fetchOne ();   Note that an unset value that is returned from a getter will be  null . If using an object's values to perform some calculation, it's your job to know if the value has been fetched or not. (While  ManagedObject T .hasValueForProperty()  checks this at runtime, that isn't a good practice.)  One last thing to note: if you wish to remove a value from a  ManagedObject T s storage (and likewise, its  asMap() ), you must use  ManagedObject T .removePropertyFromBackingMap() .  It is helpful to think of a  ManagedObject T  as a proxy to a database row that may or may not exist yet, and may have less data than actually exists in the database row.", 
            "title": "Null Behavior"
        }, 
        {
            "location": "/db/serialization/#transient-properties-and-serializationdeserialization", 
            "text": "By default, transient properties and getters - those declared in the subclass of  ManagedObject T  - are  not  included in the  asMap() . (Setters are obviously not included, as you can't get a value from them.) To include a transient property or getter in  asMap() , you may mark it with  @Serialize()  metadata. Properties marked with this metadata will be included in  asMap()  if and only if they are not null. A good reason to use this feature is when you want to provide a value to the consumer of the API that is derived from persistent properties:  class   User   extends   ManagedObject _User   implements   _User   { \n   @ Serialize () \n   String   get   fullName   =   $ firstName   $ lastName ;  }  class   _User   { \n   String   firstName ; \n   String   lastName ; \n\n   ...  }  var   user   =   User () \n   .. firstName   =   Bob \n   .. lastName   =   Boberson ;  var   map   =   user . asMap ();  map   ==   { \n   firstName   :   Bob , \n   lastName   :   Boberson , \n   fullName   :   Bob Boberson  };   Transient properties with this annotation may also be used as inputs when reading with  readFromMap() . For example, consider how to handle user passwords. A password is not stored in plain-text in a database, but they are sent in requests. Thus, a password could read from a request body, but it needs to be salted, hashed and stored in two columns in the database. An instance type could then define a password property, which automatically set the salt and hash of the password in the table definition:  class   User   extends   ManagedObject _User   implements   _User   { \n   @ Serialize () \n   void   set   password ( String   pw )   { \n     salt   =   generateSalt (); \n     hashedPassword   =   hash ( pw ,   salt ); \n   }  }  class   _User   { \n   String   salt ; \n   String   hashedPassword ; \n   ...  }  var   map   =   { \n   password   :   mypassword  };  var   user   =   User ().. readFromMap ( map );  var   salt   =   user . salt ;   //  somerandomstring  var   hashedPassword   =   user . hashedPassword ;   //  somehashedstring  var   password   =   user . password ;   // Analyzer error - user.password doesn t exist!   A transient property can also be used only when reading or only when writing.  class   User   extends   ManagedObject _User   implements   _User   { \n   @ Serialize ( input:   true ,   output:   false ) \n   String   readable ;   // Can be readFromMap, but not emitted in asMap \n\n   @ Serialize ( input:   false ,   output:   true ) \n   String   writable ;   // Is emitted in asMap, but cannot be readFromMap.  }   Also, a separate getter and setter may exist for the same name to allow both input and output:  class   User   extends   ManagedObject _User   implements   _User   { \n   @ Serialize () \n   void   set   transientValue ( String   s )   { \n     ... \n   } \n\n   @ Serialize () \n   String   get   transientValue   =   ...;  }   On a related note, persistent properties are always included in  asMap()  by default, but can be omitted by adding  Column  metadata with the  omitByDefault  option:  class   _User   { \n   @ Column ( omitByDefault:   true ) \n   String   salt ; \n\n   @ Column ( omitByDefault:   true ) \n   String   hashedPassword ; \n   ...  }", 
            "title": "Transient Properties and Serialization/Deserialization"
        }, 
        {
            "location": "/db/serialization/#serialization-and-deserialization-of-relationship-properties", 
            "text": "Relationship properties - references to other  ManagedObject T  subclasses - can also be included in  asMap()  and read from  readFromMap() . Relationship properties are populated when using  Query.join  - aka, a SQL JOIN.  If a relationship property has been set or read from the database, its  asMap()  will contain the nested  Map  produced by the related objects  asMap() . For example, recall the  User  with a  job :  var   job   =   Job () \n   .. title   =   Programmer ;  var   user   =   User () \n   .. name   =   Bob \n   .. job   =   job ;  var   userMap   =   user . asMap ();  userMap   ==   { \n   id :   1 , \n   name :   Bob , \n   job :   { \n     id :   1 \n     title :   Programmer \n   }  };   // yup   Notice that the names of the keys - including relationship properties and properties of the related object - all match the names of their declared properties.  It's important to note that \"belongs to\" relationships - those with  Relate  metadata - are always returned in  asMap()  when fetching an object from the database. However, the full object is not returned - only its primary key. Therefore, you will get the following result:  var   jobQuery   =   Query Job ( context );  var   job   =   await   jobQuery . fetchOne ();  job . asMap ()   ==   { \n   id :   1 , \n   title :   Programmer , \n   user :   { \n     id :   1 \n   }  };   // yup   This behavior might be different than some ORMs, which may collapse the  user  into a scalar  user_id :  job . asMap ()   ==   { \n   id :   1 , \n   title :   Programmer , \n   user_id :   1  };   // nope   Aqueduct treats relationships consistently and chooses not to expose any of the underlying database details to the API consumer. An iOS app, for example, shouldn't care - a relationship could be maintained by foreign key references or by witchcraft. The interesting piece to the API consumer is that job's have a user, and user's have a job.  \"Has-many\" relationships, which are represented as  ManagedSet T s, are written as  List Map s in  asMap() .  var   user   =   User () \n   .. id   =   1 ; \n   .. posts   =   ManagedSet . from ([ \n       Post ().. id   =   2 , \n       Post ().. id   =   3 \n   ]);  var   userMap   =   user . asMap ();  userMap   ==   { \n   id   :   1 , \n   posts   :   [ \n     { \n       id   :   2 \n     }, \n     { \n       id   :   3 \n     } \n   ]  };   It is important to note the potential for cyclic object graphs. Since all relationship properties are two-sided, the two properties in that relationship are references to one another. That is, you could do something like this:  identical ( user . profile . user ,   user );  identical ( user . posts . first . user ,   user );   When fetching objects from a database, this won't happen - Aqueduct will create multiple instances of the same row when necessary to avoid this. Therefore, the previous code snippet would not be true, but the following two statements that check the values inside those objects would be:  user.profile.user.id == user.id;\n\nuser.posts.first.user.id == user.id  While managed objects from a database will not have cyclic references, managed objects you instantiate yourself can if you mistakenly do so. When you invoke  asMap()  on a cyclic graph, you'll get a stack overflow error. It's best to avoid creating cyclic graphs altogether. For example:  // do:  var   user   =   User ();  posts . forEach (( p )   { \n   p . user   =   User ().. id   =   user . id ;  });  // do not:  var   user   =   User ();  posts . forEach (( p )   { \n   p . user   =   user ;  });   When reading the values of a  ManagedObject T  with  readFromMap() , relationship properties must also be represented as nested  Map s or  List Map . Thus:  var   userMap   =   { \n   id :   1 , \n   name :   Bob , \n   posts :   [ \n     { id :   1 ,   text :   hello } \n   ]  };  var   user   =   User ().. readFromMap ( userMap );  user . posts   ==   ManagedSet Post [ \n   Post () \n     .. id   =   1 \n     .. text   =   hello  ];   // yup, other Post doesn t implement == to check property equality", 
            "title": "Serialization and Deserialization of Relationship Properties"
        }, 
        {
            "location": "/db/executing_queries/", 
            "text": "Inserting, Updating, Deleting and Fetching Objects\n\n\nTo send commands to a database - whether to fetch, insert, delete or update objects - you will create, configure and execute instances of \nQuery\nT\n. The type of object the query is performed on is determined by the type argument. The argument must be a subclass of \nManagedObject\n.\n\n\nA query compiles and executes a SQL query on a given \nManagedContext\n. Here's an example of a \nQuery\nT\n that fetches all instances of \nUser\n:\n\n\nvar\n \nquery\n \n=\n \nQuery\nUser\n(\ncontext\n);\n\n\nvar\n \nallUsers\n \n=\n \nawait\n \nquery\n.\nfetch\n();\n\n\n\n\n\n\nA \nQuery\nT\n has four basic execution methods: \nfetch\n, \nupdate\n, \ninsert\n, \ndelete\n.\n\n\n\n\nfetch\n will retrieve data from a database (it is equivalent to the SQL operation \nSELECT\n).\n\n\nupdate\n will modify existing data in a database (it is equivalent to the SQL operation \nUPDATE\n).\n\n\ninsert\n will add new data to a database (it is equivalent to the SQL operation \nINSERT\n).\n\n\ndelete\n will remove data from a database (it is equivalent to the SQL operation \nDELETE\n).\n\n\n\n\nA \nQuery\nT\n has many configurable properties. These properties will impact which objects get fetched, the data that gets sent to the database, the order that data is returned in, and so on.\n\n\nInserting Data with a Query\n\n\nLet's assume this \nUser\n type exists:\n\n\nclass\n \nUser\n \nextends\n \nManagedObject\n_User\n \nimplements\n \n_User\n \n{}\n\n\nclass\n \n_User\n \n{\n\n  \n@\nprimaryKey\n\n  \nint\n \nid\n;\n\n\n  \n@\nColumn\n(\nindexed:\n \ntrue\n)\n\n  \nString\n \nemail\n;\n\n\n  \nString\n \nname\n;\n\n\n}\n\n\n\n\n\n\nTo insert a new row into the \n_User\n table, a \nQuery\nT\n is constructed and executed:\n\n\nvar\n \nquery\n \n=\n \nQuery\nUser\n(\ncontext\n)\n\n  \n..\nvalues\n.\nname\n \n=\n \nBob\n\n  \n..\nvalues\n.\nemail\n \n=\n \nbob@stablekernel.com\n;\n  \n\n\nvar\n \nuser\n \n=\n \nawait\n \nquery\n.\ninsert\n();\n  \n\nuser\n.\nasMap\n()\n \n==\n \n{\n\n  \nid\n:\n \n1\n,\n\n  \nname\n:\n \nBob\n,\n\n  \nemail\n:\n \nbob@stablekernel.com\n\n\n};\n\n\n\n\n\n\nEvery \nQuery\nT\n has a \nvalues\n property that is the type of managed object being inserted. Here, \nvalues\n is an instance of \nUser\n. When a \nQuery\nT\n is executed with \ninsert()\n, a new row is created in the database with every property that has been set in \nvalues\n. In this case, both \nname\n and \nemail\n have been set. The generated SQL looks like this:\n\n\nINSERT\n \nINTO\n \n_user\n \n(\nname\n,\n \nemail\n)\n \nVALUES\n \n(\nBob\n,\n \nbob@stablekernel.com\n)\n\n\n\n\n\n\nNote there is no value provided for the \nid\n property in this query. Recall that \nprimaryKey\n is a convenience for \nColumn\n with auto-incrementing behavior. Therefore, the database will assign a value for \nid\n during insertion. The object returned from \ninsert()\n will be an instance of \nUser\n that represents the inserted row and will include the auto-generated \nid\n.\n\n\nProperties that are not set in the \nvalues\n property will not be sent to the database.\n\n\nValues that are explicitly set to \nnull\n will be sent as \nNULL\n. For example, consider the following \nQuery\nT\n:\n\n\nvar\n \nquery\n \n=\n \nQuery\nUser\n(\ncontext\n)\n\n  \n..\nvalues\n.\nname\n \n=\n \nnull\n;\n\n\nawait\n \nquery\n.\ninsert\n();\n\n\n\n\n\n\nThe generated SQL for this query does not send \nemail\n - because it isn't included - and sends \nNULL\n for \nname\n:\n\n\nINSERT\n \nINTO\n \n_user\n \n(\nname\n)\n \nVALUES\n \n(\nNULL\n);\n\n\n\n\n\n\nIf a property is not nullable (its \nColumn\n has \nnullable: false\n) and its value is not set in a query prior to inserting it, the query will fail and throw an exception.\n\n\nYou may also set \nQuery.values\n with an instance of a managed object. This is valuable when reading an object from a HTTP request body:\n\n\nvar\n \nuser\n \n=\n \nUser\n()\n\n  \n..\nreadFromMap\n(\nrequest\n.\nbody\n.\nasMap\n());\n\n\n\nvar\n \nquery\n \n=\n \nQuery\nUser\n(\ncontext\n)\n\n  \n..\nvalues\n \n=\n \nuser\n;\n\n\n\n\n\n\nIf an insert query fails because of a unique constraint is violated, a \nQueryException\n will be thrown.  See a later section on how \nQueryException\ns are gracefully handled by \nController\ns. In short, it is unlikely that you have to handle \nQueryException\n directly - \nController\ns know how to turn them into the appropriate HTTP response.\n\n\n\n\nSetting Query.values\n\n\nBy default, \nQuery.values\n is an empty instance of the object being inserted. If you replace it with an object - that you got from a request body or instantiated yourself - the properties are \ncopied\n into \nQuery.values\n. Further modifications of the replacement object have no effect on \nQuery.values\n.\n\n\n\n\nThere is a convenience static method on \nQuery\n for inserting objects without having to create a \nQuery\n object.\n\n\nfinal\n \ninsertedObject\n \n=\n \nawait\n \nQuery\n.\ninsertObject\n(\ncontext\n,\n \nUser\n()..\nname\n \n=\n \nBob\n);\n\n\n\n\n\n\nUpdating Data with a Query\n\n\nUpdating rows with a \nQuery\nT\n is similar to inserting data: you set the \nQuery.values\n for properties you want to change. The type parameter for the \nQuery\nT\n indicates which database table will get updated when the query is executed.\n\n\nAn update query can - and likely should - be restricted to a single row or subset of rows. This is done by configuring the \nQuery.where\n property - which gets translated into the \nwhere clause\n of the SQL command. Here's an example:\n\n\n// A Query that will change any user\ns whose name is \nBob\n to \nFred\n\n\nvar\n \nquery\n \n=\n \nQuery\nUser\n(\ncontext\n)\n\n  \n..\nvalues\n.\nname\n \n=\n \nFred\n\n  \n..\nwhere\n((\nu\n)\n \n=\n \nu\n.\nname\n).\nequalTo\n(\nBob\n);\n\n\n\nList\nUser\n \nbobsThatAreNowFreds\n \n=\n \nawait\n \nquery\n.\nupdate\n();\n\n\n\n\n\n\nLike \nvalues\n, \nwhere\n is also the same managed object type the query is being executed on. In the above example, then, both \nvalues\n and \nwhere\n and instances of \nUser\n. This query executes the following SQL:\n\n\nUPDATE\n \n_user\n \nSET\n \nname\n=\nFred\n \nWHERE\n \nname\n=\nBob\n;\n\n\n\n\n\n\nThe \nwhere\n property is a very powerful and flexible, and so there is an entire section dedicated to it later in this guide. For now, we'll stick to some of the things specific to \nupdate()\n.\n\n\nLike \ninsert()\n, only the values set in the \nvalues\n property of a query get updated when executing \nupdate()\n. Values that are omitted are not included. Values that need to be set to \nnull\n must explicitly be set to \nnull\n in the query:\n\n\n// A Query that will remove names from anyone currently named Bob.\n\n\nvar\n \nquery\n \n=\n \nQuery\nUser\n(\ncontext\n)\n\n  \n..\nvalues\n.\nname\n \n=\n \nnull\n\n  \n..\nwhere\n((\nu\n)\n \n=\n \nu\n.\nname\n).\nequalTo\n(\nBob\n);\n\n\n\n\n\n\nAn update query returns every modified row as a result. If no rows are updated, the return value is an empty list.  \n\n\nThere is a variant to \nQuery\nT\n.update\n named \nupdateOne\n. The \nupdateOne\n method will build and execute a SQL query in the same way a normal \nupdate\n does, however, it will only return the single instance that was updated instead of a list. This is convenience method for the caller to get back a single instance instead of a list:\n\n\n// Update user with id = 1 to have the name \nFred\n\n\nvar\n \nquery\n \n=\n \nQuery\nUser\n(\ncontext\n)\n\n  \n..\nvalues\n.\nname\n \n=\n \nFred\n\n  \n..\nwhere\n((\nu\n)\n \n=\n \nu\n.\nid\n).\nequalTo\n(\n1\n);\n\n\n\nvar\n \nupdatedUser\n \n=\n \nawait\n \nquery\n.\nupdateOne\n();\n\n\n\n\n\n\nThe \nupdateOne\n method will return \nnull\n if no rows were updated. It is important to note that if \nupdateOne\n is used and more than one row is updated, \nupdateOne\n will throw an exception and the changes to the data \nare not reversible\n. Because this is likely a mistake, this is considered an error, hence the exception is thrown. It is up to the programmer to recognize whether or not a particular \nupdateOne\n query would impact multiple rows.\n\n\nUpdate queries have a safety feature that prevents you from accidentally updating every row. If you try to execute a \nQuery\nT\n to do an update without configuring \nwhere\n, an exception is thrown prior to carrying out the request. If you actually want to update every row of a table, you must set the \nQuery.canModifyAllInstances\n to \ntrue\n prior to execution. (This property defaults to \nfalse\n.)\n\n\nDeleting Data with a Query\n\n\nA \nQuery\nT\n will delete rows from a database when using \ndelete()\n. Like update queries, you should specify a row or rows using \nwhere\n properties of the \nQuery\nT\n. The result of a delete operation will be a \nFuture\nint\n with the number of rows deleted.\n\n\nvar\n \nquery\n \n=\n \nQuery\nUser\n(\ncontext\n)\n\n  \n..\nwhere\n((\nu\n)\n \n=\n \nu\n.\nid\n).\nequalTo\n(\n1\n);\n\n\n\nint\n \nusersDeleted\n \n=\n \nawait\n \nquery\n.\ndelete\n();\n\n\n\n\n\n\nAlso like update queries, delete queries have a safety feature that prevents you from accidentally deleting every row in a table with \ncanModifyAllInstances\n.\n\n\nAny properties set in the query's \nvalues\n are ignored when executing a delete.\n\n\nFetching Data with a Query\n\n\nOf the four basic operations of a \nQuery\nT\n, fetching data is the most configurable. A simple \nQuery\nT\n that would fetch every instance of some entity looks like this:\n\n\nvar\n \nquery\n \n=\n \nQuery\nUser\n(\ncontext\n);\n\n\n\nList\nUser\n \nallUsers\n \n=\n \nawait\n \nquery\n.\nfetch\n();\n\n\n\n\n\n\nA fetch \nQuery\nT\n uses its \nwhere\n property to filter the result set, just like delete and update queries. Any properties set in the query's \nvalues\n are ignored when executing a fetch, since there is no need for them. In addition to fetching a list of instances from a database, you may also fetch a single instance with \nfetchOne\n. If no instance is found, \nnull\n is returned.\n\n\nvar\n \nquery\n \n=\n \nQuery\nUser\n(\ncontext\n)\n\n  \n..\nwhere\n((\nu\n)\n \n=\n \nu\n.\nid\n).\nequalTo\n(\n1\n);\n\n\n\nUser\n \noneUser\n \n=\n \nawait\n \nquery\n.\nfetchOne\n();\n\n\n\n\n\n\nFetch queries can be limited to a number of instances with the \nfetchLimit\n property. You may also set the \noffset\n of a \nQuery\nT\n to skip the first \noffset\n number of rows. Between \nfetchLimit\n and \noffset\n, you can implement naive paging. However, this type of paging suffers from a number of problems and so there is another paging mechanism covered in later sections.\n\n\nSorting\n\n\nResults of a fetch can be sorted using the \nsortBy\n method of a \nQuery\nT\n. Here's an example:\n\n\nvar\n \nq\n \n=\n \nQuery\nUser\n(\ncontext\n)\n\n  \n..\nsortBy\n((\nu\n)\n \n=\n \nu\n.\ndateCreated\n,\n \nQuerySortOrder\n.\nascending\n);\n\n\n\n\n\n\nsortBy\n takes two arguments: a closure that returns which property to sort by and the order of the sort.\n\n\nA \nQuery\nT\n results can be sorted by multiple properties. When multiple \nsortBy\ns are invoked on a \nQuery\nT\n, later \nsortBy\ns are used to break ties in previous \nsortBy\ns. For example, the following query will sort by last name, then by first name:\n\n\nvar\n \nq\n \n=\n \nQuery\nUser\n(\ncontext\n)\n\n  \n..\nsortBy\n((\nu\n)\n \n=\n \nu\n.\nlastName\n,\n \nQuerySortOrder\n.\nascending\n)\n\n  \n..\nsortBy\n((\nu\n)\n \n=\n \nu\n.\nfirstName\n,\n \nQuerySortOrder\n.\nascending\n);\n\n\n\n\n\n\nThus, the following three names would be ordered like so: 'Sally Smith', 'John Wu', 'Sally Wu'.\n\n\nProperty Selectors\n\n\nIn the section on sorting, you saw the use of a \nproperty selector\n to select the property of the user to sort by. This syntax is used for many other query manipulations, like filtering and joining. A property selector is a closure that gives you an object of the type you are querying and must return a property of that object. The selector \n(u) =\n u.lastName\n in the previous section is a property selector that selects the last name of a user.\n\n\nThe Dart analyzer will infer that the argument of a property selector, and it is always the same type as the object being queried. This enables IDE auto-completion, static error checking, and other tools like project-wide renaming.\n\n\n\n\nLive Templates\n\n\nTo speed up query building, create a Live Template in IntelliJ that generates a property selector when typing 'ps'. The source of the template is \n(o) =\n o.$END$\n. A downloadable settings configuration for IntelliJ exists \nhere\n that includes this shortcut.\n\n\n\n\nSpecifying Result Properties\n\n\nWhen executing queries that return managed objects (i.e., \ninsert()\n, \nupdate()\n and \nfetch()\n), the default properties for each object are fetched. The default properties of a managed object are properties that correspond to a database column - attributes declared in the table definition. A managed object's default properties can be modified when declaring its table definition:\n\n\nclass\n \n_User\n \n{\n\n  \n@\nColumn\n(\nomitByDefault:\n \ntrue\n)\n\n  \nString\n \nhashedPassword\n;\n\n\n}\n\n\n\n\n\n\nAny property with \nomitByDefault\n set to true will not be fetched by default.\n\n\nA property that is \nomitByDefault\n can still be fetched. Likewise, a property that is in the defaults can still be omitted. Each \nQuery\nT\n has a \nreturningProperties\n method to adjust which properties do get returned from the query. Its usage looks like this:\n\n\nvar\n \nquery\n \n=\n \nQuery\nUser\n(\ncontext\n)\n\n  \n..\nreturningProperties\n((\nuser\n)\n \n=\n \n[\nuser\n.\nid\n,\n \nuser\n.\nname\n]);\n\n\n\n\n\n\nreturningProperties\n is a multiple property selector - instead of returning just one property, it returns a list of properties.\n\n\nYou may include 'belongs-to' relationships in \nreturningProperties\n, but you may not include 'has-many' or 'has-one' relationships. An exception will be thrown if you attempt to. To include properties from relationships like these, see \njoin in Advanced Queries\n.\n\n\nNote that if you omit the primary key of a managed object from \nreturningProperties\n, it will automatically be added. The primary key is necessary to transform the rows into instances of their \nManagedObject\nT\n subclass.\n\n\nExceptions and Errors\n\n\nWhen executing a query, it may fail for any number of reasons: the query is invalid, a database couldn't be reached, constraints were violated, etc. In many cases, this exception originates from the underlying database driver. When thrown in a controller, these exceptions will trigger a 500 Server Error response.\n\n\nExceptions that are thrown in response to user input (e.g., violating a database constraint, invalid data type) are re-interpreted into a \nQueryException\n or \nValidationException\n. Both of these exception types have an associated \nResponse\n object that is sent instead of the default 500 Server error.\n\n\nFor this reason, you don't need to catch database query exceptions in a controller; an appropriate response will be sent on your behalf.\n\n\nStatement Reuse\n\n\nAqueduct will parameterize and reuse queries when possible. This allows for significant speed and security improvements. Note that you do not have to do anything special to take advantage of this feature. However, currently at this time, you may not disable this feature.", 
            "title": "Executing Queries"
        }, 
        {
            "location": "/db/executing_queries/#inserting-updating-deleting-and-fetching-objects", 
            "text": "To send commands to a database - whether to fetch, insert, delete or update objects - you will create, configure and execute instances of  Query T . The type of object the query is performed on is determined by the type argument. The argument must be a subclass of  ManagedObject .  A query compiles and executes a SQL query on a given  ManagedContext . Here's an example of a  Query T  that fetches all instances of  User :  var   query   =   Query User ( context );  var   allUsers   =   await   query . fetch ();   A  Query T  has four basic execution methods:  fetch ,  update ,  insert ,  delete .   fetch  will retrieve data from a database (it is equivalent to the SQL operation  SELECT ).  update  will modify existing data in a database (it is equivalent to the SQL operation  UPDATE ).  insert  will add new data to a database (it is equivalent to the SQL operation  INSERT ).  delete  will remove data from a database (it is equivalent to the SQL operation  DELETE ).   A  Query T  has many configurable properties. These properties will impact which objects get fetched, the data that gets sent to the database, the order that data is returned in, and so on.", 
            "title": "Inserting, Updating, Deleting and Fetching Objects"
        }, 
        {
            "location": "/db/executing_queries/#inserting-data-with-a-query", 
            "text": "Let's assume this  User  type exists:  class   User   extends   ManagedObject _User   implements   _User   {}  class   _User   { \n   @ primaryKey \n   int   id ; \n\n   @ Column ( indexed:   true ) \n   String   email ; \n\n   String   name ;  }   To insert a new row into the  _User  table, a  Query T  is constructed and executed:  var   query   =   Query User ( context ) \n   .. values . name   =   Bob \n   .. values . email   =   bob@stablekernel.com ;    var   user   =   await   query . insert ();    user . asMap ()   ==   { \n   id :   1 , \n   name :   Bob , \n   email :   bob@stablekernel.com  };   Every  Query T  has a  values  property that is the type of managed object being inserted. Here,  values  is an instance of  User . When a  Query T  is executed with  insert() , a new row is created in the database with every property that has been set in  values . In this case, both  name  and  email  have been set. The generated SQL looks like this:  INSERT   INTO   _user   ( name ,   email )   VALUES   ( Bob ,   bob@stablekernel.com )   Note there is no value provided for the  id  property in this query. Recall that  primaryKey  is a convenience for  Column  with auto-incrementing behavior. Therefore, the database will assign a value for  id  during insertion. The object returned from  insert()  will be an instance of  User  that represents the inserted row and will include the auto-generated  id .  Properties that are not set in the  values  property will not be sent to the database.  Values that are explicitly set to  null  will be sent as  NULL . For example, consider the following  Query T :  var   query   =   Query User ( context ) \n   .. values . name   =   null ;  await   query . insert ();   The generated SQL for this query does not send  email  - because it isn't included - and sends  NULL  for  name :  INSERT   INTO   _user   ( name )   VALUES   ( NULL );   If a property is not nullable (its  Column  has  nullable: false ) and its value is not set in a query prior to inserting it, the query will fail and throw an exception.  You may also set  Query.values  with an instance of a managed object. This is valuable when reading an object from a HTTP request body:  var   user   =   User () \n   .. readFromMap ( request . body . asMap ());  var   query   =   Query User ( context ) \n   .. values   =   user ;   If an insert query fails because of a unique constraint is violated, a  QueryException  will be thrown.  See a later section on how  QueryException s are gracefully handled by  Controller s. In short, it is unlikely that you have to handle  QueryException  directly -  Controller s know how to turn them into the appropriate HTTP response.   Setting Query.values  By default,  Query.values  is an empty instance of the object being inserted. If you replace it with an object - that you got from a request body or instantiated yourself - the properties are  copied  into  Query.values . Further modifications of the replacement object have no effect on  Query.values .   There is a convenience static method on  Query  for inserting objects without having to create a  Query  object.  final   insertedObject   =   await   Query . insertObject ( context ,   User ().. name   =   Bob );", 
            "title": "Inserting Data with a Query"
        }, 
        {
            "location": "/db/executing_queries/#updating-data-with-a-query", 
            "text": "Updating rows with a  Query T  is similar to inserting data: you set the  Query.values  for properties you want to change. The type parameter for the  Query T  indicates which database table will get updated when the query is executed.  An update query can - and likely should - be restricted to a single row or subset of rows. This is done by configuring the  Query.where  property - which gets translated into the  where clause  of the SQL command. Here's an example:  // A Query that will change any user s whose name is  Bob  to  Fred  var   query   =   Query User ( context ) \n   .. values . name   =   Fred \n   .. where (( u )   =   u . name ). equalTo ( Bob );  List User   bobsThatAreNowFreds   =   await   query . update ();   Like  values ,  where  is also the same managed object type the query is being executed on. In the above example, then, both  values  and  where  and instances of  User . This query executes the following SQL:  UPDATE   _user   SET   name = Fred   WHERE   name = Bob ;   The  where  property is a very powerful and flexible, and so there is an entire section dedicated to it later in this guide. For now, we'll stick to some of the things specific to  update() .  Like  insert() , only the values set in the  values  property of a query get updated when executing  update() . Values that are omitted are not included. Values that need to be set to  null  must explicitly be set to  null  in the query:  // A Query that will remove names from anyone currently named Bob.  var   query   =   Query User ( context ) \n   .. values . name   =   null \n   .. where (( u )   =   u . name ). equalTo ( Bob );   An update query returns every modified row as a result. If no rows are updated, the return value is an empty list.    There is a variant to  Query T .update  named  updateOne . The  updateOne  method will build and execute a SQL query in the same way a normal  update  does, however, it will only return the single instance that was updated instead of a list. This is convenience method for the caller to get back a single instance instead of a list:  // Update user with id = 1 to have the name  Fred  var   query   =   Query User ( context ) \n   .. values . name   =   Fred \n   .. where (( u )   =   u . id ). equalTo ( 1 );  var   updatedUser   =   await   query . updateOne ();   The  updateOne  method will return  null  if no rows were updated. It is important to note that if  updateOne  is used and more than one row is updated,  updateOne  will throw an exception and the changes to the data  are not reversible . Because this is likely a mistake, this is considered an error, hence the exception is thrown. It is up to the programmer to recognize whether or not a particular  updateOne  query would impact multiple rows.  Update queries have a safety feature that prevents you from accidentally updating every row. If you try to execute a  Query T  to do an update without configuring  where , an exception is thrown prior to carrying out the request. If you actually want to update every row of a table, you must set the  Query.canModifyAllInstances  to  true  prior to execution. (This property defaults to  false .)", 
            "title": "Updating Data with a Query"
        }, 
        {
            "location": "/db/executing_queries/#deleting-data-with-a-query", 
            "text": "A  Query T  will delete rows from a database when using  delete() . Like update queries, you should specify a row or rows using  where  properties of the  Query T . The result of a delete operation will be a  Future int  with the number of rows deleted.  var   query   =   Query User ( context ) \n   .. where (( u )   =   u . id ). equalTo ( 1 );  int   usersDeleted   =   await   query . delete ();   Also like update queries, delete queries have a safety feature that prevents you from accidentally deleting every row in a table with  canModifyAllInstances .  Any properties set in the query's  values  are ignored when executing a delete.", 
            "title": "Deleting Data with a Query"
        }, 
        {
            "location": "/db/executing_queries/#fetching-data-with-a-query", 
            "text": "Of the four basic operations of a  Query T , fetching data is the most configurable. A simple  Query T  that would fetch every instance of some entity looks like this:  var   query   =   Query User ( context );  List User   allUsers   =   await   query . fetch ();   A fetch  Query T  uses its  where  property to filter the result set, just like delete and update queries. Any properties set in the query's  values  are ignored when executing a fetch, since there is no need for them. In addition to fetching a list of instances from a database, you may also fetch a single instance with  fetchOne . If no instance is found,  null  is returned.  var   query   =   Query User ( context ) \n   .. where (( u )   =   u . id ). equalTo ( 1 );  User   oneUser   =   await   query . fetchOne ();   Fetch queries can be limited to a number of instances with the  fetchLimit  property. You may also set the  offset  of a  Query T  to skip the first  offset  number of rows. Between  fetchLimit  and  offset , you can implement naive paging. However, this type of paging suffers from a number of problems and so there is another paging mechanism covered in later sections.", 
            "title": "Fetching Data with a Query"
        }, 
        {
            "location": "/db/executing_queries/#sorting", 
            "text": "Results of a fetch can be sorted using the  sortBy  method of a  Query T . Here's an example:  var   q   =   Query User ( context ) \n   .. sortBy (( u )   =   u . dateCreated ,   QuerySortOrder . ascending );   sortBy  takes two arguments: a closure that returns which property to sort by and the order of the sort.  A  Query T  results can be sorted by multiple properties. When multiple  sortBy s are invoked on a  Query T , later  sortBy s are used to break ties in previous  sortBy s. For example, the following query will sort by last name, then by first name:  var   q   =   Query User ( context ) \n   .. sortBy (( u )   =   u . lastName ,   QuerySortOrder . ascending ) \n   .. sortBy (( u )   =   u . firstName ,   QuerySortOrder . ascending );   Thus, the following three names would be ordered like so: 'Sally Smith', 'John Wu', 'Sally Wu'.", 
            "title": "Sorting"
        }, 
        {
            "location": "/db/executing_queries/#property-selectors", 
            "text": "In the section on sorting, you saw the use of a  property selector  to select the property of the user to sort by. This syntax is used for many other query manipulations, like filtering and joining. A property selector is a closure that gives you an object of the type you are querying and must return a property of that object. The selector  (u) =  u.lastName  in the previous section is a property selector that selects the last name of a user.  The Dart analyzer will infer that the argument of a property selector, and it is always the same type as the object being queried. This enables IDE auto-completion, static error checking, and other tools like project-wide renaming.   Live Templates  To speed up query building, create a Live Template in IntelliJ that generates a property selector when typing 'ps'. The source of the template is  (o) =  o.$END$ . A downloadable settings configuration for IntelliJ exists  here  that includes this shortcut.", 
            "title": "Property Selectors"
        }, 
        {
            "location": "/db/executing_queries/#specifying-result-properties", 
            "text": "When executing queries that return managed objects (i.e.,  insert() ,  update()  and  fetch() ), the default properties for each object are fetched. The default properties of a managed object are properties that correspond to a database column - attributes declared in the table definition. A managed object's default properties can be modified when declaring its table definition:  class   _User   { \n   @ Column ( omitByDefault:   true ) \n   String   hashedPassword ;  }   Any property with  omitByDefault  set to true will not be fetched by default.  A property that is  omitByDefault  can still be fetched. Likewise, a property that is in the defaults can still be omitted. Each  Query T  has a  returningProperties  method to adjust which properties do get returned from the query. Its usage looks like this:  var   query   =   Query User ( context ) \n   .. returningProperties (( user )   =   [ user . id ,   user . name ]);   returningProperties  is a multiple property selector - instead of returning just one property, it returns a list of properties.  You may include 'belongs-to' relationships in  returningProperties , but you may not include 'has-many' or 'has-one' relationships. An exception will be thrown if you attempt to. To include properties from relationships like these, see  join in Advanced Queries .  Note that if you omit the primary key of a managed object from  returningProperties , it will automatically be added. The primary key is necessary to transform the rows into instances of their  ManagedObject T  subclass.", 
            "title": "Specifying Result Properties"
        }, 
        {
            "location": "/db/executing_queries/#exceptions-and-errors", 
            "text": "When executing a query, it may fail for any number of reasons: the query is invalid, a database couldn't be reached, constraints were violated, etc. In many cases, this exception originates from the underlying database driver. When thrown in a controller, these exceptions will trigger a 500 Server Error response.  Exceptions that are thrown in response to user input (e.g., violating a database constraint, invalid data type) are re-interpreted into a  QueryException  or  ValidationException . Both of these exception types have an associated  Response  object that is sent instead of the default 500 Server error.  For this reason, you don't need to catch database query exceptions in a controller; an appropriate response will be sent on your behalf.", 
            "title": "Exceptions and Errors"
        }, 
        {
            "location": "/db/executing_queries/#statement-reuse", 
            "text": "Aqueduct will parameterize and reuse queries when possible. This allows for significant speed and security improvements. Note that you do not have to do anything special to take advantage of this feature. However, currently at this time, you may not disable this feature.", 
            "title": "Statement Reuse"
        }, 
        {
            "location": "/db/advanced_queries/", 
            "text": "Advanced Queries: Filtering, Joins, Paging and Reduce\n\n\nPaging Fetched Result Sets\n\n\nIn larger data sets, it may make sense to only return a portion of rows from a database. For example, in a social media application, a user could have thousands of pieces of content they had created over many years. The likely use case for fetching their content would be to grab only the most recent content, and only grab earlier content as necessary. Aqueduct has two mechanisms in \nQuery\nT\n for building queries that can fetch a subset of rows within a certain range.\n\n\nNaive paging can be accomplished using the \nfetchLimit\n and \noffset\n properties of a \nQuery\nT\n. For example, if a table contains 100 rows, and you would like to grab 10 at a time, each query would have a value of 10 for its \nfetchLimit\n. The first query would have an \noffset\n of 0, then 10, then 20, and so on. Especially when using \nsortBy\n, this type of paging can be effective. One of the drawbacks to this type of paging is that it can skip or duplicate rows if rows are being added or deleted between fetches.\n\n\n\n\nFor example, consider the seven objects above that are ordered by time. If we page by two objects at a time (\nfetchLimit=2\n) starting at the first item (\noffset=0\n), our first result set is the first two objects. The next page is the original offset plus the same limit - we grab the next two rows. But before the next page is fetched, a new object is inserted and its at an index that we already fetched. The next page would return \n3:00pm\n again. A similar problem occurs if a row is deleted when paging in this way.\n\n\nIt is really annoying for client applications to have to check for and merge duplicates. Another paging technique that doesn't suffer from this problem relies on the client sending a value from the last object in the previous page, instead of an offset. So in the above example, instead of asking for offset 2 in the second query, it'd send the value \n1:30pm\n. The query filters out rows with a value less than the one it was sent, orders the remaining rows and then fetches the newest from the top.\n\n\nQuery.pageBy\n uses this technique. Its usage is similar to \nsortBy\n:\n\n\nvar\n \nfirstQuery\n \n=\n \nQuery\nPost\n(\ncontext\n)\n\n  \n..\npageBy\n((\np\n)\n \n=\n \np\n.\ndateCreated\n,\n \nQuerySortOrder\n.\ndescending\n)\n\n  \n..\nfetchLimit\n \n=\n \n10\n;\n\n\n\nvar\n \nfirstQueryResults\n \n=\n \nawait\n \nfirstQuery\n.\nfetch\n();\n\n\n\nvar\n \noldestPostWeGot\n \n=\n \nfirstQueryResults\n.\nlast\n.\ndateCreated\n;\n\n\nvar\n \nnextQuery\n \n=\n \nQuery\nPost\n(\ncontext\n)\n\n  \n..\npageBy\n((\np\n)\n \n=\n \np\n.\ndateCreated\n,\n \nQuerySortOrder\n.\ndescending\n,\n \nboundingValue:\n \noldestPostWeGot\n)\n\n  \n..\nfetchLimit\n \n=\n \n10\n;\n\n\n\n\n\n\nThis query would fetch the newest 10 posts. Then, it fetches the next 10 after skipping past all of the ones newer than the oldest post it got in the first result set.\n\n\nWhen paging, the query must have a \nfetchLimit\n - otherwise you're just sorting and returning every row. You identify which property to page on by using a property selector. The second argument to \npageBy\n defines the order the rows will be sorted in.\n\n\nWhen you first start paging, you don't have any results yet, so you can't specify a value from the last result set. In this case, the \nboundingValue\n of \npageBy\n is null - meaning start from the beginning. Once the first set has been fetched, the \nboundingValue\n is the value of the paging property in the last object returned.\n\n\nThis is often accomplished by adding a query parameter to an endpoint that takes in a bounding value. (See \nManagedObjectController\nT\n as an example.)\n\n\nA \npageBy\n query will return an empty list of objects when no more values are left. If the number of objects remaining in the last page are less than the \nfetchLimit\n, only those objects will be returned. For example, if there four more objects left and the \nfetchLimit\n is 10, the number of objects returned will be four.\n\n\nYou should index properties that will be paged by:\n\n\n@\nColumn\n(\nindexed:\n \ntrue\n)\n\n\nint\n \npageableProperty\n;\n\n\n\n\n\n\nFiltering Results of a Fetch Operation\n\n\nFetching every row of a table usually doesn't make sense. Instead, we want a specific object or a set of objects matching some criteria.\n\n\nA \nQuery\n's \nwhere\n method is a safe and elegant way to add this criteria to a query. This method allows you to assign boolean expressions to the properties of the object being queried. Each expression is added to the WHERE clause of the generated SQL query. Here's an example of a query that finds a \nUser\n with an \nid\n equal to 1:\n\n\nvar\n \nquery\n \n=\n \nQuery\nUser\n(\ncontext\n)\n\n  \n..\nwhere\n((\nu\n)\n \n=\n \nu\n.\nid\n).\nequalTo\n(\n1\n);\n\n\n\n\n\n\n(The generated SQL here would be 'SELECT _user.id, _user.name, ... FROM _user WHERE _user.id = 1'.)\n\n\nThere are many expression methods like \nequalTo\n - see the documentation for \nQueryExpression\nT\n for a complete list.\n\n\nYou may add multiple criteria to a query by invoking \nwhere\n multiple times. Each criteria is combined together with a logical 'and'. For example, the following query will find all users whose \nname\n is \"Bob\" \nand\n \nemail\n is not null:\n\n\nfinal\n \nquery\n \n=\n \nQuery\nUser\n(\ncontext\n)\n\n  \n..\nwhere\n((\nu\n)\n \n=\n \nu\n.\nname\n).\nequalTo\n(\nBob\n)\n\n  \n..\nwhere\n((\nu\n)\n \n=\n \nu\n.\nemail\n).\nisNotNull\n();\n\n\n\n\n\n\nYou may apply criteria to relationship properties, too. For nullable relationships, you can apply null/not null checks:\n\n\nvar\n \nemployedQuery\n \n=\n \nQuery\nPerson\n(\ncontext\n)\n\n  \n..\nwhere\n((\nc\n)\n \n=\n \nc\n.\ncompany\n).\nisNotNull\n();\n\n\n\n\n\n\nMore often, you use the \nidentifiedBy\n expression for finding objects that belong to a specific object. For example, when finding all employees for a given company:\n\n\nvar\n \npreferredQuery\n \n=\n \nQuery\nEmployee\n(\ncontext\n)\n\n  \n..\nwhere\n((\nc\n)\n \n=\n \nc\n.\ncompany\n).\nidentifiedBy\n(\n23\n);\n\n\n\n\n\n\nThe above will only return employees who work for company with a primary key value of 23. It is equivalent to the following, and both are acceptable:\n\n\nvar\n \nsameQuery\n \n=\n \nQuery\nEmployee\n(\ncontext\n)\n\n  \n..\nwhere\n((\nc\n)\n \n=\n \nc\n.\ncompany\n.\nid\n).\nequalTo\n(\n23\n);\n\n\n\n\n\n\nNotice in the above that you may select properties of relationships when building a query. Since an employee 'belongs-to' a company, the employee table has a column to store the primary key of a company. This is called a foreign key column. When building a query that selects the primary key of a belongs-to relationship, Aqueduct can interpret this to use the foreign key column value.\n\n\nFor selecting properties that are not backed by a foreign key column in the table being queried, see the next section on Joins.\n\n\nIncluding Relationships in a Fetch (aka, Joins)\n\n\nA \nQuery\nT\n can also fetch relationship properties. This allows queries to fetch entire model graphs and reduces the number of round-trips to a database.\n\n\nBy default, relationship properties are not fetched in a query and therefore aren't included in an object's \nasMap()\n. For example, consider the following definitions, where a \nUser\n has-many \nTask\ns:\n\n\nclass\n \nUser\n \nextends\n \nManagedObject\n_User\n \nimplements\n \n_User\n \n{}\n\n\nclass\n \n_User\n \n{\n\n  \n@\nprimaryKey\n\n  \nint\n \nid\n;\n\n\n  \nString\n \nname\n;\n\n  \nManagedSet\nTask\n \ntasks\n;\n  \n\n}\n\n\n\nclass\n \nTask\n \nextends\n \nManagedObject\n_Task\n \nimplements\n \n_Task\n \n{}\n\n\nclass\n \n_Task\n \n{\n\n  \n@\nprimaryKey\n\n  \nint\n \nid\n;\n\n\n  \n@\nColumn\n(\n#\ntasks\n)\n\n  \nUser\n \nuser\n;\n\n\n  \nString\n \ncontents\n;\n\n\n}\n\n\n\n\n\n\nA \nQuery\nUser\n will fetch the \nname\n and \nid\n of each \nUser\n. A \nUser\n's \ntasks\n are not fetched, so the data returned looks like this:\n\n\nvar\n \nq\n \n=\n \nQuery\nUser\n(\ncontext\n);\n\n\nvar\n \nusers\n \n=\n \nawait\n \nq\n.\nfetch\n();\n\n\n\nusers\n.\nfirst\n.\nasMap\n()\n \n==\n \n{\n\n  \nid\n:\n \n1\n,\n\n  \nname\n:\n \nBob\n\n\n};\n \n// yup\n\n\n\n\n\n\nThe \njoin()\n method will tell a query to also include related objects. The following shows a fetch that gets users and their tasks:\n\n\nvar\n \nq\n \n=\n \nQuery\nUser\n(\ncontext\n)\n\n  \n..\njoin\n(\nset\n:\n \n(\nu\n)\n \n=\n \nu\n.\ntasks\n);\n\n\nvar\n \nusers\n \n=\n \nawait\n \nq\n.\nfetch\n();\n\n\n\nusers\n.\nfirst\n.\nasMap\n()\n \n==\n \n{\n\n  \nid\n:\n \n1\n,\n\n  \nname\n:\n \nBob\n,\n\n  \ntasks\n:\n \n[\n\n      \n{\nid\n:\n \n1\n,\n \ncontents\n:\n \nTake out trash\n,\n \nuser\n \n:\n \n{\nid\n:\n \n1\n}},\n\n      \n...\n\n  \n]\n\n\n};\n \n// yup\n\n\n\n\n\n\nWhen joining a has-many relationship, the \nset:\n argument takes a property selector that must select a \nManagedSet\n. (When fetching a has-one or belongs-to relationship, use the \nobject:\n argument.)\n\n\nThe method \njoin()\n returns a new \nQuery\nT\n, where \nT\n is the type of the joined object. That is, the above code could also be written as such:\n\n\nvar\n \nq\n \n=\n \nQuery\nUser\n(\ncontext\n);\n\n\n\n// type annotation added for clarity\n\n\nQuery\nTask\n \ntaskSubQuery\n \n=\n \nq\n.\njoin\n(\nset\n:\n \n(\nu\n)\n \n=\n \nu\n.\ntasks\n);\n\n\n\n\n\n\nConfiguring Join Queries\n\n\nYou do not execute a query created by a join, but you do configure it like any other query. (The parent query keeps track of the joined query and you execute the parent query.) For example, you may modify the properties that are returned for the joined objects:\n\n\nvar\n \nq\n \n=\n \nQuery\nUser\n(\ncontext\n);\n\n\n\nq\n.\njoin\n(\nset\n:\n \n(\nu\n)\n \n=\n \nu\n.\ntasks\n)\n  \n  \n..\nreturningProperties\n((\nt\n)\n \n=\n \n[\nt\n.\nid\n,\n \nt\n.\ncontents\n]);\n\n\n\nfinal\n \nusersAndTasks\n \n=\n \nawait\n \nq\n.\nfetch\n();\n  \n\n\n\n\n\nYou may also apply filtering criteria to a join query. Consider a \nParent\n that has-many \nChildren\n. When fetching parents and joining their children, a \nwhere\n expression on the join query impacts which children are returned, but does not impact which parents are returned. For example, the following query would fetch every parent, but would only include children who are greater than 1 years old:\n\n\nfinal\n \nq\n \n=\n \nQuery\nParent\n(\ncontext\n);\n\n\nq\n.\njoin\n(\nset\n:\n \n(\np\n)\n \n=\n \np\n.\nchildren\n)\n\n  \n..\nwhere\n((\nc\n)\n \n=\n \nc\n.\nage\n).\ngreaterThan\n(\n1\n);\n\n\n\nfinal\n \nparentsAndTheirChildren\n \n=\n \nawait\n \nq\n.\nfetch\n();\n\n\n\n\n\n\nFiltering Objects by Their Relationships\n\n\nHowever, consider if we applied a similar expression to the parent query - it would only return parents \nwho have children that are greater than 1 years old\n.\n\n\nfinal\n \nq\n \n=\n \nQuery\nParent\n(\ncontext\n)\n\n  \n..\nwhere\n((\nc\n)\n \n=\n \nc\n.\nchildren\n.\nhaveAtLeastOneWhere\n.\nage\n).\ngreaterThan\n(\n1\n);\n\n  \n..\njoin\n(\nset\n:\n \n(\np\n)\n \n=\n \np\n.\nchildren\n);\n\n\n\nfinal\n \nparentsWithOlderChildren\n \n=\n \nawait\n \nq\n.\nfetch\n();\n\n\n\n\n\n\nThe difference is where the expression is applied. When applying it to the child query, it removes child objects that don't meet the criteria. When applying it to the parent query, it removes parents that don't meet the criteria. The property \nhaveAtLeastOneWhere\n is specific to has-many relationships. When selecting properties of a has-one or belongs-to relationship, you access the property directly:\n\n\nfinal\n \nq\n \n=\n \nQuery\nChild\n(\ncontext\n)\n\n  \n..\nwhere\n((\np\n)\n \n=\n \np\n.\nparent\n.\nage\n).\ngreaterThan\n(\n30\n)\n\n  \n..\njoin\n(\nobject:\n \n(\np\n)\n \n=\n \ne\n.\nparent\n);\n\n\n\nfinal\n \nchildrenWithParentsOver30\n \n=\n \nawait\n \nq\n.\nfetch\n();\n\n\n\n\n\n\nNote that you may use relationship properties without explicitly joining the property. A SQL JOIN is still performed, but the related object is not included in the result set.\n\n\nfinal\n \nq\n \n=\n \nQuery\nChild\n(\ncontext\n)\n\n  \n..\nwhere\n((\np\n)\n \n=\n \np\n.\nparent\n.\nage\n).\ngreaterThan\n(\n30\n);\n\n\n\nfinal\n \nemployeesWithManagersOver30YearsOld\n \n=\n \nawait\n \nq\n.\nfetch\n();\n\n\n\n\n\n\nMultiple Joins\n\n\nMore than one join can be applied to a query, and subqueries can be nested. So, this is all valid, assuming the relationship properties exist:\n\n\nvar\n \nq\n \n=\n \nQuery\nUser\n(\ncontext\n)\n\n  \n..\njoin\n(\nobject:\n \n(\nu\n)\n \n=\n \nu\n.\naddress\n);\n\n\n\nq\n.\njoin\n(\nset\n:\n \n(\nu\n)\n \n=\n \nu\n.\ntasks\n)\n\n  \n..\njoin\n(\nobject:\n \n(\nu\n)\n \n=\n \nu\n.\nlocation\n);\n\n\n\n\n\n\nThis would fetch all users, their addresses, all of their tasks, and the location for each of their tasks. You'd get a nice sized tree of objects here.\n\n\nReduce Functions (aka, Aggregate Functions)\n\n\nQueries can also be used to perform functions like \ncount\n, \nsum\n, \naverage\n, \nmin\n and \nmax\n. Here's an example:\n\n\nvar\n \nquery\n \n=\n \nQuery\nUser\n(\ncontext\n);\n\n\nvar\n \nnumberOfUsers\n \n=\n \nawait\n \nquery\n.\nreduce\n.\ncount\n();\n\n\n\n\n\n\nFor reduce functions that use the value of some property, a property selector is used to identify that property.\n\n\nvar\n \naverageSalary\n \n=\n \nawait\n \nquery\n.\nreduce\n.\nsum\n((\nu\n)\n \n=\n \nu\n.\nsalary\n);\n\n\n\n\n\n\nAny values configured in a \nQuery\nT\n also impact the \nreduce\n function. For example, applying a \nQuery.where\n and then executing a \nsum\n function will only sum the rows that meet the criteria of the where clause:\n\n\nvar\n \nquery\n \n=\n \nQuery\nUser\n(\ncontext\n)\n\n  \n..\nwhere\n((\nu\n)\n \n=\n \nu\n.\nname\n.\nequalTo\n(\nBob\n);\n\n\nvar\n \naverageSalaryOfPeopleNamedBob\n \n=\n \nawait\n \nquery\n.\nreduce\n.\nsum\n((\nu\n)\n \n=\n \nu\n.\nsalary\n);\n\n\n\n\n\n\nFallbacks\n\n\nYou may always execute arbitrary SQL with \nPersistentStore.execute\n. Note that the objects returned will be a \nList\nList\ndynamic\n - a list of rows, for each a list of columns.\n\n\nYou may also provide raw WHERE clauses with \nQuery.predicate\n. A \nQueryPredicate\n is a \nString\n that is set as the query's where clause. A \nQueryPredicate\n has two properties, a format string and a \nMap\nString, dynamic\n of parameter values. The \nformat\n string can (and should) parameterize any input values. Parameters are indicated in the format string using the \n@\n token:\n\n\n// Creates a predicate that would only include instances where some column \nid\n is less than 2\n\n\nvar\n \npredicate\n \n=\n \nQueryPredicate\n(\nid \n @idVariable\n,\n \n{\nidVariable\n \n:\n \n2\n});\n\n\n\n\n\n\nThe text following the \n@\n token may contain \n[A-Za-z0-9_]\n. The resulting where clause will be formed by replacing each token with the matching key in the parameters map. The value is not transformed in any way, so it must be the appropriate type for the column. If a key is not present in the \nMap\n, an exception will be thrown. Extra keys will be ignored.", 
            "title": "Advanced Queries"
        }, 
        {
            "location": "/db/advanced_queries/#advanced-queries-filtering-joins-paging-and-reduce", 
            "text": "", 
            "title": "Advanced Queries: Filtering, Joins, Paging and Reduce"
        }, 
        {
            "location": "/db/advanced_queries/#paging-fetched-result-sets", 
            "text": "In larger data sets, it may make sense to only return a portion of rows from a database. For example, in a social media application, a user could have thousands of pieces of content they had created over many years. The likely use case for fetching their content would be to grab only the most recent content, and only grab earlier content as necessary. Aqueduct has two mechanisms in  Query T  for building queries that can fetch a subset of rows within a certain range.  Naive paging can be accomplished using the  fetchLimit  and  offset  properties of a  Query T . For example, if a table contains 100 rows, and you would like to grab 10 at a time, each query would have a value of 10 for its  fetchLimit . The first query would have an  offset  of 0, then 10, then 20, and so on. Especially when using  sortBy , this type of paging can be effective. One of the drawbacks to this type of paging is that it can skip or duplicate rows if rows are being added or deleted between fetches.   For example, consider the seven objects above that are ordered by time. If we page by two objects at a time ( fetchLimit=2 ) starting at the first item ( offset=0 ), our first result set is the first two objects. The next page is the original offset plus the same limit - we grab the next two rows. But before the next page is fetched, a new object is inserted and its at an index that we already fetched. The next page would return  3:00pm  again. A similar problem occurs if a row is deleted when paging in this way.  It is really annoying for client applications to have to check for and merge duplicates. Another paging technique that doesn't suffer from this problem relies on the client sending a value from the last object in the previous page, instead of an offset. So in the above example, instead of asking for offset 2 in the second query, it'd send the value  1:30pm . The query filters out rows with a value less than the one it was sent, orders the remaining rows and then fetches the newest from the top.  Query.pageBy  uses this technique. Its usage is similar to  sortBy :  var   firstQuery   =   Query Post ( context ) \n   .. pageBy (( p )   =   p . dateCreated ,   QuerySortOrder . descending ) \n   .. fetchLimit   =   10 ;  var   firstQueryResults   =   await   firstQuery . fetch ();  var   oldestPostWeGot   =   firstQueryResults . last . dateCreated ;  var   nextQuery   =   Query Post ( context ) \n   .. pageBy (( p )   =   p . dateCreated ,   QuerySortOrder . descending ,   boundingValue:   oldestPostWeGot ) \n   .. fetchLimit   =   10 ;   This query would fetch the newest 10 posts. Then, it fetches the next 10 after skipping past all of the ones newer than the oldest post it got in the first result set.  When paging, the query must have a  fetchLimit  - otherwise you're just sorting and returning every row. You identify which property to page on by using a property selector. The second argument to  pageBy  defines the order the rows will be sorted in.  When you first start paging, you don't have any results yet, so you can't specify a value from the last result set. In this case, the  boundingValue  of  pageBy  is null - meaning start from the beginning. Once the first set has been fetched, the  boundingValue  is the value of the paging property in the last object returned.  This is often accomplished by adding a query parameter to an endpoint that takes in a bounding value. (See  ManagedObjectController T  as an example.)  A  pageBy  query will return an empty list of objects when no more values are left. If the number of objects remaining in the last page are less than the  fetchLimit , only those objects will be returned. For example, if there four more objects left and the  fetchLimit  is 10, the number of objects returned will be four.  You should index properties that will be paged by:  @ Column ( indexed:   true )  int   pageableProperty ;", 
            "title": "Paging Fetched Result Sets"
        }, 
        {
            "location": "/db/advanced_queries/#filtering-results-of-a-fetch-operation", 
            "text": "Fetching every row of a table usually doesn't make sense. Instead, we want a specific object or a set of objects matching some criteria.  A  Query 's  where  method is a safe and elegant way to add this criteria to a query. This method allows you to assign boolean expressions to the properties of the object being queried. Each expression is added to the WHERE clause of the generated SQL query. Here's an example of a query that finds a  User  with an  id  equal to 1:  var   query   =   Query User ( context ) \n   .. where (( u )   =   u . id ). equalTo ( 1 );   (The generated SQL here would be 'SELECT _user.id, _user.name, ... FROM _user WHERE _user.id = 1'.)  There are many expression methods like  equalTo  - see the documentation for  QueryExpression T  for a complete list.  You may add multiple criteria to a query by invoking  where  multiple times. Each criteria is combined together with a logical 'and'. For example, the following query will find all users whose  name  is \"Bob\"  and   email  is not null:  final   query   =   Query User ( context ) \n   .. where (( u )   =   u . name ). equalTo ( Bob ) \n   .. where (( u )   =   u . email ). isNotNull ();   You may apply criteria to relationship properties, too. For nullable relationships, you can apply null/not null checks:  var   employedQuery   =   Query Person ( context ) \n   .. where (( c )   =   c . company ). isNotNull ();   More often, you use the  identifiedBy  expression for finding objects that belong to a specific object. For example, when finding all employees for a given company:  var   preferredQuery   =   Query Employee ( context ) \n   .. where (( c )   =   c . company ). identifiedBy ( 23 );   The above will only return employees who work for company with a primary key value of 23. It is equivalent to the following, and both are acceptable:  var   sameQuery   =   Query Employee ( context ) \n   .. where (( c )   =   c . company . id ). equalTo ( 23 );   Notice in the above that you may select properties of relationships when building a query. Since an employee 'belongs-to' a company, the employee table has a column to store the primary key of a company. This is called a foreign key column. When building a query that selects the primary key of a belongs-to relationship, Aqueduct can interpret this to use the foreign key column value.  For selecting properties that are not backed by a foreign key column in the table being queried, see the next section on Joins.", 
            "title": "Filtering Results of a Fetch Operation"
        }, 
        {
            "location": "/db/advanced_queries/#including-relationships-in-a-fetch-aka-joins", 
            "text": "A  Query T  can also fetch relationship properties. This allows queries to fetch entire model graphs and reduces the number of round-trips to a database.  By default, relationship properties are not fetched in a query and therefore aren't included in an object's  asMap() . For example, consider the following definitions, where a  User  has-many  Task s:  class   User   extends   ManagedObject _User   implements   _User   {}  class   _User   { \n   @ primaryKey \n   int   id ; \n\n   String   name ; \n   ManagedSet Task   tasks ;    }  class   Task   extends   ManagedObject _Task   implements   _Task   {}  class   _Task   { \n   @ primaryKey \n   int   id ; \n\n   @ Column ( # tasks ) \n   User   user ; \n\n   String   contents ;  }   A  Query User  will fetch the  name  and  id  of each  User . A  User 's  tasks  are not fetched, so the data returned looks like this:  var   q   =   Query User ( context );  var   users   =   await   q . fetch ();  users . first . asMap ()   ==   { \n   id :   1 , \n   name :   Bob  };   // yup   The  join()  method will tell a query to also include related objects. The following shows a fetch that gets users and their tasks:  var   q   =   Query User ( context ) \n   .. join ( set :   ( u )   =   u . tasks );  var   users   =   await   q . fetch ();  users . first . asMap ()   ==   { \n   id :   1 , \n   name :   Bob , \n   tasks :   [ \n       { id :   1 ,   contents :   Take out trash ,   user   :   { id :   1 }}, \n       ... \n   ]  };   // yup   When joining a has-many relationship, the  set:  argument takes a property selector that must select a  ManagedSet . (When fetching a has-one or belongs-to relationship, use the  object:  argument.)  The method  join()  returns a new  Query T , where  T  is the type of the joined object. That is, the above code could also be written as such:  var   q   =   Query User ( context );  // type annotation added for clarity  Query Task   taskSubQuery   =   q . join ( set :   ( u )   =   u . tasks );", 
            "title": "Including Relationships in a Fetch (aka, Joins)"
        }, 
        {
            "location": "/db/advanced_queries/#configuring-join-queries", 
            "text": "You do not execute a query created by a join, but you do configure it like any other query. (The parent query keeps track of the joined query and you execute the parent query.) For example, you may modify the properties that are returned for the joined objects:  var   q   =   Query User ( context );  q . join ( set :   ( u )   =   u . tasks )   \n   .. returningProperties (( t )   =   [ t . id ,   t . contents ]);  final   usersAndTasks   =   await   q . fetch ();     You may also apply filtering criteria to a join query. Consider a  Parent  that has-many  Children . When fetching parents and joining their children, a  where  expression on the join query impacts which children are returned, but does not impact which parents are returned. For example, the following query would fetch every parent, but would only include children who are greater than 1 years old:  final   q   =   Query Parent ( context );  q . join ( set :   ( p )   =   p . children ) \n   .. where (( c )   =   c . age ). greaterThan ( 1 );  final   parentsAndTheirChildren   =   await   q . fetch ();", 
            "title": "Configuring Join Queries"
        }, 
        {
            "location": "/db/advanced_queries/#filtering-objects-by-their-relationships", 
            "text": "However, consider if we applied a similar expression to the parent query - it would only return parents  who have children that are greater than 1 years old .  final   q   =   Query Parent ( context ) \n   .. where (( c )   =   c . children . haveAtLeastOneWhere . age ). greaterThan ( 1 ); \n   .. join ( set :   ( p )   =   p . children );  final   parentsWithOlderChildren   =   await   q . fetch ();   The difference is where the expression is applied. When applying it to the child query, it removes child objects that don't meet the criteria. When applying it to the parent query, it removes parents that don't meet the criteria. The property  haveAtLeastOneWhere  is specific to has-many relationships. When selecting properties of a has-one or belongs-to relationship, you access the property directly:  final   q   =   Query Child ( context ) \n   .. where (( p )   =   p . parent . age ). greaterThan ( 30 ) \n   .. join ( object:   ( p )   =   e . parent );  final   childrenWithParentsOver30   =   await   q . fetch ();   Note that you may use relationship properties without explicitly joining the property. A SQL JOIN is still performed, but the related object is not included in the result set.  final   q   =   Query Child ( context ) \n   .. where (( p )   =   p . parent . age ). greaterThan ( 30 );  final   employeesWithManagersOver30YearsOld   =   await   q . fetch ();", 
            "title": "Filtering Objects by Their Relationships"
        }, 
        {
            "location": "/db/advanced_queries/#multiple-joins", 
            "text": "More than one join can be applied to a query, and subqueries can be nested. So, this is all valid, assuming the relationship properties exist:  var   q   =   Query User ( context ) \n   .. join ( object:   ( u )   =   u . address );  q . join ( set :   ( u )   =   u . tasks ) \n   .. join ( object:   ( u )   =   u . location );   This would fetch all users, their addresses, all of their tasks, and the location for each of their tasks. You'd get a nice sized tree of objects here.", 
            "title": "Multiple Joins"
        }, 
        {
            "location": "/db/advanced_queries/#reduce-functions-aka-aggregate-functions", 
            "text": "Queries can also be used to perform functions like  count ,  sum ,  average ,  min  and  max . Here's an example:  var   query   =   Query User ( context );  var   numberOfUsers   =   await   query . reduce . count ();   For reduce functions that use the value of some property, a property selector is used to identify that property.  var   averageSalary   =   await   query . reduce . sum (( u )   =   u . salary );   Any values configured in a  Query T  also impact the  reduce  function. For example, applying a  Query.where  and then executing a  sum  function will only sum the rows that meet the criteria of the where clause:  var   query   =   Query User ( context ) \n   .. where (( u )   =   u . name . equalTo ( Bob );  var   averageSalaryOfPeopleNamedBob   =   await   query . reduce . sum (( u )   =   u . salary );", 
            "title": "Reduce Functions (aka, Aggregate Functions)"
        }, 
        {
            "location": "/db/advanced_queries/#fallbacks", 
            "text": "You may always execute arbitrary SQL with  PersistentStore.execute . Note that the objects returned will be a  List List dynamic  - a list of rows, for each a list of columns.  You may also provide raw WHERE clauses with  Query.predicate . A  QueryPredicate  is a  String  that is set as the query's where clause. A  QueryPredicate  has two properties, a format string and a  Map String, dynamic  of parameter values. The  format  string can (and should) parameterize any input values. Parameters are indicated in the format string using the  @  token:  // Creates a predicate that would only include instances where some column  id  is less than 2  var   predicate   =   QueryPredicate ( id   @idVariable ,   { idVariable   :   2 });   The text following the  @  token may contain  [A-Za-z0-9_] . The resulting where clause will be formed by replacing each token with the matching key in the parameters map. The value is not transformed in any way, so it must be the appropriate type for the column. If a key is not present in the  Map , an exception will be thrown. Extra keys will be ignored.", 
            "title": "Fallbacks"
        }, 
        {
            "location": "/db/transactions/", 
            "text": "Database Transactions\n\n\nLearn how to execute multiple \nQuery\nT\ns in a database transaction.\n\n\nTransactions\n\n\nConsider an application that keeps employee records. Each employee belongs to a department. Management decides to combine two departments into a totally new department. To do this, the application must insert a new department, set each employee's foreign key reference to that department, and then delete the old departments. It'd look like this:\n\n\n// Create the new department\n\n\nfinal\n \nnewDepartment\n \n=\n \nawait\n \nQuery\n.\ninsertObject\n(\nctx\n,\n \nDepartment\n()..\nname\n \n=\n \nNew Department\n);\n\n\n\n// Set employee\ns departments to the new one\n\n\nfinal\n \nchangeDepartmentQuery\n \n=\n \nQuery\nEmployee\n(\nctx\n)\n\n  \n..\nwhere\n((\ne\n)\n \n=\n \ne\n.\ndepartment\n.\nid\n).\noneOf\n([\n1\n,\n \n2\n])\n      \n  \n..\nvalues\n.\ndepartment\n.\nid\n \n=\n \nnewDepartment\n.\nid\n;\n\n\nawait\n \nchangeDepartmentQuery\n.\nupdate\n();\n\n\n\n// Delete the old ones\n\n\nfinal\n \ndeleteDepartmentQuery\n \n=\n \nQuery\nDepartment\n(\nctx\n)\n\n  \n..\nwhere\n((\ne\n)\n \n=\n \ne\n.\ndepartment\n.\nid\n).\noneOf\n([\n1\n,\n \n2\n]);\n\n\nawait\n \ndeleteDepartmentQuery\n.\ndelete\n();\n      \n\n\n\n\n\nThis change to your database is three separate queries, but they all most complete for the 'transfer' to be successful. If one of them fails, our database can be left in an inconsistent state. For example, if deleting the departments succeeds, but the employees failed to be transferred to the new department, then a lot of employees would be without a department.\n\n\nA database transaction combines queries together as a single unit. If a query in a transaction fails, the previous queries in that transaction are reverted and the remaining queries are aborted. You create transactions by invoking \nManagedContext.transaction\n and writing your queries in its closure argument.\n\n\nawait\n \ncontext\n.\ntransaction\n((\ntransaction\n)\n \nasync\n \n{\n\n  \n// note that \ntransaction\n is the context for each of these queries.\n\n  \nfinal\n \nnewDepartment\n \n=\n \nawait\n \nQuery\n.\ninsertObject\n(\ntransaction\n,\n \nDepartment\n()..\nname\n \n=\n \nNew Department\n);\n\n\n  \nfinal\n \nchangeDepartmentQuery\n \n=\n \nQuery\nEmployee\n(\ntransaction\n)\n\n    \n..\nwhere\n((\ne\n)\n \n=\n \ne\n.\ndepartment\n.\nid\n).\noneOf\n([\n1\n,\n \n2\n])\n      \n    \n..\nvalues\n.\ndepartment\n.\nid\n \n=\n \nnewDepartment\n.\nid\n;\n\n  \nawait\n \nchangeDepartmentQuery\n.\nupdate\n();\n\n\n  \nfinal\n \ndeleteDepartmentQuery\n \n=\n \nQuery\nDepartment\n(\ntransaction\n)\n\n    \n..\nwhere\n((\ne\n)\n \n=\n \ne\n.\ndepartment\n.\nid\n).\noneOf\n([\n1\n,\n \n2\n]);\n\n  \nawait\n \ndeleteDepartmentQuery\n();\n      \n\n});\n\n\n\n\n\n\nAll of the queries in the transaction closure will run in the same transaction. Once they have all succeeded, the \ntransaction\n method's future completes. If an exception is thrown in the closure, the transaction is rolled back and the \ntransaction\n method re-throws that exception.\n\n\nNotice that the context for each query is the \ntransaction\n object passed to the transaction closure. You must use this object when using \nQuery\n in a transaction closure.\n\n\n\n\nFailing to Use the Transaction Context will Deadlock your Application\n\n\n\n\nA \nManagedContext\n has a single database connection. While a transaction is in progress, any query sent by the same connection becomes part of that transaction. Because Dart is asynchronous, a its likely that another request will trigger a database request while a transaction is in progress. For this reason, a context must queue queries from outside of a transaction while the transaction is running. A new context is created for each transaction and the database connection is shared with the original context. If you await on a query on the original context from inside a transaction closure, it won't complete until the transaction completes - but the transaction can't complete because it is awaiting for the query to complete. This will prevent the connection from being used until the transaction or query times out.\n\n\nReturning Values\n\n\nThe value returned from a transaction closure is returned to the caller, so values created within the transaction closure can escape its scope.\n\n\nfinal\n \nemployees\n \n=\n \n[...];\n\n\nfinal\n \ninsertedEmployees\n \n=\n \nawait\n \ncontext\n.\ntransaction\n((\nt\n)\n \nasync\n \n{\n\n  \nreturn\n \nFuture\n.\nwait\n(\nemployees\n.\nmap\n((\ne\n)\n \n=\n \nQuery\n.\ninsertObject\n(\nt\n,\n \ne\n)));\n\n\n});\n\n\n\n\n\n\nRollbacks\n\n\nYou can cancel a transaction and revert its changes at anytime within the transaction closure by throwing a \nRollback\n object.\n\n\ntry\n \n{\n\n  \nawait\n \ncontext\n.\ntransaction\n((\nt\n)\n \nasync\n \n{\n\n    \n// do something\n\n\n    \nif\n \n(\nsomethingIsTrue\n)\n \n{\n\n      \nthrow\n \nRollback\n(\nsomething was true\n);\n    \n    \n}\n\n\n    \n// do something\n\n  \n});\n\n\n}\n \non\n \nRollback\n \ncatch\n \n(\nrollback\n)\n \n{\n\n  \nprint\n(\n${\nrollback\n.\nreason\n}\n);\n \n// prints \nsomething was true\n\n\n}\n\n\n\n\n\n\nWhen you rollback, your transaction fails, the transaction closure is aborted and all changes are reverted. The \ntransaction\n method completes with an error, where the error object is the \nRollback\n.", 
            "title": "Transactions"
        }, 
        {
            "location": "/db/transactions/#database-transactions", 
            "text": "Learn how to execute multiple  Query T s in a database transaction.", 
            "title": "Database Transactions"
        }, 
        {
            "location": "/db/transactions/#transactions", 
            "text": "Consider an application that keeps employee records. Each employee belongs to a department. Management decides to combine two departments into a totally new department. To do this, the application must insert a new department, set each employee's foreign key reference to that department, and then delete the old departments. It'd look like this:  // Create the new department  final   newDepartment   =   await   Query . insertObject ( ctx ,   Department ().. name   =   New Department );  // Set employee s departments to the new one  final   changeDepartmentQuery   =   Query Employee ( ctx ) \n   .. where (( e )   =   e . department . id ). oneOf ([ 1 ,   2 ])       \n   .. values . department . id   =   newDepartment . id ;  await   changeDepartmentQuery . update ();  // Delete the old ones  final   deleteDepartmentQuery   =   Query Department ( ctx ) \n   .. where (( e )   =   e . department . id ). oneOf ([ 1 ,   2 ]);  await   deleteDepartmentQuery . delete ();         This change to your database is three separate queries, but they all most complete for the 'transfer' to be successful. If one of them fails, our database can be left in an inconsistent state. For example, if deleting the departments succeeds, but the employees failed to be transferred to the new department, then a lot of employees would be without a department.  A database transaction combines queries together as a single unit. If a query in a transaction fails, the previous queries in that transaction are reverted and the remaining queries are aborted. You create transactions by invoking  ManagedContext.transaction  and writing your queries in its closure argument.  await   context . transaction (( transaction )   async   { \n   // note that  transaction  is the context for each of these queries. \n   final   newDepartment   =   await   Query . insertObject ( transaction ,   Department ().. name   =   New Department ); \n\n   final   changeDepartmentQuery   =   Query Employee ( transaction ) \n     .. where (( e )   =   e . department . id ). oneOf ([ 1 ,   2 ])       \n     .. values . department . id   =   newDepartment . id ; \n   await   changeDepartmentQuery . update (); \n\n   final   deleteDepartmentQuery   =   Query Department ( transaction ) \n     .. where (( e )   =   e . department . id ). oneOf ([ 1 ,   2 ]); \n   await   deleteDepartmentQuery ();        });   All of the queries in the transaction closure will run in the same transaction. Once they have all succeeded, the  transaction  method's future completes. If an exception is thrown in the closure, the transaction is rolled back and the  transaction  method re-throws that exception.  Notice that the context for each query is the  transaction  object passed to the transaction closure. You must use this object when using  Query  in a transaction closure.   Failing to Use the Transaction Context will Deadlock your Application   A  ManagedContext  has a single database connection. While a transaction is in progress, any query sent by the same connection becomes part of that transaction. Because Dart is asynchronous, a its likely that another request will trigger a database request while a transaction is in progress. For this reason, a context must queue queries from outside of a transaction while the transaction is running. A new context is created for each transaction and the database connection is shared with the original context. If you await on a query on the original context from inside a transaction closure, it won't complete until the transaction completes - but the transaction can't complete because it is awaiting for the query to complete. This will prevent the connection from being used until the transaction or query times out.", 
            "title": "Transactions"
        }, 
        {
            "location": "/db/transactions/#returning-values", 
            "text": "The value returned from a transaction closure is returned to the caller, so values created within the transaction closure can escape its scope.  final   employees   =   [...];  final   insertedEmployees   =   await   context . transaction (( t )   async   { \n   return   Future . wait ( employees . map (( e )   =   Query . insertObject ( t ,   e )));  });", 
            "title": "Returning Values"
        }, 
        {
            "location": "/db/transactions/#rollbacks", 
            "text": "You can cancel a transaction and revert its changes at anytime within the transaction closure by throwing a  Rollback  object.  try   { \n   await   context . transaction (( t )   async   { \n     // do something \n\n     if   ( somethingIsTrue )   { \n       throw   Rollback ( something was true );     \n     } \n\n     // do something \n   });  }   on   Rollback   catch   ( rollback )   { \n   print ( ${ rollback . reason } );   // prints  something was true  }   When you rollback, your transaction fails, the transaction closure is aborted and all changes are reverted. The  transaction  method completes with an error, where the error object is the  Rollback .", 
            "title": "Rollbacks"
        }, 
        {
            "location": "/db/validations/", 
            "text": "Validating Data\n\n\nData is added to a database through \nupdate\n and \ninsert\n queries. As part of these two operations, a \nManagedObject\nT\n will ensure that its properties have valid values. For example, a \nPerson\n object might ensure that its name starts with a capital letter and that its phone number has only numeric values.  If one or more validation fails, the update or insert operation will fail and the data is not sent to the database. A validation failure will throw a \nQueryException\n, which automatically sends an HTTP response with error messaging to help the client correct their request.\n\n\nThe preferred way of setting a validation is to add \nValidate\n metadata to properties of a table definition. Here's an example of a validation that ensures a tweet is less than 140 characters:\n\n\nclass\n \nTweet\n \nextends\n \nManagedObject\n_Tweet\n \nimplements\n \n_Tweet\n \n{}\n\n\nclass\n \n_Tweet\n \n{\n\n  \n@\nprimaryKey\n\n  \nint\n \nid\n;\n\n\n  \n@\nValidate\n.\nlength\n(\nlessThan:\n \n140\n)\n\n  \nString\n \nmessage\n;\n\n\n}\n\n\n\n\n\n\nBuilt-in Validators\n\n\nThere are a handful of built-in validations for common operations. For example, it is common to apply a regular expression to a value to ensure it formatted correctly or restrict the possible values to a list of available options. Common validators are available as named constructors on the \nValidate\n class. Here is an example:\n\n\nclass\n \n_Story\n \n{\n\n  \n@\nprimaryKey\n\n  \nint\n \nid\n;\n\n\n  \n@\nValidate\n.\noneOf\n(\nconst\n \n[\nstarted\n,\n \naccepted\n,\n \nrejected\n,\n \ndelivered\n])\n\n  \nString\n \nstate\n;\n\n\n}\n\n\n\n\n\n\nA built-in validator is useful because it automatically generates an error message that is returned in an HTTP response. For example, the previous code snippet indicates that the \nstate\n property must be one of the four listed strings. If a value other than one of those four strings is used, the error message returned to the HTTP client would be:\n\n\nThe value `invalidValue` is not valid for `state`. Valid values are: \nstarted\n, \naccepted\n, \nrejected\n, \ndelivered\n.\n.\n\n\n\n\n\nSee the API reference for \nValidate\n and its named constructors for possible options.\n\n\nValidate\n metadata on transient properties have no effect. This metadata is only valid for database-backed properties declared in a table definition.\n\n\nCustom Validators\n\n\nThere will be times where the built-in validators are not sufficient for your application's use case. You may create subclasses of \nValidate\n to provide custom validation behavior.For example, a \nValidate\n subclass you have declared named \nValidatePhoneNumber\n would be used like so:\n\n\nclass\n \n_Person\n \n{\n\n  \n@\nprimaryKey\n\n  \nint\n \nid\n;\n\n\n  \n@\nValidatePhoneNumber\n()\n\n  \nString\n \nphoneNumber\n;\n\n\n}\n\n\n\n\n\n\nA subclass of \nValidate\n must override \nValidate.validate()\n and call the superclass' primary constructor when instantiated. Here's an example of that phone number validator:\n\n\nclass\n \nValidatePhoneNumber\n \nextends\n \nValidate\n \n{\n\n  \nValidatePhoneNumber\n({\nbool\n \nonUpdate:\n \ntrue\n,\n \nbool\n \nonInsert:\n \ntrue\n})\n \n:\n\n    \nsuper\n(\nonUpdate:\n \nonUpdate\n,\n \nonInsert:\n \nonInsert\n);\n\n\n  \n@\noverride\n\n  \nvoid\n \nvalidate\n(\nValidationContext\n \ncontext\n,\n \ndynamic\n \nvalue\n)\n \n{\n  \n    \nif\n \n(\nvalue\n.\nlength\n \n!=\n \n15\n)\n \n{\n\n      \ncontext\n.\naddError\n(\nmust be 15 digits\n);\n      \n    \n}\n\n\n    \nif\n \n(\ncontainsNonNumericValues\n(\nvalue\n))\n \n{\n\n      \ncontext\n.\naddError\n(\nmust contain characters 0-9 only.\n);\n      \n    \n}\n\n  \n}\n\n\n}\n\n\n\n\n\n\nIf \nvalue\n is doesn't meet the validation criteria, this method adds an error string to the \nValidationContext\n it is passed. Error messages should be brief and indicate the successful criteria that failed. Information about the property being validated will automatically be added to the error message, so you do not need to include that information. If the context has no errors at the end of validation, the validation succeeds; otherwise, it fails.\n\n\nA \nValidationContext\n also has information about the property being validated, and whether the validation is running for an object being inserted or an object being updated.\n\n\nValidation Behavior\n\n\nA property may have more than one \nValidate\n metadata. In this case, all of the validations for a property must pass. The order in which multiple validations are performed is undefined and subject to change. Here's an example of validations that ensure a property's value is 10 characters long and only contains 10 alphabetic capital letters:\n\n\n@\nValidate\n.\nlength\n(\nequalTo:\n \n10\n)\n\n\n@\nValidate\n.\nmatches\n(\nr\n$[A-Z]+^\n)\n\n\nString\n \ntenCapitalLetters\n;\n\n\n\n\n\n\nBy default, validations are executed when a \nQuery\nT\n's \ninsert\n or \nupdate\n method is invoked. A validator can be restricted to only run on \ninsert\n or \nupdate\n by passing values for its optional constructor arguments \nonUpdate\n and \nonInsert\n:\n\n\n@\nValidate\n.\nmatches\n(\nr\n^[A-Z]+$\n,\n \nonInsert:\n \ntrue\n,\n \nonUpdate:\n \nfalse\n)\n\n\nString\n \nvalidateOnInsertOnly\n;\n\n\n\n\n\n\nIt is important to understand how validations work when a value for a property is \nnot\n specified in an insert or update query. For example, consider a \nPerson\n with a \nname\n and \nemail\n property and then inserted in a query where \nemail\n hasn't been set:\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nPerson\n(\ncontext\n)\n\n  \n..\nvalues\n.\nname\n \n=\n \nBob\n;\n\n\n\nawait\n \nquery\n.\ninsert\n();\n\n\n\n\n\n\nBecause \nemail\n was not set on \nQuery.values\n, validations will not be run on that property.\n\n\nThere are two special validators that can require a property to be set, or require that a property \nnot\n be set. \nValidate.present()\n requires that the associated property must have a value. A property with this validator must be provided each time the object is inserted or updated. Like all validators, \nValidate.present()\n can be adjusted to be invoked on only inserts or only updates. For example, the following declaration requires that \nemail\n is set on insertion, but doesn't have to be for updates:\n\n\n@\nValidate\n.\npresent\n(\nonUpdate:\n \nfalse\n,\n \nonInsert:\n \ntrue\n)\n\n\nString\n \nemail\n;\n\n\n\n\n\n\nThe inverse of \nValidate.present()\n is \nValidate.absent()\n. This validation prevents a property from being set. This is useful when a value should be included during insertion, but can't be updated. Here's an example:\n\n\n@\nValidate\n.\nabsent\n(\nonUpdate:\n \ntrue\n,\n \nonInsert:\n \nfalse\n)\n\n\nString\n \ncanOnlyBeSetOnce\n;\n\n\n\n\n\n\nIn the above declaration, the validator is only run on update operations and ensures that the property \ncanOnlyBeSetOnce\n does not have a value. Because this validator is not run on insert operations, there is no restriction when the object is first inserted.\n\n\nValidators are not run when a value is null. For example, the following insertion explicitly inserts \nnull\n for the property \nemail\n:\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nPerson\n(\ncontext\n)\n\n  \n..\nvalues\n.\nemail\n \n=\n \nnull\n\n  \n..\nvalues\n.\nname\n \n=\n \nBob\n;\n\n\n\nawait\n \nquery\n.\ninsert\n();\n\n\n\n\n\n\nNullability is enforced by \nColumn.isNullable\n property. Consider the following declaration:\n\n\n@\nColumn\n(\nnullable:\n \nfalse\n)\n\n\n@\nValidate\n.\nlength\n(\ngreaterThan:\n \n10\n)\n\n\nString\n \nname\n;\n\n\n\n\n\n\nHere, the property \nname\n must not be null and must be greater than 10 characters long. The behavior of inserting or updating this property is shown in the following table.\n\n\n\n\n\n\n\n\nInput Value for Name\n\n\nValidation Runs?\n\n\nOutcome\n\n\n\n\n\n\n\n\n\n\nInsert value longer than 10 characters\n\n\nYes\n\n\nSuccessful database insert\n\n\n\n\n\n\nInsert value shorter than 10 characters\n\n\nYes\n\n\nDatabase insert not executed, exception thrown\n\n\n\n\n\n\nInsert value not specified\n\n\nNo\n\n\nDatabase insert fails with non-null violation, exception thrown\n\n\n\n\n\n\nInsert value is null\n\n\nNo\n\n\nDatabase insert fails with non-null violation, exception thrown\n\n\n\n\n\n\nUpdate value longer than 10 characters\n\n\nYes\n\n\nSuccessful database update\n\n\n\n\n\n\nUpdate value shorter than 10 characters\n\n\nYes\n\n\nDatabase update not executed, exception thrown\n\n\n\n\n\n\nUpdate value not specified\n\n\nNo\n\n\nSuccessful database update\n\n\n\n\n\n\nUpdate value is explicit null\n\n\nNo\n\n\nSuccessful database update\n\n\n\n\n\n\n\n\nThis behavior allows \nManagedObject\nT\n instances to be partially updated, which also allows for partial PUTs. Partial PUTs can be prevented by adding \nValidate.present()\n metadata to all properties. While partial PUTs are not idiomatic REST, they are pragmatic software development.\n\n\nThis also means that any custom validator can safely assume that a value passed to \nValidate.validate()\n is non-null.\n\n\nOther Validator Behavior\n\n\nFor validators that can't be built by subclassing \nValidate\n, you may override \nManagedObject\nT\n.validate()\n. This method is useful when a validation involves more than one property. Here's an example:\n\n\nclass\n \nPerson\n \nextends\n \nManagedObject\n_Person\n \nimplements\n \n_Person\n \n{\n\n  \n@\noverride\n\n  \nValidationContext\n \nvalidate\n({\nValidating\n \nforEvent:\n \nValidating\n.\ninsert\n})\n \n{\n\n   \nfinal\n \nctx\n \n=\n \nsuper\n.\nvalidate\n(\nforEvent:\n \nforEvent\n);\n\n\n    \nif\n \n(\na\n \n+\n \nb\n \n \n10\n)\n \n{\n\n      \nctx\n.\naddError\n(\na + b must be greater than 10\n);\n\n    \n}\n\n\n    \nreturn\n \nctx\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nWhen overriding this method, the \nsuper\n implementation must be invoked to run validations managed by annotations. You must return the \nValidationContext\n created by the superclass' implementation.\n\n\nSkipping Validations\n\n\nValidations are only run when values are set via \nQuery\nT\n.values\n. Values set via \nQuery\nT\n.valueMap\n are not validated. Therefore, objects should typically be inserted and updated using \nQuery\nT\n.values\n unless validation must be ignored. Here's an example of skipping validation:\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nPerson\n(\ncontext\n)\n\n  \n..\nvalueMap\n \n=\n \n{\n\n    \nname\n \n:\n \nxyz\n,\n\n    \nemail\n \n:\n \nwhatever\n\n  \n};\n\n\n\n\n\n\nSkipping validation should be rare.\n\n\nUpdate and Insert Callbacks\n\n\nManagedObject\nT\n subclasses may override \nwillUpdate\n and \nwillInsert\n to modify its properties prior to being updated or inserted by a \nQuery\nT\n. For example, a managed object may have updated and created dates that can be guaranteed to be set when inserted or updated:\n\n\nclass\n \nPerson\n \nextends\n \nManagedObject\n_Person\n \nimplements\n \n_Person\n \n{\n\n  \n@\noverride\n\n  \nvoid\n \nwillUpdate\n()\n \n{\n\n    \nupdatedAt\n \n=\n \nnew\n \nDateTime\n.\nnow\n().\ntoUtc\n();\n\n  \n}\n\n\n  \n@\noverride\n\n  \nvoid\n \nwillInsert\n()\n \n{\n\n    \ncreatedAt\n \n=\n \nnew\n \nDateTime\n.\nnow\n().\ntoUtc\n();\n\n  \n}\n\n\n}\n\n\nclass\n \n_Person\n \n{\n\n  \n@\nprimaryKey\n\n  \nint\n \nid\n;\n\n\n  \nString\n \nname\n;\n\n  \nDateTime\n \ncreatedAt\n;\n\n  \nDateTime\n \nupdatedAt\n;\n\n\n}\n\n\n\n\n\n\nNote that all operations must be synchronous in these methods.\n\n\nBoth \nwillUpdate\n and \nwillInsert\n are invoked prior the validation phase. Thus, any values set in these methods will be subject to the declared validations of the instance.\n\n\nLike validations, \nwillUpdate\n and \nwillInsert\n  are skipped when using \nQuery.valueMap\n.", 
            "title": "Validations"
        }, 
        {
            "location": "/db/validations/#validating-data", 
            "text": "Data is added to a database through  update  and  insert  queries. As part of these two operations, a  ManagedObject T  will ensure that its properties have valid values. For example, a  Person  object might ensure that its name starts with a capital letter and that its phone number has only numeric values.  If one or more validation fails, the update or insert operation will fail and the data is not sent to the database. A validation failure will throw a  QueryException , which automatically sends an HTTP response with error messaging to help the client correct their request.  The preferred way of setting a validation is to add  Validate  metadata to properties of a table definition. Here's an example of a validation that ensures a tweet is less than 140 characters:  class   Tweet   extends   ManagedObject _Tweet   implements   _Tweet   {}  class   _Tweet   { \n   @ primaryKey \n   int   id ; \n\n   @ Validate . length ( lessThan:   140 ) \n   String   message ;  }", 
            "title": "Validating Data"
        }, 
        {
            "location": "/db/validations/#built-in-validators", 
            "text": "There are a handful of built-in validations for common operations. For example, it is common to apply a regular expression to a value to ensure it formatted correctly or restrict the possible values to a list of available options. Common validators are available as named constructors on the  Validate  class. Here is an example:  class   _Story   { \n   @ primaryKey \n   int   id ; \n\n   @ Validate . oneOf ( const   [ started ,   accepted ,   rejected ,   delivered ]) \n   String   state ;  }   A built-in validator is useful because it automatically generates an error message that is returned in an HTTP response. For example, the previous code snippet indicates that the  state  property must be one of the four listed strings. If a value other than one of those four strings is used, the error message returned to the HTTP client would be:  The value `invalidValue` is not valid for `state`. Valid values are:  started ,  accepted ,  rejected ,  delivered . .  See the API reference for  Validate  and its named constructors for possible options.  Validate  metadata on transient properties have no effect. This metadata is only valid for database-backed properties declared in a table definition.", 
            "title": "Built-in Validators"
        }, 
        {
            "location": "/db/validations/#custom-validators", 
            "text": "There will be times where the built-in validators are not sufficient for your application's use case. You may create subclasses of  Validate  to provide custom validation behavior.For example, a  Validate  subclass you have declared named  ValidatePhoneNumber  would be used like so:  class   _Person   { \n   @ primaryKey \n   int   id ; \n\n   @ ValidatePhoneNumber () \n   String   phoneNumber ;  }   A subclass of  Validate  must override  Validate.validate()  and call the superclass' primary constructor when instantiated. Here's an example of that phone number validator:  class   ValidatePhoneNumber   extends   Validate   { \n   ValidatePhoneNumber ({ bool   onUpdate:   true ,   bool   onInsert:   true })   : \n     super ( onUpdate:   onUpdate ,   onInsert:   onInsert ); \n\n   @ override \n   void   validate ( ValidationContext   context ,   dynamic   value )   {   \n     if   ( value . length   !=   15 )   { \n       context . addError ( must be 15 digits );       \n     } \n\n     if   ( containsNonNumericValues ( value ))   { \n       context . addError ( must contain characters 0-9 only. );       \n     } \n   }  }   If  value  is doesn't meet the validation criteria, this method adds an error string to the  ValidationContext  it is passed. Error messages should be brief and indicate the successful criteria that failed. Information about the property being validated will automatically be added to the error message, so you do not need to include that information. If the context has no errors at the end of validation, the validation succeeds; otherwise, it fails.  A  ValidationContext  also has information about the property being validated, and whether the validation is running for an object being inserted or an object being updated.", 
            "title": "Custom Validators"
        }, 
        {
            "location": "/db/validations/#validation-behavior", 
            "text": "A property may have more than one  Validate  metadata. In this case, all of the validations for a property must pass. The order in which multiple validations are performed is undefined and subject to change. Here's an example of validations that ensure a property's value is 10 characters long and only contains 10 alphabetic capital letters:  @ Validate . length ( equalTo:   10 )  @ Validate . matches ( r $[A-Z]+^ )  String   tenCapitalLetters ;   By default, validations are executed when a  Query T 's  insert  or  update  method is invoked. A validator can be restricted to only run on  insert  or  update  by passing values for its optional constructor arguments  onUpdate  and  onInsert :  @ Validate . matches ( r ^[A-Z]+$ ,   onInsert:   true ,   onUpdate:   false )  String   validateOnInsertOnly ;   It is important to understand how validations work when a value for a property is  not  specified in an insert or update query. For example, consider a  Person  with a  name  and  email  property and then inserted in a query where  email  hasn't been set:  var   query   =   new   Query Person ( context ) \n   .. values . name   =   Bob ;  await   query . insert ();   Because  email  was not set on  Query.values , validations will not be run on that property.  There are two special validators that can require a property to be set, or require that a property  not  be set.  Validate.present()  requires that the associated property must have a value. A property with this validator must be provided each time the object is inserted or updated. Like all validators,  Validate.present()  can be adjusted to be invoked on only inserts or only updates. For example, the following declaration requires that  email  is set on insertion, but doesn't have to be for updates:  @ Validate . present ( onUpdate:   false ,   onInsert:   true )  String   email ;   The inverse of  Validate.present()  is  Validate.absent() . This validation prevents a property from being set. This is useful when a value should be included during insertion, but can't be updated. Here's an example:  @ Validate . absent ( onUpdate:   true ,   onInsert:   false )  String   canOnlyBeSetOnce ;   In the above declaration, the validator is only run on update operations and ensures that the property  canOnlyBeSetOnce  does not have a value. Because this validator is not run on insert operations, there is no restriction when the object is first inserted.  Validators are not run when a value is null. For example, the following insertion explicitly inserts  null  for the property  email :  var   query   =   new   Query Person ( context ) \n   .. values . email   =   null \n   .. values . name   =   Bob ;  await   query . insert ();   Nullability is enforced by  Column.isNullable  property. Consider the following declaration:  @ Column ( nullable:   false )  @ Validate . length ( greaterThan:   10 )  String   name ;   Here, the property  name  must not be null and must be greater than 10 characters long. The behavior of inserting or updating this property is shown in the following table.     Input Value for Name  Validation Runs?  Outcome      Insert value longer than 10 characters  Yes  Successful database insert    Insert value shorter than 10 characters  Yes  Database insert not executed, exception thrown    Insert value not specified  No  Database insert fails with non-null violation, exception thrown    Insert value is null  No  Database insert fails with non-null violation, exception thrown    Update value longer than 10 characters  Yes  Successful database update    Update value shorter than 10 characters  Yes  Database update not executed, exception thrown    Update value not specified  No  Successful database update    Update value is explicit null  No  Successful database update     This behavior allows  ManagedObject T  instances to be partially updated, which also allows for partial PUTs. Partial PUTs can be prevented by adding  Validate.present()  metadata to all properties. While partial PUTs are not idiomatic REST, they are pragmatic software development.  This also means that any custom validator can safely assume that a value passed to  Validate.validate()  is non-null.", 
            "title": "Validation Behavior"
        }, 
        {
            "location": "/db/validations/#other-validator-behavior", 
            "text": "For validators that can't be built by subclassing  Validate , you may override  ManagedObject T .validate() . This method is useful when a validation involves more than one property. Here's an example:  class   Person   extends   ManagedObject _Person   implements   _Person   { \n   @ override \n   ValidationContext   validate ({ Validating   forEvent:   Validating . insert })   { \n    final   ctx   =   super . validate ( forEvent:   forEvent ); \n\n     if   ( a   +   b     10 )   { \n       ctx . addError ( a + b must be greater than 10 ); \n     } \n\n     return   ctx ; \n   }  }   When overriding this method, the  super  implementation must be invoked to run validations managed by annotations. You must return the  ValidationContext  created by the superclass' implementation.", 
            "title": "Other Validator Behavior"
        }, 
        {
            "location": "/db/validations/#skipping-validations", 
            "text": "Validations are only run when values are set via  Query T .values . Values set via  Query T .valueMap  are not validated. Therefore, objects should typically be inserted and updated using  Query T .values  unless validation must be ignored. Here's an example of skipping validation:  var   query   =   new   Query Person ( context ) \n   .. valueMap   =   { \n     name   :   xyz , \n     email   :   whatever \n   };   Skipping validation should be rare.", 
            "title": "Skipping Validations"
        }, 
        {
            "location": "/db/validations/#update-and-insert-callbacks", 
            "text": "ManagedObject T  subclasses may override  willUpdate  and  willInsert  to modify its properties prior to being updated or inserted by a  Query T . For example, a managed object may have updated and created dates that can be guaranteed to be set when inserted or updated:  class   Person   extends   ManagedObject _Person   implements   _Person   { \n   @ override \n   void   willUpdate ()   { \n     updatedAt   =   new   DateTime . now (). toUtc (); \n   } \n\n   @ override \n   void   willInsert ()   { \n     createdAt   =   new   DateTime . now (). toUtc (); \n   }  }  class   _Person   { \n   @ primaryKey \n   int   id ; \n\n   String   name ; \n   DateTime   createdAt ; \n   DateTime   updatedAt ;  }   Note that all operations must be synchronous in these methods.  Both  willUpdate  and  willInsert  are invoked prior the validation phase. Thus, any values set in these methods will be subject to the declared validations of the instance.  Like validations,  willUpdate  and  willInsert   are skipped when using  Query.valueMap .", 
            "title": "Update and Insert Callbacks"
        }, 
        {
            "location": "/db/db_tools/", 
            "text": "Database Migration and Tooling\n\n\nThe \naqueduct db\n command line tool creates and executes \nmigration files\n. A migration file contains SQL commands that create and modify database tables to match your application's data model.\n\n\nMigration Files\n\n\nDatabase tables are described by \nManagedObject\nT\n subclasses and their table definition. Migration files describe a series of database commands that will create or modify a database schema to match an application's \nManagedObject\nT\n declarations. Migration files are executed on a database when an application is first deployed and when changes to the data model occur - like adding new \nManagedObject\nT\n subclasses or changing the name of a \nManagedObject\nT\n property.\n\n\nEach migration file contains only the changes made since the last migration file was generated. For example, let's say that version 1 of your application has two \nManagedObject\nT\n subclasses, \nUser\n and \nPost\n. Before you launch, you create a migration file that creates two tables, one for \nUser\n and one for \nPost\n. A month later, you have developed version 1.1 of your application and now you have a third \nManagedObject\nT\n named \nLocation\n. Prior to deploying version 1.1, you generate a new migration file and execute it. This migration file only contains instructions to create a table for \nLocation\n. The 'final product' of your database is the sum of both migration files.\n\n\nFor this reason, migrations files should be stored in source control.\n\n\nGenerating Migration Files\n\n\nMigration files are automatically generated by running \naqueduct db generate\n in an Aqueduct project directory. This tool finds every \nManagedObject\nT\n subclass and adds commands to the migration file to create a database table that matches its declaration. When subsequent migration files are generated, the difference between the schema created by existing migration files is compared to the current schema declared in an application's code. The commands to rectify those differences are added to the new migration file.\n\n\nThis tool will find \nManagedObject\nT\n subclasses in an application. As a convention, every \nManagedObject\nT\n subclass is declared in its own file in \nlib/model/\n. For example, a \nUser\n class is defined in \nlib/model/user.dart\n.\n\n\nMigration files are stored in an application's \nmigrations\n directory. Migration files are prefixed with a version number, a \"0\" padded eight digit number, ad suffixed with \n.migration.dart\n. For example, \n00000001_initial.migration.dart\n is a migration filename. The version number portion of the filename is required, as is the \n.migration.dart\n suffix. The underscore and remainder of the filename are optional and have no effect, they are just a way to name the file. Here is an example of two migration file names:\n\n\n00000001_initial.migration.dart\n00000002_add_user_nickname.migration.dart\n\n\n\n\n\nThe version number of migration files indicate the order in which they are applied. Leading zeros are stripped from the filenames before their version numbers are compared. Version numbers do not necessarily have to be continuous, but doing otherwise is not recommended.\n\n\nMigration files may be created manually or altered after they are generated by \naqueduct db generate\n. A migration file's \nMigration.upgrade\n method makes calls to \nMigration.database\n (an instance of \nSchemaBuilder\n) property to add, remove, and modify tables and columns. Each method invocation creates one or more SQL commands. When a migration file is executed, its \nupgrade\n method is invoked and each command is collected and run within a transaction. The commands are executed in order, and it's important to note that the order often matters.\n\n\nThere are scenarios where there are more than one operation can rectify a change in the data model. It is important to review migration files after they have been generated to ensure the expected behavior.\n\n\nValidating Migration Files\n\n\nMigration files may be altered after they have been generated. This is often the case if \naqueduct db generate\n can't say for certain how a database should change. For example, is renaming a property just renaming a column, or is it deleting a column and creating a new column? The \naqueduct db validate\n tool ensures that the database schema after running all migration files matches the database schema declared by an application's \nManagedObject\nT\ns. Any generated migration file will pass \naqueduct db validate\n. The validate tool will display differences found between the schema in code and the schema created by migration files.\n\n\nListing Migration Files\n\n\nUse \naqueduct db list\n to list all database migration files and their resolved version number.\n\n\nExecuting Migration Files\n\n\nThe tool \naqueduct db upgrade\n will apply migration files to a running database. This tool is run in an application's directory and finds migration files in the \nmigrations\n directory. The connection info for a the running database is provided with the \n--connect\n option. For example, the following would execute migration files on a PostgreSQL database:\n\n\naqueduct db upgrade --connect postgres://username:password@localhost:5432/my_application\n\n\n\n\n\nThe first time \naqueduct db upgrade\n is executed, it creates a version table that keeps the version number and dates of upgrades. When \naqueduct db upgrade\n is ran after the initial migration, the version number is fetched from the database. The tool only runs migration files after the version number stored in the database.\n\n\nConnection information can also be stored in a database configuration file named \ndatabase.yaml\n in the application directory. If this file exists with the following format, \n--connect\n can be omitted and connection information will be read from this file:\n\n\nusername: \nuser\n\npassword: \npassword\n\nhost: \nhost\n\nport: port\ndatabaseName: \ndatabase\n\n\n\n\n\n\nGetting a Database's Version\n\n\nYou can fetch a database's current version number with \naqueduct db get-version\n. This command takes \n--connect\n or a \ndatabase.yaml\n file as described in the previous section to get connection info for the database.\n\n\nWhen to Execute Migration Files\n\n\nDuring development, there is no need to create a migration file for each change. Execute migration files prior to deployment of a new version of an application.\n\n\nYou may delete migration files. When \naqueduct db generate\n is run again, will replay only the existing migration files before determining which commands to add to the new migration file. For example, if you have 10 migration files over time and delete them all - the next generated migration file will contain commands to recreate the entire database schema.", 
            "title": "Migration and Tooling"
        }, 
        {
            "location": "/db/db_tools/#database-migration-and-tooling", 
            "text": "The  aqueduct db  command line tool creates and executes  migration files . A migration file contains SQL commands that create and modify database tables to match your application's data model.", 
            "title": "Database Migration and Tooling"
        }, 
        {
            "location": "/db/db_tools/#migration-files", 
            "text": "Database tables are described by  ManagedObject T  subclasses and their table definition. Migration files describe a series of database commands that will create or modify a database schema to match an application's  ManagedObject T  declarations. Migration files are executed on a database when an application is first deployed and when changes to the data model occur - like adding new  ManagedObject T  subclasses or changing the name of a  ManagedObject T  property.  Each migration file contains only the changes made since the last migration file was generated. For example, let's say that version 1 of your application has two  ManagedObject T  subclasses,  User  and  Post . Before you launch, you create a migration file that creates two tables, one for  User  and one for  Post . A month later, you have developed version 1.1 of your application and now you have a third  ManagedObject T  named  Location . Prior to deploying version 1.1, you generate a new migration file and execute it. This migration file only contains instructions to create a table for  Location . The 'final product' of your database is the sum of both migration files.  For this reason, migrations files should be stored in source control.", 
            "title": "Migration Files"
        }, 
        {
            "location": "/db/db_tools/#generating-migration-files", 
            "text": "Migration files are automatically generated by running  aqueduct db generate  in an Aqueduct project directory. This tool finds every  ManagedObject T  subclass and adds commands to the migration file to create a database table that matches its declaration. When subsequent migration files are generated, the difference between the schema created by existing migration files is compared to the current schema declared in an application's code. The commands to rectify those differences are added to the new migration file.  This tool will find  ManagedObject T  subclasses in an application. As a convention, every  ManagedObject T  subclass is declared in its own file in  lib/model/ . For example, a  User  class is defined in  lib/model/user.dart .  Migration files are stored in an application's  migrations  directory. Migration files are prefixed with a version number, a \"0\" padded eight digit number, ad suffixed with  .migration.dart . For example,  00000001_initial.migration.dart  is a migration filename. The version number portion of the filename is required, as is the  .migration.dart  suffix. The underscore and remainder of the filename are optional and have no effect, they are just a way to name the file. Here is an example of two migration file names:  00000001_initial.migration.dart\n00000002_add_user_nickname.migration.dart  The version number of migration files indicate the order in which they are applied. Leading zeros are stripped from the filenames before their version numbers are compared. Version numbers do not necessarily have to be continuous, but doing otherwise is not recommended.  Migration files may be created manually or altered after they are generated by  aqueduct db generate . A migration file's  Migration.upgrade  method makes calls to  Migration.database  (an instance of  SchemaBuilder ) property to add, remove, and modify tables and columns. Each method invocation creates one or more SQL commands. When a migration file is executed, its  upgrade  method is invoked and each command is collected and run within a transaction. The commands are executed in order, and it's important to note that the order often matters.  There are scenarios where there are more than one operation can rectify a change in the data model. It is important to review migration files after they have been generated to ensure the expected behavior.", 
            "title": "Generating Migration Files"
        }, 
        {
            "location": "/db/db_tools/#validating-migration-files", 
            "text": "Migration files may be altered after they have been generated. This is often the case if  aqueduct db generate  can't say for certain how a database should change. For example, is renaming a property just renaming a column, or is it deleting a column and creating a new column? The  aqueduct db validate  tool ensures that the database schema after running all migration files matches the database schema declared by an application's  ManagedObject T s. Any generated migration file will pass  aqueduct db validate . The validate tool will display differences found between the schema in code and the schema created by migration files.", 
            "title": "Validating Migration Files"
        }, 
        {
            "location": "/db/db_tools/#listing-migration-files", 
            "text": "Use  aqueduct db list  to list all database migration files and their resolved version number.", 
            "title": "Listing Migration Files"
        }, 
        {
            "location": "/db/db_tools/#executing-migration-files", 
            "text": "The tool  aqueduct db upgrade  will apply migration files to a running database. This tool is run in an application's directory and finds migration files in the  migrations  directory. The connection info for a the running database is provided with the  --connect  option. For example, the following would execute migration files on a PostgreSQL database:  aqueduct db upgrade --connect postgres://username:password@localhost:5432/my_application  The first time  aqueduct db upgrade  is executed, it creates a version table that keeps the version number and dates of upgrades. When  aqueduct db upgrade  is ran after the initial migration, the version number is fetched from the database. The tool only runs migration files after the version number stored in the database.  Connection information can also be stored in a database configuration file named  database.yaml  in the application directory. If this file exists with the following format,  --connect  can be omitted and connection information will be read from this file:  username:  user \npassword:  password \nhost:  host \nport: port\ndatabaseName:  database", 
            "title": "Executing Migration Files"
        }, 
        {
            "location": "/db/db_tools/#getting-a-databases-version", 
            "text": "You can fetch a database's current version number with  aqueduct db get-version . This command takes  --connect  or a  database.yaml  file as described in the previous section to get connection info for the database.", 
            "title": "Getting a Database's Version"
        }, 
        {
            "location": "/db/db_tools/#when-to-execute-migration-files", 
            "text": "During development, there is no need to create a migration file for each change. Execute migration files prior to deployment of a new version of an application.  You may delete migration files. When  aqueduct db generate  is run again, will replay only the existing migration files before determining which commands to add to the new migration file. For example, if you have 10 migration files over time and delete them all - the next generated migration file will contain commands to recreate the entire database schema.", 
            "title": "When to Execute Migration Files"
        }, 
        {
            "location": "/db/json_columns/", 
            "text": "JSON Document Storage\n\n\nLearn how to store unstructured, binary JSON data in \nManagedObject\nT\n properties.\n\n\nJSON Columns in Relational Databases\n\n\nPostgreSQL supports many column data types like integers, strings, booleans and dates. A column may also be JSON data. This allows for storing unstructured data and simple objects in a table column. The data from JSON columns can be fetched all at once, or in pieces. Elements of JSON data can be used to filter the results of a query.\n\n\nThe Document Data Type\n\n\nJSON document columns are added to a database table by declaring a \nDocument\n property in a \nManagedObject\nT\n's table definition. In PostgreSQL, a \nDocument\n column data type is \njsonb\n. A document column can only contain JSON-encodable data. This data is typically a \nMap\n or \nList\n that contains only JSON-encodable data. The following \nManagedObject\nT\n declaration will have a \ncontents\n column of type \njsonb\n.\n\n\nclass\n \nEvent\n \nextends\n \nManagedObject\n_Event\n \nimplements\n \n_Event\n \n{}\n\n\nclass\n \n_Event\n \n{\n\n  \n@\nprimaryKey\n\n  \nint\n \nid\n;\n\n\n  \n@\nColumn\n(\nindexed:\n \ntrue\n)\n\n  \nDateTime\n \ntimestamp\n;\n\n\n  \nDocument\n \ncontents\n;\n\n\n}\n\n\n\n\n\n\nA \nDocument\n object has a \ndata\n property to hold its JSON-encodable data. When instantiating \nDocument\n, this property defaults to null unless a value has been provided to the optional, ordered parameter in its constructor.\n\n\nfinal\n \ndoc\n \n=\n \nnew\n \nDocument\n();\n\n\nassert\n(\ndoc\n.\ndata\n \n==\n \nnull\n);\n\n\n\nfinal\n \ndoc\n \n=\n \nnew\n \nDocument\n({\nkey\n:\n \nvalue\n});\n\n\nassert\n(\ndoc\n.\ndata\n \nis\n \nMap\n);\n\n\n\nfinal\n \ndoc\n \n=\n \nnew\n \nDocument\n([\n0\n]);\n\n\nassert\n(\ndoc\n.\ndata\n \nis\n \nList\n);\n\n\n\n\n\n\nThe data in a document can be accessed through its \ndata\n property, or through its subscript operator. \nDocument\n's subscript operator forwards the invocation to its \ndata\n property.\n\n\nfinal\n \ndoc\n \n=\n \nnew\n \nDocument\n({\nkey\n:\n \nvalue\n});\n\n\n\nassert\n(\ndoc\n[\nkey\n]\n \n==\n \ndoc\n.\ndata\n[\nkey\n]);\n\n\n\n\n\n\nThe argument to the subscript operator may be a string (if \ndata\n is a map) or an integer (if \ndata\n is a list).\n\n\nBasic Operations on Document Properties\n\n\nDocument\n columns are like any other type of column, and can therefore be set during an insert or update, and read during a fetch.\n\n\nInserting Rows with Document Properties\n\n\nA \nDocument\n property is first set when inserting with a \nQuery\nT\n. The \nvalues\n property of the query is set to a \nDocument\n object initialized with a JSON-encodable value.\n\n\nfinal\n \nquery\n \n=\n \nQuery\nEvent\n(\ncontext\n)\n\n  \n..\nvalues\n.\ntimestamp\n \n=\n \nDateTime\n.\nnow\n()\n\n  \n..\nvalues\n.\ncontents\n \n=\n \nDocument\n({\n\n    \ntype\n:\n \npush\n,\n\n    \nuser\n:\n \nbob\n,\n\n    \ntags\n:\n \n[\nv1\n]\n\n  \n});\n\n\nfinal\n \nevent\n \n=\n \nawait\n \nquery\n.\ninsert\n();\n  \n\n\n\n\n\nIn the above, the argument to \nDocument\n will be JSON-encoded and stored in the database for column \ncontents\n. If the object can't be encoded as JSON, an exception will be thrown.\n\n\nFetching Rows with Document Properties\n\n\nWhen fetching an object with \nDocument\n properties with a \nQuery\nT\n, you access the column's value through the document's \ndata\n property.\n\n\nfinal\n \nquery\n \n=\n \nQuery\nEvent\n(\ncontext\n)\n\n  \n..\nwhere\n((\ne\n)\n \n=\n \ne\n.\nid\n).\nequalTo\n(\n1\n);\n\n\nfinal\n \nevent1\n \n=\n \nawait\n \nquery\n.\nfetchOne\n();\n\n\nevent1\n.\ncontents\n.\ndata\n \n==\n \n{\n\n  \ntype\n:\n \npush\n,\n\n  \nuser\n:\n \nbob\n,\n\n  \ntags\n:\n \n[\nv1\n]\n\n\n};\n\n\n\n\n\n\nWhen fetching \nDocument\n properties, the JSON data is decoded into the appropriate type. This is likely a \nMap\n or \nList\n, but can be any JSON-encodable object. Because the data stored in a \nDocument\n property is unstructured, the type of \ndata\n is \ndynamic\n. It is good practice to store consistent data structures in a column; i.e., always storing a \nMap\n or always storing a \nList\n.\n\n\nUpdating Rows with Document Properties\n\n\nUpdating a row with \nDocument\n properties works the same as inserting rows.\n\n\nfinal\n \nquery\n \n=\n \nQuery\nEvent\n(\ncontext\n)\n\n  \n..\nwhere\n((\ne\n)\n \n=\n \ne\n.\nid\n).\nequalTo\n(\n1\n)\n\n  \n..\nvalues\n.\ncontents\n \n=\n \nDocument\n({\n\n    \ntype\n:\n \npush\n,\n\n    \nuser\n:\n \nbob\n,\n\n    \ntags\n:\n \n[\nv1\n,\n \nnew\n]\n\n  \n});\n\n\nfinal\n \nevent\n \n=\n \nawait\n \nquery\n.\nupdateOne\n();\n  \n\n\n\n\n\nWhen updating in this way, the document stored in the column is replaced entirely.\n\n\nAccessing Document Values\n\n\nThe type of \nDocument.data\n is \ndynamic\n - it can be any valid JSON type and may be casted to the expected type when used. This data can also be nested - a \nList\n of \nMaps\n, for example. When accessing object keys or list indices, you may use the subscript operator directly on \nDocument\n.\n\n\n// Object Access by key\n\n\nfinal\n \ndoc\n \n=\n \nDocument\n({\nkey\n:\n \nvalue\n});\n\n\nfinal\n \nvalue\n \n=\n \ndoc\n[\nkey\n]\n \n==\n \nvalue\n;\n\n\n\n// List Access by index\n\n\nfinal\n \ndoc\n \n=\n \nDocument\n([\nv1\n,\n \nv2\n]);\n\n\nfinal\n \nvalue\n \n=\n \ndoc\n[\n0\n]\n \n==\n \nv1\n;\n\n\n\n\n\n\nYou can access nested elements with the same syntax:\n\n\nfinal\n \ndoc\n \n=\n \nDocument\n([\n\n  \n{\nid\n:\n \n1\n},\n\n  \n{\nid\n:\n \n2\n}\n\n\n]);\n\n\n\nfinal\n \nobj1\n \n=\n \ndoc\n[\n0\n][\nid\n];\n \n// == 1\n\n\nfinal\n \nobj2\n \n=\n \ndoc\n[\n1\n][\nid\n];\n \n// == 2\n\n\n\n\n\n\nNote that using the subscript operator on a \nDocument\n simply invokes it on its \ndata\n property. Therefore, any subscript values must be valid for Dart \nList\n and \nMap\n types.\n\n\nFetching Sub-documents\n\n\nWhen fetching a \nDocument\n property, the default behavior is to return the entire JSON document as it is stored in the database column. You may fetch parts of the document you need by using \nQuery.returningProperties\n and the subscript operator.\n\n\nfinal\n \nquery\n \n=\n \nQuery\nEvent\n(\ncontext\n)\n\n  \n..\nreturningProperties\n((\ne\n)\n \n=\n \n[\ne\n.\nid\n,\n \ne\n.\ncontents\n[\ntags\n]]);\n\n\nfinal\n \neventsWithTags\n \n=\n \nquery\n.\nfetch\n();\n\n\n\n\n\n\nWhen using the subscript operator on a returned \nDocument\n property, only the value for that key is returned. For example, if the above query were executed and the stored column's value were:\n\n\n{\n\n  \ntype\n:\n \npush\n,\n  \n  \nuser\n:\n \nbob\n,\n\n  \ntags\n:\n \n[\nv1\n]\n  \n\n}\n\n\n\n\n\n\nThe value of \nEvent.contents\n would only contain the array for the key \"tags\":\n\n\n[\nv1\n]\n\n\n\n\n\n\nYou may also index arrays in a JSON column using the same subscript operator, and the subscript operator can also be nested. For example, the following query would fetch the \"tags\" array, and then fetch the string at index 0 from it:\n\n\nfinal\n \nquery\n \n=\n \nQuery\nEvent\n(\ncontext\n)\n\n  \n..\nreturningProperties\n((\ne\n)\n \n=\n \n[\ne\n.\nid\n,\n \ne\n.\ncontents\n[\ntags\n][\n0\n]]);\n\n\nfinal\n \neventsWithFirstTag\n \n=\n \nawait\n \nquery\n.\nfetchOne\n();\n\n\neventsWithFirstTag\n.\ncontents\n.\ndata\n \n==\n \nv1\n;\n\n\n\n\n\n\nIf a key or index does not exist in the JSON document, the value of the returned property will be null. For this reason, you should use null-aware operators when accessing \nDocument.data\n:\n\n\nfinal\n \nquery\n \n=\n \nQuery\nEvent\n(\ncontext\n)\n\n  \n..\nreturningProperties\n((\ne\n)\n \n=\n \n[\ne\n.\nid\n,\n \ne\n.\ncontents\n[\ntags\n][\n7\n]]);\n \n// 7 is out of bounds\n\n\nfinal\n \neventsWithFirstTag\n \n=\n \nawait\n \nquery\n.\nfetchOne\n();\n\n\nif\n \n(\neventsWithFirstTag\n.\ncontents\n?\n.\ndata\n \n==\n \nv1\n)\n \n{\n\n  \n...\n\n\n}\n\n\n\n\n\n\nWhen fetching elements from a JSON array, you may use negative indices to specify a index from the end of the array.\n\n\nfinal\n \nquery\n \n=\n \nQuery\nEvent\n(\ncontext\n)\n\n  \n..\nreturningProperties\n((\ne\n)\n \n=\n \n[\ne\n.\nid\n,\n \ne\n.\ncontents\n[\ntags\n][\n-\n1\n]]);\n\n\nfinal\n \neventsWithLastTag\n \n=\n \nawait\n \nquery\n.\nfetchOne\n();\n\n\n\n\n\n\nNote that you can only fetch a single sub-structure from a \nDocument\n column per query. That is, you may not do the following:\n\n\n// Invalid\n\n\nfinal\n \nquery\n \n=\n \nQuery\nEvent\n(\ncontext\n)\n\n  \n..\nreturningProperties\n((\ne\n)\n \n=\n \n[\ne\n.\nid\n,\n \ne\n.\ncontents\n[\ntype\n],\n \ne\n.\ncontents\n[\nuser\n]]);\n\n\n\n\n\n\nFor operations not supported by \nQuery\nT\n, you may use SQL directly:\n\n\nfinal\n \neventTagCounts\n \n=\n \nawait\n \ncontext\n.\nquery\n(\nSELECT jsonb_array_length(contents-\ntags\n) from _Event\n);", 
            "title": "JSON Document Storage"
        }, 
        {
            "location": "/db/json_columns/#json-document-storage", 
            "text": "Learn how to store unstructured, binary JSON data in  ManagedObject T  properties.", 
            "title": "JSON Document Storage"
        }, 
        {
            "location": "/db/json_columns/#json-columns-in-relational-databases", 
            "text": "PostgreSQL supports many column data types like integers, strings, booleans and dates. A column may also be JSON data. This allows for storing unstructured data and simple objects in a table column. The data from JSON columns can be fetched all at once, or in pieces. Elements of JSON data can be used to filter the results of a query.", 
            "title": "JSON Columns in Relational Databases"
        }, 
        {
            "location": "/db/json_columns/#the-document-data-type", 
            "text": "JSON document columns are added to a database table by declaring a  Document  property in a  ManagedObject T 's table definition. In PostgreSQL, a  Document  column data type is  jsonb . A document column can only contain JSON-encodable data. This data is typically a  Map  or  List  that contains only JSON-encodable data. The following  ManagedObject T  declaration will have a  contents  column of type  jsonb .  class   Event   extends   ManagedObject _Event   implements   _Event   {}  class   _Event   { \n   @ primaryKey \n   int   id ; \n\n   @ Column ( indexed:   true ) \n   DateTime   timestamp ; \n\n   Document   contents ;  }   A  Document  object has a  data  property to hold its JSON-encodable data. When instantiating  Document , this property defaults to null unless a value has been provided to the optional, ordered parameter in its constructor.  final   doc   =   new   Document ();  assert ( doc . data   ==   null );  final   doc   =   new   Document ({ key :   value });  assert ( doc . data   is   Map );  final   doc   =   new   Document ([ 0 ]);  assert ( doc . data   is   List );   The data in a document can be accessed through its  data  property, or through its subscript operator.  Document 's subscript operator forwards the invocation to its  data  property.  final   doc   =   new   Document ({ key :   value });  assert ( doc [ key ]   ==   doc . data [ key ]);   The argument to the subscript operator may be a string (if  data  is a map) or an integer (if  data  is a list).", 
            "title": "The Document Data Type"
        }, 
        {
            "location": "/db/json_columns/#basic-operations-on-document-properties", 
            "text": "Document  columns are like any other type of column, and can therefore be set during an insert or update, and read during a fetch.", 
            "title": "Basic Operations on Document Properties"
        }, 
        {
            "location": "/db/json_columns/#inserting-rows-with-document-properties", 
            "text": "A  Document  property is first set when inserting with a  Query T . The  values  property of the query is set to a  Document  object initialized with a JSON-encodable value.  final   query   =   Query Event ( context ) \n   .. values . timestamp   =   DateTime . now () \n   .. values . contents   =   Document ({ \n     type :   push , \n     user :   bob , \n     tags :   [ v1 ] \n   });  final   event   =   await   query . insert ();     In the above, the argument to  Document  will be JSON-encoded and stored in the database for column  contents . If the object can't be encoded as JSON, an exception will be thrown.", 
            "title": "Inserting Rows with Document Properties"
        }, 
        {
            "location": "/db/json_columns/#fetching-rows-with-document-properties", 
            "text": "When fetching an object with  Document  properties with a  Query T , you access the column's value through the document's  data  property.  final   query   =   Query Event ( context ) \n   .. where (( e )   =   e . id ). equalTo ( 1 );  final   event1   =   await   query . fetchOne ();  event1 . contents . data   ==   { \n   type :   push , \n   user :   bob , \n   tags :   [ v1 ]  };   When fetching  Document  properties, the JSON data is decoded into the appropriate type. This is likely a  Map  or  List , but can be any JSON-encodable object. Because the data stored in a  Document  property is unstructured, the type of  data  is  dynamic . It is good practice to store consistent data structures in a column; i.e., always storing a  Map  or always storing a  List .", 
            "title": "Fetching Rows with Document Properties"
        }, 
        {
            "location": "/db/json_columns/#updating-rows-with-document-properties", 
            "text": "Updating a row with  Document  properties works the same as inserting rows.  final   query   =   Query Event ( context ) \n   .. where (( e )   =   e . id ). equalTo ( 1 ) \n   .. values . contents   =   Document ({ \n     type :   push , \n     user :   bob , \n     tags :   [ v1 ,   new ] \n   });  final   event   =   await   query . updateOne ();     When updating in this way, the document stored in the column is replaced entirely.", 
            "title": "Updating Rows with Document Properties"
        }, 
        {
            "location": "/db/json_columns/#accessing-document-values", 
            "text": "The type of  Document.data  is  dynamic  - it can be any valid JSON type and may be casted to the expected type when used. This data can also be nested - a  List  of  Maps , for example. When accessing object keys or list indices, you may use the subscript operator directly on  Document .  // Object Access by key  final   doc   =   Document ({ key :   value });  final   value   =   doc [ key ]   ==   value ;  // List Access by index  final   doc   =   Document ([ v1 ,   v2 ]);  final   value   =   doc [ 0 ]   ==   v1 ;   You can access nested elements with the same syntax:  final   doc   =   Document ([ \n   { id :   1 }, \n   { id :   2 }  ]);  final   obj1   =   doc [ 0 ][ id ];   // == 1  final   obj2   =   doc [ 1 ][ id ];   // == 2   Note that using the subscript operator on a  Document  simply invokes it on its  data  property. Therefore, any subscript values must be valid for Dart  List  and  Map  types.", 
            "title": "Accessing Document Values"
        }, 
        {
            "location": "/db/json_columns/#fetching-sub-documents", 
            "text": "When fetching a  Document  property, the default behavior is to return the entire JSON document as it is stored in the database column. You may fetch parts of the document you need by using  Query.returningProperties  and the subscript operator.  final   query   =   Query Event ( context ) \n   .. returningProperties (( e )   =   [ e . id ,   e . contents [ tags ]]);  final   eventsWithTags   =   query . fetch ();   When using the subscript operator on a returned  Document  property, only the value for that key is returned. For example, if the above query were executed and the stored column's value were:  { \n   type :   push ,   \n   user :   bob , \n   tags :   [ v1 ]    }   The value of  Event.contents  would only contain the array for the key \"tags\":  [ v1 ]   You may also index arrays in a JSON column using the same subscript operator, and the subscript operator can also be nested. For example, the following query would fetch the \"tags\" array, and then fetch the string at index 0 from it:  final   query   =   Query Event ( context ) \n   .. returningProperties (( e )   =   [ e . id ,   e . contents [ tags ][ 0 ]]);  final   eventsWithFirstTag   =   await   query . fetchOne ();  eventsWithFirstTag . contents . data   ==   v1 ;   If a key or index does not exist in the JSON document, the value of the returned property will be null. For this reason, you should use null-aware operators when accessing  Document.data :  final   query   =   Query Event ( context ) \n   .. returningProperties (( e )   =   [ e . id ,   e . contents [ tags ][ 7 ]]);   // 7 is out of bounds  final   eventsWithFirstTag   =   await   query . fetchOne ();  if   ( eventsWithFirstTag . contents ? . data   ==   v1 )   { \n   ...  }   When fetching elements from a JSON array, you may use negative indices to specify a index from the end of the array.  final   query   =   Query Event ( context ) \n   .. returningProperties (( e )   =   [ e . id ,   e . contents [ tags ][ - 1 ]]);  final   eventsWithLastTag   =   await   query . fetchOne ();   Note that you can only fetch a single sub-structure from a  Document  column per query. That is, you may not do the following:  // Invalid  final   query   =   Query Event ( context ) \n   .. returningProperties (( e )   =   [ e . id ,   e . contents [ type ],   e . contents [ user ]]);   For operations not supported by  Query T , you may use SQL directly:  final   eventTagCounts   =   await   context . query ( SELECT jsonb_array_length(contents- tags ) from _Event );", 
            "title": "Fetching Sub-documents"
        }, 
        {
            "location": "/db/transactions/", 
            "text": "Database Transactions\n\n\nLearn how to execute multiple \nQuery\nT\ns in a database transaction.\n\n\nTransactions\n\n\nConsider an application that keeps employee records. Each employee belongs to a department. Management decides to combine two departments into a totally new department. To do this, the application must insert a new department, set each employee's foreign key reference to that department, and then delete the old departments. It'd look like this:\n\n\n// Create the new department\n\n\nfinal\n \nnewDepartment\n \n=\n \nawait\n \nQuery\n.\ninsertObject\n(\nctx\n,\n \nDepartment\n()..\nname\n \n=\n \nNew Department\n);\n\n\n\n// Set employee\ns departments to the new one\n\n\nfinal\n \nchangeDepartmentQuery\n \n=\n \nQuery\nEmployee\n(\nctx\n)\n\n  \n..\nwhere\n((\ne\n)\n \n=\n \ne\n.\ndepartment\n.\nid\n).\noneOf\n([\n1\n,\n \n2\n])\n      \n  \n..\nvalues\n.\ndepartment\n.\nid\n \n=\n \nnewDepartment\n.\nid\n;\n\n\nawait\n \nchangeDepartmentQuery\n.\nupdate\n();\n\n\n\n// Delete the old ones\n\n\nfinal\n \ndeleteDepartmentQuery\n \n=\n \nQuery\nDepartment\n(\nctx\n)\n\n  \n..\nwhere\n((\ne\n)\n \n=\n \ne\n.\ndepartment\n.\nid\n).\noneOf\n([\n1\n,\n \n2\n]);\n\n\nawait\n \ndeleteDepartmentQuery\n.\ndelete\n();\n      \n\n\n\n\n\nThis change to your database is three separate queries, but they all most complete for the 'transfer' to be successful. If one of them fails, our database can be left in an inconsistent state. For example, if deleting the departments succeeds, but the employees failed to be transferred to the new department, then a lot of employees would be without a department.\n\n\nA database transaction combines queries together as a single unit. If a query in a transaction fails, the previous queries in that transaction are reverted and the remaining queries are aborted. You create transactions by invoking \nManagedContext.transaction\n and writing your queries in its closure argument.\n\n\nawait\n \ncontext\n.\ntransaction\n((\ntransaction\n)\n \nasync\n \n{\n\n  \n// note that \ntransaction\n is the context for each of these queries.\n\n  \nfinal\n \nnewDepartment\n \n=\n \nawait\n \nQuery\n.\ninsertObject\n(\ntransaction\n,\n \nDepartment\n()..\nname\n \n=\n \nNew Department\n);\n\n\n  \nfinal\n \nchangeDepartmentQuery\n \n=\n \nQuery\nEmployee\n(\ntransaction\n)\n\n    \n..\nwhere\n((\ne\n)\n \n=\n \ne\n.\ndepartment\n.\nid\n).\noneOf\n([\n1\n,\n \n2\n])\n      \n    \n..\nvalues\n.\ndepartment\n.\nid\n \n=\n \nnewDepartment\n.\nid\n;\n\n  \nawait\n \nchangeDepartmentQuery\n.\nupdate\n();\n\n\n  \nfinal\n \ndeleteDepartmentQuery\n \n=\n \nQuery\nDepartment\n(\ntransaction\n)\n\n    \n..\nwhere\n((\ne\n)\n \n=\n \ne\n.\ndepartment\n.\nid\n).\noneOf\n([\n1\n,\n \n2\n]);\n\n  \nawait\n \ndeleteDepartmentQuery\n();\n      \n\n});\n\n\n\n\n\n\nAll of the queries in the transaction closure will run in the same transaction. Once they have all succeeded, the \ntransaction\n method's future completes. If an exception is thrown in the closure, the transaction is rolled back and the \ntransaction\n method re-throws that exception.\n\n\nNotice that the context for each query is the \ntransaction\n object passed to the transaction closure. You must use this object when using \nQuery\n in a transaction closure.\n\n\n\n\nFailing to Use the Transaction Context will Deadlock your Application\n\n\n\n\nA \nManagedContext\n has a single database connection. While a transaction is in progress, any query sent by the same connection becomes part of that transaction. Because Dart is asynchronous, a its likely that another request will trigger a database request while a transaction is in progress. For this reason, a context must queue queries from outside of a transaction while the transaction is running. A new context is created for each transaction and the database connection is shared with the original context. If you await on a query on the original context from inside a transaction closure, it won't complete until the transaction completes - but the transaction can't complete because it is awaiting for the query to complete. This will prevent the connection from being used until the transaction or query times out.\n\n\nReturning Values\n\n\nThe value returned from a transaction closure is returned to the caller, so values created within the transaction closure can escape its scope.\n\n\nfinal\n \nemployees\n \n=\n \n[...];\n\n\nfinal\n \ninsertedEmployees\n \n=\n \nawait\n \ncontext\n.\ntransaction\n((\nt\n)\n \nasync\n \n{\n\n  \nreturn\n \nFuture\n.\nwait\n(\nemployees\n.\nmap\n((\ne\n)\n \n=\n \nQuery\n.\ninsertObject\n(\nt\n,\n \ne\n)));\n\n\n});\n\n\n\n\n\n\nRollbacks\n\n\nYou can cancel a transaction and revert its changes at anytime within the transaction closure by throwing a \nRollback\n object.\n\n\ntry\n \n{\n\n  \nawait\n \ncontext\n.\ntransaction\n((\nt\n)\n \nasync\n \n{\n\n    \n// do something\n\n\n    \nif\n \n(\nsomethingIsTrue\n)\n \n{\n\n      \nthrow\n \nRollback\n(\nsomething was true\n);\n    \n    \n}\n\n\n    \n// do something\n\n  \n});\n\n\n}\n \non\n \nRollback\n \ncatch\n \n(\nrollback\n)\n \n{\n\n  \nprint\n(\n${\nrollback\n.\nreason\n}\n);\n \n// prints \nsomething was true\n\n\n}\n\n\n\n\n\n\nWhen you rollback, your transaction fails, the transaction closure is aborted and all changes are reverted. The \ntransaction\n method completes with an error, where the error object is the \nRollback\n.", 
            "title": "Transactions"
        }, 
        {
            "location": "/db/transactions/#database-transactions", 
            "text": "Learn how to execute multiple  Query T s in a database transaction.", 
            "title": "Database Transactions"
        }, 
        {
            "location": "/db/transactions/#transactions", 
            "text": "Consider an application that keeps employee records. Each employee belongs to a department. Management decides to combine two departments into a totally new department. To do this, the application must insert a new department, set each employee's foreign key reference to that department, and then delete the old departments. It'd look like this:  // Create the new department  final   newDepartment   =   await   Query . insertObject ( ctx ,   Department ().. name   =   New Department );  // Set employee s departments to the new one  final   changeDepartmentQuery   =   Query Employee ( ctx ) \n   .. where (( e )   =   e . department . id ). oneOf ([ 1 ,   2 ])       \n   .. values . department . id   =   newDepartment . id ;  await   changeDepartmentQuery . update ();  // Delete the old ones  final   deleteDepartmentQuery   =   Query Department ( ctx ) \n   .. where (( e )   =   e . department . id ). oneOf ([ 1 ,   2 ]);  await   deleteDepartmentQuery . delete ();         This change to your database is three separate queries, but they all most complete for the 'transfer' to be successful. If one of them fails, our database can be left in an inconsistent state. For example, if deleting the departments succeeds, but the employees failed to be transferred to the new department, then a lot of employees would be without a department.  A database transaction combines queries together as a single unit. If a query in a transaction fails, the previous queries in that transaction are reverted and the remaining queries are aborted. You create transactions by invoking  ManagedContext.transaction  and writing your queries in its closure argument.  await   context . transaction (( transaction )   async   { \n   // note that  transaction  is the context for each of these queries. \n   final   newDepartment   =   await   Query . insertObject ( transaction ,   Department ().. name   =   New Department ); \n\n   final   changeDepartmentQuery   =   Query Employee ( transaction ) \n     .. where (( e )   =   e . department . id ). oneOf ([ 1 ,   2 ])       \n     .. values . department . id   =   newDepartment . id ; \n   await   changeDepartmentQuery . update (); \n\n   final   deleteDepartmentQuery   =   Query Department ( transaction ) \n     .. where (( e )   =   e . department . id ). oneOf ([ 1 ,   2 ]); \n   await   deleteDepartmentQuery ();        });   All of the queries in the transaction closure will run in the same transaction. Once they have all succeeded, the  transaction  method's future completes. If an exception is thrown in the closure, the transaction is rolled back and the  transaction  method re-throws that exception.  Notice that the context for each query is the  transaction  object passed to the transaction closure. You must use this object when using  Query  in a transaction closure.   Failing to Use the Transaction Context will Deadlock your Application   A  ManagedContext  has a single database connection. While a transaction is in progress, any query sent by the same connection becomes part of that transaction. Because Dart is asynchronous, a its likely that another request will trigger a database request while a transaction is in progress. For this reason, a context must queue queries from outside of a transaction while the transaction is running. A new context is created for each transaction and the database connection is shared with the original context. If you await on a query on the original context from inside a transaction closure, it won't complete until the transaction completes - but the transaction can't complete because it is awaiting for the query to complete. This will prevent the connection from being used until the transaction or query times out.", 
            "title": "Transactions"
        }, 
        {
            "location": "/db/transactions/#returning-values", 
            "text": "The value returned from a transaction closure is returned to the caller, so values created within the transaction closure can escape its scope.  final   employees   =   [...];  final   insertedEmployees   =   await   context . transaction (( t )   async   { \n   return   Future . wait ( employees . map (( e )   =   Query . insertObject ( t ,   e )));  });", 
            "title": "Returning Values"
        }, 
        {
            "location": "/db/transactions/#rollbacks", 
            "text": "You can cancel a transaction and revert its changes at anytime within the transaction closure by throwing a  Rollback  object.  try   { \n   await   context . transaction (( t )   async   { \n     // do something \n\n     if   ( somethingIsTrue )   { \n       throw   Rollback ( something was true );     \n     } \n\n     // do something \n   });  }   on   Rollback   catch   ( rollback )   { \n   print ( ${ rollback . reason } );   // prints  something was true  }   When you rollback, your transaction fails, the transaction closure is aborted and all changes are reverted. The  transaction  method completes with an error, where the error object is the  Rollback .", 
            "title": "Rollbacks"
        }, 
        {
            "location": "/auth/", 
            "text": "Tasks\n\n\nAqueduct has types to manage authentication and authorization according to the \nOAuth 2.0 specification\n.\n\n\nYou create an \nAuthServer\n service object for your application that manages authentication and authorization logic. An \nAuthServer\n requires a helper object that implements \nAuthServerDelegate\n to handle configuration and required data storage. Most often, this object is a \nManagedAuthDelegate\nT\n that uses the Aqueduct ORM to manage this storage.\n\n\nAn \nAuthServer\n service object is injected into \nAuthorizer\n controllers that protect access to controller channels. An \nAuthServer\n is also injected into \nAuthCodeController\n and \nAuthController\n to provide HTTP APIs for authentication.\n\n\nThe \naqueduct auth\n command-line tool manages configuration - such as client identifier management - for live applications.\n\n\n\n\nGuides\n\n\n\n\nWhat is OAuth 2.0?\n\n\nCreating and Using AuthServers\n\n\nSecuring Routes with Authorizer\n\n\nAdding Authentication Endpoints\n\n\nUsing Scopes to Control Access\n\n\nManaging OAuth 2.0 Clients", 
            "title": "Overview"
        }, 
        {
            "location": "/auth/#tasks", 
            "text": "Aqueduct has types to manage authentication and authorization according to the  OAuth 2.0 specification .  You create an  AuthServer  service object for your application that manages authentication and authorization logic. An  AuthServer  requires a helper object that implements  AuthServerDelegate  to handle configuration and required data storage. Most often, this object is a  ManagedAuthDelegate T  that uses the Aqueduct ORM to manage this storage.  An  AuthServer  service object is injected into  Authorizer  controllers that protect access to controller channels. An  AuthServer  is also injected into  AuthCodeController  and  AuthController  to provide HTTP APIs for authentication.  The  aqueduct auth  command-line tool manages configuration - such as client identifier management - for live applications.", 
            "title": "Tasks"
        }, 
        {
            "location": "/auth/#guides", 
            "text": "What is OAuth 2.0?  Creating and Using AuthServers  Securing Routes with Authorizer  Adding Authentication Endpoints  Using Scopes to Control Access  Managing OAuth 2.0 Clients", 
            "title": "Guides"
        }, 
        {
            "location": "/auth/server/", 
            "text": "Creating AuthServers to Authenticate and Authorize\n\n\nAn \nAuthServer\n is a service that handles creating, verifying and refreshing authorization tokens. You create an \nAuthServer\n in your application channel and inject into types that deal with authorization. This types include:\n\n\n\n\nAuthorizer\n: middleware controller that protects endpoint controllers from unauthorized access\n\n\nAuthController\n: endpoint controller that grants access tokens\n\n\nAuthCodeController\n: endpoint controller that grants authorization codes to be exchanged for access tokens\n\n\n\n\nAn \nAuthServer\n must persist the data it uses and creates - like client identifiers and access tokens. Storage is often performed by a database, but it can be in memory, a cache or some other medium. Because of the many different storage mediums, an \nAuthServer\n doesn't perform any storage itself - it relies on an instance of \nAuthServerDelegate\n specific to your application. This allows storage to be independent of verification logic.\n\n\nCreating Instances of AuthServer and AuthServerDelegate\n\n\nAuthServerDelegate\n is an interface that an \nAuthServer\n uses to handle storage of client identifiers, tokens and other authorization artifacts. An \nAuthServer\n must be created with a concrete implementation of \nAuthServerDelegate\n. Aqueduct contains a concrete implementation of \nAuthServerDelegate\n that uses the ORM. It is highly recommended to use this implementation instead of implementing your own storage because it has been thoroughly tested and handles cleaning up expired data correctly.\n\n\nThis concrete implementation is named \nManagedAuthDelegate\nT\n. It exists in a sub-package of Aqueduct and must be explicitly imported. Here's an example of creating an \nAuthServer\n and \nManagedAuthDelegate\nT\n:\n\n\nimport\n \npackage:aqueduct/aqueduct.dart\n;\n\n\nimport\n \npackage:aqueduct/managed_auth.dart\n;\n\n\n\nclass\n \nMyApplicationChannel\n \nextends\n \nApplicationChannel\n \n{\n  \n  \nAuthServer\n \nauthServer\n;\n\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \nfinal\n \ncontext\n \n=\n \nManagedContext\n(...);\n\n    \nfinal\n \ndelegate\n \n=\n \nManagedAuthDelegate\nUser\n(\ncontext\n);\n\n    \nauthServer\n \n=\n \nAuthServer\n(\ndelegate\n);\n\n  \n}\n\n\n  \n...\n\n\n}\n\n\n\n\n\n\n(Notice that \nManagedAuthDelegate\n has a type argument - this will be covered in the next section.)\n\n\nWhile \nAuthServer\n has methods for handling authorization tasks, it is rarely used directly. Instead, \nAuthCodeController\n and \nAuthController\n are hooked up to routes to grant authorization tokens through your application's HTTP API. Instances of \nAuthorizer\n secure routes in channels. All of these types invoke the appropriate methods on the \nAuthServer\n. Here's an example \nApplicationChannel\n subclass that sets up and uses authorization:\n\n\nimport\n \npackage:aqueduct/aqueduct.dart\n;\n\n\nimport\n \npackage:aqueduct/managed_auth.dart\n;\n\n\n\nclass\n \nMyApplicationChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \nAuthServer\n \nauthServer\n;\n\n  \nManagedContext\n \ncontext\n;\n\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \ncontext\n \n=\n \nManagedContext\n(...);\n\n    \nfinal\n \ndelegate\n \n=\n \nManagedAuthDelegate\nUser\n(\ncontext\n);\n\n    \nauthServer\n \n=\n \nAuthServer\n(\ndelegate\n);\n\n  \n}\n\n\n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nRouter\n();\n\n\n    \n// Set up auth token route- this grants and refresh tokens\n\n    \nrouter\n.\nroute\n(\n/auth/token\n).\nlink\n(()\n \n=\n \nAuthController\n(\nauthServer\n));\n\n\n    \n// Set up auth code route- this grants temporary access codes that can be exchanged for token\n\n    \nrouter\n.\nroute\n(\n/auth/code\n).\nlink\n(()\n \n=\n \nAuthCodeController\n(\nauthServer\n));\n\n\n    \n// Set up protected route\n\n    \nrouter\n\n      \n.\nroute\n(\n/protected\n)\n\n      \n.\nlink\n(()\n \n=\n \nAuthorizer\n.\nbearer\n(\nauthServer\n))\n\n      \n.\nlink\n(()\n \n=\n \nProtectedController\n());\n\n\n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nFor more details on authorization controllers like \nAuthController\n, see \nAuthorization Controllers\n. For more details on securing routes, see \nAuthorizers\n.\n\n\nUsing ManagedAuthDelegate\n\n\nManagedAuthDelegate\nT\n is a concrete implementation of \nAuthServerDelegate\n, providing storage of authorization tokens and clients for an \nAuthServer\n. Storage is accomplished by Aqueduct's ORM. \nManagedAuthDelegate\nT\n, by default, is not part of the standard \naqueduct\n library. To use this class, an application must import \npackage:aqueduct/managed_auth.dart\n.\n\n\nThe type argument to \nManagedAuthDelegate\nT\n represents the application's concept of a 'user' or 'account' - OAuth 2.0 terminology would refer to this type as a \nresource owner\n. A resource owner must be a \nManagedObject\nT\n subclass that is specific to your application. Its table definition \nmust extend\n \nResourceOwnerTableDefinition\n and the instance type must implement \nManagedAuthResourceOwner\nT\n, where \nT\n is the table definition. A basic definition may look like this:\n\n\nclass\n \nUser\n \nextends\n \nManagedObject\n_User\n\n    \nimplements\n \n_User\n,\n \nManagedAuthResourceOwner\n_User\n \n{\n\n\n}\n\n\n\nclass\n \n_User\n \nextends\n \nResourceOwnerTableDefinition\n \n{\n\n  \n@\nColumn\n(\nunique:\n \ntrue\n)\n\n  \nString\n \nemail\n;\n\n\n}\n\n\n\n\n\n\nBy extending \nResourceOwnerTableDefinition\n in the table definition, the database table has the following four columns:\n\n\n\n\nan integer primary key named \nid\n\n\na unique string \nusername\n\n\na password hash\n\n\na salt used to generate the password hash\n\n\n\n\nA \nResourceOwnerTableDefinition\n also has a \nManagedSet\n of \ntokens\n for each token that has been granted on its behalf.\n\n\nThe interface \nManagedAuthResourceOwner\nT\n is a requirement that ensures the type argument is both a \nManagedObject\nT\n and \nResourceOwnerTableDefinition\n, and serves no other purpose than to restrict \nManagedAuthDelegate\nT\n's type parameter.\n\n\nThis structure allows an application to declare its own 'user' type while still enforcing the needs of Aqueduct's OAuth 2.0 implementation.\n\n\nThe \nmanaged_auth\n library also declares two \nManagedObject\nT\n subclasses. \nManagedAuthToken\n represents instances of authorization tokens and codes, and \nManagedAuthClient\n represents instances of OAuth 2.0 clients. This means that an Aqueduct application that uses \nManagedAuthDelegate\nT\n has a minimum of three database tables: users, tokens and clients.\n\n\nManagedAuthDelegate\nT\n will delete authorization tokens and codes when they are no longer in use. This is determined by how many tokens a resource owner has and the tokens expiration dates. Once a resource owner acquires more than 40 tokens/codes, the oldest tokens/codes (determined by expiration date) are deleted. Effectively, the resource owner is limited to 40 tokens. This number can be changed when instantiating \nManagedAuthDelegate\nT\n:\n\n\nfinal\n \ndelegate\n \n=\n \nManagedAuthDelegate\n(\ncontext\n,\n \ntokenLimit:\n \n20\n);\n\n\n\n\n\n\nConfiguring the Database\n\n\nManagedAuthDelegate\nT\n requires database tables for its users, tokens and clients. Use the \ndatabase command-line tool\n on your project to generate migration scripts and execute them against a database. This tool will see the declarations for your user type, \nManagedAuthToken\n and \nManagedAuthClient\n and create the appropriate tables.", 
            "title": "Setting up Authorization"
        }, 
        {
            "location": "/auth/server/#creating-authservers-to-authenticate-and-authorize", 
            "text": "An  AuthServer  is a service that handles creating, verifying and refreshing authorization tokens. You create an  AuthServer  in your application channel and inject into types that deal with authorization. This types include:   Authorizer : middleware controller that protects endpoint controllers from unauthorized access  AuthController : endpoint controller that grants access tokens  AuthCodeController : endpoint controller that grants authorization codes to be exchanged for access tokens   An  AuthServer  must persist the data it uses and creates - like client identifiers and access tokens. Storage is often performed by a database, but it can be in memory, a cache or some other medium. Because of the many different storage mediums, an  AuthServer  doesn't perform any storage itself - it relies on an instance of  AuthServerDelegate  specific to your application. This allows storage to be independent of verification logic.", 
            "title": "Creating AuthServers to Authenticate and Authorize"
        }, 
        {
            "location": "/auth/server/#creating-instances-of-authserver-and-authserverdelegate", 
            "text": "AuthServerDelegate  is an interface that an  AuthServer  uses to handle storage of client identifiers, tokens and other authorization artifacts. An  AuthServer  must be created with a concrete implementation of  AuthServerDelegate . Aqueduct contains a concrete implementation of  AuthServerDelegate  that uses the ORM. It is highly recommended to use this implementation instead of implementing your own storage because it has been thoroughly tested and handles cleaning up expired data correctly.  This concrete implementation is named  ManagedAuthDelegate T . It exists in a sub-package of Aqueduct and must be explicitly imported. Here's an example of creating an  AuthServer  and  ManagedAuthDelegate T :  import   package:aqueduct/aqueduct.dart ;  import   package:aqueduct/managed_auth.dart ;  class   MyApplicationChannel   extends   ApplicationChannel   {   \n   AuthServer   authServer ; \n\n   @ override \n   Future   prepare ()   async   { \n     final   context   =   ManagedContext (...); \n     final   delegate   =   ManagedAuthDelegate User ( context ); \n     authServer   =   AuthServer ( delegate ); \n   } \n\n   ...  }   (Notice that  ManagedAuthDelegate  has a type argument - this will be covered in the next section.)  While  AuthServer  has methods for handling authorization tasks, it is rarely used directly. Instead,  AuthCodeController  and  AuthController  are hooked up to routes to grant authorization tokens through your application's HTTP API. Instances of  Authorizer  secure routes in channels. All of these types invoke the appropriate methods on the  AuthServer . Here's an example  ApplicationChannel  subclass that sets up and uses authorization:  import   package:aqueduct/aqueduct.dart ;  import   package:aqueduct/managed_auth.dart ;  class   MyApplicationChannel   extends   ApplicationChannel   { \n   AuthServer   authServer ; \n   ManagedContext   context ; \n\n   @ override \n   Future   prepare ()   async   { \n     context   =   ManagedContext (...); \n     final   delegate   =   ManagedAuthDelegate User ( context ); \n     authServer   =   AuthServer ( delegate ); \n   } \n\n   @ override \n   Controller   get   entryPoint   { \n     final   router   =   Router (); \n\n     // Set up auth token route- this grants and refresh tokens \n     router . route ( /auth/token ). link (()   =   AuthController ( authServer )); \n\n     // Set up auth code route- this grants temporary access codes that can be exchanged for token \n     router . route ( /auth/code ). link (()   =   AuthCodeController ( authServer )); \n\n     // Set up protected route \n     router \n       . route ( /protected ) \n       . link (()   =   Authorizer . bearer ( authServer )) \n       . link (()   =   ProtectedController ()); \n\n     return   router ; \n   }  }   For more details on authorization controllers like  AuthController , see  Authorization Controllers . For more details on securing routes, see  Authorizers .", 
            "title": "Creating Instances of AuthServer and AuthServerDelegate"
        }, 
        {
            "location": "/auth/server/#using-managedauthdelegate", 
            "text": "ManagedAuthDelegate T  is a concrete implementation of  AuthServerDelegate , providing storage of authorization tokens and clients for an  AuthServer . Storage is accomplished by Aqueduct's ORM.  ManagedAuthDelegate T , by default, is not part of the standard  aqueduct  library. To use this class, an application must import  package:aqueduct/managed_auth.dart .  The type argument to  ManagedAuthDelegate T  represents the application's concept of a 'user' or 'account' - OAuth 2.0 terminology would refer to this type as a  resource owner . A resource owner must be a  ManagedObject T  subclass that is specific to your application. Its table definition  must extend   ResourceOwnerTableDefinition  and the instance type must implement  ManagedAuthResourceOwner T , where  T  is the table definition. A basic definition may look like this:  class   User   extends   ManagedObject _User \n     implements   _User ,   ManagedAuthResourceOwner _User   {  }  class   _User   extends   ResourceOwnerTableDefinition   { \n   @ Column ( unique:   true ) \n   String   email ;  }   By extending  ResourceOwnerTableDefinition  in the table definition, the database table has the following four columns:   an integer primary key named  id  a unique string  username  a password hash  a salt used to generate the password hash   A  ResourceOwnerTableDefinition  also has a  ManagedSet  of  tokens  for each token that has been granted on its behalf.  The interface  ManagedAuthResourceOwner T  is a requirement that ensures the type argument is both a  ManagedObject T  and  ResourceOwnerTableDefinition , and serves no other purpose than to restrict  ManagedAuthDelegate T 's type parameter.  This structure allows an application to declare its own 'user' type while still enforcing the needs of Aqueduct's OAuth 2.0 implementation.  The  managed_auth  library also declares two  ManagedObject T  subclasses.  ManagedAuthToken  represents instances of authorization tokens and codes, and  ManagedAuthClient  represents instances of OAuth 2.0 clients. This means that an Aqueduct application that uses  ManagedAuthDelegate T  has a minimum of three database tables: users, tokens and clients.  ManagedAuthDelegate T  will delete authorization tokens and codes when they are no longer in use. This is determined by how many tokens a resource owner has and the tokens expiration dates. Once a resource owner acquires more than 40 tokens/codes, the oldest tokens/codes (determined by expiration date) are deleted. Effectively, the resource owner is limited to 40 tokens. This number can be changed when instantiating  ManagedAuthDelegate T :  final   delegate   =   ManagedAuthDelegate ( context ,   tokenLimit:   20 );", 
            "title": "Using ManagedAuthDelegate"
        }, 
        {
            "location": "/auth/server/#configuring-the-database", 
            "text": "ManagedAuthDelegate T  requires database tables for its users, tokens and clients. Use the  database command-line tool  on your project to generate migration scripts and execute them against a database. This tool will see the declarations for your user type,  ManagedAuthToken  and  ManagedAuthClient  and create the appropriate tables.", 
            "title": "Configuring the Database"
        }, 
        {
            "location": "/auth/authorizer/", 
            "text": "Securing Routes with Authorizer\n\n\nInstances of \nAuthorizer\n are added to an application channel to verify HTTP request's authorization information before passing the request onwards. They protect channel access and typically come right after \nroute\n. Here's an example:\n\n\n@\noverride\n\n\nController\n \nget\n \nentryPoint\n \n{\n\n  \nfinal\n \nrouter\n \n=\n \nRouter\n();\n\n\n  \nrouter\n\n    \n.\nroute\n(\n/protected\n)\n\n    \n.\nlink\n(()\n \n=\n \nAuthorizer\n.\nbearer\n(\nauthServer\n))\n\n    \n.\nlink\n(()\n \n=\n \nProtectedController\n());\n\n\n  \nrouter\n\n    \n.\nroute\n(\n/other\n)\n\n    \n.\nlink\n(()\n \n=\n \nAuthorizer\n.\nbasic\n(\nauthServer\n))\n\n    \n.\nlink\n(()\n \n=\n \nOtherProtectedController\n());\n\n\n  \nreturn\n \nrouter\n;\n\n\n}\n\n\n\n\n\n\nAn \nAuthorizer\n parses the Authorization header of an HTTP request. The named constructors of \nAuthorizer\n indicate the required format of Authorization header. The \nAuthorization.bearer()\n constructor expects an OAuth 2.0 bearer token in the header, which has the following format:\n\n\nAuthorization\n:\n \nBearer\n \n768\niuzjkx82jkasjkd9z9\n\n\n\n\n\n\nAuthorizer.basic\n expects HTTP Basic Authentication, where the username and password are joined with the colon character (\n:\n) and Base 64-encoded:\n\n\n// \ndXNlcjpwYXNzd29yZA==\n is \nuser:password\n\nAuthorization: Basic dXNlcjpwYXNzd29yZA==\n\n\n\n\n\nIf the header can't be parsed, doesn't exist or is in the wrong format, an \nAuthorizer\n responds to the request with a 401 status code and prevents the next controller from receiving the request.\n\n\nOnce parsed, an \nAuthorizer\n sends the information - either the bearer token, or the username and password - to its \nAuthServer\n for verification. If the \nAuthServer\n rejects the authorization info, the \nAuthorizer\n responds to the request with a 401 status code and prevents the next controller from receiving the request. Otherwise, the request continues to the next controller.\n\n\nFor \nAuthorizer.bearer\n, the value in a request's header must be a valid, unexpired access token. These types of authorizers are used when an endpoint requires a logged in user.\n\n\nFor \nAuthorizer.basic\n authorizers, credentials are verified by finding an OAuth 2.0 client identifier and ensuring its client secret matches. Routes with this type of authorizer are known as \nclient authenticated\n routes. These types of authorizers are used when an endpoint requires a valid client application, but not a logged in user.\n\n\nAuthorizer and OAuth 2.0 Scope\n\n\nAn \nAuthorizer\n may restrict access to controllers based on the scope of the request's bearer token. By default, an \nAuthorizer.bearer\n allows any valid bearer token to pass through it. If desired, an \nAuthorizer\n is initialized with a list of required scopes. A request may only pass the \nAuthorizer\n if it has access to \nall\n scopes listed in the \nAuthorizer\n. For example, the following requires at least \nuser:posts\n and \nlocation\n scope:\n\n\nrouter\n\n  \n.\nroute\n(\n/checkin\n)\n\n  \n.\nlink\n(()\n \n=\n \nAuthorizer\n.\nbearer\n(\nauthServer\n,\n \nscopes:\n \n[\nuser:posts\n,\n \nlocation\n]))\n\n  \n.\nlink\n(()\n \n=\n \nCheckInController\n());\n\n\n\n\n\n\nNote that you don't have to use an \nAuthorizer\n to restrict access based on scope. A controller has access to scope information after the request has passed through an \nAuthorizer\n, so it can use the scope to make more granular authorization decisions.\n\n\nAuthorization Objects\n\n\nA bearer token represents a granted authorization - at some point in the past, a user provided their credentials and the token is the proof of that. When a bearer token is sent in the authorization header of an HTTP request, the application can look up which user the token is for and the client application it was issued for. This information is stored in an instance of \nAuthorization\n after the token has been verified and is assigned to \nRequest.authorization\n.\n\n\nControllers protected by an \nAuthorizer\n can access this information to further determine their behavior. For example, a social networking application might have a \n/news_feed\n endpoint protected by an \nAuthorizer\n. When an authenticated user makes a request for \n/news_feed\n, the controller will return that user's news feed. It can determine this by using the \nAuthorization\n:\n\n\nclass\n \nNewsFeedController\n \nextends\n \nResourceController\n \n{\n\n  \nNewsFeedController\n(\nthis\n.\ncontext\n);\n\n\n  \nManagedContext\n \ncontext\n;\n\n\n  \n@\nOperation\n.\nget\n()\n\n  \nFuture\nResponse\n \ngetNewsFeed\n()\n \nasync\n \n{\n\n    \nvar\n \nforUserID\n \n=\n \nrequest\n.\nauthorization\n.\nownerID\n;\n\n\n    \nvar\n \nquery\n \n=\n \nQuery\nPost\n(\ncontext\n)\n\n      \n..\nwhere\n((\np\n)\n \n=\n \np\n.\nauthor\n).\nidentifiedBy\n(\nforUserID\n);\n\n\n    \nreturn\n \nResponse\n.\nok\n(\nawait\n \nquery\n.\nfetch\n());\n\n  \n}\n\n\n}\n\n\n\n\n\n\nIn the above controller, it's impossible for a user to access another user's posts.\n\n\nAuthorization\n objects also retain the scope of an access token so that a controller can make more granular decisions about the information/action in the endpoint. Checking whether an \nAuthorization\n has access to a particular scope is accomplished by either looking at the list of its \nscopes\n or using \nauthorizedForScope\n:\n\n\nclass\n \nNewsFeedController\n \nextends\n \nResourceController\n \n{\n\n  \nNewsFeedController\n(\nthis\n.\ncontext\n);\n\n\n  \nManagedContext\n \ncontext\n;\n\n\n  \n@\nOperation\n.\nget\n()\n\n  \nFuture\nResponse\n \ngetNewsFeed\n()\n \nasync\n \n{\n\n    \nif\n \n(\n!\nrequest\n.\nauthorization\n.\nauthorizedForScope\n(\nuser:feed\n))\n \n{\n\n      \nreturn\n \nResponse\n.\nunauthorized\n();\n\n    \n}\n\n\n    \nvar\n \nforUserID\n \n=\n \nrequest\n.\nauthorization\n.\nownerID\n;\n\n\n    \nvar\n \nquery\n \n=\n \nQuery\nPost\n(\ncontext\n)\n\n      \n..\nwhere\n((\np\n)\n \n=\n \np\n.\nauthor\n).\nidentifiedBy\n(\nforUserID\n);\n\n\n    \nreturn\n \nResponse\n.\nok\n(\nawait\n \nquery\n.\nfetch\n());\n\n  \n}\n\n\n}\n\n\n\n\n\n\nUsing Authorizers Without AuthServer\n\n\nThroughout this guide, the argument to an instance of \nAuthorizer\n has been referred to as an \nAuthServer\n. This is true - but only because \nAuthServer\n implements \nAuthValidator\n. \nAuthValidator\n is an interface for verifying bearer tokens and username/password credentials.\n\n\nYou may use \nAuthorizer\n without using \nAuthServer\n. For example, an application that doesn't use OAuth 2.0 could provide its own \nAuthValidator\n interface to simply verify the username and password of every request:\n\n\nclass\n \nBasicValidator\n \nimplements\n \nAuthValidator\n \n{\n\n  \n@\noverride\n\n  \nFutureOr\nAuthorization\n \nvalidate\nT\n(\nAuthorizationParser\nT\n \nparser\n,\n \nT\n \nauthorizationData\n,\n \n{\nList\nAuthScope\n \nrequiredScope\n})\n \n{}\n\n    \nvar\n \nuser\n \n=\n \nawait\n \nuserForName\n(\nusernameAndPassword\n.\nusername\n);\n\n    \nif\n \n(\nuser\n.\npassword\n \n==\n \nhash\n(\nusernameAndPassword\n.\npassword\n,\n \nuser\n.\nsalt\n))\n \n{\n\n      \nreturn\n \nAuthorization\n(...);\n\n    \n}\n\n\n    \n// Will end up creating a 401 Not Authorized Response\n\n    \nreturn\n \nnull\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nThe \nvalidate\n method must return an \nAuthorization\n if the credentials are valid, or null if they are not. The \nparser\n lets the validator know the format of the Authorization header (e.g., 'Basic' or 'Bearer') and \nauthorizationData\n is the meaningful information in that header. There are two concrete types of \nAuthorizationParser\nT\n: \nAuthorizationBasicParser\n and \nAuthorizationBearerParser\n. The authorization data for a basic parser is an instance of \nAuthBasicCredentials\n that contain the username and password, while the bearer parser's authorization data is the bearer token string.", 
            "title": "Protecting Routes"
        }, 
        {
            "location": "/auth/authorizer/#securing-routes-with-authorizer", 
            "text": "Instances of  Authorizer  are added to an application channel to verify HTTP request's authorization information before passing the request onwards. They protect channel access and typically come right after  route . Here's an example:  @ override  Controller   get   entryPoint   { \n   final   router   =   Router (); \n\n   router \n     . route ( /protected ) \n     . link (()   =   Authorizer . bearer ( authServer )) \n     . link (()   =   ProtectedController ()); \n\n   router \n     . route ( /other ) \n     . link (()   =   Authorizer . basic ( authServer )) \n     . link (()   =   OtherProtectedController ()); \n\n   return   router ;  }   An  Authorizer  parses the Authorization header of an HTTP request. The named constructors of  Authorizer  indicate the required format of Authorization header. The  Authorization.bearer()  constructor expects an OAuth 2.0 bearer token in the header, which has the following format:  Authorization :   Bearer   768 iuzjkx82jkasjkd9z9   Authorizer.basic  expects HTTP Basic Authentication, where the username and password are joined with the colon character ( : ) and Base 64-encoded:  //  dXNlcjpwYXNzd29yZA==  is  user:password \nAuthorization: Basic dXNlcjpwYXNzd29yZA==  If the header can't be parsed, doesn't exist or is in the wrong format, an  Authorizer  responds to the request with a 401 status code and prevents the next controller from receiving the request.  Once parsed, an  Authorizer  sends the information - either the bearer token, or the username and password - to its  AuthServer  for verification. If the  AuthServer  rejects the authorization info, the  Authorizer  responds to the request with a 401 status code and prevents the next controller from receiving the request. Otherwise, the request continues to the next controller.  For  Authorizer.bearer , the value in a request's header must be a valid, unexpired access token. These types of authorizers are used when an endpoint requires a logged in user.  For  Authorizer.basic  authorizers, credentials are verified by finding an OAuth 2.0 client identifier and ensuring its client secret matches. Routes with this type of authorizer are known as  client authenticated  routes. These types of authorizers are used when an endpoint requires a valid client application, but not a logged in user.", 
            "title": "Securing Routes with Authorizer"
        }, 
        {
            "location": "/auth/authorizer/#authorizer-and-oauth-20-scope", 
            "text": "An  Authorizer  may restrict access to controllers based on the scope of the request's bearer token. By default, an  Authorizer.bearer  allows any valid bearer token to pass through it. If desired, an  Authorizer  is initialized with a list of required scopes. A request may only pass the  Authorizer  if it has access to  all  scopes listed in the  Authorizer . For example, the following requires at least  user:posts  and  location  scope:  router \n   . route ( /checkin ) \n   . link (()   =   Authorizer . bearer ( authServer ,   scopes:   [ user:posts ,   location ])) \n   . link (()   =   CheckInController ());   Note that you don't have to use an  Authorizer  to restrict access based on scope. A controller has access to scope information after the request has passed through an  Authorizer , so it can use the scope to make more granular authorization decisions.", 
            "title": "Authorizer and OAuth 2.0 Scope"
        }, 
        {
            "location": "/auth/authorizer/#authorization-objects", 
            "text": "A bearer token represents a granted authorization - at some point in the past, a user provided their credentials and the token is the proof of that. When a bearer token is sent in the authorization header of an HTTP request, the application can look up which user the token is for and the client application it was issued for. This information is stored in an instance of  Authorization  after the token has been verified and is assigned to  Request.authorization .  Controllers protected by an  Authorizer  can access this information to further determine their behavior. For example, a social networking application might have a  /news_feed  endpoint protected by an  Authorizer . When an authenticated user makes a request for  /news_feed , the controller will return that user's news feed. It can determine this by using the  Authorization :  class   NewsFeedController   extends   ResourceController   { \n   NewsFeedController ( this . context ); \n\n   ManagedContext   context ; \n\n   @ Operation . get () \n   Future Response   getNewsFeed ()   async   { \n     var   forUserID   =   request . authorization . ownerID ; \n\n     var   query   =   Query Post ( context ) \n       .. where (( p )   =   p . author ). identifiedBy ( forUserID ); \n\n     return   Response . ok ( await   query . fetch ()); \n   }  }   In the above controller, it's impossible for a user to access another user's posts.  Authorization  objects also retain the scope of an access token so that a controller can make more granular decisions about the information/action in the endpoint. Checking whether an  Authorization  has access to a particular scope is accomplished by either looking at the list of its  scopes  or using  authorizedForScope :  class   NewsFeedController   extends   ResourceController   { \n   NewsFeedController ( this . context ); \n\n   ManagedContext   context ; \n\n   @ Operation . get () \n   Future Response   getNewsFeed ()   async   { \n     if   ( ! request . authorization . authorizedForScope ( user:feed ))   { \n       return   Response . unauthorized (); \n     } \n\n     var   forUserID   =   request . authorization . ownerID ; \n\n     var   query   =   Query Post ( context ) \n       .. where (( p )   =   p . author ). identifiedBy ( forUserID ); \n\n     return   Response . ok ( await   query . fetch ()); \n   }  }", 
            "title": "Authorization Objects"
        }, 
        {
            "location": "/auth/authorizer/#using-authorizers-without-authserver", 
            "text": "Throughout this guide, the argument to an instance of  Authorizer  has been referred to as an  AuthServer . This is true - but only because  AuthServer  implements  AuthValidator .  AuthValidator  is an interface for verifying bearer tokens and username/password credentials.  You may use  Authorizer  without using  AuthServer . For example, an application that doesn't use OAuth 2.0 could provide its own  AuthValidator  interface to simply verify the username and password of every request:  class   BasicValidator   implements   AuthValidator   { \n   @ override \n   FutureOr Authorization   validate T ( AuthorizationParser T   parser ,   T   authorizationData ,   { List AuthScope   requiredScope })   {} \n     var   user   =   await   userForName ( usernameAndPassword . username ); \n     if   ( user . password   ==   hash ( usernameAndPassword . password ,   user . salt ))   { \n       return   Authorization (...); \n     } \n\n     // Will end up creating a 401 Not Authorized Response \n     return   null ; \n   }  }   The  validate  method must return an  Authorization  if the credentials are valid, or null if they are not. The  parser  lets the validator know the format of the Authorization header (e.g., 'Basic' or 'Bearer') and  authorizationData  is the meaningful information in that header. There are two concrete types of  AuthorizationParser T :  AuthorizationBasicParser  and  AuthorizationBearerParser . The authorization data for a basic parser is an instance of  AuthBasicCredentials  that contain the username and password, while the bearer parser's authorization data is the bearer token string.", 
            "title": "Using Authorizers Without AuthServer"
        }, 
        {
            "location": "/auth/controllers/", 
            "text": "Issue Access Tokens with AuthController\n\n\nAn application using Aqueduct's Auth framework must have endpoints to exchange credentials for access tokens. While a developer could implement these endpoints themselves and talk directly to an \nAuthServer\n, the OAuth 2.0 specification is where happiness goes to die. Therefore, there exist two \nController\ns in Aqueduct that handle granting and refreshing authorization tokens - \nAuthController\n and \nAuthCodeController\n.\n\n\nIssue, Refresh and Exchange Tokens with AuthController\n\n\nAn \nAuthController\n grants access tokens and refreshes them. It also exchanges authorization codes obtained from \nAuthCodeController\n for access tokens.\n\n\nUsing an \nAuthController\n in an application is straightforward - hook it up to a \nRouter\n and pass it an \nAuthServer\n.\n\n\n@\noverride\n\n\nController\n \nget\n \nentryPoint\n \n{\n\n  \nfinal\n \nrouter\n \n=\n \nRouter\n();\n\n\n  \nrouter\n\n    \n.\nroute\n(\n/auth/token\n)\n\n    \n.\nlink\n(()\n \n=\n \nAuthController\n(\nauthServer\n));\n\n\n  \nreturn\n \nrouter\n;\n\n\n}\n\n\n\n\n\n\nTo grant an access token, a client application sends a HTTP \nPOST\n to the controller. The request must have:\n\n\n\n\nan Authorization header with the Client ID and Client Secret (if one exists) and,\n\n\na \nx-www-form-urlencoded\n body with the username and password of the authenticating user.\n\n\n\n\nThe body must also contain the key-value pair \ngrant_type=password\n. For example, the following Dart code will initiate successful authentication:\n\n\nvar\n \nclientID\n \n=\n \ncom.app.demo\n;\n\n\nvar\n \nclientSecret\n \n=\n \nmySecret\n;\n\n\nvar\n \nbody\n \n=\n \nusername=bob@stablekernel.com\npassword=foobar\ngrant_type=password\n;\n\n\nvar\n \nclientCredentials\n \n=\n \nBase64Encoder\n().\nconvert\n(\n$\nclientID\n:\n$\nclientSecret\n.\ncodeUnits\n);\n\n\n\nvar\n \nresponse\n \n=\n \nawait\n \nhttp\n.\npost\n(\n\n  \nhttps://stablekernel.com/auth/token\n,\n\n  \nheaders:\n \n{\n\n    \nContent-Type\n:\n \napplication/x-www-form-urlencoded\n,\n\n    \nAuthorization\n:\n \nBasic \n$\nclientCredentials\n\n  \n},\n\n  \nbody:\n \nbody\n);\n\n\n\n\n\n\nIf the OAuth 2.0 client ID is public - that is, it does not have a client secret - the secret is omitted from the authorization header:\n\n\n// Notice that the separating colon (:) is still present.\n\n\nvar\n \nclientCredentials\n \n=\n \nBase64Encoder\n().\nconvert\n(\n$\nclientID\n:\n.\ncodeUnits\n);\n\n\n\n\n\n\nThe response to a password token request is a JSON body that follows the OAuth 2.0 specification:\n\n\n{\n  \naccess_token\n: \n...\n\n  \nrefresh_token\n: \n...\n,\n  \nexpires_in\n: 3600,\n  \ntoken_type\n: \nbearer\n\n}\n\n\n\n\n\n\n\nThe \nexpires_in\n field is a computed property based on the delta of the issue date and expiration date. You should avoid manually editing the values for the columns \nissuedate\n and \nexpirationdate\n\n\n\n\nTokens are refreshed through the same endpoint, but with a payload that only contains the refresh token and \ngrant_type=refresh_token\n.\n\n\ngrant_type=refresh_token\nrefresh_token=kjasdiuz9u3namnsd\n\n\n\n\n\nSee \nAqueduct Auth CLI\n for more details on creating OAuth 2.0 client identifier and secrets.\n\n\nIf an Aqueduct application is using scope, an additional \nscope\n parameter can contain a space-delimited list of requested authorization scope. Only allowed scopes are returned and granted, and if no scopes are allowed then the request fails. If scope is provided, granted scope will be available in the response body.\n\n\nIt is important that an \nAuthorizer\n \nmust not\n protect instances of \nAuthController\n. The Authorization header is parsed and verified by \nAuthController\n.\n\n\nOnce granted, an access token can be used to pass \nAuthorizer.bearer()\ns in the application channel.\n\n\nIssue Authorization Codes with AuthCodeController\n\n\nAn \nAuthCodeController\n manages the OAuth 2.0 authorization code flow. The authorization code flow is used when an Aqueduct application allows third party applications access to authorized resources.\n\n\nLet's say you've built an Aqueduct application that allows people to store notes for themselves. Now, a friend approaches you with their application that is a to-do list. Instead of building their own note-taking feature, your friend wants users of their application to access the notes the user has stored in your application. While trustworthy, you don't want your friend to have access to the username and passwords of your subscribers.\n\n\nYour friend adds a link to their application that takes the user to an HTML page hosted by your server. The user enters their credentials in this page, which sends a \nPOST\n request to your server. Your server responds by redirecting the user's browser back into your friend's application. An \nauthorization code\n is included in the query string of the redirect URL.\n\n\nYour friend's application parses the code from the URL and sends it to \ntheir\n server. Behind the scenes, their server exchanges this code with your server for an access token.\n\n\nAn \nAuthCodeController\n responds to both \nGET\n and \nPOST\n requests. When issued a \nGET\n, it serves up a HTML page with a login form. This login form's submit action sends a \nPOST\n to the same endpoint with the username and password of the user. Upon success, the response from the \nPOST\n is a 302 redirect with an authorization code.\n\n\nSetting up an \nAuthCodeController\n is nearly as simple as setting up an \nAuthController\n, but requires a function that renders the HTML login form. Here's an example:\n\n\n@\noverride\n\n\nController\n \nget\n \nentryPoint\n \n{\n\n  \nfinal\n \nrouter\n \n=\n \nRouter\n();\n\n\n  \nrouter\n\n    \n.\nroute\n(\n/auth/code\n)\n\n    \n.\nlink\n(()\n \n=\n \nAuthCodeController\n(\n\n      \nauthServer\n,\n \nrenderAuthorizationPageHTML:\n \nrenderLogin\n));\n\n\n  \nreturn\n \nrouter\n;\n\n\n}\n\n\n\nFuture\nString\n \nrenderLogin\n(\n\n    \nAuthCodeController\n \nrequestingController\n,\n\n    \nURI\n \nrequestURI\n,\n\n    \nMap\nString\n,\n \nString\n \nqueryParameters\n)\n \n{\n\n  \nvar\n \nhtml\n \n=\n \nHTMLRenderer\n.\ntemplateWithSubstitutions\n(\n\n    \nweb/login.html\n,\n \nrequestURI\n,\n \nqueryParameters\n);\n\n\n  \nreturn\n \nhtml\n;\n\n\n}\n\n\n\n\n\n\nIt is important that all values passed to HTML rendering function are sent in the form's query parameters - they contain necessary security components and scope information.\n\n\nWhen your friend's application links to your login page - \nGET /auth/code\n - they must include three query parameters: \nstate\n, \nclient_id\n, \nresponse_type\n. They may optionally include \nscope\n.\n\n\nhttps://stablekernel.com/auth/code?client_id=friend.app\nresponse_type=code\nstate=87uijn3rkja\n\n\n\n\n\nThe value of \nclient_id\n must be created specifically for your friend's application and stored in your database. (See more on generating client identifiers with \naqueduct auth\n in \nAqueduct Auth CLI\n.) The \nresponse_type\n must always be \ncode\n. The \nstate\n must be a value your friend's application creates - it is often some random value like a session cookie.\n\n\nWhen a user of your friend's application goes through this process, they are redirected back into your friend's application. Both the generated authorization code and the value for \nstate\n will be query parameters in the URL. That redirect URL will look like:\n\n\nhttps://friends.app/code_callback?code=abcd672kk\nstate=87uijn3rkja\n\n\n\n\n\nThe redirect URL is pre-determined when generating the client identifier with \naqueduct auth\n.\n\n\nYour friend's application verifies that \nstate\n matches the \nstate\n they sent in \nGET /auth/code\n. They then send the \ncode\n to their server. The server then exchanges this code with your server by issuing a \nPOST\n to an \nAuthController\n - \nNOT\n the \nAuthCodeController\n - with the following \napplication/x-www-form-urlencoded\n body:\n\n\ngrant_type=authorization_code\ncode=abcd672kk\n\n\n\n\n\nAn access token will be returned to the server which your friend then stores in their database. Whenever one of their users makes a request that requires accessing your application's data, they will execute requests with that access token.", 
            "title": "Issuing Access Tokens"
        }, 
        {
            "location": "/auth/controllers/#issue-access-tokens-with-authcontroller", 
            "text": "An application using Aqueduct's Auth framework must have endpoints to exchange credentials for access tokens. While a developer could implement these endpoints themselves and talk directly to an  AuthServer , the OAuth 2.0 specification is where happiness goes to die. Therefore, there exist two  Controller s in Aqueduct that handle granting and refreshing authorization tokens -  AuthController  and  AuthCodeController .", 
            "title": "Issue Access Tokens with AuthController"
        }, 
        {
            "location": "/auth/controllers/#issue-refresh-and-exchange-tokens-with-authcontroller", 
            "text": "An  AuthController  grants access tokens and refreshes them. It also exchanges authorization codes obtained from  AuthCodeController  for access tokens.  Using an  AuthController  in an application is straightforward - hook it up to a  Router  and pass it an  AuthServer .  @ override  Controller   get   entryPoint   { \n   final   router   =   Router (); \n\n   router \n     . route ( /auth/token ) \n     . link (()   =   AuthController ( authServer )); \n\n   return   router ;  }   To grant an access token, a client application sends a HTTP  POST  to the controller. The request must have:   an Authorization header with the Client ID and Client Secret (if one exists) and,  a  x-www-form-urlencoded  body with the username and password of the authenticating user.   The body must also contain the key-value pair  grant_type=password . For example, the following Dart code will initiate successful authentication:  var   clientID   =   com.app.demo ;  var   clientSecret   =   mySecret ;  var   body   =   username=bob@stablekernel.com password=foobar grant_type=password ;  var   clientCredentials   =   Base64Encoder (). convert ( $ clientID : $ clientSecret . codeUnits );  var   response   =   await   http . post ( \n   https://stablekernel.com/auth/token , \n   headers:   { \n     Content-Type :   application/x-www-form-urlencoded , \n     Authorization :   Basic  $ clientCredentials \n   }, \n   body:   body );   If the OAuth 2.0 client ID is public - that is, it does not have a client secret - the secret is omitted from the authorization header:  // Notice that the separating colon (:) is still present.  var   clientCredentials   =   Base64Encoder (). convert ( $ clientID : . codeUnits );   The response to a password token request is a JSON body that follows the OAuth 2.0 specification:  {\n   access_token :  ... \n   refresh_token :  ... ,\n   expires_in : 3600,\n   token_type :  bearer \n}   The  expires_in  field is a computed property based on the delta of the issue date and expiration date. You should avoid manually editing the values for the columns  issuedate  and  expirationdate   Tokens are refreshed through the same endpoint, but with a payload that only contains the refresh token and  grant_type=refresh_token .  grant_type=refresh_token refresh_token=kjasdiuz9u3namnsd  See  Aqueduct Auth CLI  for more details on creating OAuth 2.0 client identifier and secrets.  If an Aqueduct application is using scope, an additional  scope  parameter can contain a space-delimited list of requested authorization scope. Only allowed scopes are returned and granted, and if no scopes are allowed then the request fails. If scope is provided, granted scope will be available in the response body.  It is important that an  Authorizer   must not  protect instances of  AuthController . The Authorization header is parsed and verified by  AuthController .  Once granted, an access token can be used to pass  Authorizer.bearer() s in the application channel.", 
            "title": "Issue, Refresh and Exchange Tokens with AuthController"
        }, 
        {
            "location": "/auth/controllers/#issue-authorization-codes-with-authcodecontroller", 
            "text": "An  AuthCodeController  manages the OAuth 2.0 authorization code flow. The authorization code flow is used when an Aqueduct application allows third party applications access to authorized resources.  Let's say you've built an Aqueduct application that allows people to store notes for themselves. Now, a friend approaches you with their application that is a to-do list. Instead of building their own note-taking feature, your friend wants users of their application to access the notes the user has stored in your application. While trustworthy, you don't want your friend to have access to the username and passwords of your subscribers.  Your friend adds a link to their application that takes the user to an HTML page hosted by your server. The user enters their credentials in this page, which sends a  POST  request to your server. Your server responds by redirecting the user's browser back into your friend's application. An  authorization code  is included in the query string of the redirect URL.  Your friend's application parses the code from the URL and sends it to  their  server. Behind the scenes, their server exchanges this code with your server for an access token.  An  AuthCodeController  responds to both  GET  and  POST  requests. When issued a  GET , it serves up a HTML page with a login form. This login form's submit action sends a  POST  to the same endpoint with the username and password of the user. Upon success, the response from the  POST  is a 302 redirect with an authorization code.  Setting up an  AuthCodeController  is nearly as simple as setting up an  AuthController , but requires a function that renders the HTML login form. Here's an example:  @ override  Controller   get   entryPoint   { \n   final   router   =   Router (); \n\n   router \n     . route ( /auth/code ) \n     . link (()   =   AuthCodeController ( \n       authServer ,   renderAuthorizationPageHTML:   renderLogin )); \n\n   return   router ;  }  Future String   renderLogin ( \n     AuthCodeController   requestingController , \n     URI   requestURI , \n     Map String ,   String   queryParameters )   { \n   var   html   =   HTMLRenderer . templateWithSubstitutions ( \n     web/login.html ,   requestURI ,   queryParameters ); \n\n   return   html ;  }   It is important that all values passed to HTML rendering function are sent in the form's query parameters - they contain necessary security components and scope information.  When your friend's application links to your login page -  GET /auth/code  - they must include three query parameters:  state ,  client_id ,  response_type . They may optionally include  scope .  https://stablekernel.com/auth/code?client_id=friend.app response_type=code state=87uijn3rkja  The value of  client_id  must be created specifically for your friend's application and stored in your database. (See more on generating client identifiers with  aqueduct auth  in  Aqueduct Auth CLI .) The  response_type  must always be  code . The  state  must be a value your friend's application creates - it is often some random value like a session cookie.  When a user of your friend's application goes through this process, they are redirected back into your friend's application. Both the generated authorization code and the value for  state  will be query parameters in the URL. That redirect URL will look like:  https://friends.app/code_callback?code=abcd672kk state=87uijn3rkja  The redirect URL is pre-determined when generating the client identifier with  aqueduct auth .  Your friend's application verifies that  state  matches the  state  they sent in  GET /auth/code . They then send the  code  to their server. The server then exchanges this code with your server by issuing a  POST  to an  AuthController  -  NOT  the  AuthCodeController  - with the following  application/x-www-form-urlencoded  body:  grant_type=authorization_code code=abcd672kk  An access token will be returned to the server which your friend then stores in their database. Whenever one of their users makes a request that requires accessing your application's data, they will execute requests with that access token.", 
            "title": "Issue Authorization Codes with AuthCodeController"
        }, 
        {
            "location": "/auth/cli/", 
            "text": "Manage OAuth 2.0 Clients\n\n\nThe \naqueduct auth\n command line tool creates OAuth 2.0 client application identifiers and inserts them into an application's database. To use this tool, you must use \nManagedAuthDelegate\nT\n and\nyour database must be contain the tables to support it (see \nthis guide\n for more details).\n\n\nExchanging a username and password for an authorization token requires a registered client identifier. A token belongs to both the authenticating user and the client application. Clients are represented by instances of \nManagedAuthClient\n from \naqueduct/managed_auth\n. Authenticating clients must provide their client ID (and client secret, if applicable) in the Authorization header when requesting access tokens.\n\n\nAn OAuth 2.0 client must have a string identifier that uniquely identifies the client. For example, \ncom.food_app.mobile\n may be a client identifier for the mobile applications for some 'Food App'.\n\n\nTo create a simple OAuth 2.0 client, the following command line utility can be run:\n\n\naqueduct auth add-client \\\n  --id com.food_app.mobile \\\n  --connect postgres://user:password@dbhost:5432/food_app\n\n\n\n\n\nThe \nconnect\n option identifies the database for the application, which this tool will connect to and insert a record into the \nManagedAuthClient\n database table. The identifier is provided through the \nid\n option.\n\n\nAn OAuth 2.0 client created in this way is a \npublic\n client; there is no client secret. An OAuth 2.0 client that uses the resource owner grant flow, but cannot secure its client secret, should use this type of client. An application can't secure its client secret if its source code is viewable - like any JavaScript application. It is suggested that native mobile applications also use public clients because their source code could potentially disassembled to reveal a client secret, but isn't necessarily required.\n\n\nWhen making requests to client authenticated endpoints (those protected with \nAuthorizer.basic\n), the client secret is omitted from the authorization header. The string to base64 encode is \nclientID:\n, where the colon (\n:\n) is required. For example, to generate an authorization header in Dart for a public client:\n\n\nvar\n \nclientID\n \n=\n \ncom.foobar.xyz\n;\n\n\nvar\n \nclientCredentials\n \n=\n \nBase64Encoder\n()\n.\nconvert\n(\n$clientID:\n.\ncodeUnits\n);\n\n\nvar\n \nheader\n \n=\n \nBasic $clientCredentials\n;\n\n\n\n\n\n\nConfidential Clients\n\n\nAn OAuth 2.0 client is \nconfidential\n if it has a client secret. Client secrets can be provided with the \nauth\n tool:\n\n\naqueduct auth add-client \\\n  --id com.food_app.mobile \\\n  --secret myspecialsecret \\\n  --connect postgres://user:password@dbhost:5432/food_app\n\n\n\n\n\nClient secrets are hashed (many times) with a randomly generated salt before they are stored. Therefore, their actual value must be stored securely elsewhere. (We use LastPass, for example.)\n\n\nRedirect URIs\n\n\nTo allow the authorization code flow (provided by \nAuthCodeController\n), a client must have a redirect URI. This is the URI that an authenticating user's browser will be redirected to after entering their username and password. A client must be a confidential client to have a redirect URI.\n\n\naqueduct auth add-client \\\n  --id com.food_app.mobile \\\n  --secret myspecialsecret \\\n  --redirect-uri https://someapp.com/callback \\\n  --connect postgres://user:password@dbhost:5432/food_app\n\n\n\n\n\nScopes\n\n\nIf an application is using OAuth 2.0 scopes, a client can have scopes that it allows tokens to have access to. This allows scopes to be restricted by the client they are authenticating with.\n\n\naqueduct auth add-client \\\n  --id com.food_app.mobile \\\n  --secret myspecialsecret \\\n  --allowed-scopes \nscopeA scopeB scopeC.readonly\n \\\n  --connect postgres://user:password@dbhost:5432/food_app\n\n\n\n\n\nScopes are space-delimited and must be enclosed in quotes so that your shell will treat the entire string as one value.\n\n\nScope may be set after a client has already been created with \naqueduct auth set-scope\n:\n\n\naqueduct auth set-scope \\\n  --id com.food_app.mobile \\\n  --scopes \nscopeA scopeC\n \\\n  --connect postgres://user:password@dbhost:5432/food_app\n\n\n\n\n\nOther Info\n\n\nLike all \naqueduct\n commands that send commands to a database, the \nconnect\n option can be replaced by a \ndatabase.yaml\n file in the project directory with the following format:\n\n\nusername: \nuser\n\npassword: \npassword\n\nhost: \nhost\n\nport: 5432\ndatabaseName: \nmy_app", 
            "title": "Managing OAuth 2.0 Clients"
        }, 
        {
            "location": "/auth/cli/#manage-oauth-20-clients", 
            "text": "The  aqueduct auth  command line tool creates OAuth 2.0 client application identifiers and inserts them into an application's database. To use this tool, you must use  ManagedAuthDelegate T  and\nyour database must be contain the tables to support it (see  this guide  for more details).  Exchanging a username and password for an authorization token requires a registered client identifier. A token belongs to both the authenticating user and the client application. Clients are represented by instances of  ManagedAuthClient  from  aqueduct/managed_auth . Authenticating clients must provide their client ID (and client secret, if applicable) in the Authorization header when requesting access tokens.  An OAuth 2.0 client must have a string identifier that uniquely identifies the client. For example,  com.food_app.mobile  may be a client identifier for the mobile applications for some 'Food App'.  To create a simple OAuth 2.0 client, the following command line utility can be run:  aqueduct auth add-client \\\n  --id com.food_app.mobile \\\n  --connect postgres://user:password@dbhost:5432/food_app  The  connect  option identifies the database for the application, which this tool will connect to and insert a record into the  ManagedAuthClient  database table. The identifier is provided through the  id  option.  An OAuth 2.0 client created in this way is a  public  client; there is no client secret. An OAuth 2.0 client that uses the resource owner grant flow, but cannot secure its client secret, should use this type of client. An application can't secure its client secret if its source code is viewable - like any JavaScript application. It is suggested that native mobile applications also use public clients because their source code could potentially disassembled to reveal a client secret, but isn't necessarily required.  When making requests to client authenticated endpoints (those protected with  Authorizer.basic ), the client secret is omitted from the authorization header. The string to base64 encode is  clientID: , where the colon ( : ) is required. For example, to generate an authorization header in Dart for a public client:  var   clientID   =   com.foobar.xyz ;  var   clientCredentials   =   Base64Encoder () . convert ( $clientID: . codeUnits );  var   header   =   Basic $clientCredentials ;", 
            "title": "Manage OAuth 2.0 Clients"
        }, 
        {
            "location": "/auth/cli/#confidential-clients", 
            "text": "An OAuth 2.0 client is  confidential  if it has a client secret. Client secrets can be provided with the  auth  tool:  aqueduct auth add-client \\\n  --id com.food_app.mobile \\\n  --secret myspecialsecret \\\n  --connect postgres://user:password@dbhost:5432/food_app  Client secrets are hashed (many times) with a randomly generated salt before they are stored. Therefore, their actual value must be stored securely elsewhere. (We use LastPass, for example.)", 
            "title": "Confidential Clients"
        }, 
        {
            "location": "/auth/cli/#redirect-uris", 
            "text": "To allow the authorization code flow (provided by  AuthCodeController ), a client must have a redirect URI. This is the URI that an authenticating user's browser will be redirected to after entering their username and password. A client must be a confidential client to have a redirect URI.  aqueduct auth add-client \\\n  --id com.food_app.mobile \\\n  --secret myspecialsecret \\\n  --redirect-uri https://someapp.com/callback \\\n  --connect postgres://user:password@dbhost:5432/food_app", 
            "title": "Redirect URIs"
        }, 
        {
            "location": "/auth/cli/#scopes", 
            "text": "If an application is using OAuth 2.0 scopes, a client can have scopes that it allows tokens to have access to. This allows scopes to be restricted by the client they are authenticating with.  aqueduct auth add-client \\\n  --id com.food_app.mobile \\\n  --secret myspecialsecret \\\n  --allowed-scopes  scopeA scopeB scopeC.readonly  \\\n  --connect postgres://user:password@dbhost:5432/food_app  Scopes are space-delimited and must be enclosed in quotes so that your shell will treat the entire string as one value.  Scope may be set after a client has already been created with  aqueduct auth set-scope :  aqueduct auth set-scope \\\n  --id com.food_app.mobile \\\n  --scopes  scopeA scopeC  \\\n  --connect postgres://user:password@dbhost:5432/food_app", 
            "title": "Scopes"
        }, 
        {
            "location": "/auth/cli/#other-info", 
            "text": "Like all  aqueduct  commands that send commands to a database, the  connect  option can be replaced by a  database.yaml  file in the project directory with the following format:  username:  user \npassword:  password \nhost:  host \nport: 5432\ndatabaseName:  my_app", 
            "title": "Other Info"
        }, 
        {
            "location": "/auth/auth_scopes/", 
            "text": "Granular Authorization with OAuth 2.0 Scopes\n\n\nIn many applications, operations have varying levels of access control. For example, a user may need special permission to create 'notes', but every user can read notes. In OAuth 2.0, permissions for operations are determined by an access token's \nscope\n. Operations can be defined to require certain scopes, and a request may only invoke those operations if its access token was granted with those scopes.\n\n\nA scope is a string identifier, like \nnotes\n or \nnotes.readonly\n. When a client application authenticates on behalf of a user, it requests one or more of these scope identifiers to be granted to the access token. Valid scopes will be stored with the access token, so that the scope can be referenced by subsequent uses of the access token.\n\n\nScope Usage in Aqueduct\n\n\nAn access token's scope is determined when a user authenticates. During authentication, a client application indicates the requested scope, and the Aqueduct application determines if that scope is permissible for the client application and the user. This scope information is attached to the access token.\n\n\nWhen a request is made with an access token, an \nAuthorizer\n retrieves the token's scope. After the request is validated, the \nAuthorizer\n stores scope information in \nRequest.authorization\n. Linked controllers can use this information to determine how the request is handled. In general, a controller will reject a request and send a 403 Forbidden response when an access token has insufficient scope for an operation.\n\n\nTherefore, adding scopes to an application consists of three steps:\n\n\n\n\nAdding scope restrictions to operations.\n\n\nAdding permissible scopes for OAuth2 client identifiers (and optionally users).\n\n\nUpdating client applications to request scope when authenticating.\n\n\n\n\nAdding Scope Restrictions to Operations\n\n\nWhen an \nAuthorizer\n handles a request, it creates an \nAuthorization\n object that is attached to the request. An \nAuthorization\n object has a \nscopes\n property that contains every scope granted for the access token. This object also has a convenience method for checking if a particular scope is valid for that list of scopes:\n\n\nclass\n \nNoteController\n \nextends\n \nController\n \n{\n\n  \n@\noverride\n\n  \nFuture\nRequestOrResponse\n \nhandle\n(\nRequest\n \nrequest\n)\n \nasync\n \n{\n\n    \nif\n \n(\n!\nrequest\n.\nauthorization\n.\nisAuthorizedForScope\n(\nnotes\n))\n \n{\n\n      \nreturn\n \nResponse\n.\nforbidden\n();\n\n    \n}\n\n\n    \nreturn\n \nResponse\n.\nok\n(\nawait\n \ngetAllNotes\n());\n\n  \n}\n\n\n}\n\n\n\n\n\n\n\n\nUse an Authorizer\n\n\nThe \nauthorization\n property of \nRequest\n is only valid after the request is handled by an \nAuthorizer\n. It is \nnull\n otherwise.\n\n\n\n\nAn \nAuthorizer\n may also validate the scope of a request before letting it pass to its linked controller.\n\n\nrouter\n\n  \n.\nroute\n(\n/notes\n)\n\n  \n.\nlink\n(()\n \n=\n \nAuthorizer\n.\nbearer\n(\nauthServer\n,\n \nscopes:\n \n[\nnotes\n]))\n\n  \n.\nlink\n(()\n \n=\n \nNoteController\n());\n\n\n\n\n\n\nIn the above, the \nNoteController\n will only be reached if the request's bearer token has 'notes' scope. If there is insufficient scope, a 403 Forbidden response is sent. This applies to all operations of the \nNoteController\n.\n\n\nIt often makes sense to have separate scope for different operations on the same resource. The \nScope\n annotation may be added to \nResourceController\n operation methods for this purpose.\n\n\nclass\n \nNoteController\n \nextends\n \nResourceController\n \n{\n\n  \n@\nScope\n([\nnotes.readonly\n])\n\n  \n@\nOperation\n.\nget\n()\n\n  \nFuture\nResponse\n \ngetNotes\n()\n \nasync\n \n=\n \n...;\n\n\n  \n@\nScope\n([\nnotes\n])\n\n  \n@\nOperation\n.\npost\n()\n\n  \nFuture\nResponse\n \ncreateNote\n(\n@\nBind\n.\nbody\n()\n \nNote\n \nnote\n)\n \nasync\n \n=\n \n...;\n\n\n}\n\n\n\n\n\n\nIf a request does not have sufficient scope for the intended operation method, a 403 Forbidden response is sent. When using \nScope\n annotations, you must link an \nAuthorizer\n prior to the \nResourceController\n, but it is not necessary to specify \nAuthorizer\n scopes.  \n\n\nIf a \nScope\n annotation or \nAuthorizer\n contains multiple scope entries, an access token must have scope for each of those entries. For example, the annotation \n@Scope(['notes', 'user'])\n requires an access token to have both 'notes' and 'user' scope.\n\n\nDefining Permissible Scope\n\n\nWhen a client application authenticates on behalf of a user, it includes a list of request scopes for the access token. An Aqueduct application will grant the requested scopes to the  token if the scopes are permissible for both the authenticating client identifier and the authenticating user.\n\n\nTo add permissible scopes to an authenticating client, you use the \naqueduct auth\n command-line tool. When creating a new client identifier, include the \n--allowed-scopes\n options:\n\n\naqueduct auth add-client \n\\\n\n  --id com.app.mobile \n\\\n\n  --secret myspecialsecret \n\\\n\n  --allowed-scopes \nnotes users\n \n\\\n\n  --connect postgres://user:password@dbhost:5432/db_name\n\n\n\n\n\nWhen modifying an existing client identifier, use the command \naqueduct auth set-scope\n:\n\n\naqueduct auth set-scope \n\\\n\n  --id com.app.mobile \n\\\n\n  --scopes \nnotes users\n \n\\\n\n  --connect postgres://user:password@dbhost:5432/db_name\n\n\n\n\n\nEach scope is a space-delimited string; the above examples allow clients authenticating with the \ncom.app.mobile\n client ID to grant access tokens with 'notes' and 'users' scope. If a client application requests scopes that are not available for that client application, the granted access token will not contain that scope. If none of the request scopes are available for the client identifier, no access token is granted. When adding scope restrictions to your application, you must ensure that all of the client applications that have access to those operations are able to grant that scope.\n\n\nScopes may also be limited by some attribute of your application's concept of a 'user'. This user-level filtering is done by overriding \ngetAllowedScopes\n in \nAuthServerDelegate\n. By default, this method returns \nAuthScope.Any\n - which means there are no restrictions. If the client application allows the scope, then any user that logs in with that application can request that scope.\n\n\nThis method may return a list of \nAuthScope\ns that are valid for the authenticating user. The following example shows a \nManagedAuthDelegate\nT\n subclass that allows any scope for \n@stablekernel.com\n usernames, no scopes for \n@hotmail.com\n addresses and some limited scope for everyone else:\n\n\nclass\n \nDomainBasedAuthDelegate\n \nextends\n \nManagedAuthDelegate\nUser\n \n{\n\n  \nDomainBasedAuthDelegate\n(\nManagedContext\n \ncontext\n,\n \n{\nint\n \ntokenLimit:\n \n40\n})\n \n:\n\n        \nsuper\n(\ncontext\n,\n \ntokenLimit:\n \ntokenLimit\n);\n\n\n  \n@\noverride\n\n  \nList\nAuthScope\n \ngetAllowedScopes\n(\ncovariant\n \nUser\n \nuser\n)\n \n{\n\n    \nif\n \n(\nuser\n.\nusername\n.\nendsWith\n(\n@stablekernel.com\n))\n \n{\n\n      \nreturn\n \nAuthScope\n.\nAny\n;\n\n    \n}\n \nelse\n \nif\n \n(\nuser\n.\nusername\n.\nendsWith\n(\n@hotmail.com\n))\n \n{\n\n      \nreturn\n \n[];\n\n    \n}\n \nelse\n \n{\n\n      \nreturn\n \n[\nAuthScope\n(\nuser\n)];\n\n    \n}\n\n  \n}\n      \n\n}\n\n\n\n\n\n\nThe \nuser\n passed to \ngetAllowedScopes\n is the user being authenticated. It will have previously been fetched by the \nAuthServer\n. The \nAuthServer\n fetches this object by invoking \nAuthDelegate.getResourceOwner\n. The default implementation of this method for \nManagedAuthDelegate\nT\n only fetches the \nid\n, \nusername\n, \nsalt\n and \nhashedPassword\n of the user.\n\n\nWhen using some other attribute of an application's user object to restrict allowed scopes, you must also override \ngetResourceOwner\n to fetch these attributes. For example, if your application's user has a \nrole\n attribute, you must fetch it and the other four required properties. Here's an example implementation:\n\n\nclass\n \nRoleBasedAuthDelegate\n \nextends\n \nManagedAuthDelegate\nUser\n \n{\n\n  \nRoleBasedAuthDelegate\n(\nManagedContext\n \ncontext\n,\n \n{\nint\n \ntokenLimit:\n \n40\n})\n \n:\n\n        \nsuper\n(\ncontext\n,\n \ntokenLimit:\n \ntokenLimit\n);\n\n\n  \n@\noverride\n\n  \nFuture\nUser\n \ngetResourceOwner\n(\n\n      \nAuthServer\n \nserver\n,\n \nString\n \nusername\n)\n \n{\n\n    \nfinal\n \nquery\n \n=\n \nQuery\nUser\n(\ncontext\n)\n\n      \n..\nwhere\n((\nu\n)\n \n=\n \nu\n.\nusername\n).\nequalTo\n(\nusername\n)\n\n      \n..\nreturningProperties\n((\nt\n)\n \n=\n\n        \n[\nt\n.\nid\n,\n \nt\n.\nusername\n,\n \nt\n.\nhashedPassword\n,\n \nt\n.\nsalt\n,\n \nt\n.\nrole\n]);\n\n\n    \nreturn\n \nquery\n.\nfetchOne\n();\n\n  \n}\n\n\n  \n@\noverride\n\n  \nList\nAuthScope\n \ngetAllowedScopes\n(\ncovariant\n \nUser\n \nuser\n)\n \n{\n\n    \nvar\n \nscopeStrings\n \n=\n \n[];\n\n    \nif\n \n(\nuser\n.\nrole\n \n==\n \nadmin\n)\n \n{\n\n      \nscopeStrings\n \n=\n \n[\nadmin\n,\n \nuser\n];\n\n    \n}\n \nelse\n \nif\n \n(\nuser\n.\nrole\n \n==\n \nuser\n)\n \n{\n\n      \nscopeStrings\n \n=\n \n[\nuser:email\n];\n\n    \n}\n\n\n    \nreturn\n \nscopeStrings\n.\nmap\n((\nstr\n)\n \n=\n \nAuthScope\n(\nstr\n)).\ntoList\n();\n\n  \n}\n\n\n}\n\n\n\n\n\n\nClient Application Integration\n\n\nClient applications that integrate with your scoped Aqueduct application must include a list of requested scopes when performing authentication. When authenticating through \nAuthController\n, a \nscope\n parameter must be added to the form data body. This parameter's value must be a space-delimited, URL-encoded list of requested scopes.\n\n\nusername=bob\npassword=foo\ngrant_type=password\nscope=notes%20users\n\n\n\n\n\nWhen authenticating via an \nAuthCodeController\n, this same query parameter is added to the initial \nGET\n request to render the login form.\n\n\nWhen authentication is complete, the list of granted scopes will be available in the JSON response body as a space-delimited string.\n\n\n{\n\n  \naccess_token\n:\n \n...\n,\n\n  \nrefresh_token\n:\n \n...\n,\n\n  \ntoken_type\n:\n \nbearer\n,\n\n  \nexpires_in\n:\n \n3600\n,\n\n  \nscopes\n:\n \nnotes users\n\n\n}\n\n\n\n\n\n\nScope Format and Hierarchy\n\n\nThere is no definitive guide on what a scope string should look like, other than being restricted to alphanumeric characters and some symbols. Aqueduct, however, provides a simple scoping structure - there are two special symbols, \n:\n and \n.\n.\n\n\nHierarchy is specified by the \n:\n character. For example, the following is a hierarchy of scopes related to a user and its sub-resources:\n\n\n\n\nuser\n (can read/write everything a user has)\n\n\nuser:email\n (can read/write a user's email)\n\n\nuser:documents\n (can read/write a user's documents)\n\n\nuser:documents:spreadsheets\n (can read/write a user's spreadsheet documents)\n\n\n\n\nNotice how these scopes form a hierarchy. Each segment makes the scope more restrictive. For example, if an access token has \nuser:email\n scope, it only allows access to a user's email. However, if the access token has \nuser\n scope, it allows access to everything a user has, including their email.\n\n\nAs another example, an access token with \nuser:documents\n scope can access all of a user's documents, but the scope \nuser:documents:spreadsheets\n is limited to only spreadsheet documents.\n\n\nScope is often used to indicate read vs. write access. At first glance, it might sound like a good idea to use the hierarchy operator, e.g. \nuser:email:read\n and \nuser:email:write\n. However, an access token with \nuser:email:write\n \ndoes not\n have permission to read email and this is likely unintended.\n\n\nThis is where \nscope modifiers\n come in. A scope modifier is added after a \n.\n at the end of a scope string. For example, \nuser:email.readonly\n grants readonly access to a user's email whereas \nuser:email\n grants read and write access.\n\n\nAn access token without a modifier has permission \nany\n modifier. Thus, \nuser\n and \nuser:email\n can both access \nuser:email.readonly\n protected resources and actions, but \nuser:email.readonly\n cannot access resources protected by \nuser:email\n.\n\n\nA scope modifier is only valid for the last segment of a scope string. That is, \nuser:documents.readonly:spreadsheets\n is not valid, but \nuser:documents:spreadsheets.readonly\n is.", 
            "title": "OAuth 2.0 Scoping"
        }, 
        {
            "location": "/auth/auth_scopes/#granular-authorization-with-oauth-20-scopes", 
            "text": "In many applications, operations have varying levels of access control. For example, a user may need special permission to create 'notes', but every user can read notes. In OAuth 2.0, permissions for operations are determined by an access token's  scope . Operations can be defined to require certain scopes, and a request may only invoke those operations if its access token was granted with those scopes.  A scope is a string identifier, like  notes  or  notes.readonly . When a client application authenticates on behalf of a user, it requests one or more of these scope identifiers to be granted to the access token. Valid scopes will be stored with the access token, so that the scope can be referenced by subsequent uses of the access token.", 
            "title": "Granular Authorization with OAuth 2.0 Scopes"
        }, 
        {
            "location": "/auth/auth_scopes/#scope-usage-in-aqueduct", 
            "text": "An access token's scope is determined when a user authenticates. During authentication, a client application indicates the requested scope, and the Aqueduct application determines if that scope is permissible for the client application and the user. This scope information is attached to the access token.  When a request is made with an access token, an  Authorizer  retrieves the token's scope. After the request is validated, the  Authorizer  stores scope information in  Request.authorization . Linked controllers can use this information to determine how the request is handled. In general, a controller will reject a request and send a 403 Forbidden response when an access token has insufficient scope for an operation.  Therefore, adding scopes to an application consists of three steps:   Adding scope restrictions to operations.  Adding permissible scopes for OAuth2 client identifiers (and optionally users).  Updating client applications to request scope when authenticating.", 
            "title": "Scope Usage in Aqueduct"
        }, 
        {
            "location": "/auth/auth_scopes/#adding-scope-restrictions-to-operations", 
            "text": "When an  Authorizer  handles a request, it creates an  Authorization  object that is attached to the request. An  Authorization  object has a  scopes  property that contains every scope granted for the access token. This object also has a convenience method for checking if a particular scope is valid for that list of scopes:  class   NoteController   extends   Controller   { \n   @ override \n   Future RequestOrResponse   handle ( Request   request )   async   { \n     if   ( ! request . authorization . isAuthorizedForScope ( notes ))   { \n       return   Response . forbidden (); \n     } \n\n     return   Response . ok ( await   getAllNotes ()); \n   }  }    Use an Authorizer  The  authorization  property of  Request  is only valid after the request is handled by an  Authorizer . It is  null  otherwise.   An  Authorizer  may also validate the scope of a request before letting it pass to its linked controller.  router \n   . route ( /notes ) \n   . link (()   =   Authorizer . bearer ( authServer ,   scopes:   [ notes ])) \n   . link (()   =   NoteController ());   In the above, the  NoteController  will only be reached if the request's bearer token has 'notes' scope. If there is insufficient scope, a 403 Forbidden response is sent. This applies to all operations of the  NoteController .  It often makes sense to have separate scope for different operations on the same resource. The  Scope  annotation may be added to  ResourceController  operation methods for this purpose.  class   NoteController   extends   ResourceController   { \n   @ Scope ([ notes.readonly ]) \n   @ Operation . get () \n   Future Response   getNotes ()   async   =   ...; \n\n   @ Scope ([ notes ]) \n   @ Operation . post () \n   Future Response   createNote ( @ Bind . body ()   Note   note )   async   =   ...;  }   If a request does not have sufficient scope for the intended operation method, a 403 Forbidden response is sent. When using  Scope  annotations, you must link an  Authorizer  prior to the  ResourceController , but it is not necessary to specify  Authorizer  scopes.    If a  Scope  annotation or  Authorizer  contains multiple scope entries, an access token must have scope for each of those entries. For example, the annotation  @Scope(['notes', 'user'])  requires an access token to have both 'notes' and 'user' scope.", 
            "title": "Adding Scope Restrictions to Operations"
        }, 
        {
            "location": "/auth/auth_scopes/#defining-permissible-scope", 
            "text": "When a client application authenticates on behalf of a user, it includes a list of request scopes for the access token. An Aqueduct application will grant the requested scopes to the  token if the scopes are permissible for both the authenticating client identifier and the authenticating user.  To add permissible scopes to an authenticating client, you use the  aqueduct auth  command-line tool. When creating a new client identifier, include the  --allowed-scopes  options:  aqueduct auth add-client  \\ \n  --id com.app.mobile  \\ \n  --secret myspecialsecret  \\ \n  --allowed-scopes  notes users   \\ \n  --connect postgres://user:password@dbhost:5432/db_name  When modifying an existing client identifier, use the command  aqueduct auth set-scope :  aqueduct auth set-scope  \\ \n  --id com.app.mobile  \\ \n  --scopes  notes users   \\ \n  --connect postgres://user:password@dbhost:5432/db_name  Each scope is a space-delimited string; the above examples allow clients authenticating with the  com.app.mobile  client ID to grant access tokens with 'notes' and 'users' scope. If a client application requests scopes that are not available for that client application, the granted access token will not contain that scope. If none of the request scopes are available for the client identifier, no access token is granted. When adding scope restrictions to your application, you must ensure that all of the client applications that have access to those operations are able to grant that scope.  Scopes may also be limited by some attribute of your application's concept of a 'user'. This user-level filtering is done by overriding  getAllowedScopes  in  AuthServerDelegate . By default, this method returns  AuthScope.Any  - which means there are no restrictions. If the client application allows the scope, then any user that logs in with that application can request that scope.  This method may return a list of  AuthScope s that are valid for the authenticating user. The following example shows a  ManagedAuthDelegate T  subclass that allows any scope for  @stablekernel.com  usernames, no scopes for  @hotmail.com  addresses and some limited scope for everyone else:  class   DomainBasedAuthDelegate   extends   ManagedAuthDelegate User   { \n   DomainBasedAuthDelegate ( ManagedContext   context ,   { int   tokenLimit:   40 })   : \n         super ( context ,   tokenLimit:   tokenLimit ); \n\n   @ override \n   List AuthScope   getAllowedScopes ( covariant   User   user )   { \n     if   ( user . username . endsWith ( @stablekernel.com ))   { \n       return   AuthScope . Any ; \n     }   else   if   ( user . username . endsWith ( @hotmail.com ))   { \n       return   []; \n     }   else   { \n       return   [ AuthScope ( user )]; \n     } \n   }        }   The  user  passed to  getAllowedScopes  is the user being authenticated. It will have previously been fetched by the  AuthServer . The  AuthServer  fetches this object by invoking  AuthDelegate.getResourceOwner . The default implementation of this method for  ManagedAuthDelegate T  only fetches the  id ,  username ,  salt  and  hashedPassword  of the user.  When using some other attribute of an application's user object to restrict allowed scopes, you must also override  getResourceOwner  to fetch these attributes. For example, if your application's user has a  role  attribute, you must fetch it and the other four required properties. Here's an example implementation:  class   RoleBasedAuthDelegate   extends   ManagedAuthDelegate User   { \n   RoleBasedAuthDelegate ( ManagedContext   context ,   { int   tokenLimit:   40 })   : \n         super ( context ,   tokenLimit:   tokenLimit ); \n\n   @ override \n   Future User   getResourceOwner ( \n       AuthServer   server ,   String   username )   { \n     final   query   =   Query User ( context ) \n       .. where (( u )   =   u . username ). equalTo ( username ) \n       .. returningProperties (( t )   = \n         [ t . id ,   t . username ,   t . hashedPassword ,   t . salt ,   t . role ]); \n\n     return   query . fetchOne (); \n   } \n\n   @ override \n   List AuthScope   getAllowedScopes ( covariant   User   user )   { \n     var   scopeStrings   =   []; \n     if   ( user . role   ==   admin )   { \n       scopeStrings   =   [ admin ,   user ]; \n     }   else   if   ( user . role   ==   user )   { \n       scopeStrings   =   [ user:email ]; \n     } \n\n     return   scopeStrings . map (( str )   =   AuthScope ( str )). toList (); \n   }  }", 
            "title": "Defining Permissible Scope"
        }, 
        {
            "location": "/auth/auth_scopes/#client-application-integration", 
            "text": "Client applications that integrate with your scoped Aqueduct application must include a list of requested scopes when performing authentication. When authenticating through  AuthController , a  scope  parameter must be added to the form data body. This parameter's value must be a space-delimited, URL-encoded list of requested scopes.  username=bob password=foo grant_type=password scope=notes%20users  When authenticating via an  AuthCodeController , this same query parameter is added to the initial  GET  request to render the login form.  When authentication is complete, the list of granted scopes will be available in the JSON response body as a space-delimited string.  { \n   access_token :   ... , \n   refresh_token :   ... , \n   token_type :   bearer , \n   expires_in :   3600 , \n   scopes :   notes users  }", 
            "title": "Client Application Integration"
        }, 
        {
            "location": "/auth/auth_scopes/#scope-format-and-hierarchy", 
            "text": "There is no definitive guide on what a scope string should look like, other than being restricted to alphanumeric characters and some symbols. Aqueduct, however, provides a simple scoping structure - there are two special symbols,  :  and  . .  Hierarchy is specified by the  :  character. For example, the following is a hierarchy of scopes related to a user and its sub-resources:   user  (can read/write everything a user has)  user:email  (can read/write a user's email)  user:documents  (can read/write a user's documents)  user:documents:spreadsheets  (can read/write a user's spreadsheet documents)   Notice how these scopes form a hierarchy. Each segment makes the scope more restrictive. For example, if an access token has  user:email  scope, it only allows access to a user's email. However, if the access token has  user  scope, it allows access to everything a user has, including their email.  As another example, an access token with  user:documents  scope can access all of a user's documents, but the scope  user:documents:spreadsheets  is limited to only spreadsheet documents.  Scope is often used to indicate read vs. write access. At first glance, it might sound like a good idea to use the hierarchy operator, e.g.  user:email:read  and  user:email:write . However, an access token with  user:email:write   does not  have permission to read email and this is likely unintended.  This is where  scope modifiers  come in. A scope modifier is added after a  .  at the end of a scope string. For example,  user:email.readonly  grants readonly access to a user's email whereas  user:email  grants read and write access.  An access token without a modifier has permission  any  modifier. Thus,  user  and  user:email  can both access  user:email.readonly  protected resources and actions, but  user:email.readonly  cannot access resources protected by  user:email .  A scope modifier is only valid for the last segment of a scope string. That is,  user:documents.readonly:spreadsheets  is not valid, but  user:documents:spreadsheets.readonly  is.", 
            "title": "Scope Format and Hierarchy"
        }, 
        {
            "location": "/auth/what_is_oauth/", 
            "text": "What is OAuth 2.0?\n\n\nMost applications have the concept of a user. To prevent just anyone from saying they are this user, the user has a password. When a user wants to use your application, they send their username and password to the server so it can ensure they are who they say they are.\n\n\nThe simple way to do this is to send the username and password in an Authorization header for every request. Two reasons this is bad: first, every time the user wants to do something, their password is sent in every request and that can be unsafe. Second, any application that wants to keep the user logged in has to store that password - and that is unsafe.\n\n\nIn OAuth 2.0, the user gives their username and password to a client application once. The application sends those credentials to a server, and the server gives the application back an access token. A access token is a long, random string that no one can guess. When the user wants to do more stuff, the application sends the token with every request, instead of the user's password. The server checks the token, makes sure its not expired, and then lets the application's request go through. The application doesn't have to store the password and doesn't have to ask the user for their password again.\n\n\nThis credential-for-token exchange happens by sending a POST request to some endpoint, where the username and password are sent in the request body. Typically, an Aqueduct application's route for this is \n/auth/token\n and handled by an instance of \nAuthController\n.\n\n\nOAuth 2.0 makes a subtle distinction: a user and the application they are using are not the same thing. It's intuitive to think of a user as \"making a request to the server\", but in reality, the user makes a request to an application and \nthe application\n makes the request to the server. The server \ngrants\n the application access on behalf of the user. In other words, when a user enters their credentials into an application, the application goes to the server and says \"Hey, this user said I can do stuff for them. Look, this is their secret password!\"\n\n\nThis is an important distinction, because an OAuth 2.0 server doesn't just verify users: it also verifies applications. An application has a identifier that has been registered with the server. So, for an ecosystem that has a web client, an Android and an iOS app there would likely be three identifiers - one for each. The client application usually stores that identifier in a database. This identifier is called a \nclient identifier\n. Client identifiers are added to Aqueduct applications with the \naqueduct auth\n tool (see \nAqueduct Auth CLI\n).\n\n\nWhen the user is logging in through an application, they submit their username and password. The user doesn't provide the client identifier - in fact, the user doesn't know it. The application sends a request with the user's username and password in the request body, and the client identifier in the Authorization header. All three have to check out for the server to give the application back a token. The full request in pseudo-code looks something like:\n\n\nvar\n \nrequest\n \n=\n \nHTTPRequest\n(\n/auth/token\n);\n\n\nrequest\n.\nmethod\n \n=\n \nPOST\n;\n\n\nrequest\n.\ncontentType\n \n=\n \napplication/x-www-form-urlencoded\n;\n\n\nrequest\n.\nauthorization\n \n=\n \nBase64\n.\nencode\n(\n$\nclientID\n:\n);\n\n\nrequest\n.\nbody\n \n=\n \n{\n\n  \nusername\n \n:\n \nbob@stablekernel.com\n,\n\n  \npassword\n \n:\n \nsupersecretstuff\n,\n\n  \ngrant_type\n \n:\n \npassword\n\n\n};\n\n\n\n\n\n\nAn access token can expire. How long it takes to expire is up to the server - Aqueduct defaults to 24 hours. At first glance, this means that the application would have to ask the user for a password again. But, tokens can also be refreshed. Refreshing a token grants a brand new access token, but without having to ask for the password. This is possible because an access token comes with a \nrefresh token\n. The refresh token is another long, random string. So, the JSON the server sends back when granting a token looks like this:\n\n\n{\n\n  \naccess_token\n \n:\n \nAbca09zzzza2o2kelmzlli3ijlka\n,\n\n  \ntoken_type\n \n:\n \nbearer\n,\n\n  \nrefresh_token\n \n:\n \nlkmLIAmooa898nm20jannnnnxaww\n,\n\n  \nexpire_in\n \n:\n \n3600\n\n\n}\n\n\n\n\n\n\nThe application hangs on to both an access token and a refresh token. When the token expires, it will send the refresh token back to the server to get a replacement access token. This is done through the same route that the access token came from - \n/auth/token\n - except the parameters are a bit different:\n\n\nvar\n \nrequest\n \n=\n \nHTTPRequest\n(\n/auth/token\n);\n\n\nrequest\n.\nmethod\n \n=\n \nPOST\n;\n\n\nrequest\n.\ncontentType\n \n=\n \napplication/x-www-form-urlencoded\n;\n\n\nrequest\n.\nauthorization\n \n=\n \nBase64\n.\nencode\n(\n$\nclientID\n:\n);\n\n\nrequest\n.\nbody\n \n=\n \n{\n\n  \nrefresh_token\n \n:\n \nlkmLIAmooa898nm20jannnnnxaww\n,\n\n  \ngrant_type\n \n:\n \nrefresh_token\n\n\n};\n\n\n\n\n\n\nExchanging a refresh token has the same response as the initial exchange for username and password - except a few values will have changed.\n\n\nThe verification and storage of authorization and authentication information is managed by an \nAuthServer\n.\n\n\nOther Methods for Obtaining Authorization\n\n\nThe method of getting a token above - sending a username and password to \n/auth/token\n - is just one of four possible methods OAuth 2.0 uses to authenticate a user. This particular one is called the \nresource owner password credentials grant\n. A resource owner is a fancy word for a 'user'. We can shorten it up to just the 'password flow'. It's probably the most common flow - mobiles applications and front-end web applications often use this flow. When you enter your credentials, the client application sends them directly to the server.\n\n\nThe other commonly used flow prevents the client application from ever seeing the user's credentials. For example, you might sign into Pivotal Tracker with your Google account. Your account on Pivotal Tracker doesn't have a password. Instead, it is linked to your Google account - which does. Pivotal Tracker never sees your Google password. When you login to Pivotal Tracker in this way, it takes you to Google's authentication page - owned and operated by Google. When you login successfully, Google gives Pivotal Tracker your token. Pivotal Tracker is now an application that can do things on your behalf.\n\n\nThis is called the \nauthorization code grant\n - or just 'auth code flow'. An instance of \nAuthCodeController\n handles granting authorization codes. Once a code is received, it can be exchanged for a token via an \nAuthController\n.", 
            "title": "What is OAuth 2.0?"
        }, 
        {
            "location": "/auth/what_is_oauth/#what-is-oauth-20", 
            "text": "Most applications have the concept of a user. To prevent just anyone from saying they are this user, the user has a password. When a user wants to use your application, they send their username and password to the server so it can ensure they are who they say they are.  The simple way to do this is to send the username and password in an Authorization header for every request. Two reasons this is bad: first, every time the user wants to do something, their password is sent in every request and that can be unsafe. Second, any application that wants to keep the user logged in has to store that password - and that is unsafe.  In OAuth 2.0, the user gives their username and password to a client application once. The application sends those credentials to a server, and the server gives the application back an access token. A access token is a long, random string that no one can guess. When the user wants to do more stuff, the application sends the token with every request, instead of the user's password. The server checks the token, makes sure its not expired, and then lets the application's request go through. The application doesn't have to store the password and doesn't have to ask the user for their password again.  This credential-for-token exchange happens by sending a POST request to some endpoint, where the username and password are sent in the request body. Typically, an Aqueduct application's route for this is  /auth/token  and handled by an instance of  AuthController .  OAuth 2.0 makes a subtle distinction: a user and the application they are using are not the same thing. It's intuitive to think of a user as \"making a request to the server\", but in reality, the user makes a request to an application and  the application  makes the request to the server. The server  grants  the application access on behalf of the user. In other words, when a user enters their credentials into an application, the application goes to the server and says \"Hey, this user said I can do stuff for them. Look, this is their secret password!\"  This is an important distinction, because an OAuth 2.0 server doesn't just verify users: it also verifies applications. An application has a identifier that has been registered with the server. So, for an ecosystem that has a web client, an Android and an iOS app there would likely be three identifiers - one for each. The client application usually stores that identifier in a database. This identifier is called a  client identifier . Client identifiers are added to Aqueduct applications with the  aqueduct auth  tool (see  Aqueduct Auth CLI ).  When the user is logging in through an application, they submit their username and password. The user doesn't provide the client identifier - in fact, the user doesn't know it. The application sends a request with the user's username and password in the request body, and the client identifier in the Authorization header. All three have to check out for the server to give the application back a token. The full request in pseudo-code looks something like:  var   request   =   HTTPRequest ( /auth/token );  request . method   =   POST ;  request . contentType   =   application/x-www-form-urlencoded ;  request . authorization   =   Base64 . encode ( $ clientID : );  request . body   =   { \n   username   :   bob@stablekernel.com , \n   password   :   supersecretstuff , \n   grant_type   :   password  };   An access token can expire. How long it takes to expire is up to the server - Aqueduct defaults to 24 hours. At first glance, this means that the application would have to ask the user for a password again. But, tokens can also be refreshed. Refreshing a token grants a brand new access token, but without having to ask for the password. This is possible because an access token comes with a  refresh token . The refresh token is another long, random string. So, the JSON the server sends back when granting a token looks like this:  { \n   access_token   :   Abca09zzzza2o2kelmzlli3ijlka , \n   token_type   :   bearer , \n   refresh_token   :   lkmLIAmooa898nm20jannnnnxaww , \n   expire_in   :   3600  }   The application hangs on to both an access token and a refresh token. When the token expires, it will send the refresh token back to the server to get a replacement access token. This is done through the same route that the access token came from -  /auth/token  - except the parameters are a bit different:  var   request   =   HTTPRequest ( /auth/token );  request . method   =   POST ;  request . contentType   =   application/x-www-form-urlencoded ;  request . authorization   =   Base64 . encode ( $ clientID : );  request . body   =   { \n   refresh_token   :   lkmLIAmooa898nm20jannnnnxaww , \n   grant_type   :   refresh_token  };   Exchanging a refresh token has the same response as the initial exchange for username and password - except a few values will have changed.  The verification and storage of authorization and authentication information is managed by an  AuthServer .", 
            "title": "What is OAuth 2.0?"
        }, 
        {
            "location": "/auth/what_is_oauth/#other-methods-for-obtaining-authorization", 
            "text": "The method of getting a token above - sending a username and password to  /auth/token  - is just one of four possible methods OAuth 2.0 uses to authenticate a user. This particular one is called the  resource owner password credentials grant . A resource owner is a fancy word for a 'user'. We can shorten it up to just the 'password flow'. It's probably the most common flow - mobiles applications and front-end web applications often use this flow. When you enter your credentials, the client application sends them directly to the server.  The other commonly used flow prevents the client application from ever seeing the user's credentials. For example, you might sign into Pivotal Tracker with your Google account. Your account on Pivotal Tracker doesn't have a password. Instead, it is linked to your Google account - which does. Pivotal Tracker never sees your Google password. When you login to Pivotal Tracker in this way, it takes you to Google's authentication page - owned and operated by Google. When you login successfully, Google gives Pivotal Tracker your token. Pivotal Tracker is now an application that can do things on your behalf.  This is called the  authorization code grant  - or just 'auth code flow'. An instance of  AuthCodeController  handles granting authorization codes. Once a code is received, it can be exchanged for a token via an  AuthController .", 
            "title": "Other Methods for Obtaining Authorization"
        }, 
        {
            "location": "/testing/", 
            "text": "Tasks\n\n\nAqueduct applications can be run, tested, debugged and profiled.\n\n\nYou create a subclass of \nTestHarness\nT\n in your application's \ntest/\n directory. For each test suite, you install this harness to start and stop your application in 'test' mode. A test harness runs your application like a live application.\n\n\nYou use \nAgent\n objects to send HTTP requests to your application under test. Agents add default information to all of their requests, like authorization information. You use test matchers like \nhasResponse\n or \nhasStatus\n to validate the response your application sends for a given request.\n\n\nYou provide mock services for external services that your application communicates with. These are often driven by the contents of a configuration file. (By convention, a configuration file for tests is named \nconfig.src.yaml\n.) You may also create mock services with \nMockHTTPServer\n to use during testing.\n\n\nGuides\n\n\n\n\nWriting Tests with a Test Harness\n\n\nTesting with the ORM and OAuth 2.0\n\n\nDeveloping Client Applications\n\n\nUsing the Debugger and Profiling\n\n\nUse Mock Services", 
            "title": "Overview"
        }, 
        {
            "location": "/testing/#tasks", 
            "text": "Aqueduct applications can be run, tested, debugged and profiled.  You create a subclass of  TestHarness T  in your application's  test/  directory. For each test suite, you install this harness to start and stop your application in 'test' mode. A test harness runs your application like a live application.  You use  Agent  objects to send HTTP requests to your application under test. Agents add default information to all of their requests, like authorization information. You use test matchers like  hasResponse  or  hasStatus  to validate the response your application sends for a given request.  You provide mock services for external services that your application communicates with. These are often driven by the contents of a configuration file. (By convention, a configuration file for tests is named  config.src.yaml .) You may also create mock services with  MockHTTPServer  to use during testing.", 
            "title": "Tasks"
        }, 
        {
            "location": "/testing/#guides", 
            "text": "Writing Tests with a Test Harness  Testing with the ORM and OAuth 2.0  Developing Client Applications  Using the Debugger and Profiling  Use Mock Services", 
            "title": "Guides"
        }, 
        {
            "location": "/testing/tests/", 
            "text": "Testing in Aqueduct\n\n\nFrom the ground up, Aqueduct is built to be tested. In practice, this means two things:\n\n\n\n\nA deployed Aqueduct application has zero code differences from an Aqueduct application under test.\n\n\nThere are helpful utilities for writing tests in Aqueduct.\n\n\n\n\nHow Tests are Written\n\n\nAn Aqueduct test suite starts your application with a configuration file specifically built for a test instance of your application. You write test cases that verify the responses of requests sent to this application. Sometimes, you might reach into your application's services to validate that an intended side-effect was triggered. For example, you might ensure that after a request was executed, a row was added to a database table.\n\n\nA \nTestHarness\nT\n is a type from \npackage:aqueduct_test\n that handles the initialization of your application under test. It is often subclassed to add application-specific startup tasks, like seeding a database with test users or adding OAuth 2.0 clients. A test harness is installed at the beginning of your test's \nmain\n function.\n\n\nvoid\n \nmain\n()\n \n{\n\n  \nfinal\n \nharness\n \n=\n \nnew\n \nTestHarness\nMyApplicationChannel\n()..\ninstall\n();\n\n\n  \ntest\n(\nGET /endpoint returns 200 and a simple object\n,\n \n()\n \nasync\n \n{\n\n    \nfinal\n \nresponse\n \n=\n \nawait\n \nharness\n.\nagent\n.\nget\n(\n/endpoint\n);\n\n    \nexpectResponse\n(\nresponse\n,\n \n200\n,\n \nbody:\n \n{\nkey\n:\n \nvalue\n});\n\n  \n});\n\n\n}}\n\n\n\n\n\n\nWhen \nTestHarness.install\n is invoked, it installs two callbacks from \npackage:test\n that will start your application in 'test mode' when the tests start, and stop it after the tests complete. An application running in 'test mode' creates a local HTTP server and instantiates your \nApplicationChannel\n \non the same isolate as your tests are running on\n. This allows you to reach into your application channel's services to add test expectations on the state that the services manage.\n\n\nWhen your application is started in this way, its options have some default values:\n\n\n\n\nthe application listens on a random port\n\n\nthe \nconfigurationFilePath\n is \nconfig.src.yaml\n\n\n\n\nThe \nconfig.src.yaml\n file must have the same structure as your deployment configurations, but values are substituted with test control values. For example, database connection configuration will point at a local test database instead of a production database. For more details on configuring an application, see \nthis guide\n.\n\n\n\n\nHarness Install\n\n\nThe \ninstall\n method calls \nsetUpAll\n and \ntearDownAll\n from \npackage:test\n to start and stop your application. You can manually start and stop your application by invoking \nTestHarness.setUp\n and \nTestHarness.tearDown\n.\n\n\n\n\n\n\nUncaught Exceptions when Testing\n\n\nA test harness configures the application the let uncaught exceptions escape so that they trigger a failure in your test. This is different than when running an application normally, where all exceptions are caught and send an error response to the HTTP client.\n\n\n\n\nUsing a TestHarness Subclass\n\n\nApplications created with \naqueduct create\n include a \nTestHarness\nT\n subclass that can be modified for your application's specific needs (where \nT\n is your application channel subclass). This file that contains this subclass is located in \ntest/harness/app.dart\n. A simple test harness subclass looks like this:\n\n\nclass\n \nHarness\n \nextends\n \nTestHarness\nWildfireChannel\n \n{\n\n  \n@\noverride\n\n  \nFuture\n \nbeforeStart\n()\n \nasync\n \n{\n\n    \n// add initialization code that will run prior to the test application starting\n\n  \n}\n\n\n  \n@\noverride\n\n  \nFuture\n \nafterStart\n()\n \nasync\n \n{\n\n    \n// add initialization code that will run once the test application has started\n\n  \n}\n\n\n}\n\n\n\n\n\n\nUse \nbeforeStart\n to configure your test environment before your application starts. For example, you might start a \nMockHTTPServer\n that emulates another system your application integrates with, or you might set an environment variable that your application should read when it starts.\n\n\nUse \nafterStart\n to configure your test environment after the application starts. This step is useful because you may use your application's services to perform initialization. For example, you might create all of your database tables by executing queries with your \nManagedContext\n. (This is a common task, see \nharness mixins\n for a mixin that takes care of this.)\n\n\nAdd initialization code that configures your application prior to it starting in \nbeforeStart\n. This would include code that modifies \nApplicationOptions\n are sets up external services. After your application has started, you can add initialization code that configures application state, like adding OAuth 2.0 clients that will be used for testing or seeding a database with data. This initialization code is performed in \nafterStart\n.\n\n\nYou often add methods to your harness subclass for common tasks across tests. For example, if your application requires an authorized user, it makes sense to have a method that can add and authenticate a new user so that test requests are executed on behalf of that user. (This is a common task, see \nharness mixins\n for a mixin that takes care of this.)\n\n\nUsing an Agent to Execute Requests\n\n\nA \nTestHarness\nT\n has an \nagent\n property that is used to execute requests against the application being tested. An \nAgent\n has methods like \nget\n and \npost\n to execute requests and return a response object that can be validated. Its usage looks like this:\n\n\ntest\n(\nAfter POST to /thing, GET /thing/:id returns created thing\n,\n \n()\n \nasync\n \n{\n\n  \nfinal\n \npostResponse\n \n=\n \nawait\n \nharness\n.\nagent\n.\npost\n(\n/thing\n,\n \nbody:\n \n{\nkey\n:\n \nvalue\n});\n\n  \nexpectResponse\n(\npostResponse\n,\n \n200\n);\n\n\n  \nfinal\n \nthingId\n \n=\n \npostResponse\n.\nbody\n.\nas\nMap\n()[\nid\n];\n\n  \nfinal\n \ngetResponse\n \n=\n \nawait\n \nharness\n.\nagent\n.\nget\n(\n/thing/\n$\nthingId\n);\n\n  \nexpectResponse\n(\ngetResponse\n,\n \n200\n,\n \nbody:\n \n{\n\n    \nid\n:\n \nthingId\n,\n\n    \nkey\n:\n \nvalue\n\n  \n});\n\n\n});\n\n\n\n\n\n\nMost requests can be configured and executed in methods like \nTestHarness.get\n and \nTestHarness.post\n. For additional configuration options, use \nTestHarness.request\n to create a request object that can be further customized by its properties:\n\n\nfinal\n \nrequest\n \n=\n \nharness\n.\nagent\n.\nrequest\n(\n/endpoint\n)\n\n  \n..\nheaders\n[\nX-Header\n]\n \n=\n \nValue\n;\n\n\n\n\n\n\nWhen a request includes a body, the body is encoded according to the content-type of the request (defaults to JSON). The encoding behavior is provided by \nCodecRegistry\n, the same type that manages encoding and decoding for your application logic. When adding a body to a test request, you provide the unencoded value (a Dart \nMap\n, for example) and it is encoded into the correct value (a JSON object, for example). On the inverse side, when validating a response body, the body is already decoded to a Dart type prior to your test code receiving the response.\n\n\n\n\nCodecs and CodecRegistry\n\n\nYour tests will run on the same isolate as your application. Whatever codecs have been registered in the codec repository by your application are automatically made available to the code that encodes and decodes your tests requests. You don't have to do anything special to opt-in to non-default codecs.\n\n\n\n\nAgents Add Default Values to Requests\n\n\nAn \nAgent\n has defaults values that it applies to requests from it. These values include headers and the request body content-type. For example, you might want all requests to have an extra header value, without having to write the code to add the header for each request.\n\n\nThe default agent of a harness creates requests that have a \napplication/json\n \ncontentType\n. Additional agents can be created for different sets of defaults.\n\n\nThis is especially useful when testing endpoints that require authorization, where credentials need to be attached to each request. This is a common enough task that there are \nharness mixins\n that make this task easier.\n\n\nWriting Test Expectations\n\n\nAfter an agent executes a request, you write test expectations on its response. These expectations include verifying the status code, headers and body of the response are the desired values. Expectations are set by applying matchers to the properties of a response. For example:\n\n\ntest\n(\nGET /foo returns 200 OK\n,\n \n()\n \nasync\n \n{\n\n  \nfinal\n \nresponse\n \n=\n \nawait\n \nharness\n.\nagent\n.\nget\n(\n/foo\n);\n\n\n  \nexpect\n(\nresponse\n.\nstatusCode\n,\n \n200\n);\n\n  \nexpect\n(\nresponse\n,\n \nhasHeaders\n({\nx-timestamp\n:\n \ngreaterThan\n(\nDateTime\n(\n2020\n))}));\n\n  \nexpect\n(\nresponse\n,\n \nhasBody\n(\nisNull\n));\n\n\n});\n\n\n\n\n\n\nValidating response headers and bodies can be more complex than validating a status code. The \nhasBody\n and \nhasHeaders\n matchers make expectations on the response headers and body easier to write.\n\n\nThe \nhasHeaders\n matcher takes a map of header names and values, and expects that the response's headers contains a matching header for each one in the map. The value may be a \nString\n or another \nMatcher\n. The response can have more headers than expected - those headers are ignored. If you want to exactly specify all headers, there is an optional flag to pass \nhasHeaders\n.\n\n\nThe \nhasBody\n matcher takes any object or matcher that is compared to the \ndecoded\n body of the response. The body is decoded according to its content-type prior to this comparison. For example, if your response returns a JSON object \n{\"key\": \"value\"}\n, this object is first decoded into a Dart \nMap\n with the value \n{'key': 'value'}\n. The following matchers would all be true:\n\n\n// exact match of Dart Map\n\n\nexpect\n(\nresponse\n,\n \nhasBody\n({\nkey\n:\n \nvalue\n}));\n\n\n\n// a map that contains a key whose value starts with \nv\n\n\nexpect\n(\nresponse\n,\n \nhasBody\n({\nkey\n:\n \nstartsWith\n(\nv\n)}));\n\n\n\n// a map that contains the key \nkey\n\n\nexpect\n(\nresponse\n,\n \nhasBody\n(\ncontainsKey\n(\nkey\n)));\n\n\n\n// a map with one entry\n\n\nexpect\n(\nresponse\n,\n \nhasBody\n(\nhasLength\n(\n1\n)));\n\n\n\n\n\n\nFor large response bodies where you have other test coverage, you may only want to set expectations for a few values. For example, you might have a map with 50 keys, but all you care about it making sure that \nstatus='pending'\n. For this, there is a \npartial\n map matcher. It behaves similar to \nhasHeaders\n in that it only checks the keys you provide - any other keys are ignored. For example:\n\n\n// Just ensure the body contains an object with at least status=pending, version\n1\n\n\nexpect\n(\nresponse\n,\n \nhasBody\n(\npartial\n({\n\n  \nstatus\n:\n \npending\n,\n\n  \nversion\n:\n \ngreaterThan\n(\n1\n)\n\n\n})));\n\n\n\n\n\n\nWhen using \npartial\n, you can also ensure that a map doesn't have a key with the \nisNotPresent\n matcher.\n\n\ntest\n(\nGet 200 that at least have these keys\n,\n \n()\n \nasync\n \n{\n\n  \nvar\n \nresponse\n \n=\n \nawait\n \napp\n.\nclient\n.\nrequest\n(\n/endpoint\n).\nget\n();\n\n  \nexpect\n(\nresponse\n,\n \nhasResponse\n(\n200\n,\n \npartial\n({\n\n    \nkey3\n:\n \nisNotPresent\n\n  \n})));\n\n\n});\n\n\n\n\n\n\nThis ensures that \nkey3\n is not in the map. This is different than verifying \nkey3: null\n, which would be true if \nkey3\n's value was actually the null value. See the \nAPI Reference\n for \naqueduct/test\n for more matchers.\n\n\nVerifying Side Effects\n\n\nFor requests that are not idempotent (they change data in some way), you must also verify the state of the data has changed correctly after the request. This is often done by sending another request your application handles to get the updated data. For example, after you create an employee with \nPOST /employees\n, you verify the employee was stored correctly by expecting \nGET /employees/:id\n has the same data you just sent it.\n\n\nSometimes, the expected changes are not accessible through your API. For example, let's say that creating a new employee adds a record to an auditing database, but this database is not accessible through a public API. When testing, however, you would want to ensure that record was added to the database. You can access your application's services (like its database connection) in your tests through \nTestHarness.channel\n. For example, you might execute a \nQuery\nT\n against your application's test database:\n\n\ntest\n(\nPOST /employees adds an audit log record\n,\n \n()\n \nasync\n \n{\n\n  \nfinal\n \nresponse\n \n=\n \nawait\n \nharness\n.\nagent\n.\npost\n(\n/employees\n,\n \nbody:\n \n{\n\n    \nname\n:\n \nFred\n\n  \n});\n\n\n  \nexpect\n(\nresponse\n,\n \nhasStatus\n(\n202\n));\n\n\n  \nfinal\n \ncontext\n \n=\n \nharness\n.\nchannel\n.\ncontext\n;\n\n  \nfinal\n \nquery\n \n=\n \nnew\n \nQuery\nAuditRecord\n(\ncontext\n)\n\n    \n..\nwhere\n((\nrecord\n)\n \n=\n \nrecord\n.\nuser\n.\nid\n).\nequalTo\n(\nresponse\n.\nbody\n.\nas\nMap\n()[\nid\n]);\n\n  \nfinal\n \nrecord\n \n=\n \nawait\n \nquery\n.\nfetchOne\n();\n\n  \nexpect\n(\nrecord\n,\n \nisNotNull\n);\n\n\n});\n\n\n\n\n\n\nAnything the \nApplicationChannel\n can access, so too can the tests.\n\n\nFurther Reading\n\n\nFor testing applications that use OAuth 2.0 or the ORM, see the guide on \nmixins\n for important behavior.", 
            "title": "Writing Tests"
        }, 
        {
            "location": "/testing/tests/#testing-in-aqueduct", 
            "text": "From the ground up, Aqueduct is built to be tested. In practice, this means two things:   A deployed Aqueduct application has zero code differences from an Aqueduct application under test.  There are helpful utilities for writing tests in Aqueduct.", 
            "title": "Testing in Aqueduct"
        }, 
        {
            "location": "/testing/tests/#how-tests-are-written", 
            "text": "An Aqueduct test suite starts your application with a configuration file specifically built for a test instance of your application. You write test cases that verify the responses of requests sent to this application. Sometimes, you might reach into your application's services to validate that an intended side-effect was triggered. For example, you might ensure that after a request was executed, a row was added to a database table.  A  TestHarness T  is a type from  package:aqueduct_test  that handles the initialization of your application under test. It is often subclassed to add application-specific startup tasks, like seeding a database with test users or adding OAuth 2.0 clients. A test harness is installed at the beginning of your test's  main  function.  void   main ()   { \n   final   harness   =   new   TestHarness MyApplicationChannel ().. install (); \n\n   test ( GET /endpoint returns 200 and a simple object ,   ()   async   { \n     final   response   =   await   harness . agent . get ( /endpoint ); \n     expectResponse ( response ,   200 ,   body:   { key :   value }); \n   });  }}   When  TestHarness.install  is invoked, it installs two callbacks from  package:test  that will start your application in 'test mode' when the tests start, and stop it after the tests complete. An application running in 'test mode' creates a local HTTP server and instantiates your  ApplicationChannel   on the same isolate as your tests are running on . This allows you to reach into your application channel's services to add test expectations on the state that the services manage.  When your application is started in this way, its options have some default values:   the application listens on a random port  the  configurationFilePath  is  config.src.yaml   The  config.src.yaml  file must have the same structure as your deployment configurations, but values are substituted with test control values. For example, database connection configuration will point at a local test database instead of a production database. For more details on configuring an application, see  this guide .   Harness Install  The  install  method calls  setUpAll  and  tearDownAll  from  package:test  to start and stop your application. You can manually start and stop your application by invoking  TestHarness.setUp  and  TestHarness.tearDown .    Uncaught Exceptions when Testing  A test harness configures the application the let uncaught exceptions escape so that they trigger a failure in your test. This is different than when running an application normally, where all exceptions are caught and send an error response to the HTTP client.", 
            "title": "How Tests are Written"
        }, 
        {
            "location": "/testing/tests/#using-a-testharness-subclass", 
            "text": "Applications created with  aqueduct create  include a  TestHarness T  subclass that can be modified for your application's specific needs (where  T  is your application channel subclass). This file that contains this subclass is located in  test/harness/app.dart . A simple test harness subclass looks like this:  class   Harness   extends   TestHarness WildfireChannel   { \n   @ override \n   Future   beforeStart ()   async   { \n     // add initialization code that will run prior to the test application starting \n   } \n\n   @ override \n   Future   afterStart ()   async   { \n     // add initialization code that will run once the test application has started \n   }  }   Use  beforeStart  to configure your test environment before your application starts. For example, you might start a  MockHTTPServer  that emulates another system your application integrates with, or you might set an environment variable that your application should read when it starts.  Use  afterStart  to configure your test environment after the application starts. This step is useful because you may use your application's services to perform initialization. For example, you might create all of your database tables by executing queries with your  ManagedContext . (This is a common task, see  harness mixins  for a mixin that takes care of this.)  Add initialization code that configures your application prior to it starting in  beforeStart . This would include code that modifies  ApplicationOptions  are sets up external services. After your application has started, you can add initialization code that configures application state, like adding OAuth 2.0 clients that will be used for testing or seeding a database with data. This initialization code is performed in  afterStart .  You often add methods to your harness subclass for common tasks across tests. For example, if your application requires an authorized user, it makes sense to have a method that can add and authenticate a new user so that test requests are executed on behalf of that user. (This is a common task, see  harness mixins  for a mixin that takes care of this.)", 
            "title": "Using a TestHarness Subclass"
        }, 
        {
            "location": "/testing/tests/#using-an-agent-to-execute-requests", 
            "text": "A  TestHarness T  has an  agent  property that is used to execute requests against the application being tested. An  Agent  has methods like  get  and  post  to execute requests and return a response object that can be validated. Its usage looks like this:  test ( After POST to /thing, GET /thing/:id returns created thing ,   ()   async   { \n   final   postResponse   =   await   harness . agent . post ( /thing ,   body:   { key :   value }); \n   expectResponse ( postResponse ,   200 ); \n\n   final   thingId   =   postResponse . body . as Map ()[ id ]; \n   final   getResponse   =   await   harness . agent . get ( /thing/ $ thingId ); \n   expectResponse ( getResponse ,   200 ,   body:   { \n     id :   thingId , \n     key :   value \n   });  });   Most requests can be configured and executed in methods like  TestHarness.get  and  TestHarness.post . For additional configuration options, use  TestHarness.request  to create a request object that can be further customized by its properties:  final   request   =   harness . agent . request ( /endpoint ) \n   .. headers [ X-Header ]   =   Value ;   When a request includes a body, the body is encoded according to the content-type of the request (defaults to JSON). The encoding behavior is provided by  CodecRegistry , the same type that manages encoding and decoding for your application logic. When adding a body to a test request, you provide the unencoded value (a Dart  Map , for example) and it is encoded into the correct value (a JSON object, for example). On the inverse side, when validating a response body, the body is already decoded to a Dart type prior to your test code receiving the response.   Codecs and CodecRegistry  Your tests will run on the same isolate as your application. Whatever codecs have been registered in the codec repository by your application are automatically made available to the code that encodes and decodes your tests requests. You don't have to do anything special to opt-in to non-default codecs.", 
            "title": "Using an Agent to Execute Requests"
        }, 
        {
            "location": "/testing/tests/#agents-add-default-values-to-requests", 
            "text": "An  Agent  has defaults values that it applies to requests from it. These values include headers and the request body content-type. For example, you might want all requests to have an extra header value, without having to write the code to add the header for each request.  The default agent of a harness creates requests that have a  application/json   contentType . Additional agents can be created for different sets of defaults.  This is especially useful when testing endpoints that require authorization, where credentials need to be attached to each request. This is a common enough task that there are  harness mixins  that make this task easier.", 
            "title": "Agents Add Default Values to Requests"
        }, 
        {
            "location": "/testing/tests/#writing-test-expectations", 
            "text": "After an agent executes a request, you write test expectations on its response. These expectations include verifying the status code, headers and body of the response are the desired values. Expectations are set by applying matchers to the properties of a response. For example:  test ( GET /foo returns 200 OK ,   ()   async   { \n   final   response   =   await   harness . agent . get ( /foo ); \n\n   expect ( response . statusCode ,   200 ); \n   expect ( response ,   hasHeaders ({ x-timestamp :   greaterThan ( DateTime ( 2020 ))})); \n   expect ( response ,   hasBody ( isNull ));  });   Validating response headers and bodies can be more complex than validating a status code. The  hasBody  and  hasHeaders  matchers make expectations on the response headers and body easier to write.  The  hasHeaders  matcher takes a map of header names and values, and expects that the response's headers contains a matching header for each one in the map. The value may be a  String  or another  Matcher . The response can have more headers than expected - those headers are ignored. If you want to exactly specify all headers, there is an optional flag to pass  hasHeaders .  The  hasBody  matcher takes any object or matcher that is compared to the  decoded  body of the response. The body is decoded according to its content-type prior to this comparison. For example, if your response returns a JSON object  {\"key\": \"value\"} , this object is first decoded into a Dart  Map  with the value  {'key': 'value'} . The following matchers would all be true:  // exact match of Dart Map  expect ( response ,   hasBody ({ key :   value }));  // a map that contains a key whose value starts with  v  expect ( response ,   hasBody ({ key :   startsWith ( v )}));  // a map that contains the key  key  expect ( response ,   hasBody ( containsKey ( key )));  // a map with one entry  expect ( response ,   hasBody ( hasLength ( 1 )));   For large response bodies where you have other test coverage, you may only want to set expectations for a few values. For example, you might have a map with 50 keys, but all you care about it making sure that  status='pending' . For this, there is a  partial  map matcher. It behaves similar to  hasHeaders  in that it only checks the keys you provide - any other keys are ignored. For example:  // Just ensure the body contains an object with at least status=pending, version 1  expect ( response ,   hasBody ( partial ({ \n   status :   pending , \n   version :   greaterThan ( 1 )  })));   When using  partial , you can also ensure that a map doesn't have a key with the  isNotPresent  matcher.  test ( Get 200 that at least have these keys ,   ()   async   { \n   var   response   =   await   app . client . request ( /endpoint ). get (); \n   expect ( response ,   hasResponse ( 200 ,   partial ({ \n     key3 :   isNotPresent \n   })));  });   This ensures that  key3  is not in the map. This is different than verifying  key3: null , which would be true if  key3 's value was actually the null value. See the  API Reference  for  aqueduct/test  for more matchers.", 
            "title": "Writing Test Expectations"
        }, 
        {
            "location": "/testing/tests/#verifying-side-effects", 
            "text": "For requests that are not idempotent (they change data in some way), you must also verify the state of the data has changed correctly after the request. This is often done by sending another request your application handles to get the updated data. For example, after you create an employee with  POST /employees , you verify the employee was stored correctly by expecting  GET /employees/:id  has the same data you just sent it.  Sometimes, the expected changes are not accessible through your API. For example, let's say that creating a new employee adds a record to an auditing database, but this database is not accessible through a public API. When testing, however, you would want to ensure that record was added to the database. You can access your application's services (like its database connection) in your tests through  TestHarness.channel . For example, you might execute a  Query T  against your application's test database:  test ( POST /employees adds an audit log record ,   ()   async   { \n   final   response   =   await   harness . agent . post ( /employees ,   body:   { \n     name :   Fred \n   }); \n\n   expect ( response ,   hasStatus ( 202 )); \n\n   final   context   =   harness . channel . context ; \n   final   query   =   new   Query AuditRecord ( context ) \n     .. where (( record )   =   record . user . id ). equalTo ( response . body . as Map ()[ id ]); \n   final   record   =   await   query . fetchOne (); \n   expect ( record ,   isNotNull );  });   Anything the  ApplicationChannel  can access, so too can the tests.", 
            "title": "Verifying Side Effects"
        }, 
        {
            "location": "/testing/tests/#further-reading", 
            "text": "For testing applications that use OAuth 2.0 or the ORM, see the guide on  mixins  for important behavior.", 
            "title": "Further Reading"
        }, 
        {
            "location": "/testing/mixins/", 
            "text": "Testing Applications That Use ORM and OAuth 2.0\n\n\nAqueduct's ORM uses PostgreSQL as its database. To run the application or its automated tests locally, you must have PostgreSQL installed locally. On macOS, \nPostgres.app\n is a simple, self-contained PostgreSQL instance that you can run as a normal application. (See \nPostgreSQL installation for other platforms\n.)\n\n\nLocal Database for Tests\n\n\nAn application running automated tests defaults to connecting to a database with the following configuration:\n\n\nusername\n:\n \ndart\n\n\npassword\n:\n \ndart\n\n\nhost\n:\n \nlocalhost\n\n\nport\n:\n \n5432\n\n\ndatabaseName\n:\n \ndart_test\n\n\n\n\n\n\nOnce PostgreSQL has been installed locally, you may create a database user and database that matches this connection info by running the following command:\n\n\naqueduct setup\n\n\n\n\n\nAqueduct tests create a temporary database schema that matches your application schema in the \ndart_test\n database. The tables and data in this database are discarded when the tests complete. For this reason, no other tables should be created in this database to avoid conflicts with tests. This default behavior of Aqueduct tests is provided by a \ntest harness\n.\n\n\nLocal Database for Running an Application\n\n\nA database separate from the test database should be used for \nrunning\n an application locally. You can create a database locally by running \npsql\n to open a PostgreSQL terminal and run the following commands:\n\n\nCREATE DATABASE my_local_app_db;\nCREATE USER my_local_app_user WITH PASSWORD \nmypassword\n;\nGRANT ALL ON DATABASE my_local_app_db TO my_local_app_user;\n\n\n\n\n\nAdd your schema to the local database by generating and executing migration scripts:\n\n\naqueduct db generate\naqueduct db upgrade --connect postgres://my_local_app_user:mypassword@localhost:5432/my_local_app_db\n\n\n\n\n\nUse Local Configuration Files\n\n\nUse \nconfiguration files\n to manage which database an application connects to. This may or may not be checked into source control, depending on a team's preference. Control which file is loaded with command-line options to \naqueduct serve\n or the \nbin/main.dart\n script:\n\n\naqueduct serve -c local.yaml\n\n\n\n\n\nHave Scripts to Provision Based on Scenarios\n\n\nIt is often the case that you will want to have a certain set of data in an local database for the purpose of testing a client application. Create \nbin\n scripts to provision the database and add the desired data. For example, you might have a script named \nbin/ios_integration.dart\n that re-provisions a database and inserts data into it using \nQuery\nT\n instances and the \nManagedObject\nT\ns declared in your application.\n\n\nimport\n \ndart:io\n;\n\n\nimport\n \npackage:myapp/myapp.dart\n;\n\n\n\nFuture\n \nmain\n()\n \nasync\n \n{\n\n  \nawait\n \nprovisionDatabase\n();\n\n\n  \nvar\n \ndefaultUser\n \n=\n \nnew\n \nUser\n(...);\n\n  \nawait\n \nQuery\n.\ninsertObject\n(\ncontext\n,\n \ndefaultUser\n);\n\n  \n...\n\n\n}\n\n\n\nFuture\n \nprovisionDatabase\n()\n \nasync\n \n{\n\n  \nvar\n \ncommands\n \n=\n \n[\n\n    \nCREATE DATABASE local_app;\n,\n\n    \nCREATE USER local_user WITH PASSWORD \nlocal\n;\n,\n\n    \nGRANT ALL ON DATABASE local_app TO local_user;\n\n  \n];\n\n\n  \nawait\n \nFuture\n.\nforEach\n(\ncommands\n,\n \n(\ncmd\n)\n \n{\n\n    \nList\nString\n \nargs\n \n=\n \n[\n-c\n,\n \ncmd\n,\n \n-U\n,\n \ngrantingUser\n];\n\n    \nreturn\n \nProcess\n.\nrun\n(\npsql\n,\n \nargs\n,\n \nrunInShell:\n \ntrue\n);\n\n  \n});\n\n\n}", 
            "title": "Testing with the ORM and OAuth 2.0"
        }, 
        {
            "location": "/testing/mixins/#testing-applications-that-use-orm-and-oauth-20", 
            "text": "Aqueduct's ORM uses PostgreSQL as its database. To run the application or its automated tests locally, you must have PostgreSQL installed locally. On macOS,  Postgres.app  is a simple, self-contained PostgreSQL instance that you can run as a normal application. (See  PostgreSQL installation for other platforms .)", 
            "title": "Testing Applications That Use ORM and OAuth 2.0"
        }, 
        {
            "location": "/testing/mixins/#local-database-for-tests", 
            "text": "An application running automated tests defaults to connecting to a database with the following configuration:  username :   dart  password :   dart  host :   localhost  port :   5432  databaseName :   dart_test   Once PostgreSQL has been installed locally, you may create a database user and database that matches this connection info by running the following command:  aqueduct setup  Aqueduct tests create a temporary database schema that matches your application schema in the  dart_test  database. The tables and data in this database are discarded when the tests complete. For this reason, no other tables should be created in this database to avoid conflicts with tests. This default behavior of Aqueduct tests is provided by a  test harness .", 
            "title": "Local Database for Tests"
        }, 
        {
            "location": "/testing/mixins/#local-database-for-running-an-application", 
            "text": "A database separate from the test database should be used for  running  an application locally. You can create a database locally by running  psql  to open a PostgreSQL terminal and run the following commands:  CREATE DATABASE my_local_app_db;\nCREATE USER my_local_app_user WITH PASSWORD  mypassword ;\nGRANT ALL ON DATABASE my_local_app_db TO my_local_app_user;  Add your schema to the local database by generating and executing migration scripts:  aqueduct db generate\naqueduct db upgrade --connect postgres://my_local_app_user:mypassword@localhost:5432/my_local_app_db", 
            "title": "Local Database for Running an Application"
        }, 
        {
            "location": "/testing/mixins/#use-local-configuration-files", 
            "text": "Use  configuration files  to manage which database an application connects to. This may or may not be checked into source control, depending on a team's preference. Control which file is loaded with command-line options to  aqueduct serve  or the  bin/main.dart  script:  aqueduct serve -c local.yaml", 
            "title": "Use Local Configuration Files"
        }, 
        {
            "location": "/testing/mixins/#have-scripts-to-provision-based-on-scenarios", 
            "text": "It is often the case that you will want to have a certain set of data in an local database for the purpose of testing a client application. Create  bin  scripts to provision the database and add the desired data. For example, you might have a script named  bin/ios_integration.dart  that re-provisions a database and inserts data into it using  Query T  instances and the  ManagedObject T s declared in your application.  import   dart:io ;  import   package:myapp/myapp.dart ;  Future   main ()   async   { \n   await   provisionDatabase (); \n\n   var   defaultUser   =   new   User (...); \n   await   Query . insertObject ( context ,   defaultUser ); \n   ...  }  Future   provisionDatabase ()   async   { \n   var   commands   =   [ \n     CREATE DATABASE local_app; , \n     CREATE USER local_user WITH PASSWORD  local ; , \n     GRANT ALL ON DATABASE local_app TO local_user; \n   ]; \n\n   await   Future . forEach ( commands ,   ( cmd )   { \n     List String   args   =   [ -c ,   cmd ,   -U ,   grantingUser ]; \n     return   Process . run ( psql ,   args ,   runInShell:   true ); \n   });  }", 
            "title": "Have Scripts to Provision Based on Scenarios"
        }, 
        {
            "location": "/testing/debugger/", 
            "text": "Using the IntelliJ IDE Debugger\n\n\nThe debugger may be used when running tests or developing client applications locally.\n\n\nEnabling the Debugger\n\n\nApplications created by \naqueduct create\n ship with a \nbin/main.dart\n script that starts the application. When developing, running this script from an IDE is often preferred to \naqueduct serve\n because the IDE can leverage its full capabilities. One such capability is a debugger. In IntelliJ IDEA (and its suite of products), you may right-click on this file and select 'Debug' from the pop-up menu to run the application in the debugger.\n\n\n\n\nSetting Breakpoints\n\n\nA valuable feature of a debugger is the ability to set breakpoints. A breakpoint pauses execution of your application at a specific point in the code, allowing you to view variable values and monitor the code path line-by-line as execution continues.\n\n\nTo set a breakpoint, you simply click on the gutter area next to the line of code you wish to stop at.\n\n\n\n\nOnce a debugger stops, you can view variable values in the center pane of the debugging panel. The left pane (labeled 'Frames') shows the current stack trace. The row of buttons above the stack trace allow you to continue executing code line-by-line.\n\n\nEach button in this row has a slightly different behavior. From left to right:\n\n\n\n\nThe red arrow with the stack of lines continues execution until the next breakpoint is encountered.\n\n\nThe blue downwards arrow executes the current line and moves to the next line.\n\n\nThe blue right/downward arrow continues execution into the function that is about to be called and stops on its first line.\n\n\nThe red right/downward arrow is the same as above, but will also jump into dependency code.\n\n\nThe blue right/upwards arrow completes execution of the current method and stops right after the callsite.\n\n\n\n\nNote that currently asynchronous invocations confuse the debugger a bit. To continue past an asynchronous method to the next line, set a breakpoint on that next line and hit the big green arrow on the left column of buttons.\n\n\nTo jump into an asynchronous method, command-click on its definition and set a breakpoint on its first line and then click the big green arrow.\n\n\nProfiling with Observatory\n\n\nYou may also use \nObservatory\n to profile applications. Profiling consists of monitoring memory usage, allocations and how much time a function spends executing relative to the rest of your application.\n\n\nBoth \naqueduct serve\n and \nbin/main.dart\n support starting Observatory. When running the application with \naqueduct serve\n, add the \n--observe\n flag and Observatory will start listening on port 8181 and a web browser will automatically be opened.\n\n\naqueduct serve --observe\n\n\n\n\n\nWhen running the application through IntelliJ, Observatory will start listening on a random port. In the run console in IntelliJ, you may click on the Observatory hyperlink to open it in your web browser.", 
            "title": "Using the Debugger"
        }, 
        {
            "location": "/testing/debugger/#using-the-intellij-ide-debugger", 
            "text": "The debugger may be used when running tests or developing client applications locally.", 
            "title": "Using the IntelliJ IDE Debugger"
        }, 
        {
            "location": "/testing/debugger/#enabling-the-debugger", 
            "text": "Applications created by  aqueduct create  ship with a  bin/main.dart  script that starts the application. When developing, running this script from an IDE is often preferred to  aqueduct serve  because the IDE can leverage its full capabilities. One such capability is a debugger. In IntelliJ IDEA (and its suite of products), you may right-click on this file and select 'Debug' from the pop-up menu to run the application in the debugger.", 
            "title": "Enabling the Debugger"
        }, 
        {
            "location": "/testing/debugger/#setting-breakpoints", 
            "text": "A valuable feature of a debugger is the ability to set breakpoints. A breakpoint pauses execution of your application at a specific point in the code, allowing you to view variable values and monitor the code path line-by-line as execution continues.  To set a breakpoint, you simply click on the gutter area next to the line of code you wish to stop at.   Once a debugger stops, you can view variable values in the center pane of the debugging panel. The left pane (labeled 'Frames') shows the current stack trace. The row of buttons above the stack trace allow you to continue executing code line-by-line.  Each button in this row has a slightly different behavior. From left to right:   The red arrow with the stack of lines continues execution until the next breakpoint is encountered.  The blue downwards arrow executes the current line and moves to the next line.  The blue right/downward arrow continues execution into the function that is about to be called and stops on its first line.  The red right/downward arrow is the same as above, but will also jump into dependency code.  The blue right/upwards arrow completes execution of the current method and stops right after the callsite.   Note that currently asynchronous invocations confuse the debugger a bit. To continue past an asynchronous method to the next line, set a breakpoint on that next line and hit the big green arrow on the left column of buttons.  To jump into an asynchronous method, command-click on its definition and set a breakpoint on its first line and then click the big green arrow.", 
            "title": "Setting Breakpoints"
        }, 
        {
            "location": "/testing/debugger/#profiling-with-observatory", 
            "text": "You may also use  Observatory  to profile applications. Profiling consists of monitoring memory usage, allocations and how much time a function spends executing relative to the rest of your application.  Both  aqueduct serve  and  bin/main.dart  support starting Observatory. When running the application with  aqueduct serve , add the  --observe  flag and Observatory will start listening on port 8181 and a web browser will automatically be opened.  aqueduct serve --observe  When running the application through IntelliJ, Observatory will start listening on a random port. In the run console in IntelliJ, you may click on the Observatory hyperlink to open it in your web browser.", 
            "title": "Profiling with Observatory"
        }, 
        {
            "location": "/testing/clients/", 
            "text": "Using Aqueduct when Writing Client Applications\n\n\nRunning an Aqueduct server locally while developing client applications is an important part of the development process. Run applications through their \nbin/main.dart\n script or \naqueduct serve\n. The former allows for \ndebugging\n the application with a debugger.\n\n\nEnable Logging and Return Server Errors\n\n\nEnsure that logging is on while developing client applications by registering a listener on \nApplicationChannel.logger\n.\n\n\nclass\n \nMyApplicationChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \nlogger\n.\nonRecord\n.\nlisten\n((\nrecord\n)\n \n{\n\n      \nprint\n(\n$\nrecord\n \n${\nrecord\n.\nerror\n \n??\n \n}\n \n${\nrecord\n.\nstackTrace\n \n??\n \n}\n);\n\n    \n});\n\n  \n}\n\n  \n...\n\n\n}\n\n\n\n\n\n\nA useful feature to turn on during debugging is sending stack traces for 500 Server Error responses. Turn this flag on in a \nApplicationChannel\n while debugging:\n\n\nclass\n \nMyApplicationChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \nController\n.\nincludeErrorDetailsInServerErrorResponses\n \n=\n \ntrue\n;\n\n  \n}\n\n  \n...\n\n\n}\n\n\n\n\n\n\nWhen a 500 error is encountered, the server will send the stack trace back to the client so you can view it while developing the client application without having to switch terminals. This property should never be left on for production code.\n\n\nAvoid Port Conflicts\n\n\nApplications run with \naqueduct serve\n default to port 8888. You may use the \n--port\n command-line option to pick a different port:\n\n\naqueduct serve --port 4000\n\n\n\n\n\nProvision a Database for Client Testing\n\n\nFor applications that use the ORM, you must have a locally running database with your application's data model. See \nprovisioning a database\n for more details.\n\n\nIf you are using OAuth 2.0, you must have also added client identifiers to the locally running database. You may add client identifiers with the \naqueduct auth\n command-line tool, or as part of a utility provisioning script:\n\n\nimport\n \npackage:aqueduct/aqueduct.dart\n;\n\n\nimport\n \npackage:aqueduct/managed_auth.dart\n;\n\n\nimport\n \npackage:myapp/myapp.dart\n;\n\n\n\nFuture\n \nmain\n()\n \nasync\n \n{\n\n  \nfinal\n \ndataModel\n \n=\n \nnew\n \nManagedDataModel\n.\nfromCurrentMirrorSystem\n();\n\n  \nfinal\n \ncontext\n \n=\n \n=\n \nnew\n \nManagedContext\n(\ndataModel\n,\n \npersistentStore\n);\n\n\n  \nvar\n \ncredentials\n \n=\n \nAuthUtility\n.\ngenerateAPICredentialPair\n(\nlocal.testing\n,\n \nsecretpassword\n);\n\n\n  \nvar\n \nmanagedCredentials\n \n=\n \nnew\n \nManagedAuthClient\n()\n\n    \n..\nid\n \n=\n \ncredentials\n.\nid\n\n    \n..\nhashedSecret\n \n=\n \ncredentials\n.\nhashedSecret\n\n    \n..\nsalt\n \n=\n \ncredentials\n.\nsalt\n;\n\n\n  \nvar\n \nquery\n \n=\n \nnew\n \nQuery\nManagedAuthClient\n(\ncontext\n)..\nvalues\n \n=\n \nmanagedCredentials\n;\n\n  \nawait\n \nquery\n.\ninsert\n();\n\n\n}", 
            "title": "Developing Client Applications"
        }, 
        {
            "location": "/testing/clients/#using-aqueduct-when-writing-client-applications", 
            "text": "Running an Aqueduct server locally while developing client applications is an important part of the development process. Run applications through their  bin/main.dart  script or  aqueduct serve . The former allows for  debugging  the application with a debugger.", 
            "title": "Using Aqueduct when Writing Client Applications"
        }, 
        {
            "location": "/testing/clients/#enable-logging-and-return-server-errors", 
            "text": "Ensure that logging is on while developing client applications by registering a listener on  ApplicationChannel.logger .  class   MyApplicationChannel   extends   ApplicationChannel   { \n   @ override \n   Future   prepare ()   async   { \n     logger . onRecord . listen (( record )   { \n       print ( $ record   ${ record . error   ??   }   ${ record . stackTrace   ??   } ); \n     }); \n   } \n   ...  }   A useful feature to turn on during debugging is sending stack traces for 500 Server Error responses. Turn this flag on in a  ApplicationChannel  while debugging:  class   MyApplicationChannel   extends   ApplicationChannel   { \n   @ override \n   Future   prepare ()   async   { \n     Controller . includeErrorDetailsInServerErrorResponses   =   true ; \n   } \n   ...  }   When a 500 error is encountered, the server will send the stack trace back to the client so you can view it while developing the client application without having to switch terminals. This property should never be left on for production code.", 
            "title": "Enable Logging and Return Server Errors"
        }, 
        {
            "location": "/testing/clients/#avoid-port-conflicts", 
            "text": "Applications run with  aqueduct serve  default to port 8888. You may use the  --port  command-line option to pick a different port:  aqueduct serve --port 4000", 
            "title": "Avoid Port Conflicts"
        }, 
        {
            "location": "/testing/clients/#provision-a-database-for-client-testing", 
            "text": "For applications that use the ORM, you must have a locally running database with your application's data model. See  provisioning a database  for more details.  If you are using OAuth 2.0, you must have also added client identifiers to the locally running database. You may add client identifiers with the  aqueduct auth  command-line tool, or as part of a utility provisioning script:  import   package:aqueduct/aqueduct.dart ;  import   package:aqueduct/managed_auth.dart ;  import   package:myapp/myapp.dart ;  Future   main ()   async   { \n   final   dataModel   =   new   ManagedDataModel . fromCurrentMirrorSystem (); \n   final   context   =   =   new   ManagedContext ( dataModel ,   persistentStore ); \n\n   var   credentials   =   AuthUtility . generateAPICredentialPair ( local.testing ,   secretpassword ); \n\n   var   managedCredentials   =   new   ManagedAuthClient () \n     .. id   =   credentials . id \n     .. hashedSecret   =   credentials . hashedSecret \n     .. salt   =   credentials . salt ; \n\n   var   query   =   new   Query ManagedAuthClient ( context ).. values   =   managedCredentials ; \n   await   query . insert ();  }", 
            "title": "Provision a Database for Client Testing"
        }, 
        {
            "location": "/testing/mock/", 
            "text": "Mocking External Services\n\n\nAn Aqueduct application often communicates with another server. For example, an application might make requests to the GitHub API to collect analytics about a team's workflow. When running automated tests, consuming the actual GitHub API isn't feasible - because GitHub will probably rate limit you and because the data being returned is constantly changing.\n\n\nTo solve this problem, you can create \"mocks\" of a service during testing. Aqueduct has two testing utilities for this purpose - \nMockServer\n and \nMockHTTPServer\n - in the \naqueduct/test\n library.\n\n\nUsing a MockHTTPServer\n\n\nWhen testing your application, you send it requests using a \nTestClient\n. As part of the request handling logic, your application might issue requests to some other server. \nMockHTTPServer\n allows you to validate that the request your application sent was correct and gives you control what the responses are to those requests. For example, \ngithubMock\n is an instance of \nMockHTTPServer\n in the following test, which ensures that the request was constructed correctly:\n\n\ntest\n(\nWill get correct user from GitHub\n,\n \n()\n \nasync\n \n{\n\n  \nvar\n \nresponse\n \n=\n\n    \nawait\n \napp\n.\nclient\n.\nauthenticatedRequest\n(\n/github_profile/fred\n).\nget\n();\n\n\n  \nvar\n \nrequestSentByYourApplicationToGitHub\n \n=\n \nawait\n \ngithubMock\n.\nnext\n();\n\n  \nexpect\n(\nrequestSentByYourApplicationToGitHub\n.\nmethod\n,\n \nGET\n);\n\n  \nexpect\n(\nrequestSentByYourApplicationToGitHub\n.\npath\n,\n \n/users/search?name=fred\n);\n\n\n});\n\n\n\n\n\n\nIn the above code, we are expecting that anytime the request \nGET /github_profile/fred\n is sent to your application, that it turns around and searches for a user in GitHub's API. This test ensures that we have correctly translated our request to a request to be made to the GitHub API. If no request was made - because of a programmer error - this test would fail because the \nFuture\n returned from \ngithubMock.next()\n would never complete. There is no next request, because none was ever delivered!\n\n\nBy default, any request sent to a \nMockHTTPServer\n is a 200 OK Response with an empty body. You may change this behavior by queuing responses in a mock server.\n\n\ntest\n(\nWill get correct user from GitHub\n,\n \n()\n \nasync\n \n{\n\n  \ngithubMock\n.\nqueueResponse\n(\nnew\n \nResponse\n.\nok\n({\nid\n:\n \n1\n,\n \nname\n:\n \nfred\n}));\n\n\n  \nvar\n \nresponse\n \n=\n\n    \nawait\n \napp\n.\nclient\n.\nauthenticatedRequest\n(\n/github_profile/fred\n).\nget\n();\n\n  \nexpect\n(\nresponse\n,\n \nhasResponse\n(\n200\n,\n \npartial\n({\n\n    \nid\n:\n \n1\n,\n\n    \nname\n:\n \nfred\n\n  \n})))\n\n\n});\n\n\n\n\n\n\nIn the above code, \nqueueResponse\n adds a 200 OK Response to the mock server queue with a specific body. The mock server will send that response for the next request it receives. In the implementation of \n/github_profile/fred\n, your application sends a \nGET /users/search?name=fred\n to the GitHub API - except the GitHub API is your mock server, and it returns the response you queued instead. Thus, the queued up response is the expected response of the GitHub API.\n\n\nAfter the request completes, the response is removed from the queue and subsequent responses will go back to the default. You may queue as many responses as you like. You may also simulate a failed request - one that never gets a response - like so:\n\n\nmockServer\n.\nqueueResponse\n(\nMockHTTPServer\n.\nmockConnectionFailureResponse\n);\n\n\n\n\n\n\nYou may also subclass \nMockHTTPServer\n and override its \nopen\n method to add logic to determine the response. Please see the implementation of \nMockHTTPServer.open\n for more details.\n\n\nConfiguring a MockHTTPServer\n\n\nA \nMockHTTPServer\n is created when setting up tests. It must be closed when tearing down tests. If you use the same mock server to across all tests (e.g., open it in \nsetUpAll\n), make sure to clear it after each test:\n\n\nimport\n \npackage:aqueduct/test.dart\n;\n\n\n\nvoid\n \nmain\n()\n \n{\n\n  \nvar\n \nmockServer\n \n=\n \nnew\n \nMockHTTPServer\n(\n4000\n);\n\n\n  \nsetUpAll\n(()\n \nasync\n \n{\n\n    \nawait\n \nmockServer\n.\nopen\n();\n\n  \n});\n\n\n  \ntearDownAll\n(()\n \nasync\n \n{\n\n    \nawait\n \nmockServer\n.\nclose\n();\n\n  \n});\n\n\n  \ntearDown\n(()\n \nasync\n \n{\n\n    \nmockServer\n.\nclear\n();\n\n  \n});\n\n\n}\n\n\n\n\n\n\nAn instance of \nMockHTTPServer\n listens on localhost on a specific port. An application that makes testable external service requests should provide the base URI for those services in a configuration file. The URI for that service in the \nconfiguration file used during testing\n should point at localhost and a specific port. For example, if a deployed \nconfig.yaml\n file has the following key-values:\n\n\ngithub\n:\n\n  \nbaseURL\n:\n \nhttps\n://\napi\n.\ngithub\n.\ncom\n/\n  \n\n\n\n\n\nThen \nconfig.src.yaml\n would have:\n\n\ngithub\n:\n\n  \nbaseURL\n:\n \nhttp\n://\nlocalhost\n:\n4000\n/\n\n\n\n\n\n\nYour application reads this configuration file and injects the base URL into the service that will execute requests.\n\n\nclass\n \nAppConfigurationItem\n \nextends\n \nConfigurationItem\n \n{\n\n  \nAppConfigurationItem\n(\nString\n \nfileName\n)\n \n:\n \nsuper\n.\nfromFile\n(\nfileName\n);\n\n\n  \nAPIConfiguration\n \ngithub\n;\n\n\n}\n\n\n\nclass\n \nAppApplicationChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \nvar\n \nconfig\n \n=\n \nnew\n \nAppConfigurationItem\n(\noptions\n.\nconfigurationFilePath\n);\n\n\n    \ngithubService\n \n=\n \nnew\n \nGitHubService\n(\nbaseURL:\n \nconfig\n.\ngithub\n.\nbaseURL\n);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nNote that \nAPIConfiguration\n is an existing type and is meant for this purpose.\n\n\nAlso note that the testing strategy for database connections is \nnot\n to use a mock but to use a temporary, local database that is set up and torn down during tests. This is possible because you own the data model generating code - whereas you probably don't have access to an external service's development API.", 
            "title": "Mocking Services"
        }, 
        {
            "location": "/testing/mock/#mocking-external-services", 
            "text": "An Aqueduct application often communicates with another server. For example, an application might make requests to the GitHub API to collect analytics about a team's workflow. When running automated tests, consuming the actual GitHub API isn't feasible - because GitHub will probably rate limit you and because the data being returned is constantly changing.  To solve this problem, you can create \"mocks\" of a service during testing. Aqueduct has two testing utilities for this purpose -  MockServer  and  MockHTTPServer  - in the  aqueduct/test  library.", 
            "title": "Mocking External Services"
        }, 
        {
            "location": "/testing/mock/#using-a-mockhttpserver", 
            "text": "When testing your application, you send it requests using a  TestClient . As part of the request handling logic, your application might issue requests to some other server.  MockHTTPServer  allows you to validate that the request your application sent was correct and gives you control what the responses are to those requests. For example,  githubMock  is an instance of  MockHTTPServer  in the following test, which ensures that the request was constructed correctly:  test ( Will get correct user from GitHub ,   ()   async   { \n   var   response   = \n     await   app . client . authenticatedRequest ( /github_profile/fred ). get (); \n\n   var   requestSentByYourApplicationToGitHub   =   await   githubMock . next (); \n   expect ( requestSentByYourApplicationToGitHub . method ,   GET ); \n   expect ( requestSentByYourApplicationToGitHub . path ,   /users/search?name=fred );  });   In the above code, we are expecting that anytime the request  GET /github_profile/fred  is sent to your application, that it turns around and searches for a user in GitHub's API. This test ensures that we have correctly translated our request to a request to be made to the GitHub API. If no request was made - because of a programmer error - this test would fail because the  Future  returned from  githubMock.next()  would never complete. There is no next request, because none was ever delivered!  By default, any request sent to a  MockHTTPServer  is a 200 OK Response with an empty body. You may change this behavior by queuing responses in a mock server.  test ( Will get correct user from GitHub ,   ()   async   { \n   githubMock . queueResponse ( new   Response . ok ({ id :   1 ,   name :   fred })); \n\n   var   response   = \n     await   app . client . authenticatedRequest ( /github_profile/fred ). get (); \n   expect ( response ,   hasResponse ( 200 ,   partial ({ \n     id :   1 , \n     name :   fred \n   })))  });   In the above code,  queueResponse  adds a 200 OK Response to the mock server queue with a specific body. The mock server will send that response for the next request it receives. In the implementation of  /github_profile/fred , your application sends a  GET /users/search?name=fred  to the GitHub API - except the GitHub API is your mock server, and it returns the response you queued instead. Thus, the queued up response is the expected response of the GitHub API.  After the request completes, the response is removed from the queue and subsequent responses will go back to the default. You may queue as many responses as you like. You may also simulate a failed request - one that never gets a response - like so:  mockServer . queueResponse ( MockHTTPServer . mockConnectionFailureResponse );   You may also subclass  MockHTTPServer  and override its  open  method to add logic to determine the response. Please see the implementation of  MockHTTPServer.open  for more details.", 
            "title": "Using a MockHTTPServer"
        }, 
        {
            "location": "/testing/mock/#configuring-a-mockhttpserver", 
            "text": "A  MockHTTPServer  is created when setting up tests. It must be closed when tearing down tests. If you use the same mock server to across all tests (e.g., open it in  setUpAll ), make sure to clear it after each test:  import   package:aqueduct/test.dart ;  void   main ()   { \n   var   mockServer   =   new   MockHTTPServer ( 4000 ); \n\n   setUpAll (()   async   { \n     await   mockServer . open (); \n   }); \n\n   tearDownAll (()   async   { \n     await   mockServer . close (); \n   }); \n\n   tearDown (()   async   { \n     mockServer . clear (); \n   });  }   An instance of  MockHTTPServer  listens on localhost on a specific port. An application that makes testable external service requests should provide the base URI for those services in a configuration file. The URI for that service in the  configuration file used during testing  should point at localhost and a specific port. For example, if a deployed  config.yaml  file has the following key-values:  github : \n   baseURL :   https :// api . github . com /     Then  config.src.yaml  would have:  github : \n   baseURL :   http :// localhost : 4000 /   Your application reads this configuration file and injects the base URL into the service that will execute requests.  class   AppConfigurationItem   extends   ConfigurationItem   { \n   AppConfigurationItem ( String   fileName )   :   super . fromFile ( fileName ); \n\n   APIConfiguration   github ;  }  class   AppApplicationChannel   extends   ApplicationChannel   { \n   @ override \n   Future   prepare ()   async   { \n     var   config   =   new   AppConfigurationItem ( options . configurationFilePath ); \n\n     githubService   =   new   GitHubService ( baseURL:   config . github . baseURL ); \n   }  }   Note that  APIConfiguration  is an existing type and is meant for this purpose.  Also note that the testing strategy for database connections is  not  to use a mock but to use a temporary, local database that is set up and torn down during tests. This is possible because you own the data model generating code - whereas you probably don't have access to an external service's development API.", 
            "title": "Configuring a MockHTTPServer"
        }, 
        {
            "location": "/deploy/", 
            "text": "Tasks\n\n\nAqueduct has a built in tool, \naqueduct\n, for deploying Aqueduct applications, managing database schemas, OAuth 2.0 clients and creating projects. See \nGetting Started\n for installation instructions. Many of the tasks for deployment rely on using this tool.\n\n\nAqueduct applications can be run anywhere that Dart can be installed. This topic covers deployment tasks on common hosting services. If you are just getting started or a hobbyist, you should consider using \nHeroku\n to host your applications.\n\n\nGuides\n\n\n\n\nRunning an Aqueduct Application Locally\n\n\nRunning an Aqueduct Application on Heroku\n\n\nRunning an Aqueduct Application on Amazon Web Services (AWS)\n\n\nRunning an Aqueduct Application without aqueduct serve", 
            "title": "Overview"
        }, 
        {
            "location": "/deploy/#tasks", 
            "text": "Aqueduct has a built in tool,  aqueduct , for deploying Aqueduct applications, managing database schemas, OAuth 2.0 clients and creating projects. See  Getting Started  for installation instructions. Many of the tasks for deployment rely on using this tool.  Aqueduct applications can be run anywhere that Dart can be installed. This topic covers deployment tasks on common hosting services. If you are just getting started or a hobbyist, you should consider using  Heroku  to host your applications.", 
            "title": "Tasks"
        }, 
        {
            "location": "/deploy/#guides", 
            "text": "Running an Aqueduct Application Locally  Running an Aqueduct Application on Heroku  Running an Aqueduct Application on Amazon Web Services (AWS)  Running an Aqueduct Application without aqueduct serve", 
            "title": "Guides"
        }, 
        {
            "location": "/deploy/deploy_local/", 
            "text": "Deploying an Aqueduct Application on a Local Machine\n\n\nFor other deployment options, see \nDeploying Aqueduct Applications\n.\n\n\nPurpose\n\n\nTo run a local development version of an Aqueduct application with persistent storage. This is useful in developing client applications against an Aqueduct application. Make sure to also read \nTesting Aqueduct Applications\n.\n\n\nPrerequisites\n\n\n\n\nDart has been installed.\n\n\nPostgreSQL has been installed locally.\n\n\nAqueduct has been activated globally.\n\n\nAn application has been created with \naqueduct create\n.\n\n\n\n\nIf one or more of these is not true, see \nGetting Started\n.\n\n\nOverview\n\n\n\n\nCreate a local database.\n\n\nUpload the application schema to the local database.\n\n\nAdd an OAuth 2.0 client.\n\n\nModify the configuration file.\n\n\nRun the application.\n\n\n\n\nEstimated Time: \n5 minutes.\n\n\nStep 1: Create a Local Database\n\n\nCreate a database with the same name as your application and a user that can access that database. Do not use the name 'dart_test' for the database; this database is used by Aqueduct to run tests by default.\n\n\nRun the following SQL locally with a user that has privileges to create databases. (If using \nPostgres.app\n, open the \npsql\n terminal from the \nPostgres.app\n status menu item \nOpen psql\n).\n\n\nCREATE\n \nDATABASE\n \napp_name\n;\n\n\nCREATE\n \nUSER\n \napp_name_user\n \nWITH\n \nCREATEDB\n;\n\n\nALTER\n \nUSER\n \napp_name_user\n \nWITH\n \nPASSWORD\n \nyourpassword\n;\n\n\nGRANT\n \nALL\n \nON\n \nDATABASE\n \napp_name\n \nTO\n \napp_name_user\n;\n\n\n\n\n\n\nStep 2: Upload the Application Schema\n\n\nRun the database schema generation tool from the project directory:\n\n\naqueduct db generate\n\n\n\n\n\nThis command creates the file \nmigrations/00000001_initial.migration.dart\n. Now, run the database migration tool to execute the migration file against the local database. Ensure that the values for the option \n--connect\n match those of the database created in the last step.\n\n\naqueduct db upgrade --connect postgres://app_name_user:yourpassword@localhost:5432/app_name\n\n\n\n\n\n(Note that you may provide database credentials in a file named \ndatabase.yaml\n instead of using \n--connect\n. See \naqueduct db --help\n for details.)\n\n\nStep 3: Add an OAuth 2.0 client.\n\n\nFrom the command line, run the following, ensuring that the values for the option \n--connect\n match the recently created database.\n\n\naqueduct auth add-client --id com.app_name.standard --secret abcdefghi --connect postgres://app_name_user:yourpassword@localhost:5432/app_name\n\n\n\n\n\nStep 4: Modify the Configuration File\n\n\nIf \nconfig.yaml\n doesn't exist, create it by copying the configuration file template \nconfig.yaml.src\n.\n\n\nIn \nconfig.yaml\n, update the database credentials to the local database.\n\n\ndatabase\n:\n\n \nusername\n:\n \napp_name_user\n\n \npassword\n:\n \nyourpassword\n\n \nhost\n:\n \nlocalhost\n\n \nport\n:\n \n5432\n\n \ndatabaseName\n:\n \napp_name\n\n\n\n\n\n\nStep 5: Run the Application\n\n\nFrom the project directory, run:\n\n\naqueduct serve\n\n\n\n\n\nYour application is now running.\n\n\nNote: You can add the \n--observe\n flag to \naqueduct serve\n to run Observatory. Observatory will automatically open in a browser if the platform supports it.", 
            "title": "Deploy Locally"
        }, 
        {
            "location": "/deploy/deploy_local/#deploying-an-aqueduct-application-on-a-local-machine", 
            "text": "For other deployment options, see  Deploying Aqueduct Applications .", 
            "title": "Deploying an Aqueduct Application on a Local Machine"
        }, 
        {
            "location": "/deploy/deploy_local/#purpose", 
            "text": "To run a local development version of an Aqueduct application with persistent storage. This is useful in developing client applications against an Aqueduct application. Make sure to also read  Testing Aqueduct Applications .", 
            "title": "Purpose"
        }, 
        {
            "location": "/deploy/deploy_local/#prerequisites", 
            "text": "Dart has been installed.  PostgreSQL has been installed locally.  Aqueduct has been activated globally.  An application has been created with  aqueduct create .   If one or more of these is not true, see  Getting Started .", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/deploy/deploy_local/#overview", 
            "text": "Create a local database.  Upload the application schema to the local database.  Add an OAuth 2.0 client.  Modify the configuration file.  Run the application.   Estimated Time:  5 minutes.", 
            "title": "Overview"
        }, 
        {
            "location": "/deploy/deploy_local/#step-1-create-a-local-database", 
            "text": "Create a database with the same name as your application and a user that can access that database. Do not use the name 'dart_test' for the database; this database is used by Aqueduct to run tests by default.  Run the following SQL locally with a user that has privileges to create databases. (If using  Postgres.app , open the  psql  terminal from the  Postgres.app  status menu item  Open psql ).  CREATE   DATABASE   app_name ;  CREATE   USER   app_name_user   WITH   CREATEDB ;  ALTER   USER   app_name_user   WITH   PASSWORD   yourpassword ;  GRANT   ALL   ON   DATABASE   app_name   TO   app_name_user ;", 
            "title": "Step 1: Create a Local Database"
        }, 
        {
            "location": "/deploy/deploy_local/#step-2-upload-the-application-schema", 
            "text": "Run the database schema generation tool from the project directory:  aqueduct db generate  This command creates the file  migrations/00000001_initial.migration.dart . Now, run the database migration tool to execute the migration file against the local database. Ensure that the values for the option  --connect  match those of the database created in the last step.  aqueduct db upgrade --connect postgres://app_name_user:yourpassword@localhost:5432/app_name  (Note that you may provide database credentials in a file named  database.yaml  instead of using  --connect . See  aqueduct db --help  for details.)", 
            "title": "Step 2: Upload the Application Schema"
        }, 
        {
            "location": "/deploy/deploy_local/#step-3-add-an-oauth-20-client", 
            "text": "From the command line, run the following, ensuring that the values for the option  --connect  match the recently created database.  aqueduct auth add-client --id com.app_name.standard --secret abcdefghi --connect postgres://app_name_user:yourpassword@localhost:5432/app_name", 
            "title": "Step 3: Add an OAuth 2.0 client."
        }, 
        {
            "location": "/deploy/deploy_local/#step-4-modify-the-configuration-file", 
            "text": "If  config.yaml  doesn't exist, create it by copying the configuration file template  config.yaml.src .  In  config.yaml , update the database credentials to the local database.  database : \n  username :   app_name_user \n  password :   yourpassword \n  host :   localhost \n  port :   5432 \n  databaseName :   app_name", 
            "title": "Step 4: Modify the Configuration File"
        }, 
        {
            "location": "/deploy/deploy_local/#step-5-run-the-application", 
            "text": "From the project directory, run:  aqueduct serve  Your application is now running.  Note: You can add the  --observe  flag to  aqueduct serve  to run Observatory. Observatory will automatically open in a browser if the platform supports it.", 
            "title": "Step 5: Run the Application"
        }, 
        {
            "location": "/deploy/deploy_heroku/", 
            "text": "Deploying an Aqueduct Application on Heroku\n\n\nFor other deployment options, see \nDeploying Aqueduct Applications\n.\n\n\nPurpose\n\n\nTo run a production Aqueduct application on Heroku. Make sure to also read \nTesting Aqueduct Applications\n.\n\n\nPrerequisites\n\n\n\n\nDart has been installed.\n\n\nA Heroku account.\n\n\ngit\n has been installed.\n\n\nheroku\n has been installed.\n\n\nAqueduct has been activated.\n\n\n\n\nOverview\n\n\n\n\nSetting up a Heroku application\n\n\nSetting up an Aqueduct application to run on Heroku\n\n\nConfiguring application values\n\n\nRunning the Aqueduct application\n\n\n\n\nEstimated Time: \n5 minutes.\n\n\nStep 1: Setting up a Heroku Application\n\n\nCreate a new application in Heroku. Add the 'Heroku Postgres' add-on.\n\n\nNavigate to the Settings tab in the Heroku web interface and click 'Reveal Config Vars'. Note the DATABASE_URL, it'll get used later.\n\n\nStep 2: Setting up an Aqueduct Application to Run on Heroku\n\n\nIf you have not yet, create a new Aqueduct application on your local machine, go into that directory, and initialize it as a git repository:\n\n\naqueduct create app_name\n\ncd\n app_name\ngit init\n\n\n\n\n\nLogin to Heroku and run the Aqueduct tool to configure a project for Heroku. The value for \n--heroku\n \nmust\n be the name of the Heroku application (not the Aqueduct application, unless they are the same, obvi).\n\n\nheroku login\naqueduct setup --heroku\n=\napp_name\n\n\n\n\n\nThis command will create the files Heroku needs to run the application, remove \nconfig.yaml\n from \n.gitignore\n (you'll see why in a moment) and runs some \nheroku\n commands to set up the Heroku application's environment.\n\n\nStep 3: Configuring Application Values\n\n\nHeroku provides configuration values through environment variables, where Aqueduct normally provides them in \nconfig.yaml\n file. Because Aqueduct uses \nsafe_config\n, configuration files can map keys to environment variables with a simple syntax. The \nconfig.yaml\n file's values get replaced with their environment variable names and it gets checked into source control. To map configuration values to an environment variable, the value for a configuration key is prefixed with a dollar sign (\n$\n) followed by the case-sensitive name of the environment variable.\n\n\nModify \nconfig.yaml\n to appear as follows:\n\n\ndatabase: $DATABASE_URL\nlogging:\n type: console\n\n\n\n\n\nRecall that \naqueduct setup\n with the \n--heroku\n option removes \nconfig.yaml\n from \n.gitignore\n.\n\n\nStep 4: Running the Aqueduct Application\n\n\nFirst, create a database migration. The \nProcfile\n declared that Heroku will automatically run any migration files prior to running the application as long as they are checked into source control.\n\n\naqueduct db generate\n\n\n\n\n\nNow, add all of the files to \ngit\n and push it to heroku:\n\n\ngit add .\ngit commit -m \ninitial commit\n\ngit push heroku master\n\n\n\n\n\nNext, set up an OAuth 2.0 client id:\n\n\nheroku run /app/dart-sdk/bin/pub global run aqueduct:aqueduct auth add-client --id com.app.standard --secret secret --connect \n\\$\nDATABASE_URL\n\n\n\n\n\nFinally, spin up a dyno and the application will start receiving requests:\n\n\nheroku ps:scale \nweb\n=\n1", 
            "title": "Deploy on Heroku"
        }, 
        {
            "location": "/deploy/deploy_heroku/#deploying-an-aqueduct-application-on-heroku", 
            "text": "For other deployment options, see  Deploying Aqueduct Applications .", 
            "title": "Deploying an Aqueduct Application on Heroku"
        }, 
        {
            "location": "/deploy/deploy_heroku/#purpose", 
            "text": "To run a production Aqueduct application on Heroku. Make sure to also read  Testing Aqueduct Applications .", 
            "title": "Purpose"
        }, 
        {
            "location": "/deploy/deploy_heroku/#prerequisites", 
            "text": "Dart has been installed.  A Heroku account.  git  has been installed.  heroku  has been installed.  Aqueduct has been activated.", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/deploy/deploy_heroku/#overview", 
            "text": "Setting up a Heroku application  Setting up an Aqueduct application to run on Heroku  Configuring application values  Running the Aqueduct application   Estimated Time:  5 minutes.", 
            "title": "Overview"
        }, 
        {
            "location": "/deploy/deploy_heroku/#step-1-setting-up-a-heroku-application", 
            "text": "Create a new application in Heroku. Add the 'Heroku Postgres' add-on.  Navigate to the Settings tab in the Heroku web interface and click 'Reveal Config Vars'. Note the DATABASE_URL, it'll get used later.", 
            "title": "Step 1: Setting up a Heroku Application"
        }, 
        {
            "location": "/deploy/deploy_heroku/#step-2-setting-up-an-aqueduct-application-to-run-on-heroku", 
            "text": "If you have not yet, create a new Aqueduct application on your local machine, go into that directory, and initialize it as a git repository:  aqueduct create app_name cd  app_name\ngit init  Login to Heroku and run the Aqueduct tool to configure a project for Heroku. The value for  --heroku   must  be the name of the Heroku application (not the Aqueduct application, unless they are the same, obvi).  heroku login\naqueduct setup --heroku = app_name  This command will create the files Heroku needs to run the application, remove  config.yaml  from  .gitignore  (you'll see why in a moment) and runs some  heroku  commands to set up the Heroku application's environment.", 
            "title": "Step 2: Setting up an Aqueduct Application to Run on Heroku"
        }, 
        {
            "location": "/deploy/deploy_heroku/#step-3-configuring-application-values", 
            "text": "Heroku provides configuration values through environment variables, where Aqueduct normally provides them in  config.yaml  file. Because Aqueduct uses  safe_config , configuration files can map keys to environment variables with a simple syntax. The  config.yaml  file's values get replaced with their environment variable names and it gets checked into source control. To map configuration values to an environment variable, the value for a configuration key is prefixed with a dollar sign ( $ ) followed by the case-sensitive name of the environment variable.  Modify  config.yaml  to appear as follows:  database: $DATABASE_URL\nlogging:\n type: console  Recall that  aqueduct setup  with the  --heroku  option removes  config.yaml  from  .gitignore .", 
            "title": "Step 3: Configuring Application Values"
        }, 
        {
            "location": "/deploy/deploy_heroku/#step-4-running-the-aqueduct-application", 
            "text": "First, create a database migration. The  Procfile  declared that Heroku will automatically run any migration files prior to running the application as long as they are checked into source control.  aqueduct db generate  Now, add all of the files to  git  and push it to heroku:  git add .\ngit commit -m  initial commit \ngit push heroku master  Next, set up an OAuth 2.0 client id:  heroku run /app/dart-sdk/bin/pub global run aqueduct:aqueduct auth add-client --id com.app.standard --secret secret --connect  \\$ DATABASE_URL  Finally, spin up a dyno and the application will start receiving requests:  heroku ps:scale  web = 1", 
            "title": "Step 4: Running the Aqueduct Application"
        }, 
        {
            "location": "/deploy/deploy_aws/", 
            "text": "Deploying an Aqueduct Application on Amazon Web Services (AWS)\n\n\nFor other deployment options, see \nDeploying Aqueduct Applications\n.\n\n\nPurpose\n\n\nTo run a production Aqueduct application on Amazon Web Services. Make sure to also read \nTesting Aqueduct Applications\n.\n\n\nPrerequisites\n\n\n\n\nDart has been installed on your local machine.\n\n\nAn AWS Account\n\n\nA GitHub Account*\n\n\ngit\n has been installed\n on your local machine.\n\n\nAqueduct has been activated on your local machine.\n\n\n\n\n* GitHub will be used for transferring code to the remote machine. You could use \nftp\n, \nscp\n, \nrsync\n, another Git provider, another VCS system, AWS's CodeDeploy, etc.\n\n\nEstimated Time: \n15 minutes.\n\n\nOverview\n\n\n\n\nSetting up the Aqueduct application and GitHub\n\n\nSetting up an EC2 Instance\n\n\nSetting up a Database\n\n\nConfiguring application values\n\n\nRunning the Aqueduct application\n\n\n\n\nStep 1: Setting up the Aqueduct Application\n\n\nSet up a new GitHub repository with the name of your application. The purpose of GitHub here is to transfer the application code to the AWS instance. There are other ways of accomplishing this, so as long as you can get the source code to the machine, you're in good shape.\n\n\nIf you have not yet, create a new Aqueduct application on your local machine, go into that directory, and initialize it as a git repository:\n\n\naqueduct create app_name\n\ncd\n app_name\ngit init\n\n\n\n\n\nThen, setup your local git repository with your remote git repository for the application by executing one of the following commands in the project's directory:\n\n\n# If your machine is set up to use git over SSH ...\n\ngit remote add origin git@github.com:organization/app_name.git\n\n\n# If your machine is set up to use git over HTTPS\n\ngit remote add origin https://github.com/organization/app_name.git\n\n\n# If you are unsure or haven\nt set up GitHub before,\n\n\n# see https://help.github.com/articles/set-up-git/\n\n\n\n\n\n\nThen, grab the repository contents:\n\n\ngit pull\n\n\n\n\n\nKeep the GitHub web interface open, as you'll have to come back to it one more time.\n\n\nStep 2: Setting up an EC2 Instance\n\n\nIn the AWS EC2 control panel, create a new Ubuntu instance. Make sure your VPC has DNS resolution (the default VPC configuration does). Choose or create a security group that allows both HTTP and SSH access for this instance. The rest of the default configuration values are fine.\n\n\nLaunch that instance. When prompted, make sure you either create a new key pair or have access to an existing key pair.\n\n\nAfter creating the EC2 instance, select it in the AWS console and click 'Connect' for instructions on how to SSH into the instance.  \n\n\nIt's useful to add the \nssh\n command that connects to this instance as an alias in your shell and the key file into more permanent storage. The command is something like \nssh -i key.pem ubuntu@host\n. Move the key file \nkey.pem\n into \n~/.ssh\n (it may be named differently):\n\n\ncp key.pem ~/.ssh/key.pem\n\n\n\n\n\nThen add the following line to the file \n~/.bash_profile\n and then reload your profle:\n\n\nalias app_name=\nssh -i ~/.ssh/key.pem ubuntu@host\n\nsource ~/.bash_profile\n\n\n\n\n\nNext, SSH into the EC2 instance by executing the alias locally:\n\n\napp_name\n\n\n\n\n\nOnce the shell for the instance is opened, install Dart (these instructions are located at https://www.dartlang.org/install/linux):\n\n\nsudo apt-get update\nsudo apt-get install apt-transport-https\nsudo sh -c \ncurl https://dl-ssl.google.com/linux/linux_signing_key.pub | apt-key add -\n\nsudo sh -c \ncurl https://storage.googleapis.com/download.dartlang.org/linux/debian/dart_stable.list \n /etc/apt/sources.list.d/dart_stable.list\n\nsudo apt-get update\nsudo apt-get install dart\n\n\n\n\n\nWhen these steps are completed correctly, the following command will yield \n/usr/bin/dart\n:\n\n\nwhich dart\n\n\n\n\n\nAdd the Dart executable directories to your path by adding the following line to the end of the file \n~/.profile\n:\n\n\nexport PATH=$PATH:\n/usr/lib/dart/bin\n:\n~/.pub-cache/bin\n\n\n\n\n\n\nThen reload the profile:\n\n\nsource\n ~/.profile\n\n\n\n\n\nNow, we'll give this instance permission to clone the application repository from GitHub. In the instance's shell, install \ngit\n and create a new SSH key:\n\n\nsudo apt-get install git\nssh-keygen -t rsa -b \n4096\n -C \nyouremail\n\n\n\n\n\n\nThis command will prompt you three times (for a file name, password and password confirm). Simply hit the Enter key each time.\nThen, add the following to the file \n/etc/ssh/ssh_config\n (requires \nsudo\n):\n\n\nHost github.com\n    Hostname github.com\n    IdentityFile ~/.ssh/id_rsa\n    User git\n\n\n\n\n\nPrint out the contents of the public key and copy them:\n\n\ncat ~/.ssh/id_rsa.pub\n\n\n\n\n\nThe contents will start with the phrase \nssh-rsa\n and end with your email, and you must copy all of it.\n\n\nIn the GitHub repository web interface, select the \nSettings\n tab then select \nDeploy keys\n. Click \nAdd deploy key\n. Enter \"AWS\" for the title and paste the contents of the public key into the \nKey\n area. Then click \nAdd key\n.\n\n\nTo ensure this all works, clone the repository onto the AWS instance:\n\n\ngit clone git@github.com:organization/app_name.git\n\n\n\n\n\nAt this point, the repository should mostly be empty, but as long as it clones correctly you're in good shape.\n\n\nStep 3: Setting up a Database\n\n\nIn the AWS control panel, select the RDS service. Choose the \nInstances\n item from the left hand panel and select \nLaunch DB Instance\n. Choose PostgreSQL and configure the database details. Make sure to store the username and password as you'll need them shortly.\n\n\nIn the \nConfigure Advanced Settings\n, make sure the database is Publicly Accessible. Set \nDatabase Name\n to the name of your application, this will make it easy to remember.\n\n\nAdd a new Inbound entry to the security group for the database. The type must be \nPostgreSQL\n (which automatically configures the protocol to \nTCP\n and the port range to \n5432\n). Choose a custom Source and enter the name of the security group that the EC2 instance is in. (You can start by typing \"sg-\", and it give you a drop-down list so that you can select the appropriate one.)\n\n\nThen, launch the database.\n\n\nOnce the database has finished launching, we must upload the application's schema. From the project directory on your local machine, run the following:\n\n\naqueduct db generate\n\n\n\n\n\nNext, run the newly generated migration file on the database, substituting the values in the \n--connect\n option with values from the recently configured database:\n\n\naqueduct db upgrade --connect postgres://username:password@host:5432/app_name\n\n\n\n\n\nStep 4: Configuring the Application\n\n\nConfiguring an Aqueduct application on AWS means having a configuration file that lives on the instance, but is not checked into source control. There are tools for managing configurations across instances, but those are up to you.\n\n\nIn the project directory on your local machine, add all of the project files to the git repository:\n\n\ngit add .\ngit commit -am \nInitial commit\n\ngit push -u origin master\n\n\n\n\n\nOn the EC2 instance, grab these files from the repository (this assumes you ran \ngit clone\n earlier).\n\n\ncd\n app_name\ngit pull\n\n\n\n\n\nCreate a new configuration file just for this instance by cloning the configuration template file that is checked into the repository:\n\n\ncp config.yaml.src config.yaml\n\n\n\n\n\nModify \nconfig.yaml\n by replacing the database credentials with the credentials of the RDS database and change \nlogging:type\n to \nfile\n:\n\n\ndatabase\n:\n\n \nusername\n:\n \nusername\n\n \npassword\n:\n \npassword\n\n \nhost\n:\n \nhost\n\n \nport\n:\n \n5432\n\n \ndatabaseName\n:\n \napp_name\n\n\nlogging\n:\n\n \ntype\n:\n \nfile\n\n \nfilename\n:\n \napi\n.\nlog\n\n\n\n\n\n\nStep 5: Running the Application\n\n\nThen, activate the Aqueduct package:\n\n\npub global activate aqueduct\n\n\n\n\n\nFetch the application's dependencies:\n\n\npub get\n\n\n\n\n\nNow, run the application in \n--detached\n mode:\n\n\naqueduct serve --detached\n\n\n\n\n\nBy default, an Aqueduct application will listen on port 8888. HTTP requests will come in on port 80. You can't bind to port 80 without using sudo. Instead, reroute HTTP requests on port 80 to port 8888 by entering the following on the EC2 instance:\n\n\nsudo iptables -t nat -A PREROUTING -p tcp --dport \n80\n -j REDIRECT --to \n8888\n\nsudo iptables-save\n\n\n\n\n\nThen - either locally or remotely - add a new OAuth 2.0 client:\n\n\n  aqueduct auth add-client --id com.app.standard --secret secret --connect postgres://user:password@deploy-aws.hexthing.us-east-1.rds.amazonaws.com:5432/deploy_aws\n\n\n\n\n\nYour Aqueduct application is now up and running.", 
            "title": "Deploy on AWS"
        }, 
        {
            "location": "/deploy/deploy_aws/#deploying-an-aqueduct-application-on-amazon-web-services-aws", 
            "text": "For other deployment options, see  Deploying Aqueduct Applications .", 
            "title": "Deploying an Aqueduct Application on Amazon Web Services (AWS)"
        }, 
        {
            "location": "/deploy/deploy_aws/#purpose", 
            "text": "To run a production Aqueduct application on Amazon Web Services. Make sure to also read  Testing Aqueduct Applications .", 
            "title": "Purpose"
        }, 
        {
            "location": "/deploy/deploy_aws/#prerequisites", 
            "text": "Dart has been installed on your local machine.  An AWS Account  A GitHub Account*  git  has been installed  on your local machine.  Aqueduct has been activated on your local machine.   * GitHub will be used for transferring code to the remote machine. You could use  ftp ,  scp ,  rsync , another Git provider, another VCS system, AWS's CodeDeploy, etc.  Estimated Time:  15 minutes.", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/deploy/deploy_aws/#overview", 
            "text": "Setting up the Aqueduct application and GitHub  Setting up an EC2 Instance  Setting up a Database  Configuring application values  Running the Aqueduct application", 
            "title": "Overview"
        }, 
        {
            "location": "/deploy/deploy_aws/#step-1-setting-up-the-aqueduct-application", 
            "text": "Set up a new GitHub repository with the name of your application. The purpose of GitHub here is to transfer the application code to the AWS instance. There are other ways of accomplishing this, so as long as you can get the source code to the machine, you're in good shape.  If you have not yet, create a new Aqueduct application on your local machine, go into that directory, and initialize it as a git repository:  aqueduct create app_name cd  app_name\ngit init  Then, setup your local git repository with your remote git repository for the application by executing one of the following commands in the project's directory:  # If your machine is set up to use git over SSH ... \ngit remote add origin git@github.com:organization/app_name.git # If your machine is set up to use git over HTTPS \ngit remote add origin https://github.com/organization/app_name.git # If you are unsure or haven t set up GitHub before,  # see https://help.github.com/articles/set-up-git/   Then, grab the repository contents:  git pull  Keep the GitHub web interface open, as you'll have to come back to it one more time.", 
            "title": "Step 1: Setting up the Aqueduct Application"
        }, 
        {
            "location": "/deploy/deploy_aws/#step-2-setting-up-an-ec2-instance", 
            "text": "In the AWS EC2 control panel, create a new Ubuntu instance. Make sure your VPC has DNS resolution (the default VPC configuration does). Choose or create a security group that allows both HTTP and SSH access for this instance. The rest of the default configuration values are fine.  Launch that instance. When prompted, make sure you either create a new key pair or have access to an existing key pair.  After creating the EC2 instance, select it in the AWS console and click 'Connect' for instructions on how to SSH into the instance.    It's useful to add the  ssh  command that connects to this instance as an alias in your shell and the key file into more permanent storage. The command is something like  ssh -i key.pem ubuntu@host . Move the key file  key.pem  into  ~/.ssh  (it may be named differently):  cp key.pem ~/.ssh/key.pem  Then add the following line to the file  ~/.bash_profile  and then reload your profle:  alias app_name= ssh -i ~/.ssh/key.pem ubuntu@host \nsource ~/.bash_profile  Next, SSH into the EC2 instance by executing the alias locally:  app_name  Once the shell for the instance is opened, install Dart (these instructions are located at https://www.dartlang.org/install/linux):  sudo apt-get update\nsudo apt-get install apt-transport-https\nsudo sh -c  curl https://dl-ssl.google.com/linux/linux_signing_key.pub | apt-key add - \nsudo sh -c  curl https://storage.googleapis.com/download.dartlang.org/linux/debian/dart_stable.list   /etc/apt/sources.list.d/dart_stable.list \nsudo apt-get update\nsudo apt-get install dart  When these steps are completed correctly, the following command will yield  /usr/bin/dart :  which dart  Add the Dart executable directories to your path by adding the following line to the end of the file  ~/.profile :  export PATH=$PATH: /usr/lib/dart/bin : ~/.pub-cache/bin   Then reload the profile:  source  ~/.profile  Now, we'll give this instance permission to clone the application repository from GitHub. In the instance's shell, install  git  and create a new SSH key:  sudo apt-get install git\nssh-keygen -t rsa -b  4096  -C  youremail   This command will prompt you three times (for a file name, password and password confirm). Simply hit the Enter key each time.\nThen, add the following to the file  /etc/ssh/ssh_config  (requires  sudo ):  Host github.com\n    Hostname github.com\n    IdentityFile ~/.ssh/id_rsa\n    User git  Print out the contents of the public key and copy them:  cat ~/.ssh/id_rsa.pub  The contents will start with the phrase  ssh-rsa  and end with your email, and you must copy all of it.  In the GitHub repository web interface, select the  Settings  tab then select  Deploy keys . Click  Add deploy key . Enter \"AWS\" for the title and paste the contents of the public key into the  Key  area. Then click  Add key .  To ensure this all works, clone the repository onto the AWS instance:  git clone git@github.com:organization/app_name.git  At this point, the repository should mostly be empty, but as long as it clones correctly you're in good shape.", 
            "title": "Step 2: Setting up an EC2 Instance"
        }, 
        {
            "location": "/deploy/deploy_aws/#step-3-setting-up-a-database", 
            "text": "In the AWS control panel, select the RDS service. Choose the  Instances  item from the left hand panel and select  Launch DB Instance . Choose PostgreSQL and configure the database details. Make sure to store the username and password as you'll need them shortly.  In the  Configure Advanced Settings , make sure the database is Publicly Accessible. Set  Database Name  to the name of your application, this will make it easy to remember.  Add a new Inbound entry to the security group for the database. The type must be  PostgreSQL  (which automatically configures the protocol to  TCP  and the port range to  5432 ). Choose a custom Source and enter the name of the security group that the EC2 instance is in. (You can start by typing \"sg-\", and it give you a drop-down list so that you can select the appropriate one.)  Then, launch the database.  Once the database has finished launching, we must upload the application's schema. From the project directory on your local machine, run the following:  aqueduct db generate  Next, run the newly generated migration file on the database, substituting the values in the  --connect  option with values from the recently configured database:  aqueduct db upgrade --connect postgres://username:password@host:5432/app_name", 
            "title": "Step 3: Setting up a Database"
        }, 
        {
            "location": "/deploy/deploy_aws/#step-4-configuring-the-application", 
            "text": "Configuring an Aqueduct application on AWS means having a configuration file that lives on the instance, but is not checked into source control. There are tools for managing configurations across instances, but those are up to you.  In the project directory on your local machine, add all of the project files to the git repository:  git add .\ngit commit -am  Initial commit \ngit push -u origin master  On the EC2 instance, grab these files from the repository (this assumes you ran  git clone  earlier).  cd  app_name\ngit pull  Create a new configuration file just for this instance by cloning the configuration template file that is checked into the repository:  cp config.yaml.src config.yaml  Modify  config.yaml  by replacing the database credentials with the credentials of the RDS database and change  logging:type  to  file :  database : \n  username :   username \n  password :   password \n  host :   host \n  port :   5432 \n  databaseName :   app_name  logging : \n  type :   file \n  filename :   api . log", 
            "title": "Step 4: Configuring the Application"
        }, 
        {
            "location": "/deploy/deploy_aws/#step-5-running-the-application", 
            "text": "Then, activate the Aqueduct package:  pub global activate aqueduct  Fetch the application's dependencies:  pub get  Now, run the application in  --detached  mode:  aqueduct serve --detached  By default, an Aqueduct application will listen on port 8888. HTTP requests will come in on port 80. You can't bind to port 80 without using sudo. Instead, reroute HTTP requests on port 80 to port 8888 by entering the following on the EC2 instance:  sudo iptables -t nat -A PREROUTING -p tcp --dport  80  -j REDIRECT --to  8888 \nsudo iptables-save  Then - either locally or remotely - add a new OAuth 2.0 client:    aqueduct auth add-client --id com.app.standard --secret secret --connect postgres://user:password@deploy-aws.hexthing.us-east-1.rds.amazonaws.com:5432/deploy_aws  Your Aqueduct application is now up and running.", 
            "title": "Step 5: Running the Application"
        }, 
        {
            "location": "/deploy/script/", 
            "text": "You may also run Aqueduct applications with a standalone script, instead of \naqueduct serve\n. In fact, \naqueduct serve\n creates a temporary Dart script to run the application. That script looks something like this:\n\n\nimport\n \ndart:async\n;\n\n\nimport\n \ndart:io\n;\n\n\n\nimport\n \npackage:aqueduct/aqueduct.dart\n;\n\n\nimport\n \npackage:my_application/my_application.dart\n;\n\n\n\nmain\n()\n \nasync\n \n{\n\n  \ntry\n \n{\n\n    \nvar\n \napp\n \n=\n \nnew\n \nApplication\nMyApplicationChannel\n();\n\n    \nvar\n \noptions\n \n=\n \nnew\n \nApplicationOptions\n()\n\n      \n..\nport\n \n=\n \n8888\n\n      \n..\nconfigurationFilePath\n \n=\n \nconfig.yaml\n;\n\n\n    \napp\n.\noptions\n \n=\n \noptions\n;\n\n\n    \nawait\n \napp\n.\nstart\n(\nnumberOfInstances:\n \n3\n);\n    \n  \n}\n \ncatch\n \n(\ne\n,\n \nst\n)\n \n{\n\n    \nawait\n \nwriteError\n(\n$\ne\n\\n\n \n$\nst\n);\n\n  \n}\n\n\n}\n\n\n\nFuture\n \nwriteError\n(\nString\n \nerror\n)\n \nasync\n \n{\n\n  \nprint\n(\n$\nerror\n);\n\n\n}\n\n\n\n\n\n\nThe \naqueduct serve\n command properly exits and reports the error if the application fails to start.\n\n\nApplications that aren't use \naqueduct serve\n must be sure to take appropriate action when the application fails to start such that the runner of the script is aware of the failure. A standalone start script should be placed in the \nbin\n directory of a project.", 
            "title": "Deploying without aqueduct serve"
        }, 
        {
            "location": "/openapi/", 
            "text": "Tasks\n\n\nAqueduct applications auto-generate an OpenAPI 3.0 document.\n\n\nMost of your OpenAPI document is generated by reflecting on your application code, especially \nResourceController\n subclasses. You add customization or additional information by overriding methods in \nAPIComponentDocumenter\n and \nAPIOperationDocumenter\n. At minimum, you override methods in your \nResourceController\n to document the responses your application will send for a particular endpoint.\n\n\nYou create documents with the \naqueduct document\n command-line tool.\n\n\nGuides\n\n\n\n\nCreating an OpenAPI Document\n\n\nDocumenting Components\n\n\nDocumenting Endpoint Controllers\n\n\nDocumenting Middleware Controllers", 
            "title": "Overview"
        }, 
        {
            "location": "/openapi/#tasks", 
            "text": "Aqueduct applications auto-generate an OpenAPI 3.0 document.  Most of your OpenAPI document is generated by reflecting on your application code, especially  ResourceController  subclasses. You add customization or additional information by overriding methods in  APIComponentDocumenter  and  APIOperationDocumenter . At minimum, you override methods in your  ResourceController  to document the responses your application will send for a particular endpoint.  You create documents with the  aqueduct document  command-line tool.", 
            "title": "Tasks"
        }, 
        {
            "location": "/openapi/#guides", 
            "text": "Creating an OpenAPI Document  Documenting Components  Documenting Endpoint Controllers  Documenting Middleware Controllers", 
            "title": "Guides"
        }, 
        {
            "location": "/openapi/cli/", 
            "text": "Creating OpenAPI Documents\n\n\nIn this document, you'll learn how to use the \naqueduct\n command line tool to generate an OpenAPI document for your application.\n\n\nOpenAPI Documents\n\n\nOpenAPI documents describe the details of every request and possible response your application has. These documents are JSON objects that follow a specification. This specification defines which properties the document can (or must) have. By following this specification, your application can take advantage of tools such as documentation viewers and source code generators.\n\n\nThe two most important objects in an OpenAPI document are components and path operations. A path operation contains an expected request and possible responses. Components are reusable definitions that you can use in a path operation. For example, a 400 Bad Request response component can be reused across path operations that may send this response.\n\n\nMost of the documentation process revolves around registering components and creating path operations.\n\n\nThe aqueduct document Command\n\n\nDocuments can be written by hand, but it takes a lot of time and is hard to keep in sync with your code. Aqueduct analyzes your code to build (most) of a document for you. You run the \naqueduct document\n command in your project's directory, and it prints the JSON document to your console.\n\n\ncd\n my_project/\naqueduct document\n\n-- Aqueduct CLI Version: \n3\n.0.0\n-- Aqueduct project version: \n3\n.0.0\n\n{\nopenapi\n:\n3.0.0\n,\ninfo\n:...\n\n\n\n\n\nYou may copy the output to use it in another tool; for example, by entering it into \nSwagger Editor\n. If you want to build a tool that runs this command, but don't want to parse the version info from the output, use the \n--machine\n flag.\n\n\naqueduct document --machine\n\n{\nopenapi\n:\n3.0.0\n,\ninfo\n:...\n\n\n\n\n\nMuch of the metadata in an OpenAPI document - such as title or version - is derived from your application's \npubspec.yaml\n. If you want to override the derived values, or provide values that can't be derived, use options like \n--title\n or \n--license-name\n. See \naqueduct document --help\n for all options.\n\n\nHow Applications are Documented\n\n\nWhen you run the \naqueduct document\n command, it creates an empty \nAPIDocument\n that objects in your application will populate. Your application goes through its normal initialization process (i.e., \nprepare\n and \nentryPoint\n). Controllers and service objects are then told to register components. For example, all \nManagedObject\ns register themselves as a reusable schema component. After components are registered, the controllers in an application are told to create path operations that define the requests they handle.\n\n\n\n\nConfiguration Files\n\n\nBecause your application goes through initialization as if it were going to run the application, you must have a valid configuration file when documenting. This defaults to 'config.yaml.src', the same file you use for running tests. See \naqueduct document --help\n to use a different file.\n\n\n\n\nDocumenting Components\n\n\nObjects that register components implement \nAPIComponentDocumenter.documentComponents\n. Controllers - which implement this method - automatically document their components as long as they are linked to your application's entry point. Other types of objects that implement this method will be automatically documented if they are declared as a property of your \nApplicationChannel\n.\n\n\nFor example, in the following code, the \nAuthServer\n, \nRouter\n and \nPathController\n all automatically document their components.\n\n\nclass\n \nMyChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \nAuthServer\n \nauthServer\n;\n\n\n  \n@\noverride\n\n  \nFuture\n \nprepare\n()\n \nasync\n \n{\n\n    \nauthServer\n \n=\n \nnew\n \nAuthServer\n(...);\n\n  \n}\n\n\n  \n@\noverride\n\n  \nController\n \nget\n \nentryPoint\n \n{\n\n    \nfinal\n \nrouter\n \n=\n \nnew\n \nRouter\n();\n\n    \nrouter\n.\nroute\n(\n/path\n).\nlink\n(()\n \n=\n \nnew\n \nPathController\n());\n\n    \nreturn\n \nrouter\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nIn most applications, the automatically documented objects are the only objects that register components. If you have an object that needs to register components, but aren't automatically documented, override \ndocumentComponents\n in your app channel to tell that object to register components. You must call the superclass' implementation.\n\n\nclass\n \nMyChannel\n \nextends\n \nApplicationChannel\n \n{\n\n  \n...\n\n  \n@\noverride\n\n  \nvoid\n \ndocumentComponents\n(\nAPIDocumentContext\n \ncontext\n)\n \n{\n\n    \nsuper\n.\ndocumentComponents\n(\ncontext\n);\n\n\n    \nobjectWithComponents\n.\ndocumentComponents\n(\ncontext\n);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nYou can override \ndocumentComponents\n in controllers and services that you create. Read the \nguide on component documentation\n for more details.\n\n\nDocument Path Operations\n\n\nA path operation is the expected request and possible responses for a path (e.g., \n/users\n) and its request method (e.g., \nGET\n). Each operation describes how to send a request to the server, like which headers or query parameters to include. Responses describe the status code, headers and body that can be sent. Each controller implements \nAPIOperationDocumenter.documentOperations\n to define this information for the requests it handles.\n\n\nBuilt-in controllers like \nAuthorizer\n and \nResourceController\n already implement this method. You typically only override this method when creating your own middleware. For more information on documenting middleware, see \nthis guide\n.\n\n\nWhen creating documentation for \nResourceController\ns, request parameters are derived from your bindings, but you still need to provide the possible responses. For more information on documenting endpoint controllers, see \nthis guide\n.", 
            "title": "Creating an OpenAPI Document"
        }, 
        {
            "location": "/openapi/cli/#creating-openapi-documents", 
            "text": "In this document, you'll learn how to use the  aqueduct  command line tool to generate an OpenAPI document for your application.", 
            "title": "Creating OpenAPI Documents"
        }, 
        {
            "location": "/openapi/cli/#openapi-documents", 
            "text": "OpenAPI documents describe the details of every request and possible response your application has. These documents are JSON objects that follow a specification. This specification defines which properties the document can (or must) have. By following this specification, your application can take advantage of tools such as documentation viewers and source code generators.  The two most important objects in an OpenAPI document are components and path operations. A path operation contains an expected request and possible responses. Components are reusable definitions that you can use in a path operation. For example, a 400 Bad Request response component can be reused across path operations that may send this response.  Most of the documentation process revolves around registering components and creating path operations.", 
            "title": "OpenAPI Documents"
        }, 
        {
            "location": "/openapi/cli/#the-aqueduct-document-command", 
            "text": "Documents can be written by hand, but it takes a lot of time and is hard to keep in sync with your code. Aqueduct analyzes your code to build (most) of a document for you. You run the  aqueduct document  command in your project's directory, and it prints the JSON document to your console.  cd  my_project/\naqueduct document\n\n-- Aqueduct CLI Version:  3 .0.0\n-- Aqueduct project version:  3 .0.0 { openapi : 3.0.0 , info :...  You may copy the output to use it in another tool; for example, by entering it into  Swagger Editor . If you want to build a tool that runs this command, but don't want to parse the version info from the output, use the  --machine  flag.  aqueduct document --machine { openapi : 3.0.0 , info :...  Much of the metadata in an OpenAPI document - such as title or version - is derived from your application's  pubspec.yaml . If you want to override the derived values, or provide values that can't be derived, use options like  --title  or  --license-name . See  aqueduct document --help  for all options.", 
            "title": "The aqueduct document Command"
        }, 
        {
            "location": "/openapi/cli/#how-applications-are-documented", 
            "text": "When you run the  aqueduct document  command, it creates an empty  APIDocument  that objects in your application will populate. Your application goes through its normal initialization process (i.e.,  prepare  and  entryPoint ). Controllers and service objects are then told to register components. For example, all  ManagedObject s register themselves as a reusable schema component. After components are registered, the controllers in an application are told to create path operations that define the requests they handle.   Configuration Files  Because your application goes through initialization as if it were going to run the application, you must have a valid configuration file when documenting. This defaults to 'config.yaml.src', the same file you use for running tests. See  aqueduct document --help  to use a different file.", 
            "title": "How Applications are Documented"
        }, 
        {
            "location": "/openapi/cli/#documenting-components", 
            "text": "Objects that register components implement  APIComponentDocumenter.documentComponents . Controllers - which implement this method - automatically document their components as long as they are linked to your application's entry point. Other types of objects that implement this method will be automatically documented if they are declared as a property of your  ApplicationChannel .  For example, in the following code, the  AuthServer ,  Router  and  PathController  all automatically document their components.  class   MyChannel   extends   ApplicationChannel   { \n   AuthServer   authServer ; \n\n   @ override \n   Future   prepare ()   async   { \n     authServer   =   new   AuthServer (...); \n   } \n\n   @ override \n   Controller   get   entryPoint   { \n     final   router   =   new   Router (); \n     router . route ( /path ). link (()   =   new   PathController ()); \n     return   router ; \n   }  }   In most applications, the automatically documented objects are the only objects that register components. If you have an object that needs to register components, but aren't automatically documented, override  documentComponents  in your app channel to tell that object to register components. You must call the superclass' implementation.  class   MyChannel   extends   ApplicationChannel   { \n   ... \n   @ override \n   void   documentComponents ( APIDocumentContext   context )   { \n     super . documentComponents ( context ); \n\n     objectWithComponents . documentComponents ( context ); \n   }  }   You can override  documentComponents  in controllers and services that you create. Read the  guide on component documentation  for more details.", 
            "title": "Documenting Components"
        }, 
        {
            "location": "/openapi/cli/#document-path-operations", 
            "text": "A path operation is the expected request and possible responses for a path (e.g.,  /users ) and its request method (e.g.,  GET ). Each operation describes how to send a request to the server, like which headers or query parameters to include. Responses describe the status code, headers and body that can be sent. Each controller implements  APIOperationDocumenter.documentOperations  to define this information for the requests it handles.  Built-in controllers like  Authorizer  and  ResourceController  already implement this method. You typically only override this method when creating your own middleware. For more information on documenting middleware, see  this guide .  When creating documentation for  ResourceController s, request parameters are derived from your bindings, but you still need to provide the possible responses. For more information on documenting endpoint controllers, see  this guide .", 
            "title": "Document Path Operations"
        }, 
        {
            "location": "/openapi/components/", 
            "text": "Document Components\n\n\nIn this document, you'll learn how to register and use OpenAPI components in your application's documentation.\n\n\nRegistering Components with APIDocumentContext\n\n\nWhen your application is being documented, a single instance of \nAPIDocumentContext\n is created and passed to every documentation method. The context stores the document being created, but more importantly, is a container for reusable components. You may register components by implementing \nAPIComponentDocumenter\n and implementing its abstract method. For example, the following code registers a reusable schema object:\n\n\nclass\n \nSourceRepository\n \nimplements\n \nAPIComponentDocumenter\n \n{\n\n  \n@\noverride\n\n  \nvoid\n \ndocumentComponents\n(\nAPIDocumentContext\n \ncontext\n)\n \n{\n\n    \nsuper\n.\ndocumentComponents\n(\ncontext\n);\n\n\n    \ncontext\n.\nschema\n.\nregister\n(\nSourceRepository\n,\n\n        \nAPISchemaObject\n.\nobject\n({\n\n          \nid\n:\n \nAPISchemaObject\n.\ninteger\n(),\n\n          \nname\n:\n \nAPISchemaObject\n.\nstring\n()\n\n        \n});\n          \n  \n}\n\n\n}\n\n\n\n\n\n\nA \"SourceRepository\" is an object that contains two fields, \"id\" (an integer) and \"name\" (a string). This component can be used anywhere a schema object can be used. Schema objects are one type of component that document what is typically considered to be a 'model object'. You most often see schema objects in request and response bodies. By default, each of your \nManagedObject\ns are registered as schema objects. The other types of components are: responses, request bodies, parameters, headers, security schemes, and callbacks.\n\n\nComponents must be registered with a name, but can additionally be registered with a type. This allows users of a component to reference it by its Dart type. Including a type reference for an object is an optional argument when registering.\n\n\ncontext\n.\nschema\n.\nregister\n(\nSourceRepository\n,\n\n    \nAPISchemaObject\n.\nobject\n({\n\n      \nid\n:\n \nAPISchemaObject\n.\ninteger\n(),\n\n      \nname\n:\n \nAPISchemaObject\n.\nstring\n()\n\n    \n},\n \nrepresentation:\n \nSourceRepository\n);\n          \n\n\n\n\n\nThe order in which components are registered and referenced does not matter. If you reference a component that is created later in the documentation process, it will be resolved prior to the document being completed. If a referenced component is never registered, an error is thrown and your document will fail to generate.\n\n\nUsing Components\n\n\nComponents can be used when declaring path operations, or as part of other components. For example, if you were to describe a response whose body was a component named \"SourceRepository\", it would look like this:\n\n\nclass\n \nRepositoryController\n \nextends\n \nResourceController\n \n{\n\n  \n...\n\n\n  \n@\noverride\n\n  \nMap\nString\n,\n \nAPIResponse\n \ndocumentOperationResponses\n(\nAPIDocumentContext\n \ncontext\n,\n \nOperation\n \noperation\n)\n \n{\n\n    \nif\n \n(\noperation\n.\nmethod\n \n==\n \nGET\n)\n \n{\n\n      \nreturn\n \n{\n\n        \n200\n:\n \nAPIResponse\n.\nschema\n(\ncontext\n.\nschema\n[\nSourceRepository\n])\n\n      \n};\n\n    \n}\n\n    \nreturn\n \nnull\n;\n\n  \n}\n  \n\n}\n\n\n\n\n\n\nIf an object has been registered by its type, you may use \ngetObjectWithType\n.\n\n\nclass\n \nRepositoryController\n \nextends\n \nResourceController\n \n{\n\n  \n...\n\n\n  \n@\noverride\n\n  \nMap\nString\n,\n \nAPIResponse\n \ndocumentOperationResponses\n(\nAPIDocumentContext\n \ncontext\n,\n \nOperation\n \noperation\n)\n \n{\n\n    \nif\n \n(\noperation\n.\nmethod\n \n==\n \nGET\n)\n \n{\n\n      \nreturn\n \n{\n\n        \n200\n:\n \nAPIResponse\n.\nschema\n(\ncontext\n.\nschema\n.\ngetObjectWithType\n(\nSourceRepository\n))\n\n      \n};\n\n    \n}\n\n    \nreturn\n \nnull\n;\n\n  \n}\n  \n\n}\n\n\n\n\n\n\nComponent Discovery\n\n\nAll controllers are can document components when they are linked to the entry point. Objects other than controllers will automatically document their components if they implement \nAPIComponentDocumenter\n \nand\n are declared properties of your \nApplicationChannel\n. (See \nthis guide\n for other options.)\n\n\nBuilt-in Aqueduct types will register any applicable components. This includes the types that handle OAuth2 as well as all \nManagedObject\n subclasses in your application.", 
            "title": "Documenting Components"
        }, 
        {
            "location": "/openapi/components/#document-components", 
            "text": "In this document, you'll learn how to register and use OpenAPI components in your application's documentation.", 
            "title": "Document Components"
        }, 
        {
            "location": "/openapi/components/#registering-components-with-apidocumentcontext", 
            "text": "When your application is being documented, a single instance of  APIDocumentContext  is created and passed to every documentation method. The context stores the document being created, but more importantly, is a container for reusable components. You may register components by implementing  APIComponentDocumenter  and implementing its abstract method. For example, the following code registers a reusable schema object:  class   SourceRepository   implements   APIComponentDocumenter   { \n   @ override \n   void   documentComponents ( APIDocumentContext   context )   { \n     super . documentComponents ( context ); \n\n     context . schema . register ( SourceRepository , \n         APISchemaObject . object ({ \n           id :   APISchemaObject . integer (), \n           name :   APISchemaObject . string () \n         });           \n   }  }   A \"SourceRepository\" is an object that contains two fields, \"id\" (an integer) and \"name\" (a string). This component can be used anywhere a schema object can be used. Schema objects are one type of component that document what is typically considered to be a 'model object'. You most often see schema objects in request and response bodies. By default, each of your  ManagedObject s are registered as schema objects. The other types of components are: responses, request bodies, parameters, headers, security schemes, and callbacks.  Components must be registered with a name, but can additionally be registered with a type. This allows users of a component to reference it by its Dart type. Including a type reference for an object is an optional argument when registering.  context . schema . register ( SourceRepository , \n     APISchemaObject . object ({ \n       id :   APISchemaObject . integer (), \n       name :   APISchemaObject . string () \n     },   representation:   SourceRepository );             The order in which components are registered and referenced does not matter. If you reference a component that is created later in the documentation process, it will be resolved prior to the document being completed. If a referenced component is never registered, an error is thrown and your document will fail to generate.", 
            "title": "Registering Components with APIDocumentContext"
        }, 
        {
            "location": "/openapi/components/#using-components", 
            "text": "Components can be used when declaring path operations, or as part of other components. For example, if you were to describe a response whose body was a component named \"SourceRepository\", it would look like this:  class   RepositoryController   extends   ResourceController   { \n   ... \n\n   @ override \n   Map String ,   APIResponse   documentOperationResponses ( APIDocumentContext   context ,   Operation   operation )   { \n     if   ( operation . method   ==   GET )   { \n       return   { \n         200 :   APIResponse . schema ( context . schema [ SourceRepository ]) \n       }; \n     } \n     return   null ; \n   }    }   If an object has been registered by its type, you may use  getObjectWithType .  class   RepositoryController   extends   ResourceController   { \n   ... \n\n   @ override \n   Map String ,   APIResponse   documentOperationResponses ( APIDocumentContext   context ,   Operation   operation )   { \n     if   ( operation . method   ==   GET )   { \n       return   { \n         200 :   APIResponse . schema ( context . schema . getObjectWithType ( SourceRepository )) \n       }; \n     } \n     return   null ; \n   }    }", 
            "title": "Using Components"
        }, 
        {
            "location": "/openapi/components/#component-discovery", 
            "text": "All controllers are can document components when they are linked to the entry point. Objects other than controllers will automatically document their components if they implement  APIComponentDocumenter   and  are declared properties of your  ApplicationChannel . (See  this guide  for other options.)  Built-in Aqueduct types will register any applicable components. This includes the types that handle OAuth2 as well as all  ManagedObject  subclasses in your application.", 
            "title": "Component Discovery"
        }, 
        {
            "location": "/openapi/endpoint/", 
            "text": "Documenting Endpoint Controllers\n\n\nIn this document, you'll learn how to document endpoint controllers.\n\n\nResourceController Auto-Documentation\n\n\nA \nResourceController\n does most of the heavy lifting when it comes to generating OpenAPI documents. It will reflect on the bound variables of operation methods and their documentation comments to provide the majority of an OpenAPI document. You only need to provide the possible responses. You do this by overriding \ndocumentOperationResponses\n in your \nResourceController\n subclass. The below shows a trivial example of a resource controller that returns a 200 OK with no body for every request.\n\n\nclass\n \nMyController\n \nextends\n \nResourceController\n \n{\n\n  \n...\n\n\n  \nMap\nString\n,\n \nAPIResponse\n \ndocumentOperationResponses\n(\nAPIDocumentContext\n \ncontext\n,\n \nOperation\n \noperation\n)\n \n{\n\n    \nreturn\n \n{\n200\n:\n \nAPIResponse\n(\nSuccessful response.\n)};\n\n  \n}\n\n\n}\n\n\n\n\n\n\nThis method must return a map, where each key is a string status code and each value is an \nAPIResponse\n object. An \nAPIResponse\n object is highly configurable, but in most cases, you only need to declare the schema of its body. For this purpose, a convenience constructor named \nAPIResponse.schema\n exists. Here is an example where the JSON response body contains a single integer field named 'id':\n\n\nMap\nString\n,\n \nAPIResponse\n \ndocumentOperationResponses\n(\nAPIDocumentContext\n \ncontext\n,\n \nOperation\n \noperation\n)\n \n{\n\n  \nreturn\n \n{\n\n    \n200\n:\n \nAPIResponse\n.\nschema\n(\nSuccessful response.\n,\n \nAPISchemaObject\n.\nobject\n({\n\n      \nid\n:\n \nAPISchemaObject\n.\ninteger\n()\n\n    \n}))\n\n  \n};\n\n\n}\n\n\n\n\n\n\nIn practice, you'll want to have different responses depending on the request method and path variables. The \noperation\n argument tells you which operation you are documenting.\n\n\nMap\nString\n,\n \nAPIResponse\n \ndocumentOperationResponses\n(\nAPIDocumentContext\n \ncontext\n,\n \nOperation\n \noperation\n)\n \n{\n\n  \nif\n \n(\noperation\n.\nmethod\n \n==\n \nGET\n)\n \n{\n\n    \nif\n \n(\noperation\n.\npathVariables\n.\ncontains\n(\nid\n))\n \n{\n\n      \nreturn\n \n{\n200\n:\n \nAPIResponse\n(\nAn object by its id.\n)};\n\n    \n}\n \nelse\n \n{\n\n      \nreturn\n \n{\n200\n:\n \nAPIResponse\n(\nAll objects.\n)};\n\n    \n}\n\n  \n}\n\n\n  \nreturn\n \nnull\n;\n\n\n}\n\n\n\n\n\n\nWhile a resource controller derives the rest of its documentation from your code, you may at times want to override this behavior. Individual elements may be modified by overriding methods like \ndocumentOperationParameters\n, or you may override \ndocumentOperations\n to take over the whole process.\n\n\nIf you are not using \nResourceController\n, you must override \ndocumentOperations\n in your controller and provide all of the operation information yourself.", 
            "title": "Documenting Endpoint Controllers"
        }, 
        {
            "location": "/openapi/endpoint/#documenting-endpoint-controllers", 
            "text": "In this document, you'll learn how to document endpoint controllers.", 
            "title": "Documenting Endpoint Controllers"
        }, 
        {
            "location": "/openapi/endpoint/#resourcecontroller-auto-documentation", 
            "text": "A  ResourceController  does most of the heavy lifting when it comes to generating OpenAPI documents. It will reflect on the bound variables of operation methods and their documentation comments to provide the majority of an OpenAPI document. You only need to provide the possible responses. You do this by overriding  documentOperationResponses  in your  ResourceController  subclass. The below shows a trivial example of a resource controller that returns a 200 OK with no body for every request.  class   MyController   extends   ResourceController   { \n   ... \n\n   Map String ,   APIResponse   documentOperationResponses ( APIDocumentContext   context ,   Operation   operation )   { \n     return   { 200 :   APIResponse ( Successful response. )}; \n   }  }   This method must return a map, where each key is a string status code and each value is an  APIResponse  object. An  APIResponse  object is highly configurable, but in most cases, you only need to declare the schema of its body. For this purpose, a convenience constructor named  APIResponse.schema  exists. Here is an example where the JSON response body contains a single integer field named 'id':  Map String ,   APIResponse   documentOperationResponses ( APIDocumentContext   context ,   Operation   operation )   { \n   return   { \n     200 :   APIResponse . schema ( Successful response. ,   APISchemaObject . object ({ \n       id :   APISchemaObject . integer () \n     })) \n   };  }   In practice, you'll want to have different responses depending on the request method and path variables. The  operation  argument tells you which operation you are documenting.  Map String ,   APIResponse   documentOperationResponses ( APIDocumentContext   context ,   Operation   operation )   { \n   if   ( operation . method   ==   GET )   { \n     if   ( operation . pathVariables . contains ( id ))   { \n       return   { 200 :   APIResponse ( An object by its id. )}; \n     }   else   { \n       return   { 200 :   APIResponse ( All objects. )}; \n     } \n   } \n\n   return   null ;  }   While a resource controller derives the rest of its documentation from your code, you may at times want to override this behavior. Individual elements may be modified by overriding methods like  documentOperationParameters , or you may override  documentOperations  to take over the whole process.  If you are not using  ResourceController , you must override  documentOperations  in your controller and provide all of the operation information yourself.", 
            "title": "ResourceController Auto-Documentation"
        }, 
        {
            "location": "/openapi/middleware/", 
            "text": "Documenting Middleware Controllers\n\n\nIn this document, you'll learn how to document middleware controllers.\n\n\nAdding to an Operation\n\n\nFor the purposes of documentation, a middleware controller does not create operation request and responses. Rather, it modifies the operation details provided by its endpoint controller. When writing middleware controllers, you must override \ndocumentOperations\n and call the superclass' implementation. This allows the middleware's linked controller to document its operations, which will eventually reach an endpoint controller.\n\n\nOnce the endpoint controller returns the meat of the operation document, a middleware controller can modify it. For example, a middleware that requires a query parameter named 'key' would like like so:\n\n\nclass\n \nMiddleware\n \nextends\n \nController\n \n{\n\n  \n...\n\n\n  \n@\noverride\n\n  \nMap\nString\n,\n \nAPIOperation\n \ndocumentOperations\n(\nAPIDocumentContext\n \ncontext\n,\n \nString\n \nroute\n,\n \nAPIPath\n \npath\n)\n \n{\n\n    \nfinal\n \nops\n \n=\n \nsuper\n.\ndocumentOperations\n(\ncontext\n,\n \nroute\n,\n \npath\n);\n\n\n    \n// ops has been filled out by an endpoint controller,\n\n    \n// add \nkey\n query parameter to each operation.\n\n    \nops\n.\nforEach\n((\nmethod\n,\n \nop\n)\n \n{\n\n      \nop\n.\naddParameter\n(\nAPIParameter\n.\nquery\n(\nkey\n,\n \nschema:\n \nAPISchemaObject\n.\nstring\n()));\n\n    \n});\n\n\n    \nreturn\n \nops\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nEach string key in an operations map is the lowercase name of an HTTP method, e.g. 'get' or 'post'. An \nAPIOperation\n encapsulates its request parameters and responses.", 
            "title": "Documenting Middleware Controllers"
        }, 
        {
            "location": "/openapi/middleware/#documenting-middleware-controllers", 
            "text": "In this document, you'll learn how to document middleware controllers.", 
            "title": "Documenting Middleware Controllers"
        }, 
        {
            "location": "/openapi/middleware/#adding-to-an-operation", 
            "text": "For the purposes of documentation, a middleware controller does not create operation request and responses. Rather, it modifies the operation details provided by its endpoint controller. When writing middleware controllers, you must override  documentOperations  and call the superclass' implementation. This allows the middleware's linked controller to document its operations, which will eventually reach an endpoint controller.  Once the endpoint controller returns the meat of the operation document, a middleware controller can modify it. For example, a middleware that requires a query parameter named 'key' would like like so:  class   Middleware   extends   Controller   { \n   ... \n\n   @ override \n   Map String ,   APIOperation   documentOperations ( APIDocumentContext   context ,   String   route ,   APIPath   path )   { \n     final   ops   =   super . documentOperations ( context ,   route ,   path ); \n\n     // ops has been filled out by an endpoint controller, \n     // add  key  query parameter to each operation. \n     ops . forEach (( method ,   op )   { \n       op . addParameter ( APIParameter . query ( key ,   schema:   APISchemaObject . string ())); \n     }); \n\n     return   ops ; \n   }  }   Each string key in an operations map is the lowercase name of an HTTP method, e.g. 'get' or 'post'. An  APIOperation  encapsulates its request parameters and responses.", 
            "title": "Adding to an Operation"
        }, 
        {
            "location": "/cli/", 
            "text": "Tasks\n\n\nThe Aqueduct command-line utility creates projects, runs applications, manages database schemas and other tasks.\n\n\nThis tool is installed through \npub\n:\n\n\npub global activate aqueduct\n\n\n\n\n\nThe above command updates the tool if a new version is available. You should ensure that \naqueduct\n and your application use the same version of Aqueduct.\n\n\nAll command-line tools have a \n--help\n option to show their options.\n\n\nGuides\n\n\n\n\nCreating Applications\n\n\nRunning Applications\n\n\nManaging a Database\n\n\nManaging OAuth 2.0 Clients and Scopes\n\n\nDocumenting an API\n\n\nProject Setup Utilities", 
            "title": "Overview"
        }, 
        {
            "location": "/cli/#tasks", 
            "text": "The Aqueduct command-line utility creates projects, runs applications, manages database schemas and other tasks.  This tool is installed through  pub :  pub global activate aqueduct  The above command updates the tool if a new version is available. You should ensure that  aqueduct  and your application use the same version of Aqueduct.  All command-line tools have a  --help  option to show their options.", 
            "title": "Tasks"
        }, 
        {
            "location": "/cli/#guides", 
            "text": "Creating Applications  Running Applications  Managing a Database  Managing OAuth 2.0 Clients and Scopes  Documenting an API  Project Setup Utilities", 
            "title": "Guides"
        }, 
        {
            "location": "/cli/create/", 
            "text": "Creating Aqueduct Applications\n\n\nThe \naqueduct create\n command-line tool creates applications from a template. The usage is:\n\n\naqueduct create app_name\n\n\n\n\n\nThe application name must be snake_case - all lower case, no spaces, no symbols other than \n_\n.\n\n\nBy default, a generated project is fairly empty - it has the minimal content, but the structure of a complete application. For applications that use Aqueduct's ORM or OAuth 2.0 behavior, extended templates exist. These can be listed with the following:\n\n\naqueduct create list-templates\n\n\n\n\n\nTo pick a template, add the \n-t\n option to \naqueduct create\n. For example, the following uses the \ndb\n template:\n\n\naqueduct create -t db app_name\n\n\n\n\n\nThe templates are located in the Aqueduct package under \nexamples/templates\n. When creating a new project from a template, the tool copies the contents of one of the template directories into your current working directory and substitutes some names with your project name.", 
            "title": "Creating Applications"
        }, 
        {
            "location": "/cli/create/#creating-aqueduct-applications", 
            "text": "The  aqueduct create  command-line tool creates applications from a template. The usage is:  aqueduct create app_name  The application name must be snake_case - all lower case, no spaces, no symbols other than  _ .  By default, a generated project is fairly empty - it has the minimal content, but the structure of a complete application. For applications that use Aqueduct's ORM or OAuth 2.0 behavior, extended templates exist. These can be listed with the following:  aqueduct create list-templates  To pick a template, add the  -t  option to  aqueduct create . For example, the following uses the  db  template:  aqueduct create -t db app_name  The templates are located in the Aqueduct package under  examples/templates . When creating a new project from a template, the tool copies the contents of one of the template directories into your current working directory and substitutes some names with your project name.", 
            "title": "Creating Aqueduct Applications"
        }, 
        {
            "location": "/cli/running/", 
            "text": "Running Applications with Aqueduct Serve\n\n\nThe \naqueduct serve\n command-line tool runs applications. This tool is run in a project directory and it generates a Dart script that bootstraps your application.\n\n\nThe structure of the project does matter - if you are creating a project from the template, the appropriate structure already exists. Otherwise, you must ensure you have a library file with the same name as your application (as defined in \npubspec.yaml\n). For example, an application named \ntodo\n must have a \nlib/todo.dart\n file. This file must import the file that declares your application's \nApplicationChannel\n.\n\n\nYou may specify options like the number of isolates to run the application on and which port to listen for requests on. See more details with \naqueduct serve --help\n.", 
            "title": "Running Applications"
        }, 
        {
            "location": "/cli/running/#running-applications-with-aqueduct-serve", 
            "text": "The  aqueduct serve  command-line tool runs applications. This tool is run in a project directory and it generates a Dart script that bootstraps your application.  The structure of the project does matter - if you are creating a project from the template, the appropriate structure already exists. Otherwise, you must ensure you have a library file with the same name as your application (as defined in  pubspec.yaml ). For example, an application named  todo  must have a  lib/todo.dart  file. This file must import the file that declares your application's  ApplicationChannel .  You may specify options like the number of isolates to run the application on and which port to listen for requests on. See more details with  aqueduct serve --help .", 
            "title": "Running Applications with Aqueduct Serve"
        }, 
        {
            "location": "/cli/document/", 
            "text": "Documenting Aqueduct Applications\n\n\nThe \naqueduct document\n tool generates an OpenAPI (formerly Swagger) specification by reflecting on your application's code. This command is run in a project directory and will emit the JSON specification to stdout. You can redirect this to a file:\n\n\naqueduct document \n swagger.json\n\n\n\n\n\nThe file \nconfig.src.yaml\n must exist in your project directory so that the application can be initialized in 'test' mode for the documentation to be generated.", 
            "title": "Generating an OpenAPI/Swagger Specification"
        }, 
        {
            "location": "/cli/document/#documenting-aqueduct-applications", 
            "text": "The  aqueduct document  tool generates an OpenAPI (formerly Swagger) specification by reflecting on your application's code. This command is run in a project directory and will emit the JSON specification to stdout. You can redirect this to a file:  aqueduct document   swagger.json  The file  config.src.yaml  must exist in your project directory so that the application can be initialized in 'test' mode for the documentation to be generated.", 
            "title": "Documenting Aqueduct Applications"
        }, 
        {
            "location": "/cli/setup/", 
            "text": "The Aqueduct Setup Tool\n\n\nThe \naqueduct setup\n tool is used for two tasks:\n\n\n\n\nCreating a local test database\n\n\nModifying a project so that it can be deployed to Heroku.\n\n\n\n\nDuring the initial setup of a development machine, after PostgreSQL has been installed locally, the following command creates a local database specifically for testing.\n\n\naqueduct setup\n\n\n\n\n\nThis creates a database user named \ndart\n with password \ndart\n and creates a database \ndart_test\n that \ndart\n has access to on the local machine.\n\n\nFor using \naqueduct setup\n to deploy Heroku applications, see \nthis guide\n.", 
            "title": "Other Tools"
        }, 
        {
            "location": "/cli/setup/#the-aqueduct-setup-tool", 
            "text": "The  aqueduct setup  tool is used for two tasks:   Creating a local test database  Modifying a project so that it can be deployed to Heroku.   During the initial setup of a development machine, after PostgreSQL has been installed locally, the following command creates a local database specifically for testing.  aqueduct setup  This creates a database user named  dart  with password  dart  and creates a database  dart_test  that  dart  has access to on the local machine.  For using  aqueduct setup  to deploy Heroku applications, see  this guide .", 
            "title": "The Aqueduct Setup Tool"
        }
    ]
}